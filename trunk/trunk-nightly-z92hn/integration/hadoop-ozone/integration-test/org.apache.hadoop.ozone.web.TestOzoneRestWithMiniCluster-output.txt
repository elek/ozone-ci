2019-07-13 17:15:42,139 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:42,228 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:42,231 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:42,248 INFO  util.log (Log.java:initialized(192)) - Logging initialized @845ms
2019-07-13 17:15:42,350 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-07-13 17:15:42,350 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-07-13 17:15:42,351 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-07-13 17:15:42,351 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-07-13 17:15:42,351 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-07-13 17:15:42,351 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-07-13 17:15:42,363 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-07-13 17:15:42,364 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-07-13 17:15:42,365 INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-07-13 17:15:42,476 INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@56620197
2019-07-13 17:15:42,478 INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-07-13 17:15:42,556 WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-07-13 17:15:42,558 WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-07-13 17:15:42,560 INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(119)) - Entering startup safe mode.
2019-07-13 17:15:42,643 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:42,673 INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-07-13 17:15:42,675 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:42,815 WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-07-13 17:15:43,149 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-13 17:15:43,176 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44464
2019-07-13 17:15:43,199 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-13 17:15:43,200 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38879
2019-07-13 17:15:43,207 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-13 17:15:43,208 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36704
2019-07-13 17:15:43,333 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-07-13 17:15:43,493 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-07-13 17:15:43,501 WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-07-13 17:15:43,508 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-07-13 17:15:43,511 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-07-13 17:15:43,511 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-07-13 17:15:43,511 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-07-13 17:15:43,538 INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36704
2019-07-13 17:15:43,595 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-07-13 17:15:43,607 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-07-13 17:15:43,608 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-07-13 17:15:43,819 INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(149)) - RPC server for Client  is listening at /0.0.0.0:36704
2019-07-13 17:15:43,820 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-13 17:15:43,820 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36704: starting
2019-07-13 17:15:43,824 INFO  server.StorageContainerManager (StorageContainerManager.java:start(768)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38879
2019-07-13 17:15:43,824 INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:38879
2019-07-13 17:15:43,825 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-13 17:15:43,825 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38879: starting
2019-07-13 17:15:43,833 INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:44464
2019-07-13 17:15:43,834 INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:44464
2019-07-13 17:15:43,836 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-13 17:15:43,837 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44464: starting
2019-07-13 17:15:43,847 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34319
2019-07-13 17:15:43,849 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-13 17:15:43,889 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3212a8d7{/logs,file:///tmp/workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-07-13 17:15:43,890 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@495b0487{/static,file:///tmp/workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-07-13 17:15:43,921 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@591e58fa{/,file:///tmp/workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-07-13 17:15:43,926 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:34319}
2019-07-13 17:15:43,927 INFO  server.Server (Server.java:doStart(419)) - Started @2524ms
2019-07-13 17:15:43,928 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of SCM is listening at http://0.0.0.0:34319
2019-07-13 17:15:43,934 INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-07-13 17:15:43,936 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:44,077 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:44,078 INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(630)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-07-13 17:15:44,078 INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(636)) - OM Node ID is not set. Setting it to the OmStorage's OmID: ea7a15e4-6392-4ba0-a36d-432d6cbb8d9e
2019-07-13 17:15:44,079 INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(587)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-07-13 17:15:44,346 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:44,358 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-07-13 17:15:44,358 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-07-13 17:15:44,359 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-07-13 17:15:44,359 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-07-13 17:15:44,360 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-07-13 17:15:44,360 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-07-13 17:15:44,361 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-07-13 17:15:44,361 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-07-13 17:15:44,361 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-07-13 17:15:44,362 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-07-13 17:15:44,362 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-07-13 17:15:44,362 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-07-13 17:15:44,363 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-07-13 17:15:44,363 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-07-13 17:15:44,363 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-07-13 17:15:44,364 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-07-13 17:15:44,364 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-07-13 17:15:44,364 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-07-13 17:15:44,365 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-07-13 17:15:44,365 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-07-13 17:15:44,366 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-07-13 17:15:44,366 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-07-13 17:15:44,366 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-07-13 17:15:44,367 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-07-13 17:15:44,367 INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-07-13 17:15:45,196 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-13 17:15:45,197 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35154
2019-07-13 17:15:45,225 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-13 17:15:45,225 INFO  om.OzoneManager (OzoneManager.java:start(1228)) - OzoneManager RPC server is listening at localhost/127.0.0.1:35154
2019-07-13 17:15:45,226 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-07-13 17:15:45,227 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-13 17:15:45,227 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35154: starting
2019-07-13 17:15:45,242 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-07-13 17:15:45,243 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-07-13 17:15:45,244 WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-07-13 17:15:45,246 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-07-13 17:15:45,247 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-07-13 17:15:45,247 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-07-13 17:15:45,248 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-07-13 17:15:45,250 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45293
2019-07-13 17:15:45,250 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-13 17:15:45,252 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac97b84{/logs,file:///tmp/workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-07-13 17:15:45,252 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35c09b94{/static,file:///tmp/workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-07-13 17:15:45,257 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1b9c1b51{/,file:///tmp/workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-07-13 17:15:45,257 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e52fb3e{HTTP/1.1,[http/1.1]}{0.0.0.0:45293}
2019-07-13 17:15:45,258 INFO  server.Server (Server.java:doStart(419)) - Started @3855ms
2019-07-13 17:15:45,259 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:45293
2019-07-13 17:15:45,562 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-07-13 17:15:45,650 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:trunk-nightly-z92hn-1831959607 ip:192.168.5.187
2019-07-13 17:15:45,696 INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 52710309888
2019-07-13 17:15:45,699 INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/containers/hdds to VolumeSet
2019-07-13 17:15:45,703 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2e34384c
2019-07-13 17:15:45,728 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2e34384c
2019-07-13 17:15:45,855 INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-07-13 17:15:45,920 INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-07-13 17:15:45,924 INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-07-13 17:15:45,925 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-07-13 17:15:45,927 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-07-13 17:15:45,927 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-07-13 17:15:45,928 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-07-13 17:15:46,091 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis] (custom)
2019-07-13 17:15:46,128 INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-07-13 17:15:46,143 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-07-13 17:15:46,146 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-07-13 17:15:46,147 WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-07-13 17:15:46,150 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-07-13 17:15:46,151 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-07-13 17:15:46,151 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-07-13 17:15:46,151 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-07-13 17:15:46,153 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37918
2019-07-13 17:15:46,153 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-13 17:15:46,155 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15383681{/logs,file:///tmp/workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-07-13 17:15:46,156 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@109a2025{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-07-13 17:15:46,202 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a04fea7{/,file:///tmp/jetty-0.0.0.0-37918-hddsDatanode-_-any-5793804610892288377.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-07-13 17:15:46,203 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1bc49bc5{HTTP/1.1,[http/1.1]}{0.0.0.0:37918}
2019-07-13 17:15:46,203 INFO  server.Server (Server.java:doStart(419)) - Started @4800ms
2019-07-13 17:15:46,205 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37918
Jul 13, 2019 5:15:46 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-07-13 17:15:47,349 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@5921b93c
2019-07-13 17:15:47,351 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-13 17:15:47,357 INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-07-13 17:15:47,477 INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/meta/datanode.id
2019-07-13 17:15:48,351 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-13 17:15:49,352 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-13 17:15:49,420 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-07-13 17:15:49,422 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-07-13 17:15:49,422 INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis ad43cb04-7168-4c18-93b2-77c6bd345d79 at port 0
2019-07-13 17:15:49,448 INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: start RPC server
2019-07-13 17:15:49,574 INFO  server.GrpcService (GrpcService.java:startImpl(149)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: GrpcService started, listening on 0.0.0.0/0.0.0.0:37623
2019-07-13 17:15:49,575 INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis ad43cb04-7168-4c18-93b2-77c6bd345d79 is started using port 37623
2019-07-13 17:15:49,578 INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(161)) - XceiverServerGrpc ad43cb04-7168-4c18-93b2-77c6bd345d79 is started using port 45782
2019-07-13 17:15:50,353 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-13 17:15:51,353 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-13 17:15:51,404 INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/192.168.5.187
2019-07-13 17:15:51,405 INFO  node.SCMNodeManager (SCMNodeManager.java:register(269)) - Registered Data node : ad43cb04-7168-4c18-93b2-77c6bd345d79{ip: 192.168.5.187, host: trunk-nightly-z92hn-1831959607, networkLocation: /default-rack, certSerialId: null}
2019-07-13 17:15:51,410 INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-07-13 17:15:51,410 INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-07-13 17:15:51,410 INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-07-13 17:15:51,934 INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: addNew group-54B283A67EEF:[ad43cb04-7168-4c18-93b2-77c6bd345d79:192.168.5.187:37623] returns group-54B283A67EEF:java.util.concurrent.CompletableFuture@36ed8850[Not completed]
2019-07-13 17:15:51,954 INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: new RaftServerImpl for group-54B283A67EEF:[ad43cb04-7168-4c18-93b2-77c6bd345d79:192.168.5.187:37623] with ContainerStateMachine:uninitialized
2019-07-13 17:15:51,958 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-07-13 17:15:51,958 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-07-13 17:15:51,959 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-07-13 17:15:51,960 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-07-13 17:15:51,961 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-07-13 17:15:51,971 INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF ConfigurationManager, init=-1: [ad43cb04-7168-4c18-93b2-77c6bd345d79:192.168.5.187:37623], old=null, confs=<EMPTY_MAP>
2019-07-13 17:15:51,972 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis] (custom)
2019-07-13 17:15:51,981 INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef does not exist. Creating ...
2019-07-13 17:15:52,010 INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef/in_use.lock acquired by nodename 31241@trunk-nightly-z92hn-1831959607
2019-07-13 17:15:52,025 INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef has been successfully formatted.
2019-07-13 17:15:52,027 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(200)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-07-13 17:15:52,028 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-07-13 17:15:52,031 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-07-13 17:15:52,038 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000000 (custom)
2019-07-13 17:15:52,038 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-07-13 17:15:52,040 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-07-13 17:15:52,372 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-07-13 17:15:52,378 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-07-13 17:15:52,388 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new ad43cb04-7168-4c18-93b2-77c6bd345d79-SegmentedRaftLogWorker:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef for RaftStorage:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef
2019-07-13 17:15:52,415 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-07-13 17:15:52,415 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-07-13 17:15:52,422 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-07-13 17:15:52,422 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-07-13 17:15:52,423 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-07-13 17:15:52,424 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-07-13 17:15:52,425 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-07-13 17:15:52,425 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-07-13 17:15:52,426 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-07-13 17:15:52,443 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-07-13 17:15:52,450 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - ad43cb04-7168-4c18-93b2-77c6bd345d79-SegmentedRaftLogWorker:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef: flushIndex: setUnconditionally 0 -> -1
2019-07-13 17:15:52,457 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-07-13 17:15:52,458 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-07-13 17:15:52,458 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-07-13 17:15:52,487 INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: start group-54B283A67EEF
2019-07-13 17:15:52,488 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF changes role from null to FOLLOWER at term 0 for startAsFollower
2019-07-13 17:15:52,490 INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: start FollowerState
2019-07-13 17:15:52,492 INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-54B283A67EEF,id=ad43cb04-7168-4c18-93b2-77c6bd345d79
2019-07-13 17:15:52,556 INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9f9b2d3f-bc42-41c3-a286-54b283a67eef, Nodes: ad43cb04-7168-4c18-93b2-77c6bd345d79{ip: 192.168.5.187, host: trunk-nightly-z92hn-1831959607, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-07-13 17:15:52,719 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumefqjbs, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:15:52,782 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumefqjbs/bucketbhhfm, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-13 17:15:53,123 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=1, FAILED org.apache.ratis.protocol.NotLeaderException: Server ad43cb04-7168-4c18-93b2-77c6bd345d79 is not the leader (null). Request must be sent to leader., logIndex=0, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c-1]
2019-07-13 17:15:54,413 INFO  container.ReplicationManager (ReplicationManager.java:start(155)) - Starting Replication Monitor Thread.
2019-07-13 17:15:54,418 INFO  container.ReplicationManager (ReplicationManager.java:run(207)) - Replication Monitor Thread took 5 milliseconds for processing 1 containers.
2019-07-13 17:15:55,177 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=1, FAILED org.apache.ratis.protocol.NotLeaderException: Server ad43cb04-7168-4c18-93b2-77c6bd345d79 is not the leader (null). Request must be sent to leader., logIndex=0, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c-1]
2019-07-13 17:15:57,218 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=1, FAILED org.apache.ratis.protocol.NotLeaderException: Server ad43cb04-7168-4c18-93b2-77c6bd345d79 is not the leader (null). Request must be sent to leader., logIndex=0, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c-1]
2019-07-13 17:15:57,677 INFO  impl.FollowerState (FollowerState.java:run(106)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF changes to CANDIDATE, lastRpcTime:5187, electionTimeout:5186ms
2019-07-13 17:15:57,677 INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: shutdown FollowerState
2019-07-13 17:15:57,678 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-07-13 17:15:57,683 INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: start LeaderElection
2019-07-13 17:15:57,712 INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF:LeaderElection1: begin an election at term 1 for -1: [ad43cb04-7168-4c18-93b2-77c6bd345d79:192.168.5.187:37623], old=null
2019-07-13 17:15:57,714 INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: shutdown LeaderElection
2019-07-13 17:15:57,714 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-07-13 17:15:57,715 INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF change Leader from null to ad43cb04-7168-4c18-93b2-77c6bd345d79 at term 1 for becomeLeader, leader elected after 5686ms
2019-07-13 17:15:57,722 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-07-13 17:15:57,722 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-07-13 17:15:57,726 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-07-13 17:15:57,729 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-07-13 17:15:57,729 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-07-13 17:15:57,731 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-07-13 17:15:57,741 INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: start LeaderState
2019-07-13 17:15:57,765 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - ad43cb04-7168-4c18-93b2-77c6bd345d79-SegmentedRaftLogWorker:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef: Starting segment from index:0
2019-07-13 17:15:57,775 INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF set configuration 0: [ad43cb04-7168-4c18-93b2-77c6bd345d79:192.168.5.187:37623], old=null at 0
2019-07-13 17:15:57,965 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - ad43cb04-7168-4c18-93b2-77c6bd345d79-SegmentedRaftLogWorker:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef: created new log segment /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef/current/log_inprogress_0
2019-07-13 17:15:59,438 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=1, SUCCESS, logIndex=1, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c2]
2019-07-13 17:15:59,543 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=2, SUCCESS, logIndex=3, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c7]
2019-07-13 17:15:59,549 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=3, SUCCESS, logIndex=5, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c7]
2019-07-13 17:15:59,550 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=4, SUCCESS, logIndex=6, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c7]
2019-07-13 17:15:59,591 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=5, SUCCESS, logIndex=8, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c9]
2019-07-13 17:15:59,595 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=6, SUCCESS, logIndex=9, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c9]
2019-07-13 17:15:59,657 INFO  pipeline.Pipeline (Pipeline.java:getProtobufMessage(195)) - Serialize pipeline PipelineID=9f9b2d3f-bc42-41c3-a286-54b283a67eef with nodesInOrder{ }
2019-07-13 17:15:59,659 INFO  pipeline.Pipeline (Pipeline.java:build(342)) - Deserialize nodesInOrder [ad43cb04-7168-4c18-93b2-77c6bd345d79{ip: 192.168.5.187, host: trunk-nightly-z92hn-1831959607, networkLocation: /default-rack, certSerialId: null}] in pipeline PipelineID=9f9b2d3f-bc42-41c3-a286-54b283a67eef
2019-07-13 17:15:59,977 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: 78abbf22d9e2b884:78abbf22d9e2b884:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
2019-07-13 17:15:59,980 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: a4b793a96c418e3e:a4b793a96c418e3e:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
17:15:59.979 [pool-26-thread-4] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268850876419 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
17:15:59.979 [pool-26-thread-5] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268850876419 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:15:59,993 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 78abbf22d9e2b884:78abbf22d9e2b884:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
2019-07-13 17:15:59,993 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: a4b793a96c418e3e:a4b793a96c418e3e:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
17:16:00.007 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268850876419 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,007 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 78abbf22d9e2b884:78abbf22d9e2b884:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
17:16:00.008 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102435268850876419 bcsId: 0,size=1048576]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,009 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: 16d856d8c7f238d6:16d856d8c7f238d6:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
17:16:00.011 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268850876419 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,012 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: a4b793a96c418e3e:a4b793a96c418e3e:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-13 17:16:00,012 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=7, SUCCESS, logIndex=11, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c14]
17:16:00.013 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102435268850876419 bcsId: 0,size=1572864]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,014 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: e52919b3d16d2893:e52919b3d16d2893:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-13 17:16:00,015 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=8, SUCCESS, logIndex=12, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c14]
2019-07-13 17:16:00,015 ERROR storage.BlockOutputStream (BlockOutputStream.java:validateResponse(539)) - Unexpected Storage Container Exception: 
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.validateContainerResponse(ContainerProtocolCalls.java:536)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.validateResponse(BlockOutputStream.java:537)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.lambda$writeChunkToContainer$2(BlockOutputStream.java:615)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-13 17:16:00,016 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=9, SUCCESS, logIndex=13, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c14]
2019-07-13 17:16:00,019 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=10, SUCCESS, logIndex=14, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c14]
2019-07-13 17:16:00,034 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumedryae, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:16:00,041 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumedryae/bucketwxsdn, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-13 17:16:00,057 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volume88i5r, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:16:00,063 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volume88i5r/bucketdtiap, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-13 17:16:00,089 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: efe8957c47efcdcf:efe8957c47efcdcf:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
17:16:00.089 [pool-26-thread-6] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102435268859068422 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,090 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: efe8957c47efcdcf:efe8957c47efcdcf:0:0 : Message: ContainerID 3 creation failed : Result: DISK_OUT_OF_SPACE
17:16:00.101 [pool-30-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102435268859068422 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,102 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: efe8957c47efcdcf:efe8957c47efcdcf:0:0 : Message: ContainerID 3 does not exist : Result: CONTAINER_NOT_FOUND
17:16:00.103 [pool-30-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102435268859068422 bcsId: 0,size=9]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,104 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: a0b18c43ca010e1c:a0b18c43ca010e1c:0:0 : Message: ContainerID 3 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-13 17:16:00,104 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=11, SUCCESS, logIndex=16, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c17]
2019-07-13 17:16:00,106 ERROR storage.BlockOutputStream (BlockOutputStream.java:validateResponse(539)) - Unexpected Storage Container Exception: 
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 does not exist
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.validateContainerResponse(ContainerProtocolCalls.java:536)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.validateResponse(BlockOutputStream.java:537)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.lambda$writeChunkToContainer$2(BlockOutputStream.java:615)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-13 17:16:00,107 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=12, SUCCESS, logIndex=17, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c17]
2019-07-13 17:16:00,111 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumefrkw7, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:16:00,115 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumefrkw7/bucketwbgrd, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-13 17:16:00,120 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volume9jvgi, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:16:00,165 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumelwsjf, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:16:00,169 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumelwsjf/bucketfomuu, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-13 17:16:00,219 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=13, SUCCESS, logIndex=19, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c20]
2019-07-13 17:16:00,221 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=14, SUCCESS, logIndex=20, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c20]
2019-07-13 17:16:00,223 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=15, SUCCESS, logIndex=21, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c23]
2019-07-13 17:16:00,225 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=16, SUCCESS, logIndex=23, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c23]
2019-07-13 17:16:00,255 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=17, SUCCESS, logIndex=25, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c26]
2019-07-13 17:16:00,256 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=18, SUCCESS, logIndex=26, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c27]
2019-07-13 17:16:00,274 INFO  pipeline.Pipeline (Pipeline.java:getProtobufMessage(195)) - Serialize pipeline PipelineID=9f9b2d3f-bc42-41c3-a286-54b283a67eef with nodesInOrder{ }
2019-07-13 17:16:00,275 INFO  pipeline.Pipeline (Pipeline.java:build(342)) - Deserialize nodesInOrder [ad43cb04-7168-4c18-93b2-77c6bd345d79{ip: 192.168.5.187, host: trunk-nightly-z92hn-1831959607, networkLocation: /default-rack, certSerialId: null}] in pipeline PipelineID=9f9b2d3f-bc42-41c3-a286-54b283a67eef
2019-07-13 17:16:00,460 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volume8871r, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-13 17:16:00,465 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volume8871r/bucket0ftfh, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-13 17:16:00,499 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: 2036aca1a8e3e3c3:2036aca1a8e3e3c3:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
17:16:00.500 [pool-26-thread-10] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268885413898 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,500 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 2036aca1a8e3e3c3:2036aca1a8e3e3c3:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
17:16:00.504 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268885413898 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,505 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 2036aca1a8e3e3c3:2036aca1a8e3e3c3:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-13 17:16:00,506 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: 7cb1908eb3e4553f:7cb1908eb3e4553f:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
17:16:00.506 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102435268885413898 bcsId: 0,size=1048576]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
17:16:00.506 [pool-26-thread-11] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268885413898 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,507 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: 2964ad24c12747ea:2964ad24c12747ea:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-13 17:16:00,507 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 7cb1908eb3e4553f:7cb1908eb3e4553f:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
2019-07-13 17:16:00,509 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=19, SUCCESS, logIndex=28, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c29]
2019-07-13 17:16:00,511 ERROR storage.BlockOutputStream (BlockOutputStream.java:validateResponse(539)) - Unexpected Storage Container Exception: 
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.validateContainerResponse(ContainerProtocolCalls.java:536)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.validateResponse(BlockOutputStream.java:537)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.lambda$writeChunkToContainer$2(BlockOutputStream.java:615)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-13 17:16:00,511 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=20, SUCCESS, logIndex=29, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c30]
17:16:00.511 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102435268885413898 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,512 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 7cb1908eb3e4553f:7cb1908eb3e4553f:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
17:16:00.513 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102435268885413898 bcsId: 0,size=2097152]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-13 17:16:00,514 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: e29bcc80bbb509f8:e29bcc80bbb509f8:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-13 17:16:00,514 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=21, SUCCESS, logIndex=31, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c32]
2019-07-13 17:16:00,516 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79: receive RaftClientReply:client-4C8693750A95->ad43cb04-7168-4c18-93b2-77c6bd345d79@group-54B283A67EEF, cid=22, SUCCESS, logIndex=32, commits[ad43cb04-7168-4c18-93b2-77c6bd345d79:c33]
2019-07-13 17:16:00,519 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-07-13 17:16:00,520 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-07-13 17:16:00,520 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-07-13 17:16:00,520 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35154
2019-07-13 17:16:00,522 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35154
2019-07-13 17:16:00,522 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-07-13 17:16:00,522 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-13 17:16:00,538 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1b9c1b51{/,null,UNAVAILABLE}{/ozoneManager}
2019-07-13 17:16:00,545 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e52fb3e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-07-13 17:16:00,545 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35c09b94{/static,file:///tmp/workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-07-13 17:16:00,546 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac97b84{/logs,file:///tmp/workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-07-13 17:16:00,551 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-07-13 17:16:00,552 INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-07-13 17:16:00,554 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@5921b93c
2019-07-13 17:16:01,380 INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-07-13 17:16:05,556 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-07-13 17:16:05,558 INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: close
2019-07-13 17:16:05,560 INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: shutdown group-54B283A67EEF
2019-07-13 17:16:05,561 INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-54B283A67EEF,id=ad43cb04-7168-4c18-93b2-77c6bd345d79
2019-07-13 17:16:05,562 INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: shutdown LeaderState
2019-07-13 17:16:05,563 INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - ad43cb04-7168-4c18-93b2-77c6bd345d79-PendingRequests: sendNotLeaderResponses
2019-07-13 17:16:05,572 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF: set stopIndex = 33
2019-07-13 17:16:05,572 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(246)) - Taking snapshot at termIndex:(t:1, i:33)
2019-07-13 17:16:05,574 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(250)) - Taking a snapshot to file /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef/sm/snapshot.1_33
2019-07-13 17:16:05,581 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF: Took a snapshot at index 33
2019-07-13 17:16:05,582 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF: snapshotIndex: updateIncreasingly -1 -> 33
2019-07-13 17:16:05,586 INFO  impl.RaftServerImpl (ServerState.java:close(394)) - ad43cb04-7168-4c18-93b2-77c6bd345d79:group-54B283A67EEF closes. The last applied log index is 33
2019-07-13 17:16:05,591 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - ad43cb04-7168-4c18-93b2-77c6bd345d79-SegmentedRaftLogWorker:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-07-13 17:16:05,593 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - ad43cb04-7168-4c18-93b2-77c6bd345d79-SegmentedRaftLogWorker:Storage Directory /tmp/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-03ac0276-62aa-4b4f-9bc8-9f086092bde3/datanode-0/data/ratis/9f9b2d3f-bc42-41c3-a286-54b283a67eef close()
2019-07-13 17:16:05,595 INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: shutdown server with port 37623 now
2019-07-13 17:16:05,598 INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - ad43cb04-7168-4c18-93b2-77c6bd345d79: shutdown server with port 37623 successfully
2019-07-13 17:16:05,609 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-07-13 17:16:05,611 WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-07-13 17:16:05,632 INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-07-13 17:16:05,634 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a04fea7{/,null,UNAVAILABLE}{/hddsDatanode}
2019-07-13 17:16:05,636 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1bc49bc5{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-07-13 17:16:05,636 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@109a2025{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-07-13 17:16:05,637 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15383681{/logs,file:///tmp/workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-07-13 17:16:05,640 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-07-13 17:16:05,640 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(796)) - Stopping Replication Manager Service.
2019-07-13 17:16:05,641 INFO  container.ReplicationManager (ReplicationManager.java:stop(187)) - Stopping Replication Monitor Thread.
2019-07-13 17:16:05,641 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(803)) - Stopping Lease Manager of the command watchers
2019-07-13 17:16:05,641 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(810)) - Stopping datanode service RPC server
2019-07-13 17:16:05,642 INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(375)) - Stopping the RPC server for DataNodes
2019-07-13 17:16:05,642 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44464
2019-07-13 17:16:05,643 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44464
2019-07-13 17:16:05,644 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-13 17:16:05,703 WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(631)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-07-13 17:16:05,703 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(818)) - Stopping block service RPC server
2019-07-13 17:16:05,703 INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-07-13 17:16:05,704 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38879
2019-07-13 17:16:05,704 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(825)) - Stopping the StorageContainerLocationProtocol RPC server
2019-07-13 17:16:05,705 INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(157)) - Stopping the RPC server for Client Protocol
2019-07-13 17:16:05,705 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36704
2019-07-13 17:16:05,705 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36704
2019-07-13 17:16:05,705 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(832)) - Stopping Storage Container Manager HTTP server.
2019-07-13 17:16:05,706 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@591e58fa{/,null,UNAVAILABLE}{/scm}
2019-07-13 17:16:05,707 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-13 17:16:05,707 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38879
2019-07-13 17:16:05,709 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-13 17:16:05,710 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-07-13 17:16:05,710 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@495b0487{/static,file:///tmp/workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-07-13 17:16:05,711 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3212a8d7{/logs,file:///tmp/workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-07-13 17:16:05,714 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(843)) - Stopping Block Manager Service.
2019-07-13 17:16:05,714 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-07-13 17:16:05,715 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-07-13 17:16:05,715 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(865)) - Stopping SCM Event Queue.
2019-07-13 17:16:05,722 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-07-13 17:16:05,724 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.

2019-09-09 22:25:58,129 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:00,499 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:00,504 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:00,524 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3153ms
2019-09-09 22:26:00,632 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-09 22:26:00,632 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-09 22:26:00,632 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-09 22:26:00,633 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-09 22:26:00,633 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-09 22:26:00,633 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-09 22:26:00,646 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-09 22:26:00,647 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-09 22:26:00,648 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-09 22:26:17,989 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@295e37d5
2019-09-09 22:26:17,991 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-09 22:26:18,060 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-09 22:26:18,061 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-09 22:26:18,064 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-09 22:26:18,134 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(55)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-09 22:26:18,148 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:26,091 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(128)) - No pipeline exists in current db
2019-09-09 22:26:26,094 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:28,510 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:32,022 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:32,023 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:26:32,024 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-09 22:26:32,024 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-09 22:26:32,024 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-09 22:26:32,024 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-09 22:26:32,025 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-09 22:26:32,025 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-09 22:26:32,025 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-09 22:26:32,026 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-09 22:26:32,026 [Thread-3] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-09 22:26:47,237 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
FATAL StatusLogger Interrupted before Log4j Providers could be loaded.
 java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1220)
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335)
	at org.apache.logging.log4j.util.ProviderUtil.lazyInit(ProviderUtil.java:143)
	at org.apache.logging.log4j.util.ProviderUtil.hasProviders(ProviderUtil.java:130)
	at org.apache.logging.log4j.LogManager.<clinit>(LogManager.java:89)
	at org.apache.hadoop.ozone.audit.AuditLogger.initializeLogger(AuditLogger.java:50)
	at org.apache.hadoop.ozone.audit.AuditLogger.<init>(AuditLogger.java:42)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.<clinit>(SCMDatanodeProtocolServer.java:129)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.<init>(StorageContainerManager.java:323)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.<init>(StorageContainerManager.java:209)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.createSCM(StorageContainerManager.java:593)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createSCM(MiniOzoneClusterImpl.java:476)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:405)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testStartMultipleDatanodes(TestMiniOzoneCluster.java:97)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...
2019-09-09 22:26:47,401 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-09 22:26:47,433 [Socket Reader #1 for port 38850] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38850
2019-09-09 22:26:47,463 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-09 22:26:47,464 [Socket Reader #1 for port 36617] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36617
2019-09-09 22:26:47,473 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-09 22:26:47,474 [Socket Reader #1 for port 38453] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38453
2019-09-09 22:26:47,510 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-09 22:26:47,676 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-09 22:26:47,685 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-09 22:26:47,694 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-09 22:26:47,699 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-09 22:26:47,699 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-09 22:26:47,700 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-09 22:26:47,883 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:38453
2019-09-09 22:26:47,962 [Thread-0] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-09 22:26:47,975 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-09 22:26:47,975 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-09 22:26:48,261 [Thread-0] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:38453
2019-09-09 22:26:48,262 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-09 22:26:48,262 [IPC Server listener on 38453] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38453: starting
2019-09-09 22:26:48,266 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:36617
2019-09-09 22:26:48,268 [Thread-0] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:36617
2019-09-09 22:26:48,268 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-09 22:26:48,268 [IPC Server listener on 36617] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36617: starting
2019-09-09 22:26:48,273 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:38850
2019-09-09 22:26:48,273 [Thread-0] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:38850
2019-09-09 22:26:48,274 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-09 22:26:48,274 [IPC Server listener on 38850] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38850: starting
2019-09-09 22:26:48,279 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42022
2019-09-09 22:26:48,281 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-09 22:26:48,325 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48da115{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-09 22:26:48,325 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ba99dc2{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-09 22:26:48,361 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f7c76d3{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-09 22:26:48,367 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@43956fbe{HTTP/1.1,[http/1.1]}{0.0.0.0:42022}
2019-09-09 22:26:48,367 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @50997ms
2019-09-09 22:26:48,370 [Thread-0] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-09 22:26:48,370 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-09 22:26:48,371 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:42022
2019-09-09 22:26:48,382 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3bbf986b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-09 22:26:48,388 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:27:00,556 [Thread-3] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3f6a158c
2019-09-09 22:27:00,557 [Thread-3] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-09 22:27:00,563 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-09 22:27:00,564 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-09 22:27:00,564 [Thread-3] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-09 22:27:00,572 [Thread-3] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(55)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-09 22:27:00,573 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:27:08,789 [Thread-3] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(128)) - No pipeline exists in current db
2019-09-09 22:27:08,790 [Thread-3] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-09 22:27:10,037 [Thread-3] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-09 22:27:10,041 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-09 22:27:10,195 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:167)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 29 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 35 more
2019-09-09 22:27:10,205 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 29 more
2019-09-09 22:27:10,255 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-09 22:27:10,257 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds to VolumeSet
2019-09-09 22:27:10,260 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@61df66b6
2019-09-09 22:27:10,278 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@61df66b6
2019-09-09 22:27:10,848 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-09 22:27:10,874 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-09 22:27:10,941 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-09 22:27:10,946 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-09 22:27:10,947 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-09 22:27:10,949 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-09 22:27:10,950 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-09 22:27:10,950 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-09 22:27:11,115 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-09-09 22:27:11,174 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-09 22:27:11,175 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds to VolumeSet
2019-09-09 22:27:11,175 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@32f232a5
2019-09-09 22:27:11,176 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@32f232a5
2019-09-09 22:27:11,194 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-09 22:27:11,195 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-09 22:27:11,195 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-09 22:27:11,196 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-09 22:27:11,196 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-09 22:27:11,196 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-09 22:27:11,196 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-09 22:27:11,197 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-09 22:27:11,197 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-09-09 22:27:11,204 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-09 22:27:11,205 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds to VolumeSet
2019-09-09 22:27:11,205 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@126945f9
2019-09-09 22:27:11,205 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@126945f9
2019-09-09 22:27:11,222 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-09 22:27:11,223 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-09 22:27:11,223 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-09 22:27:11,223 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-09 22:27:11,223 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-09 22:27:11,224 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-09 22:27:11,224 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-09 22:27:11,224 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-09 22:27:11,225 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-09-09 22:27:11,530 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 2f560b88-4934-46b0-b773-4d84784f1989 is started using port 46004
2019-09-09 22:27:11,530 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(393)) - Starting XceiverServerRatis 2f560b88-4934-46b0-b773-4d84784f1989 at port 0
2019-09-09 22:27:11,552 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2f560b88-4934-46b0-b773-4d84784f1989: start RPC server
2019-09-09 22:27:11,555 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 2f560b88-4934-46b0-b773-4d84784f1989: GrpcService started, listening on 0.0.0.0/0.0.0.0:39927
2019-09-09 22:27:11,555 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(403)) - XceiverServerRatis 2f560b88-4934-46b0-b773-4d84784f1989 is started using port 39927
2019-09-09 22:27:11,557 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 06e8e15d-a648-4df8-9b9d-44117ed9b8ad is started using port 38327
2019-09-09 22:27:11,557 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(393)) - Starting XceiverServerRatis 06e8e15d-a648-4df8-9b9d-44117ed9b8ad at port 0
2019-09-09 22:27:11,565 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 06e8e15d-a648-4df8-9b9d-44117ed9b8ad: start RPC server
2019-09-09 22:27:11,567 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 06e8e15d-a648-4df8-9b9d-44117ed9b8ad: GrpcService started, listening on 0.0.0.0/0.0.0.0:38658
2019-09-09 22:27:11,567 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(403)) - XceiverServerRatis 06e8e15d-a648-4df8-9b9d-44117ed9b8ad is started using port 38658
2019-09-09 22:27:11,568 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 3a593ca0-1aaf-4be9-a056-30f52eb600bd is started using port 38243
2019-09-09 22:27:11,569 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(393)) - Starting XceiverServerRatis 3a593ca0-1aaf-4be9-a056-30f52eb600bd at port 0
2019-09-09 22:27:11,576 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 3a593ca0-1aaf-4be9-a056-30f52eb600bd: start RPC server
2019-09-09 22:27:11,578 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 3a593ca0-1aaf-4be9-a056-30f52eb600bd: GrpcService started, listening on 0.0.0.0/0.0.0.0:46774
2019-09-09 22:27:11,579 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(403)) - XceiverServerRatis 3a593ca0-1aaf-4be9-a056-30f52eb600bd is started using port 46774
2019-09-09 22:27:11,580 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 2f560b88-4934-46b0-b773-4d84784f1989: close
2019-09-09 22:27:11,583 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 2f560b88-4934-46b0-b773-4d84784f1989: shutdown server with port 39927 now
2019-09-09 22:27:11,598 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 2f560b88-4934-46b0-b773-4d84784f1989: shutdown server with port 39927 successfully
2019-09-09 22:27:11,616 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 06e8e15d-a648-4df8-9b9d-44117ed9b8ad: close
2019-09-09 22:27:11,616 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 06e8e15d-a648-4df8-9b9d-44117ed9b8ad: shutdown server with port 38658 now
2019-09-09 22:27:11,618 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 06e8e15d-a648-4df8-9b9d-44117ed9b8ad: shutdown server with port 38658 successfully
2019-09-09 22:27:11,619 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 3a593ca0-1aaf-4be9-a056-30f52eb600bd: close
2019-09-09 22:27:11,619 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 3a593ca0-1aaf-4be9-a056-30f52eb600bd: shutdown server with port 46774 now
2019-09-09 22:27:11,620 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 3a593ca0-1aaf-4be9-a056-30f52eb600bd: shutdown server with port 46774 successfully
2019-09-09 22:27:11,628 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(215)) - Attempting to stop container services.
2019-09-09 22:27:11,629 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-09 22:27:11,646 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-09 22:27:11,648 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(215)) - Attempting to stop container services.
2019-09-09 22:27:11,649 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-09 22:27:11,664 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-09 22:27:11,665 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(215)) - Attempting to stop container services.
2019-09-09 22:27:11,666 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-09 22:27:11,679 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-09 22:27:11,684 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea : 8192 
2019-09-09 22:27:11,685 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-09 22:27:11,686 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds to VolumeSet
2019-09-09 22:27:11,686 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@662f5666
2019-09-09 22:27:11,687 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@662f5666
2019-09-09 22:27:11,704 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-09 22:27:11,706 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-09 22:27:11,706 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-09 22:27:11,707 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-09 22:27:11,707 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-09 22:27:11,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-09 22:27:11,708 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-09 22:27:11,708 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-09 22:27:11,710 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-09-09 22:27:11,714 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea : 8192 
2019-09-09 22:27:11,715 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-09 22:27:11,715 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds to VolumeSet
2019-09-09 22:27:11,715 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4678a2eb
2019-09-09 22:27:11,716 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4678a2eb
2019-09-09 22:27:11,730 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-09 22:27:11,731 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-09 22:27:11,731 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-09 22:27:11,731 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-09 22:27:11,731 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-09 22:27:11,731 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-09 22:27:11,732 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-09 22:27:11,732 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-09 22:27:11,732 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-09-09 22:27:11,735 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea : 8192 
2019-09-09 22:27:11,736 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-09 22:27:11,736 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea/hdds to VolumeSet
2019-09-09 22:27:11,736 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@14c01636
2019-09-09 22:27:11,737 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@14c01636
2019-09-09 22:27:11,751 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-09 22:27:11,751 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-09 22:27:11,751 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-09 22:27:11,752 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-09 22:27:11,752 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-09 22:27:11,752 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-09 22:27:11,752 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-09 22:27:11,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-09 22:27:11,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-09-09 22:27:11,754 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(215)) - Attempting to stop container services.
2019-09-09 22:27:11,755 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-09 22:27:11,769 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-09 22:27:11,770 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(215)) - Attempting to stop container services.
2019-09-09 22:27:11,770 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-09 22:27:11,781 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-09 22:27:11,782 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(215)) - Attempting to stop container services.
2019-09-09 22:27:11,782 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/sYmFRDcUea] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-09 22:27:11,793 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService

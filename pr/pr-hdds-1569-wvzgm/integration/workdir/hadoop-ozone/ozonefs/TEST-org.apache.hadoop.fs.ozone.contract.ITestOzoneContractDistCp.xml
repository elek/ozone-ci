<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="100.982" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7678417320666205748.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-09-26T09-15-41_457-jvmRun1 surefire8186742927459600692tmp surefire_1046183971532671318963tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7678417320666205748.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpdateDeepDirectoryStructureNoChange" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="16.145">
    <error message="DistCp failure: Job job_local1330272719_0001 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1330272719_0001 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureNoChange(AbstractContractDistCpTest.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-26 10:56:18,392 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:18,501 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:18,505 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:18,522 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @893ms
2019-09-26 10:56:18,626 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 10:56:18,626 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 10:56:18,626 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 10:56:18,627 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 10:56:18,627 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 10:56:18,627 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 10:56:18,639 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 10:56:18,640 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 10:56:18,641 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 10:56:18,905 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@dd05255
2019-09-26 10:56:18,908 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 10:56:19,001 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 10:56:19,003 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 10:56:19,006 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 10:56:19,140 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 10:56:19,157 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:19,221 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 10:56:19,225 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:19,368 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-26 10:56:19,778 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 10:56:19,934 [Socket Reader #1 for port 40632] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40632
2019-09-26 10:56:19,966 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 10:56:19,967 [Socket Reader #1 for port 44642] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44642
2019-09-26 10:56:19,976 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 10:56:19,977 [Socket Reader #1 for port 43780] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43780
2019-09-26 10:56:19,997 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 10:56:20,108 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:20,123 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:20,133 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:20,135 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 10:56:20,135 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:20,136 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:20,163 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43780
2019-09-26 10:56:20,212 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 10:56:20,223 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 10:56:20,224 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 10:56:20,541 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:43780
2019-09-26 10:56:20,541 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 10:56:20,542 [IPC Server listener on 43780] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43780: starting
2019-09-26 10:56:20,546 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:44642
2019-09-26 10:56:20,548 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:44642
2019-09-26 10:56:20,549 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 10:56:20,549 [IPC Server listener on 44642] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44642: starting
2019-09-26 10:56:20,551 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:40632
2019-09-26 10:56:20,551 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:40632
2019-09-26 10:56:20,552 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 10:56:20,552 [IPC Server listener on 40632] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40632: starting
2019-09-26 10:56:20,556 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39986
2019-09-26 10:56:20,558 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:20,594 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:20,594 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:20,685 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@aec50a1{/,file:///tmp/jetty-0.0.0.0-39986-scm-_-any-1704355766016996029.dir/webapp/,AVAILABLE}{/scm}
2019-09-26 10:56:20,693 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:39986}
2019-09-26 10:56:20,693 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3064ms
2019-09-26 10:56:20,696 [JUnit] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 10:56:20,696 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 10:56:20,698 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:39986
2019-09-26 10:56:20,708 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c1fca1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 10:56:20,712 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:20,815 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:20,816 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:20,817 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(652)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 10:56:20,817 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(658)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 65d6d399-b2ac-444a-bbba-c97a70f69719
2019-09-26 10:56:20,818 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-26 10:56:21,556 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 10:56:21,566 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 10:56:21,566 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 10:56:21,566 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 10:56:21,567 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 10:56:21,567 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 10:56:21,567 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 10:56:21,567 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 10:56:21,568 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 10:56:21,568 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 10:56:21,568 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 10:56:21,568 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 10:56:21,569 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 10:56:21,569 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 10:56:21,569 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 10:56:21,569 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 10:56:21,569 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 10:56:21,570 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 10:56:21,570 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 10:56:21,570 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 10:56:21,570 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 10:56:21,571 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 10:56:21,571 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 10:56:21,571 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 10:56:21,571 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 10:56:21,572 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 10:56:22,046 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 10:56:22,047 [Socket Reader #1 for port 37534] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37534
2019-09-26 10:56:22,090 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37534
2019-09-26 10:56:22,091 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 10:56:22,092 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 10:56:22,092 [IPC Server listener on 37534] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37534: starting
2019-09-26 10:56:22,099 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 10:56:22,103 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:22,104 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:22,108 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:22,110 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 10:56:22,111 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:22,111 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:22,275 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41297
2019-09-26 10:56:22,275 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:22,282 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:22,283 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:22,352 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7103ab0{/,file:///tmp/jetty-0.0.0.0-41297-ozoneManager-_-any-3742519836567539977.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-26 10:56:22,353 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:41297}
2019-09-26 10:56:22,353 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4724ms
2019-09-26 10:56:22,354 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 10:56:22,355 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:41297
2019-09-26 10:56:22,512 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 10:56:22,568 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-wvzgm-824869521 ip:192.168.30.13
2019-09-26 10:56:22,623 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 10:56:22,625 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 10:56:22,629 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-26 10:56:22,647 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-26 10:56:22,799 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 10:56:22,883 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 10:56:22,888 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 10:56:22,889 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 10:56:22,890 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:22,891 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 10:56:22,892 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 10:56:23,078 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:23,138 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 10:56:23,142 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:23,143 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:23,147 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:23,149 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 10:56:23,149 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:23,149 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:23,151 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40300
2019-09-26 10:56:23,152 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:23,155 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:23,156 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:23,200 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73844119{/,file:///tmp/jetty-0.0.0.0-40300-hddsDatanode-_-any-5272131352619830020.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 10:56:23,201 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:40300}
2019-09-26 10:56:23,201 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5572ms
2019-09-26 10:56:23,203 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 10:56:23,204 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40300
2019-09-26 10:56:23,205 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 10:56:23,209 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-wvzgm-824869521 ip:192.168.30.13
2019-09-26 10:56:23,213 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@b972f30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 10:56:23,220 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 10:56:23,222 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 10:56:23,222 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@77a074b4
2019-09-26 10:56:23,223 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@77a074b4
2019-09-26 10:56:23,245 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 10:56:23,246 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 10:56:23,246 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 10:56:23,246 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 10:56:23,246 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:23,247 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 10:56:23,247 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 10:56:23,248 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:23,249 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 10:56:23,251 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:23,252 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:23,254 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:23,255 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 10:56:23,255 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:23,255 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:23,256 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45624
2019-09-26 10:56:23,256 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:23,261 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@618ff5c2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:23,261 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f84acf7{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:23,290 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6e4f263e{/,file:///tmp/jetty-0.0.0.0-45624-hddsDatanode-_-any-4769633647632131646.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 10:56:23,291 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48b4a043{HTTP/1.1,[http/1.1]}{0.0.0.0:45624}
2019-09-26 10:56:23,292 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5663ms
2019-09-26 10:56:23,293 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 10:56:23,293 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45624
2019-09-26 10:56:23,294 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 10:56:23,297 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-wvzgm-824869521 ip:192.168.30.13
2019-09-26 10:56:23,298 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@160e678d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 10:56:23,305 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 10:56:23,306 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 10:56:23,307 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cf0a747
2019-09-26 10:56:23,307 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cf0a747
2019-09-26 10:56:23,331 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 10:56:23,331 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 10:56:23,331 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 10:56:23,332 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 10:56:23,332 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:23,332 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 10:56:23,332 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 10:56:23,333 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:23,335 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 10:56:23,337 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:23,338 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:23,340 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:23,341 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 10:56:23,341 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:23,341 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:23,342 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34844
2019-09-26 10:56:23,342 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:23,345 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@272ce069{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:23,345 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c26273d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:23,364 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/meta/datanode.id
2019-09-26 10:56:23,370 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/meta/datanode.id
2019-09-26 10:56:23,379 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29149030{/,file:///tmp/jetty-0.0.0.0-34844-hddsDatanode-_-any-1334238923194135592.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 10:56:23,380 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@38b8b6c0{HTTP/1.1,[http/1.1]}{0.0.0.0:34844}
2019-09-26 10:56:23,380 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5752ms
2019-09-26 10:56:23,381 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 10:56:23,382 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34844
2019-09-26 10:56:23,383 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 10:56:23,386 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-wvzgm-824869521 ip:192.168.30.13
2019-09-26 10:56:23,386 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2223c899] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 10:56:23,389 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/meta/datanode.id
2019-09-26 10:56:23,395 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 10:56:23,395 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/containers/hdds to VolumeSet
2019-09-26 10:56:23,395 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-26 10:56:23,396 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-26 10:56:23,417 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 10:56:23,418 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 10:56:23,418 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 10:56:23,418 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 10:56:23,418 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:23,419 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 10:56:23,419 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 10:56:23,420 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:23,421 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 10:56:23,423 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:23,423 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:23,425 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:23,426 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 10:56:23,426 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:23,426 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:23,427 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37107
2019-09-26 10:56:23,427 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:23,432 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26350ea2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:23,432 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a08efdc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:23,461 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cd3ad8a{/,file:///tmp/jetty-0.0.0.0-37107-hddsDatanode-_-any-7944740787848923400.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 10:56:23,461 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@75181b50{HTTP/1.1,[http/1.1]}{0.0.0.0:37107}
2019-09-26 10:56:23,462 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5833ms
2019-09-26 10:56:23,462 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 10:56:23,464 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37107
2019-09-26 10:56:23,464 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 10:56:23,468 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-wvzgm-824869521 ip:192.168.30.13
2019-09-26 10:56:23,468 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24a92d3e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 10:56:23,472 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/meta/datanode.id
2019-09-26 10:56:23,481 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 10:56:23,481 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/containers/hdds to VolumeSet
2019-09-26 10:56:23,482 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2a869a16
2019-09-26 10:56:23,482 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2a869a16
2019-09-26 10:56:23,503 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 10:56:23,503 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 10:56:23,503 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 10:56:23,504 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 10:56:23,504 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:23,504 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 10:56:23,504 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 10:56:23,505 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:23,506 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 10:56:23,508 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 10:56:23,509 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 10:56:23,511 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 10:56:23,512 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 10:56:23,512 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 10:56:23,512 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 10:56:23,513 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38559
2019-09-26 10:56:23,513 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 10:56:23,515 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e446d92{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 10:56:23,516 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d5c2745{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 10:56:23,545 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4cb2918c{/,file:///tmp/jetty-0.0.0.0-38559-hddsDatanode-_-any-3516455377849548003.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 10:56:23,545 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72e295cc{HTTP/1.1,[http/1.1]}{0.0.0.0:38559}
2019-09-26 10:56:23,547 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5918ms
2019-09-26 10:56:23,547 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 10:56:23,548 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38559
2019-09-26 10:56:23,552 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 10:56:23,556 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27651ea8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 10:56:23,559 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/meta/datanode.id
2019-09-26 10:56:24,554 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 10:56:25,286 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 10:56:25,292 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 10:56:25,292 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b842eb89-c2cf-49c6-bf64-1aae636704d9 at port 0
2019-09-26 10:56:25,318 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 10:56:25,325 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 10:56:25,325 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b34661b1-4d86-427f-adca-7a29442b8d39 at port 0
2019-09-26 10:56:25,326 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start RPC server
2019-09-26 10:56:25,338 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b34661b1-4d86-427f-adca-7a29442b8d39: start RPC server
2019-09-26 10:56:25,402 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 10:56:25,404 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 10:56:25,404 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b286dd73-ae46-4ddf-9a85-2d36f42ec21c at port 0
2019-09-26 10:56:25,414 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start RPC server
2019-09-26 10:56:25,491 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 10:56:25,494 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 10:56:25,494 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 3a064774-b44e-45fe-8e32-0fdc3e241782 at port 0
2019-09-26 10:56:25,509 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start RPC server
2019-09-26 10:56:25,513 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: GrpcService started, listening on 0.0.0.0/0.0.0.0:35382
2019-09-26 10:56:25,513 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: GrpcService started, listening on 0.0.0.0/0.0.0.0:39351
2019-09-26 10:56:25,514 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b34661b1-4d86-427f-adca-7a29442b8d39: GrpcService started, listening on 0.0.0.0/0.0.0.0:32886
2019-09-26 10:56:25,514 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b842eb89-c2cf-49c6-bf64-1aae636704d9 is started using port 39351
2019-09-26 10:56:25,514 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: GrpcService started, listening on 0.0.0.0/0.0.0.0:38957
2019-09-26 10:56:25,514 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b286dd73-ae46-4ddf-9a85-2d36f42ec21c is started using port 35382
2019-09-26 10:56:25,515 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 3a064774-b44e-45fe-8e32-0fdc3e241782 is started using port 38957
2019-09-26 10:56:25,515 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b34661b1-4d86-427f-adca-7a29442b8d39 is started using port 32886
2019-09-26 10:56:25,525 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b34661b1-4d86-427f-adca-7a29442b8d39 is started using port 39618
2019-09-26 10:56:25,525 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 3a064774-b44e-45fe-8e32-0fdc3e241782 is started using port 39824
2019-09-26 10:56:25,526 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b842eb89-c2cf-49c6-bf64-1aae636704d9 is started using port 39469
2019-09-26 10:56:25,525 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b286dd73-ae46-4ddf-9a85-2d36f42ec21c is started using port 35308
2019-09-26 10:56:25,555 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 10:56:25,572 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 10:56:25,579 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 10:56:25,579 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 62b65582-e5b2-40ae-adce-12d706872e71 at port 0
2019-09-26 10:56:25,589 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 62b65582-e5b2-40ae-adce-12d706872e71: start RPC server
2019-09-26 10:56:25,593 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 62b65582-e5b2-40ae-adce-12d706872e71: GrpcService started, listening on 0.0.0.0/0.0.0.0:40378
2019-09-26 10:56:25,593 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 62b65582-e5b2-40ae-adce-12d706872e71 is started using port 40378
2019-09-26 10:56:25,596 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 62b65582-e5b2-40ae-adce-12d706872e71 is started using port 44272
2019-09-26 10:56:26,556 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 10:56:27,265 [IPC Server handler 2 on 40632] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:27,266 [IPC Server handler 2 on 40632] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}
2019-09-26 10:56:27,272 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 10:56:27,272 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 10:56:27,273 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 10:56:27,302 [IPC Server handler 0 on 40632] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:27,302 [IPC Server handler 0 on 40632] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}
2019-09-26 10:56:27,389 [IPC Server handler 3 on 40632] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:27,389 [IPC Server handler 3 on 40632] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}
2019-09-26 10:56:27,473 [IPC Server handler 6 on 40632] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:27,473 [IPC Server handler 6 on 40632] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}
2019-09-26 10:56:27,556 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-26 10:56:27,560 [IPC Server handler 2 on 40632] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:27,561 [IPC Server handler 2 on 40632] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}
2019-09-26 10:56:27,888 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: addNew group-8E4407FB1D1B:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] returns group-8E4407FB1D1B:java.util.concurrent.CompletableFuture@198bdd8f[Not completed]
2019-09-26 10:56:27,913 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: new RaftServerImpl for group-8E4407FB1D1B:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] with ContainerStateMachine:uninitialized
2019-09-26 10:56:27,915 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:27,917 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:27,917 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:27,918 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:27,919 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:27,930 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: ConfigurationManager, init=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:27,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:27,940 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f79a8463-e8b1-49f5-9198-8e4407fb1d1b does not exist. Creating ...
2019-09-26 10:56:27,958 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f79a8463-e8b1-49f5-9198-8e4407fb1d1b/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:27,973 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f79a8463-e8b1-49f5-9198-8e4407fb1d1b has been successfully formatted.
2019-09-26 10:56:27,976 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-8E4407FB1D1B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:27,976 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:27,979 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:27,985 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:27,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:27,988 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:27,993 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,000 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f79a8463-e8b1-49f5-9198-8e4407fb1d1b
2019-09-26 10:56:28,001 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 10:56:28,009 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 10:56:28,041 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,041 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,045 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,045 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,046 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,046 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,047 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,047 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,048 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,058 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,062 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,102 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: start as a follower, conf=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:28,103 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,104 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start FollowerState
2019-09-26 10:56:28,107 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E4407FB1D1B,id=b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:28,184 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f79a8463-e8b1-49f5-9198-8e4407fb1d1b, Nodes: b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,212 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b34661b1-4d86-427f-adca-7a29442b8d39: addNew group-FFC21BB995B1:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] returns group-FFC21BB995B1:java.util.concurrent.CompletableFuture@2c85e598[Not completed]
2019-09-26 10:56:28,260 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b34661b1-4d86-427f-adca-7a29442b8d39: new RaftServerImpl for group-FFC21BB995B1:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,261 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,261 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,262 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,262 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,262 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,262 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: ConfigurationManager, init=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,262 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:28,263 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8cb764f1-87ed-4288-9c8f-ffc21bb995b1 does not exist. Creating ...
2019-09-26 10:56:28,278 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8cb764f1-87ed-4288-9c8f-ffc21bb995b1/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,291 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8cb764f1-87ed-4288-9c8f-ffc21bb995b1 has been successfully formatted.
2019-09-26 10:56:28,293 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FFC21BB995B1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,297 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8cb764f1-87ed-4288-9c8f-ffc21bb995b1
2019-09-26 10:56:28,305 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,307 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,307 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,307 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,307 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,308 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,308 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,309 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,309 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,309 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,310 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,310 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,317 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: start as a follower, conf=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:28,317 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,317 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start FollowerState
2019-09-26 10:56:28,319 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFC21BB995B1,id=b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:28,340 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8cb764f1-87ed-4288-9c8f-ffc21bb995b1, Nodes: b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,363 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: addNew group-12DBE144E63C:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] returns group-12DBE144E63C:java.util.concurrent.CompletableFuture@6f53ee83[Not completed]
2019-09-26 10:56:28,388 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: new RaftServerImpl for group-12DBE144E63C:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,388 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,388 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,389 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,389 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,389 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,389 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: ConfigurationManager, init=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,390 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:28,390 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/f9fcc9e8-2c67-4a19-b17a-12dbe144e63c does not exist. Creating ...
2019-09-26 10:56:28,403 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/f9fcc9e8-2c67-4a19-b17a-12dbe144e63c/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,416 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/f9fcc9e8-2c67-4a19-b17a-12dbe144e63c has been successfully formatted.
2019-09-26 10:56:28,417 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-12DBE144E63C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,417 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,417 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,418 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,418 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,418 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,418 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,419 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/f9fcc9e8-2c67-4a19-b17a-12dbe144e63c
2019-09-26 10:56:28,453 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,455 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,455 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,455 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,455 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,456 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,456 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,458 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,464 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: start as a follower, conf=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:28,464 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,464 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start FollowerState
2019-09-26 10:56:28,465 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12DBE144E63C,id=b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:28,476 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f9fcc9e8-2c67-4a19-b17a-12dbe144e63c, Nodes: b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,495 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: addNew group-E64F531F18D8:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] returns group-E64F531F18D8:java.util.concurrent.CompletableFuture@33b5f285[Not completed]
2019-09-26 10:56:28,498 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: new RaftServerImpl for group-E64F531F18D8:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,498 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,498 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,499 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,499 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,499 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,499 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: ConfigurationManager, init=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,500 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:28,500 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/d2df34a2-a4ae-4aa9-bcba-e64f531f18d8 does not exist. Creating ...
2019-09-26 10:56:28,513 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/d2df34a2-a4ae-4aa9-bcba-e64f531f18d8/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,526 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/d2df34a2-a4ae-4aa9-bcba-e64f531f18d8 has been successfully formatted.
2019-09-26 10:56:28,527 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E64F531F18D8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,528 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/d2df34a2-a4ae-4aa9-bcba-e64f531f18d8
2019-09-26 10:56:28,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,531 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,531 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,538 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: start as a follower, conf=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:28,538 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,539 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start FollowerState
2019-09-26 10:56:28,539 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E64F531F18D8,id=b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:28,550 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d2df34a2-a4ae-4aa9-bcba-e64f531f18d8, Nodes: b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,561 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-26 10:56:28,571 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: addNew group-3847C4EFF424:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] returns group-3847C4EFF424:java.util.concurrent.CompletableFuture@2cd182e5[Not completed]
2019-09-26 10:56:28,573 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: new RaftServerImpl for group-3847C4EFF424:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,575 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: ConfigurationManager, init=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:28,575 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f7d4a1bc-acc9-4fa2-900a-3847c4eff424 does not exist. Creating ...
2019-09-26 10:56:28,593 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f7d4a1bc-acc9-4fa2-900a-3847c4eff424/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,606 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f7d4a1bc-acc9-4fa2-900a-3847c4eff424 has been successfully formatted.
2019-09-26 10:56:28,606 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-3847C4EFF424: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,606 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,606 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,607 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,607 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,607 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,607 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,607 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f7d4a1bc-acc9-4fa2-900a-3847c4eff424
2019-09-26 10:56:28,608 [Thread-221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 10:56:28,608 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,608 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,609 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,609 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,609 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,609 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,609 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,610 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,610 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,610 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,610 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,611 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,611 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,611 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,612 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,617 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: start as a follower, conf=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:28,617 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,617 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start FollowerState
2019-09-26 10:56:28,618 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3847C4EFF424,id=b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:28,633 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f7d4a1bc-acc9-4fa2-900a-3847c4eff424, Nodes: b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,657 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: addNew group-399F8A7BA38C:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] returns group-399F8A7BA38C:java.util.concurrent.CompletableFuture@7964a9e4[Not completed]
2019-09-26 10:56:28,660 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: new RaftServerImpl for group-399F8A7BA38C:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,660 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,660 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,661 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,661 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,661 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,661 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: ConfigurationManager, init=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,661 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:28,662 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/c8a0b2f8-3d0f-4517-8aaa-399f8a7ba38c does not exist. Creating ...
2019-09-26 10:56:28,676 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/c8a0b2f8-3d0f-4517-8aaa-399f8a7ba38c/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,689 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/c8a0b2f8-3d0f-4517-8aaa-399f8a7ba38c has been successfully formatted.
2019-09-26 10:56:28,689 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-399F8A7BA38C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,691 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/c8a0b2f8-3d0f-4517-8aaa-399f8a7ba38c
2019-09-26 10:56:28,695 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,698 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,699 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,699 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,699 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,704 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: start as a follower, conf=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:28,704 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,704 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start FollowerState
2019-09-26 10:56:28,705 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-399F8A7BA38C,id=3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:28,724 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c8a0b2f8-3d0f-4517-8aaa-399f8a7ba38c, Nodes: 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,826 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62b65582-e5b2-40ae-adce-12d706872e71: addNew group-4BAD357627F8:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] returns group-4BAD357627F8:java.util.concurrent.CompletableFuture@2a1d5465[Not completed]
2019-09-26 10:56:28,838 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62b65582-e5b2-40ae-adce-12d706872e71: new RaftServerImpl for group-4BAD357627F8:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,859 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,859 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,861 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,861 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,861 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,861 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: ConfigurationManager, init=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,862 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:28,862 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/6695f25e-4ea9-4989-900e-4bad357627f8 does not exist. Creating ...
2019-09-26 10:56:28,879 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/6695f25e-4ea9-4989-900e-4bad357627f8/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,888 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/6695f25e-4ea9-4989-900e-4bad357627f8 has been successfully formatted.
2019-09-26 10:56:28,888 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4BAD357627F8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,888 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,888 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,888 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,889 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,889 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,889 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,889 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/6695f25e-4ea9-4989-900e-4bad357627f8
2019-09-26 10:56:28,893 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,893 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,893 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,893 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,893 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,894 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,894 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,894 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,894 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,895 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,895 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,895 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,895 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,896 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,896 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,899 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: start as a follower, conf=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:28,899 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,900 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start FollowerState
2019-09-26 10:56:28,900 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4BAD357627F8,id=62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:28,913 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6695f25e-4ea9-4989-900e-4bad357627f8, Nodes: 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,928 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62b65582-e5b2-40ae-adce-12d706872e71: addNew group-5D777DA71282:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] returns group-5D777DA71282:java.util.concurrent.CompletableFuture@3973d9f3[Not completed]
2019-09-26 10:56:28,930 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62b65582-e5b2-40ae-adce-12d706872e71: new RaftServerImpl for group-5D777DA71282:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,930 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,931 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,931 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,931 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,931 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,931 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: ConfigurationManager, init=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,932 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:28,932 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/e0fdce01-65c0-45d3-b159-5d777da71282 does not exist. Creating ...
2019-09-26 10:56:28,945 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/e0fdce01-65c0-45d3-b159-5d777da71282/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:28,958 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/e0fdce01-65c0-45d3-b159-5d777da71282 has been successfully formatted.
2019-09-26 10:56:28,959 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5D777DA71282: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:28,959 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:28,960 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:28,961 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:28,961 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:28,961 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,961 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:28,961 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/e0fdce01-65c0-45d3-b159-5d777da71282
2019-09-26 10:56:28,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:28,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:28,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:28,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:28,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:28,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:28,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:28,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:28,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:28,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:28,964 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:28,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:28,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:28,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:28,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:28,968 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: start as a follower, conf=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:28,969 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:28,969 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start FollowerState
2019-09-26 10:56:28,969 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5D777DA71282,id=62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:28,979 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e0fdce01-65c0-45d3-b159-5d777da71282, Nodes: 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:28,993 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: addNew group-275ADCECAB09:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] returns group-275ADCECAB09:java.util.concurrent.CompletableFuture@6834e5a5[Not completed]
2019-09-26 10:56:28,995 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: new RaftServerImpl for group-275ADCECAB09:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] with ContainerStateMachine:uninitialized
2019-09-26 10:56:28,995 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:28,995 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:28,995 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:28,996 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:28,996 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:28,996 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: ConfigurationManager, init=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:28,996 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:28,996 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/b0d35f81-b93a-4e03-b8ea-275adcecab09 does not exist. Creating ...
2019-09-26 10:56:29,009 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/b0d35f81-b93a-4e03-b8ea-275adcecab09/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,022 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/b0d35f81-b93a-4e03-b8ea-275adcecab09 has been successfully formatted.
2019-09-26 10:56:29,023 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-275ADCECAB09: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,023 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,023 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,023 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,023 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,024 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/b0d35f81-b93a-4e03-b8ea-275adcecab09
2019-09-26 10:56:29,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,026 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,029 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: start as a follower, conf=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:29,030 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,030 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start FollowerState
2019-09-26 10:56:29,030 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-275ADCECAB09,id=b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:29,042 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0d35f81-b93a-4e03-b8ea-275adcecab09, Nodes: b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,061 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: addNew group-42B2C4F9BA28:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] returns group-42B2C4F9BA28:java.util.concurrent.CompletableFuture@6e7ed7cd[Not completed]
2019-09-26 10:56:29,063 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: new RaftServerImpl for group-42B2C4F9BA28:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,063 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,063 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,064 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,064 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,070 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,070 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: ConfigurationManager, init=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,070 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:29,071 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4f6471d8-31e9-4cc0-81e5-42b2c4f9ba28 does not exist. Creating ...
2019-09-26 10:56:29,084 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4f6471d8-31e9-4cc0-81e5-42b2c4f9ba28/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,097 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4f6471d8-31e9-4cc0-81e5-42b2c4f9ba28 has been successfully formatted.
2019-09-26 10:56:29,097 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-42B2C4F9BA28: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,097 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,097 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,098 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,098 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,098 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,098 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,098 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4f6471d8-31e9-4cc0-81e5-42b2c4f9ba28
2019-09-26 10:56:29,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,100 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,100 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,100 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,100 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,101 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,101 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,101 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,101 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,102 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,105 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: start as a follower, conf=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:29,105 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,105 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start FollowerState
2019-09-26 10:56:29,105 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-42B2C4F9BA28,id=b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:29,117 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4f6471d8-31e9-4cc0-81e5-42b2c4f9ba28, Nodes: b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,139 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: addNew group-926367C19667:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] returns group-926367C19667:java.util.concurrent.CompletableFuture@3f8cab26[Not completed]
2019-09-26 10:56:29,141 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: new RaftServerImpl for group-926367C19667:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,141 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,141 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,141 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,142 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,142 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,142 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: ConfigurationManager, init=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,142 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:29,143 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/08dc7d8e-d522-4292-96b0-926367c19667 does not exist. Creating ...
2019-09-26 10:56:29,155 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/08dc7d8e-d522-4292-96b0-926367c19667/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,180 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/08dc7d8e-d522-4292-96b0-926367c19667 has been successfully formatted.
2019-09-26 10:56:29,180 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-926367C19667: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,180 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,180 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,181 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/08dc7d8e-d522-4292-96b0-926367c19667
2019-09-26 10:56:29,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,183 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,183 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,183 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,183 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,184 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,185 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,188 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: start as a follower, conf=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:29,188 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,189 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start FollowerState
2019-09-26 10:56:29,189 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-926367C19667,id=3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:29,203 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 08dc7d8e-d522-4292-96b0-926367c19667, Nodes: 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,219 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b34661b1-4d86-427f-adca-7a29442b8d39: addNew group-13727138B3AA:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] returns group-13727138B3AA:java.util.concurrent.CompletableFuture@3574c056[Not completed]
2019-09-26 10:56:29,221 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b34661b1-4d86-427f-adca-7a29442b8d39: new RaftServerImpl for group-13727138B3AA:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,222 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: ConfigurationManager, init=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,222 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:29,222 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/99b33a62-9444-49a0-af2b-13727138b3aa does not exist. Creating ...
2019-09-26 10:56:29,235 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/99b33a62-9444-49a0-af2b-13727138b3aa/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,249 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/99b33a62-9444-49a0-af2b-13727138b3aa has been successfully formatted.
2019-09-26 10:56:29,249 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-13727138B3AA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,249 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,251 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/99b33a62-9444-49a0-af2b-13727138b3aa
2019-09-26 10:56:29,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,252 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,252 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,252 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,252 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,252 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,253 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,253 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,253 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,253 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,254 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,257 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: start as a follower, conf=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:29,257 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,257 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start FollowerState
2019-09-26 10:56:29,258 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13727138B3AA,id=b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:29,268 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 99b33a62-9444-49a0-af2b-13727138b3aa, Nodes: b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,284 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: addNew group-A15010B9AE3F:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] returns group-A15010B9AE3F:java.util.concurrent.CompletableFuture@2af9082f[Not completed]
2019-09-26 10:56:29,286 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: new RaftServerImpl for group-A15010B9AE3F:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,287 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,287 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: ConfigurationManager, init=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,287 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:29,288 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/10556c59-e8d8-4239-bb23-a15010b9ae3f does not exist. Creating ...
2019-09-26 10:56:29,301 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/10556c59-e8d8-4239-bb23-a15010b9ae3f/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,314 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/10556c59-e8d8-4239-bb23-a15010b9ae3f has been successfully formatted.
2019-09-26 10:56:29,314 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A15010B9AE3F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,316 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/10556c59-e8d8-4239-bb23-a15010b9ae3f
2019-09-26 10:56:29,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,318 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,318 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,318 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,321 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: start as a follower, conf=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:29,322 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,322 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start FollowerState
2019-09-26 10:56:29,322 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A15010B9AE3F,id=b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:29,330 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 10556c59-e8d8-4239-bb23-a15010b9ae3f, Nodes: b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,343 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: addNew group-320B53A7B547:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] returns group-320B53A7B547:java.util.concurrent.CompletableFuture@52a9a7a2[Not completed]
2019-09-26 10:56:29,346 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: new RaftServerImpl for group-320B53A7B547:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,347 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,347 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,353 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,358 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: ConfigurationManager, init=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,358 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:29,359 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/d426e516-893a-42d9-9ab8-320b53a7b547 does not exist. Creating ...
2019-09-26 10:56:29,371 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/d426e516-893a-42d9-9ab8-320b53a7b547/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,385 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/d426e516-893a-42d9-9ab8-320b53a7b547 has been successfully formatted.
2019-09-26 10:56:29,385 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-320B53A7B547: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,388 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,388 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,388 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/d426e516-893a-42d9-9ab8-320b53a7b547
2019-09-26 10:56:29,388 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,392 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,396 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: start as a follower, conf=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:29,397 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,397 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start FollowerState
2019-09-26 10:56:29,399 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-320B53A7B547,id=3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:29,410 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d426e516-893a-42d9-9ab8-320b53a7b547, Nodes: 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,427 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: addNew group-2CE50B69927B:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] returns group-2CE50B69927B:java.util.concurrent.CompletableFuture@72836d87[Not completed]
2019-09-26 10:56:29,429 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: new RaftServerImpl for group-2CE50B69927B:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,430 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,430 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,430 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,430 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,430 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,430 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: ConfigurationManager, init=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,431 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:29,431 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4a0f43c5-7323-4a1c-9d3a-2ce50b69927b does not exist. Creating ...
2019-09-26 10:56:29,442 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4a0f43c5-7323-4a1c-9d3a-2ce50b69927b/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,456 [Thread-221] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume91075, with user74516 as owner.
2019-09-26 10:56:29,461 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4a0f43c5-7323-4a1c-9d3a-2ce50b69927b has been successfully formatted.
2019-09-26 10:56:29,462 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-2CE50B69927B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,462 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,462 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,462 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,462 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,463 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,463 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,463 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4a0f43c5-7323-4a1c-9d3a-2ce50b69927b
2019-09-26 10:56:29,463 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,463 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,465 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,465 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,465 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,466 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,466 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,467 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,467 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,468 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,468 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,469 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,469 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,469 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,469 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,474 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: start as a follower, conf=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:29,474 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,475 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start FollowerState
2019-09-26 10:56:29,475 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2CE50B69927B,id=b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:29,480 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4a0f43c5-7323-4a1c-9d3a-2ce50b69927b, Nodes: b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,490 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62b65582-e5b2-40ae-adce-12d706872e71: addNew group-037BE885AA28:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] returns group-037BE885AA28:java.util.concurrent.CompletableFuture@7d917373[Not completed]
2019-09-26 10:56:29,491 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62b65582-e5b2-40ae-adce-12d706872e71: new RaftServerImpl for group-037BE885AA28:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,492 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,492 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,492 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,492 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,492 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,492 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: ConfigurationManager, init=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,493 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:29,493 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/350d3942-3410-43dd-9427-037be885aa28 does not exist. Creating ...
2019-09-26 10:56:29,506 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/350d3942-3410-43dd-9427-037be885aa28/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,518 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/350d3942-3410-43dd-9427-037be885aa28 has been successfully formatted.
2019-09-26 10:56:29,519 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-037BE885AA28: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,519 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,519 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,520 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,520 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,520 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,520 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,520 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/350d3942-3410-43dd-9427-037be885aa28
2019-09-26 10:56:29,520 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,522 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,523 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,523 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,525 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: start as a follower, conf=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:29,525 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,525 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start FollowerState
2019-09-26 10:56:29,526 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-037BE885AA28,id=62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:29,533 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 350d3942-3410-43dd-9427-037be885aa28, Nodes: 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,543 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: addNew group-999861FBDC8C:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] returns group-999861FBDC8C:java.util.concurrent.CompletableFuture@3b121b68[Not completed]
2019-09-26 10:56:29,545 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: new RaftServerImpl for group-999861FBDC8C:[b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,545 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,545 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,546 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,546 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,546 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,546 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: ConfigurationManager, init=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,546 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis] (custom)
2019-09-26 10:56:29,547 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/54c4c10b-fc32-4e76-a477-999861fbdc8c does not exist. Creating ...
2019-09-26 10:56:29,560 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/54c4c10b-fc32-4e76-a477-999861fbdc8c/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,573 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/54c4c10b-fc32-4e76-a477-999861fbdc8c has been successfully formatted.
2019-09-26 10:56:29,574 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-999861FBDC8C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:29,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:29,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:29,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:29,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:29,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:29,575 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/54c4c10b-fc32-4e76-a477-999861fbdc8c
2019-09-26 10:56:29,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:29,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:29,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:29,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:29,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:29,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:29,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:29,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:29,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:29,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:29,577 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:29,577 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:29,577 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:29,578 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:29,578 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:29,581 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: start as a follower, conf=-1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:29,582 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:29,582 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start FollowerState
2019-09-26 10:56:29,582 [IPC Server handler 1 on 37534] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume91075 for user:user74516
2019-09-26 10:56:29,582 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-999861FBDC8C,id=b286dd73-ae46-4ddf-9a85-2d36f42ec21c
2019-09-26 10:56:29,927 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 54c4c10b-fc32-4e76-a477-999861fbdc8c, Nodes: b286dd73-ae46-4ddf-9a85-2d36f42ec21c{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:29,928 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:29,956 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: addNew group-728D05CEA1F8:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] returns group-728D05CEA1F8:java.util.concurrent.CompletableFuture@678af24c[Not completed]
2019-09-26 10:56:29,959 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: new RaftServerImpl for group-728D05CEA1F8:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] with ContainerStateMachine:uninitialized
2019-09-26 10:56:29,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:29,960 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:29,960 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:29,960 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:29,960 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:29,960 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: ConfigurationManager, init=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:29,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:29,961 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/802e654b-9e20-4cf4-9947-728d05cea1f8 does not exist. Creating ...
2019-09-26 10:56:29,977 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/802e654b-9e20-4cf4-9947-728d05cea1f8/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:29,992 [Thread-221] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume91075/bucket79196, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 10:56:30,011 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/802e654b-9e20-4cf4-9947-728d05cea1f8 has been successfully formatted.
2019-09-26 10:56:30,012 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-728D05CEA1F8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,012 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,012 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,013 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,013 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,013 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,013 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,014 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/802e654b-9e20-4cf4-9947-728d05cea1f8
2019-09-26 10:56:30,014 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,014 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,014 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,014 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,015 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,015 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,015 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,015 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,015 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,016 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,016 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,017 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,017 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,017 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,017 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,022 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: start as a follower, conf=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:30,022 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,023 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start FollowerState
2019-09-26 10:56:30,023 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-728D05CEA1F8,id=b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:30,029 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 802e654b-9e20-4cf4-9947-728d05cea1f8, Nodes: b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,029 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,040 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: addNew group-43E2B41C5EAE:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] returns group-43E2B41C5EAE:java.util.concurrent.CompletableFuture@3f16d321[Not completed]
2019-09-26 10:56:30,041 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: new RaftServerImpl for group-43E2B41C5EAE:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,042 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,042 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,042 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,042 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,042 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,042 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: ConfigurationManager, init=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,043 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:30,043 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/a1900c93-05bc-4a06-b557-43e2b41c5eae does not exist. Creating ...
2019-09-26 10:56:30,064 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/a1900c93-05bc-4a06-b557-43e2b41c5eae/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,067 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/a1900c93-05bc-4a06-b557-43e2b41c5eae has been successfully formatted.
2019-09-26 10:56:30,068 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-43E2B41C5EAE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,069 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/a1900c93-05bc-4a06-b557-43e2b41c5eae
2019-09-26 10:56:30,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,071 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,075 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: start as a follower, conf=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:30,075 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,075 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start FollowerState
2019-09-26 10:56:30,076 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-43E2B41C5EAE,id=b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:30,081 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a1900c93-05bc-4a06-b557-43e2b41c5eae, Nodes: b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,081 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,101 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: addNew group-E35A4D7B4832:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] returns group-E35A4D7B4832:java.util.concurrent.CompletableFuture@2e66f57f[Not completed]
2019-09-26 10:56:30,102 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: new RaftServerImpl for group-E35A4D7B4832:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,103 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,103 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,103 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,103 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,103 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,103 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: ConfigurationManager, init=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,104 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:30,104 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/29937817-920f-4893-a1f3-e35a4d7b4832 does not exist. Creating ...
2019-09-26 10:56:30,116 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/29937817-920f-4893-a1f3-e35a4d7b4832/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,119 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/29937817-920f-4893-a1f3-e35a4d7b4832 has been successfully formatted.
2019-09-26 10:56:30,119 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E35A4D7B4832: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,119 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,120 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,120 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,120 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,120 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,120 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,120 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/29937817-920f-4893-a1f3-e35a4d7b4832
2019-09-26 10:56:30,121 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,121 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,121 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,121 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,121 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,121 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,122 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,122 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,122 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,122 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,122 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,123 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,123 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,123 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,123 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,126 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: start as a follower, conf=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:30,126 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,126 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start FollowerState
2019-09-26 10:56:30,133 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E35A4D7B4832,id=3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:30,154 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 29937817-920f-4893-a1f3-e35a4d7b4832, Nodes: 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,154 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,166 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: addNew group-8B970B6A1EF7:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] returns group-8B970B6A1EF7:java.util.concurrent.CompletableFuture@113e7ce1[Not completed]
2019-09-26 10:56:30,169 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: new RaftServerImpl for group-8B970B6A1EF7:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,169 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,170 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,170 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,170 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,170 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,170 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: ConfigurationManager, init=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,170 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:30,171 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/4d45a6d4-8e8a-4441-b4e3-8b970b6a1ef7 does not exist. Creating ...
2019-09-26 10:56:30,175 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/4d45a6d4-8e8a-4441-b4e3-8b970b6a1ef7/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,180 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/4d45a6d4-8e8a-4441-b4e3-8b970b6a1ef7 has been successfully formatted.
2019-09-26 10:56:30,180 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-8B970B6A1EF7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,180 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,180 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,181 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/4d45a6d4-8e8a-4441-b4e3-8b970b6a1ef7
2019-09-26 10:56:30,181 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,182 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,183 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,183 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,183 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,184 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,187 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: start as a follower, conf=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:30,187 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,187 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start FollowerState
2019-09-26 10:56:30,187 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8B970B6A1EF7,id=3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:30,193 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4d45a6d4-8e8a-4441-b4e3-8b970b6a1ef7, Nodes: 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,193 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,204 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b34661b1-4d86-427f-adca-7a29442b8d39: addNew group-D177CA6AB445:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] returns group-D177CA6AB445:java.util.concurrent.CompletableFuture@652a20ff[Not completed]
2019-09-26 10:56:30,208 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b34661b1-4d86-427f-adca-7a29442b8d39: new RaftServerImpl for group-D177CA6AB445:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,208 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,208 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,210 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,210 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,210 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,210 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: ConfigurationManager, init=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,211 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:30,211 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/21bdefff-6e14-4811-b1a6-d177ca6ab445 does not exist. Creating ...
2019-09-26 10:56:30,214 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/21bdefff-6e14-4811-b1a6-d177ca6ab445/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,272 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/21bdefff-6e14-4811-b1a6-d177ca6ab445 has been successfully formatted.
2019-09-26 10:56:30,286 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D177CA6AB445: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,286 [Thread-221] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket79196.volume91075 implemented by OzoneFileSystem{URI=o3fs://bucket79196.volume91075, workingDir=o3fs://bucket79196.volume91075/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-26 10:56:30,286 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,286 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,287 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,287 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,287 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,287 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,287 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/21bdefff-6e14-4811-b1a6-d177ca6ab445
2019-09-26 10:56:30,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,289 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,289 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,289 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,295 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,298 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,434 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: start as a follower, conf=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:30,435 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,435 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start FollowerState
2019-09-26 10:56:30,435 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-26 10:56:30,436 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D177CA6AB445,id=b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:30,438 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-26 10:56:30,444 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 21bdefff-6e14-4811-b1a6-d177ca6ab445, Nodes: b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,445 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,455 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b34661b1-4d86-427f-adca-7a29442b8d39: addNew group-58E549D56874:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] returns group-58E549D56874:java.util.concurrent.CompletableFuture@5e283d8a[Not completed]
2019-09-26 10:56:30,456 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b34661b1-4d86-427f-adca-7a29442b8d39: new RaftServerImpl for group-58E549D56874:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,456 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,456 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,456 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,457 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,457 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,457 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: ConfigurationManager, init=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,457 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:30,457 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/0ecff0f0-7f08-46d1-8e85-58e549d56874 does not exist. Creating ...
2019-09-26 10:56:30,471 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/0ecff0f0-7f08-46d1-8e85-58e549d56874/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,485 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/0ecff0f0-7f08-46d1-8e85-58e549d56874 has been successfully formatted.
2019-09-26 10:56:30,486 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-58E549D56874: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,486 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,486 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,486 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,486 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,487 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,487 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,487 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/0ecff0f0-7f08-46d1-8e85-58e549d56874
2019-09-26 10:56:30,487 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,487 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,488 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,488 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,488 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,488 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,488 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,489 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,489 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,489 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,489 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,491 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,491 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,491 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,491 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,493 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: start as a follower, conf=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:30,493 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,494 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start FollowerState
2019-09-26 10:56:30,495 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-58E549D56874,id=b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:30,499 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0ecff0f0-7f08-46d1-8e85-58e549d56874, Nodes: b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,500 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,510 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: addNew group-80C2E6C6E1A0:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] returns group-80C2E6C6E1A0:java.util.concurrent.CompletableFuture@61bca031[Not completed]
2019-09-26 10:56:30,512 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: new RaftServerImpl for group-80C2E6C6E1A0:[b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351] with ContainerStateMachine:uninitialized
10:56:30.500 [IPC Server handler 14 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:30,512 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,512 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,512 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,513 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,513 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,513 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: ConfigurationManager, init=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,513 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis] (custom)
2019-09-26 10:56:30,514 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/36e3c65a-c590-446b-a109-80c2e6c6e1a0 does not exist. Creating ...
2019-09-26 10:56:30,527 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/36e3c65a-c590-446b-a109-80c2e6c6e1a0/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,531 [Thread-221] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-26 10:56:30,558 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/36e3c65a-c590-446b-a109-80c2e6c6e1a0 has been successfully formatted.
2019-09-26 10:56:30,559 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-80C2E6C6E1A0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,566 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,566 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,566 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,566 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,567 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/36e3c65a-c590-446b-a109-80c2e6c6e1a0
2019-09-26 10:56:30,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,568 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,568 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,568 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,568 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,573 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,573 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,574 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,583 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: start as a follower, conf=-1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:30,583 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,583 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start FollowerState
2019-09-26 10:56:30,584 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-80C2E6C6E1A0,id=b842eb89-c2cf-49c6-bf64-1aae636704d9
2019-09-26 10:56:30,588 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 36e3c65a-c590-446b-a109-80c2e6c6e1a0, Nodes: b842eb89-c2cf-49c6-bf64-1aae636704d9{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,589 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,589 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,607 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b34661b1-4d86-427f-adca-7a29442b8d39: addNew group-1140DA02B3EB:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] returns group-1140DA02B3EB:java.util.concurrent.CompletableFuture@5e684da5[Not completed]
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b34661b1-4d86-427f-adca-7a29442b8d39: new RaftServerImpl for group-1140DA02B3EB:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,613 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: ConfigurationManager, init=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,614 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:30,614 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/75875cee-d4d7-4591-872d-1140da02b3eb does not exist. Creating ...
2019-09-26 10:56:30,628 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/75875cee-d4d7-4591-872d-1140da02b3eb/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,641 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/75875cee-d4d7-4591-872d-1140da02b3eb has been successfully formatted.
2019-09-26 10:56:30,641 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1140DA02B3EB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,641 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,642 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,642 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,642 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,642 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,642 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,645 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/75875cee-d4d7-4591-872d-1140da02b3eb
2019-09-26 10:56:30,646 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,646 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,646 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,646 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,646 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,647 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,647 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,647 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,647 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,647 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,648 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,648 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,651 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,651 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,652 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,658 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: start as a follower, conf=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:30,658 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,658 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start FollowerState
2019-09-26 10:56:30,659 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1140DA02B3EB,id=b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:30,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 75875cee-d4d7-4591-872d-1140da02b3eb, Nodes: b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,686 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b34661b1-4d86-427f-adca-7a29442b8d39: addNew group-1E67760E2FA3:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] returns group-1E67760E2FA3:java.util.concurrent.CompletableFuture@25f640a5[Not completed]
2019-09-26 10:56:30,687 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b34661b1-4d86-427f-adca-7a29442b8d39: new RaftServerImpl for group-1E67760E2FA3:[b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,688 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: ConfigurationManager, init=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,689 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis] (custom)
2019-09-26 10:56:30,689 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8ec126b3-142a-4315-ae57-1e67760e2fa3 does not exist. Creating ...
2019-09-26 10:56:30,703 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8ec126b3-142a-4315-ae57-1e67760e2fa3/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,716 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8ec126b3-142a-4315-ae57-1e67760e2fa3 has been successfully formatted.
2019-09-26 10:56:30,717 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1E67760E2FA3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,718 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8ec126b3-142a-4315-ae57-1e67760e2fa3
2019-09-26 10:56:30,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,719 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,719 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,719 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,719 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,719 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,720 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,725 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: start as a follower, conf=-1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:30,725 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,725 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start FollowerState
2019-09-26 10:56:30,726 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1E67760E2FA3,id=b34661b1-4d86-427f-adca-7a29442b8d39
2019-09-26 10:56:30,732 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8ec126b3-142a-4315-ae57-1e67760e2fa3, Nodes: b34661b1-4d86-427f-adca-7a29442b8d39{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,732 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,732 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,732 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,741 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: addNew group-506CEC069BF4:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] returns group-506CEC069BF4:java.util.concurrent.CompletableFuture@6761270c[Not completed]
2019-09-26 10:56:30,743 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: new RaftServerImpl for group-506CEC069BF4:[3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,743 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,743 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,744 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,744 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,744 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,744 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: ConfigurationManager, init=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,744 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis] (custom)
2019-09-26 10:56:30,745 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/aebcef6d-9318-4c24-bb60-506cec069bf4 does not exist. Creating ...
2019-09-26 10:56:30,757 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/aebcef6d-9318-4c24-bb60-506cec069bf4/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,772 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/aebcef6d-9318-4c24-bb60-506cec069bf4 has been successfully formatted.
2019-09-26 10:56:30,772 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-506CEC069BF4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,772 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/aebcef6d-9318-4c24-bb60-506cec069bf4
2019-09-26 10:56:30,773 [Thread-221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:56:30,773 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,775 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,775 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,775 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,775 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,775 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,776 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,776 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,776 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,779 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: start as a follower, conf=-1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:30,779 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,779 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start FollowerState
2019-09-26 10:56:30,780 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-506CEC069BF4,id=3a064774-b44e-45fe-8e32-0fdc3e241782
2019-09-26 10:56:30,788 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: aebcef6d-9318-4c24-bb60-506cec069bf4, Nodes: 3a064774-b44e-45fe-8e32-0fdc3e241782{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,788 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,788 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,788 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,789 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,815 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62b65582-e5b2-40ae-adce-12d706872e71: addNew group-42BA11FA4F5F:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] returns group-42BA11FA4F5F:java.util.concurrent.CompletableFuture@2f198dce[Not completed]
2019-09-26 10:56:30,817 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62b65582-e5b2-40ae-adce-12d706872e71: new RaftServerImpl for group-42BA11FA4F5F:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,817 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,820 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,820 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,820 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,820 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,820 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: ConfigurationManager, init=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,821 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:30,821 [Thread-221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:56:30,821 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/9d6e58a9-fa8b-4454-9ce1-42ba11fa4f5f does not exist. Creating ...
2019-09-26 10:56:30,834 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/9d6e58a9-fa8b-4454-9ce1-42ba11fa4f5f/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,847 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/9d6e58a9-fa8b-4454-9ce1-42ba11fa4f5f has been successfully formatted.
2019-09-26 10:56:30,848 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-42BA11FA4F5F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,849 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,849 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/9d6e58a9-fa8b-4454-9ce1-42ba11fa4f5f
2019-09-26 10:56:30,849 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,849 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,849 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,849 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,850 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,850 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,850 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,850 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,850 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,851 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,851 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,851 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,851 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,852 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,852 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,854 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: start as a follower, conf=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:30,855 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,855 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start FollowerState
2019-09-26 10:56:30,855 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-42BA11FA4F5F,id=62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:30,860 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9d6e58a9-fa8b-4454-9ce1-42ba11fa4f5f, Nodes: 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,861 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,861 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,861 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,861 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,870 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62b65582-e5b2-40ae-adce-12d706872e71: addNew group-141B930DDB55:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] returns group-141B930DDB55:java.util.concurrent.CompletableFuture@782a6956[Not completed]
2019-09-26 10:56:30,872 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62b65582-e5b2-40ae-adce-12d706872e71: new RaftServerImpl for group-141B930DDB55:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,873 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: ConfigurationManager, init=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,873 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:30,873 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/47de4b7f-212e-4f8d-95c3-141b930ddb55 does not exist. Creating ...
2019-09-26 10:56:30,886 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/47de4b7f-212e-4f8d-95c3-141b930ddb55/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,899 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/47de4b7f-212e-4f8d-95c3-141b930ddb55 has been successfully formatted.
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-141B930DDB55: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,900 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/47de4b7f-212e-4f8d-95c3-141b930ddb55
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,901 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,902 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,902 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,902 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,902 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,902 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,905 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: start as a follower, conf=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:30,905 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,905 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start FollowerState
2019-09-26 10:56:30,906 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-141B930DDB55,id=62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:30,911 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 47de4b7f-212e-4f8d-95c3-141b930ddb55, Nodes: 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
10:56:30.910 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:30,911 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,911 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,911 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,911 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,920 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62b65582-e5b2-40ae-adce-12d706872e71: addNew group-7AB4DD8F063C:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] returns group-7AB4DD8F063C:java.util.concurrent.CompletableFuture@4b1b7d9c[Not completed]
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62b65582-e5b2-40ae-adce-12d706872e71: new RaftServerImpl for group-7AB4DD8F063C:[62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378] with ContainerStateMachine:uninitialized
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 10:56:30,921 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: ConfigurationManager, init=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null, confs=<EMPTY_MAP>
2019-09-26 10:56:30,922 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis] (custom)
2019-09-26 10:56:30,922 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/d32b1b63-6b54-4204-a181-7ab4dd8f063c does not exist. Creating ...
2019-09-26 10:56:30,952 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/d32b1b63-6b54-4204-a181-7ab4dd8f063c/in_use.lock acquired by nodename 7876@pr-hdds-1569-wvzgm-824869521
2019-09-26 10:56:30,964 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/d32b1b63-6b54-4204-a181-7ab4dd8f063c has been successfully formatted.
2019-09-26 10:56:30,964 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7AB4DD8F063C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/d32b1b63-6b54-4204-a181-7ab4dd8f063c
2019-09-26 10:56:30,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 10:56:30,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 10:56:30,967 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 10:56:30,967 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 10:56:30,967 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 10:56:30,967 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 10:56:30,967 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 10:56:30,969 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: start as a follower, conf=-1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:30,969 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 10:56:30,970 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start FollowerState
2019-09-26 10:56:30,970 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7AB4DD8F063C,id=62b65582-e5b2-40ae-adce-12d706872e71
2019-09-26 10:56:30,977 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d32b1b63-6b54-4204-a181-7ab4dd8f063c, Nodes: 62b65582-e5b2-40ae-adce-12d706872e71{ip: 192.168.30.13, host: pr-hdds-1569-wvzgm-824869521, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 10:56:30,977 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,977 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:30,978 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,978 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,978 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,978 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:30,979 [grpc-default-worker-ELG-3-4] WARN  nio.NioEventLoop (NioEventLoop.java:select(786)) - Selector.select() returned prematurely {} times in a row; rebuilding Selector {}.
2019-09-26 10:56:30,979 [grpc-default-worker-ELG-3-4] INFO  nio.NioEventLoop (NioEventLoop.java:rebuildSelector0(396)) - Migrated 0 channel(s) to the new Selector.
2019-09-26 10:56:30,980 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:30,988 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:30,989 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:30,990 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:30,990 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:30,990 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:30,990 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:30,990 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:30,990 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:30,991 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:31,048 [Thread-221] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-26 10:56:31,048 [Thread-221] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 10:56:31,050 [Thread-221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-26 10:56:31,050 [Thread-221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-26 10:56:31,079 [Thread-221] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 10:56:31,091 [Thread-221] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 10:56:31,095 [Thread-221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:56:31,121 [Thread-221] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 10:56:31,195 [Thread-221] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:8
2019-09-26 10:56:31,332 [Thread-221] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1330272719_0001
2019-09-26 10:56:31,332 [Thread-221] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 10:56:31,539 [Thread-221] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 10:56:31,539 [Thread-221] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1330272719_0001
2019-09-26 10:56:31,540 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1330272719_0001
2019-09-26 10:56:31,547 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 10:56:31,560 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:31,560 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:31,564 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 10:56:31,645 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 10:56:31,647 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:31,699 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:31,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:31,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:31,740 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:1956+1112
2019-09-26 10:56:31,754 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:31,754 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:56:31.791 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:31,794 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
10:56:31.802 [IPC Server handler 10 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:31,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:31,843 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:31,843 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:31,843 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:31,844 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:31,844 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:31,844 [IPC Server handler 0 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:31,844 [IPC Server handler 0 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:31,845 [IPC Server handler 0 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:31,845 [IPC Server handler 0 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:31,846 [IPC Server handler 0 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:31.853 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:31,855 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:31,855 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:32,542 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1330272719_0001 running in uber mode : false
2019-09-26 10:56:32,545 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 10:56:33,277 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - b842eb89-c2cf-49c6-bf64-1aae636704d9:group-8E4407FB1D1B changes to CANDIDATE, lastRpcTime:5172, electionTimeout:5171ms
2019-09-26 10:56:33,283 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown FollowerState
2019-09-26 10:56:33,283 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,288 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderElection
2019-09-26 10:56:33,308 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1: begin an election at term 1 for -1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:33,311 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown LeaderElection
2019-09-26 10:56:33,312 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:33,312 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: change Leader from null to b842eb89-c2cf-49c6-bf64-1aae636704d9 at term 1 for becomeLeader, leader elected after 5335ms
2019-09-26 10:56:33,322 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:33,323 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:33,327 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:33,331 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:33,331 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:33,332 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:33,347 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderState
2019-09-26 10:56:33,374 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:33,383 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B: set configuration 0: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null at 0
2019-09-26 10:56:33,466 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - b34661b1-4d86-427f-adca-7a29442b8d39:group-FFC21BB995B1 changes to CANDIDATE, lastRpcTime:5149, electionTimeout:5147ms
2019-09-26 10:56:33,468 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown FollowerState
2019-09-26 10:56:33,468 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,469 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderElection
2019-09-26 10:56:33,487 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2: begin an election at term 1 for -1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:33,489 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown LeaderElection
2019-09-26 10:56:33,489 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:33,490 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: change Leader from null to b34661b1-4d86-427f-adca-7a29442b8d39 at term 1 for becomeLeader, leader elected after 5194ms
2019-09-26 10:56:33,491 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:33,492 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:33,492 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:33,492 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:33,493 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:33,493 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:33,496 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c:group-12DBE144E63C changes to CANDIDATE, lastRpcTime:5031, electionTimeout:5031ms
2019-09-26 10:56:33,496 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown FollowerState
2019-09-26 10:56:33,496 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,496 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderElection
2019-09-26 10:56:33,503 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderState
2019-09-26 10:56:33,503 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:33,504 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1: set configuration 0: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null at 0
2019-09-26 10:56:33,516 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3: begin an election at term 1 for -1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:33,516 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown LeaderElection
2019-09-26 10:56:33,516 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:33,516 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: change Leader from null to b286dd73-ae46-4ddf-9a85-2d36f42ec21c at term 1 for becomeLeader, leader elected after 5098ms
2019-09-26 10:56:33,518 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:33,518 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:33,518 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:33,518 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:33,519 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:33,519 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:33,522 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderState
2019-09-26 10:56:33,523 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:33,523 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C: set configuration 0: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null at 0
2019-09-26 10:56:33,606 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c:group-E64F531F18D8 changes to CANDIDATE, lastRpcTime:5067, electionTimeout:5067ms
2019-09-26 10:56:33,607 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown FollowerState
2019-09-26 10:56:33,607 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,607 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderElection
2019-09-26 10:56:33,647 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - b842eb89-c2cf-49c6-bf64-1aae636704d9:group-3847C4EFF424 changes to CANDIDATE, lastRpcTime:5029, electionTimeout:5009ms
2019-09-26 10:56:33,651 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown FollowerState
2019-09-26 10:56:33,651 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,651 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderElection
2019-09-26 10:56:33,665 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4: begin an election at term 1 for -1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:33,665 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5: begin an election at term 1 for -1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:33,665 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-12DBE144E63C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/f9fcc9e8-2c67-4a19-b17a-12dbe144e63c/current/log_inprogress_0
2019-09-26 10:56:33,665 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-8E4407FB1D1B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f79a8463-e8b1-49f5-9198-8e4407fb1d1b/current/log_inprogress_0
2019-09-26 10:56:33,665 [b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-FFC21BB995B1-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8cb764f1-87ed-4288-9c8f-ffc21bb995b1/current/log_inprogress_0
2019-09-26 10:56:33,665 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown LeaderElection
2019-09-26 10:56:33,665 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown LeaderElection
2019-09-26 10:56:33,666 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:33,666 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:33,666 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: change Leader from null to b842eb89-c2cf-49c6-bf64-1aae636704d9 at term 1 for becomeLeader, leader elected after 5059ms
2019-09-26 10:56:33,666 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: change Leader from null to b286dd73-ae46-4ddf-9a85-2d36f42ec21c at term 1 for becomeLeader, leader elected after 5138ms
2019-09-26 10:56:33,666 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:33,666 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:33,666 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:33,666 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:33,667 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:33,667 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:33,667 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:33,667 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:33,667 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:33,667 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:33,667 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:33,668 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:33,672 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderState
2019-09-26 10:56:33,672 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderState
2019-09-26 10:56:33,672 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:33,672 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:33,673 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424: set configuration 0: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null at 0
2019-09-26 10:56:33,673 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8: set configuration 0: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null at 0
2019-09-26 10:56:33,734 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-E64F531F18D8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/d2df34a2-a4ae-4aa9-bcba-e64f531f18d8/current/log_inprogress_0
2019-09-26 10:56:33,734 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-3847C4EFF424-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/f7d4a1bc-acc9-4fa2-900a-3847c4eff424/current/log_inprogress_0
2019-09-26 10:56:33,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:33,784 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:33,785 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:33,785 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:33,785 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:33,785 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:33,786 [IPC Server handler 0 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:33,786 [IPC Server handler 0 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:33,787 [IPC Server handler 0 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:33,787 [IPC Server handler 0 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:33,787 [IPC Server handler 0 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:33.791 [IPC Server handler 10 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:33,792 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:33,792 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:33,874 [Thread-226] INFO  impl.FollowerState (FollowerState.java:run(106)) - 3a064774-b44e-45fe-8e32-0fdc3e241782:group-399F8A7BA38C changes to CANDIDATE, lastRpcTime:5169, electionTimeout:5169ms
2019-09-26 10:56:33,874 [Thread-226] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown FollowerState
2019-09-26 10:56:33,875 [Thread-226] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,875 [Thread-226] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderElection
2019-09-26 10:56:33,895 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6: begin an election at term 1 for -1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:33,895 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown LeaderElection
2019-09-26 10:56:33,895 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:33,895 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: change Leader from null to 3a064774-b44e-45fe-8e32-0fdc3e241782 at term 1 for becomeLeader, leader elected after 5205ms
2019-09-26 10:56:33,897 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:33,897 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:33,898 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:33,898 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:33,898 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:33,898 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:33,902 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderState
2019-09-26 10:56:33,902 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:33,903 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C: set configuration 0: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null at 0
2019-09-26 10:56:33,957 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-399F8A7BA38C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/c8a0b2f8-3d0f-4517-8aaa-399f8a7ba38c/current/log_inprogress_0
2019-09-26 10:56:33,992 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62b65582-e5b2-40ae-adce-12d706872e71:group-4BAD357627F8 changes to CANDIDATE, lastRpcTime:5092, electionTimeout:5092ms
2019-09-26 10:56:33,992 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown FollowerState
2019-09-26 10:56:33,993 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:33,993 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderElection
2019-09-26 10:56:33,998 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62b65582-e5b2-40ae-adce-12d706872e71:group-5D777DA71282 changes to CANDIDATE, lastRpcTime:5028, electionTimeout:5024ms
2019-09-26 10:56:34,002 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown FollowerState
2019-09-26 10:56:34,002 [Thread-232] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,002 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderElection
2019-09-26 10:56:34,014 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7: begin an election at term 1 for -1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:34,014 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8: begin an election at term 1 for -1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:34,014 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown LeaderElection
2019-09-26 10:56:34,014 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown LeaderElection
2019-09-26 10:56:34,014 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,014 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,015 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: change Leader from null to 62b65582-e5b2-40ae-adce-12d706872e71 at term 1 for becomeLeader, leader elected after 5126ms
2019-09-26 10:56:34,015 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: change Leader from null to 62b65582-e5b2-40ae-adce-12d706872e71 at term 1 for becomeLeader, leader elected after 5055ms
2019-09-26 10:56:34,016 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,017 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,017 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,017 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,017 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,017 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,017 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,018 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,018 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,018 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,018 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,018 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,024 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderState
2019-09-26 10:56:34,025 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,025 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8: set configuration 0: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null at 0
2019-09-26 10:56:34,064 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderState
2019-09-26 10:56:34,064 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,065 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282: set configuration 0: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null at 0
2019-09-26 10:56:34,106 [62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-4BAD357627F8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/6695f25e-4ea9-4989-900e-4bad357627f8/current/log_inprogress_0
2019-09-26 10:56:34,110 [Thread-235] INFO  impl.FollowerState (FollowerState.java:run(106)) - b842eb89-c2cf-49c6-bf64-1aae636704d9:group-275ADCECAB09 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5080ms
2019-09-26 10:56:34,111 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown FollowerState
2019-09-26 10:56:34,111 [Thread-235] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,111 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderElection
2019-09-26 10:56:34,118 [62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-5D777DA71282-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/e0fdce01-65c0-45d3-b159-5d777da71282/current/log_inprogress_0
2019-09-26 10:56:34,121 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9: begin an election at term 1 for -1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:34,122 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown LeaderElection
2019-09-26 10:56:34,122 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,122 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: change Leader from null to b842eb89-c2cf-49c6-bf64-1aae636704d9 at term 1 for becomeLeader, leader elected after 5099ms
2019-09-26 10:56:34,122 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,122 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,123 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,123 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,123 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,123 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,126 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderState
2019-09-26 10:56:34,127 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,127 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09: set configuration 0: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null at 0
2019-09-26 10:56:34,179 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-275ADCECAB09-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/b0d35f81-b93a-4e03-b8ea-275adcecab09/current/log_inprogress_0
2019-09-26 10:56:34,232 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(106)) - 3a064774-b44e-45fe-8e32-0fdc3e241782:group-926367C19667 changes to CANDIDATE, lastRpcTime:5043, electionTimeout:5043ms
2019-09-26 10:56:34,232 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown FollowerState
2019-09-26 10:56:34,233 [Thread-242] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,233 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderElection
2019-09-26 10:56:34,251 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10: begin an election at term 1 for -1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:34,252 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown LeaderElection
2019-09-26 10:56:34,252 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,252 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: change Leader from null to 3a064774-b44e-45fe-8e32-0fdc3e241782 at term 1 for becomeLeader, leader elected after 5071ms
2019-09-26 10:56:34,252 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,252 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,252 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,253 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,253 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,253 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,256 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderState
2019-09-26 10:56:34,256 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,257 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667: set configuration 0: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null at 0
2019-09-26 10:56:34,296 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c:group-42B2C4F9BA28 changes to CANDIDATE, lastRpcTime:5190, electionTimeout:5160ms
2019-09-26 10:56:34,296 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown FollowerState
2019-09-26 10:56:34,296 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,297 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderElection
2019-09-26 10:56:34,309 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-926367C19667-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/08dc7d8e-d522-4292-96b0-926367c19667/current/log_inprogress_0
2019-09-26 10:56:34,309 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11: begin an election at term 1 for -1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:34,309 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown LeaderElection
2019-09-26 10:56:34,309 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,309 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: change Leader from null to b286dd73-ae46-4ddf-9a85-2d36f42ec21c at term 1 for becomeLeader, leader elected after 5212ms
2019-09-26 10:56:34,310 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,310 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,310 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,310 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,310 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,311 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,314 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderState
2019-09-26 10:56:34,314 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,315 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28: set configuration 0: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null at 0
2019-09-26 10:56:34,362 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-42B2C4F9BA28-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4f6471d8-31e9-4cc0-81e5-42b2c4f9ba28/current/log_inprogress_0
2019-09-26 10:56:34,419 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(106)) - b34661b1-4d86-427f-adca-7a29442b8d39:group-13727138B3AA changes to CANDIDATE, lastRpcTime:5161, electionTimeout:5161ms
2019-09-26 10:56:34,419 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown FollowerState
2019-09-26 10:56:34,419 [Thread-245] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,420 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderElection
2019-09-26 10:56:34,439 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12: begin an election at term 1 for -1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:34,440 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown LeaderElection
2019-09-26 10:56:34,440 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,440 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: change Leader from null to b34661b1-4d86-427f-adca-7a29442b8d39 at term 1 for becomeLeader, leader elected after 5190ms
2019-09-26 10:56:34,440 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,440 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,440 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,441 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,441 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,441 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,444 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderState
2019-09-26 10:56:34,444 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,445 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA: set configuration 0: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null at 0
2019-09-26 10:56:34,499 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(106)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c:group-A15010B9AE3F changes to CANDIDATE, lastRpcTime:5177, electionTimeout:5177ms
2019-09-26 10:56:34,500 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown FollowerState
2019-09-26 10:56:34,500 [Thread-248] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,500 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderElection
2019-09-26 10:56:34,505 [b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-13727138B3AA-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/99b33a62-9444-49a0-af2b-13727138b3aa/current/log_inprogress_0
2019-09-26 10:56:34,519 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13: begin an election at term 1 for -1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:34,519 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown LeaderElection
2019-09-26 10:56:34,520 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,520 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: change Leader from null to b286dd73-ae46-4ddf-9a85-2d36f42ec21c at term 1 for becomeLeader, leader elected after 5205ms
2019-09-26 10:56:34,520 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,520 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,521 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,521 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,521 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,521 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,524 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderState
2019-09-26 10:56:34,525 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,525 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F: set configuration 0: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null at 0
2019-09-26 10:56:34,570 [Thread-252] INFO  impl.FollowerState (FollowerState.java:run(106)) - 3a064774-b44e-45fe-8e32-0fdc3e241782:group-320B53A7B547 changes to CANDIDATE, lastRpcTime:5173, electionTimeout:5142ms
2019-09-26 10:56:34,570 [Thread-252] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown FollowerState
2019-09-26 10:56:34,571 [Thread-252] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,571 [Thread-252] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderElection
2019-09-26 10:56:34,580 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-A15010B9AE3F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/10556c59-e8d8-4239-bb23-a15010b9ae3f/current/log_inprogress_0
2019-09-26 10:56:34,580 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14: begin an election at term 1 for -1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:34,581 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown LeaderElection
2019-09-26 10:56:34,581 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,581 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: change Leader from null to 3a064774-b44e-45fe-8e32-0fdc3e241782 at term 1 for becomeLeader, leader elected after 5195ms
2019-09-26 10:56:34,581 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,582 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,582 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,582 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,582 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,582 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,585 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderState
2019-09-26 10:56:34,586 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,586 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(106)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c:group-2CE50B69927B changes to CANDIDATE, lastRpcTime:5111, electionTimeout:5111ms
2019-09-26 10:56:34,586 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547: set configuration 0: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null at 0
2019-09-26 10:56:34,586 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown FollowerState
2019-09-26 10:56:34,627 [Thread-259] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62b65582-e5b2-40ae-adce-12d706872e71:group-037BE885AA28 changes to CANDIDATE, lastRpcTime:5101, electionTimeout:5081ms
2019-09-26 10:56:34,627 [Thread-256] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,627 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown FollowerState
2019-09-26 10:56:34,627 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderElection
2019-09-26 10:56:34,627 [Thread-259] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,628 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderElection
2019-09-26 10:56:34,632 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(106)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c:group-999861FBDC8C changes to CANDIDATE, lastRpcTime:5050, electionTimeout:5048ms
2019-09-26 10:56:34,636 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown FollowerState
2019-09-26 10:56:34,636 [Thread-262] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:34,636 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderElection
2019-09-26 10:56:34,642 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-320B53A7B547-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/d426e516-893a-42d9-9ab8-320b53a7b547/current/log_inprogress_0
2019-09-26 10:56:34,642 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15: begin an election at term 1 for -1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:34,642 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16: begin an election at term 1 for -1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:34,643 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown LeaderElection
2019-09-26 10:56:34,643 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown LeaderElection
2019-09-26 10:56:34,643 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,643 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,643 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: change Leader from null to b286dd73-ae46-4ddf-9a85-2d36f42ec21c at term 1 for becomeLeader, leader elected after 5181ms
2019-09-26 10:56:34,643 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: change Leader from null to 62b65582-e5b2-40ae-adce-12d706872e71 at term 1 for becomeLeader, leader elected after 5124ms
2019-09-26 10:56:34,643 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,644 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,644 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,644 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,644 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,644 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,644 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,644 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,645 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,645 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,645 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,645 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,648 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderState
2019-09-26 10:56:34,649 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,649 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderState
2019-09-26 10:56:34,649 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,649 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B: set configuration 0: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null at 0
2019-09-26 10:56:34,689 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17: begin an election at term 1 for -1: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null
2019-09-26 10:56:34,689 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28: set configuration 0: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null at 0
2019-09-26 10:56:34,689 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: shutdown LeaderElection
2019-09-26 10:56:34,733 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-2CE50B69927B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/4a0f43c5-7323-4a1c-9d3a-2ce50b69927b/current/log_inprogress_0
2019-09-26 10:56:34,733 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:34,733 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: change Leader from null to b286dd73-ae46-4ddf-9a85-2d36f42ec21c at term 1 for becomeLeader, leader elected after 5159ms
2019-09-26 10:56:34,734 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:34,734 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:34,734 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:34,734 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:34,734 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:34,735 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:34,738 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c: start LeaderState
2019-09-26 10:56:34,738 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:34,738 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C: set configuration 0: [b286dd73-ae46-4ddf-9a85-2d36f42ec21c:192.168.30.13:35382], old=null at 0
2019-09-26 10:56:34,780 [62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-037BE885AA28-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/350d3942-3410-43dd-9427-037be885aa28/current/log_inprogress_0
2019-09-26 10:56:34,792 [b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b286dd73-ae46-4ddf-9a85-2d36f42ec21c@group-999861FBDC8C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-2/data/ratis/54c4c10b-fc32-4e76-a477-999861fbdc8c/current/log_inprogress_0
2019-09-26 10:56:35,040 [Thread-266] INFO  impl.FollowerState (FollowerState.java:run(106)) - b842eb89-c2cf-49c6-bf64-1aae636704d9:group-728D05CEA1F8 changes to CANDIDATE, lastRpcTime:5017, electionTimeout:5017ms
2019-09-26 10:56:35,040 [Thread-266] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown FollowerState
2019-09-26 10:56:35,041 [Thread-266] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,041 [Thread-266] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderElection
2019-09-26 10:56:35,061 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18: begin an election at term 1 for -1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:35,062 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown LeaderElection
2019-09-26 10:56:35,062 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,062 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: change Leader from null to b842eb89-c2cf-49c6-bf64-1aae636704d9 at term 1 for becomeLeader, leader elected after 5049ms
2019-09-26 10:56:35,062 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,062 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,063 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,063 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,063 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,063 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,066 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderState
2019-09-26 10:56:35,067 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,067 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8: set configuration 0: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null at 0
2019-09-26 10:56:35,111 [Thread-269] INFO  impl.FollowerState (FollowerState.java:run(106)) - b842eb89-c2cf-49c6-bf64-1aae636704d9:group-43E2B41C5EAE changes to CANDIDATE, lastRpcTime:5035, electionTimeout:5014ms
2019-09-26 10:56:35,111 [Thread-269] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown FollowerState
2019-09-26 10:56:35,111 [Thread-269] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,111 [Thread-269] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderElection
2019-09-26 10:56:35,124 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-728D05CEA1F8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/802e654b-9e20-4cf4-9947-728d05cea1f8/current/log_inprogress_0
2019-09-26 10:56:35,124 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19: begin an election at term 1 for -1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:35,124 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown LeaderElection
2019-09-26 10:56:35,124 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,124 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: change Leader from null to b842eb89-c2cf-49c6-bf64-1aae636704d9 at term 1 for becomeLeader, leader elected after 5056ms
2019-09-26 10:56:35,125 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,125 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,125 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,125 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,126 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,126 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,129 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderState
2019-09-26 10:56:35,130 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,130 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE: set configuration 0: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null at 0
2019-09-26 10:56:35,184 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-43E2B41C5EAE-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/a1900c93-05bc-4a06-b557-43e2b41c5eae/current/log_inprogress_0
2019-09-26 10:56:35,222 [Thread-272] INFO  impl.FollowerState (FollowerState.java:run(106)) - 3a064774-b44e-45fe-8e32-0fdc3e241782:group-E35A4D7B4832 changes to CANDIDATE, lastRpcTime:5095, electionTimeout:5089ms
2019-09-26 10:56:35,222 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown FollowerState
2019-09-26 10:56:35,222 [Thread-272] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,222 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderElection
2019-09-26 10:56:35,252 [Thread-276] INFO  impl.FollowerState (FollowerState.java:run(106)) - 3a064774-b44e-45fe-8e32-0fdc3e241782:group-8B970B6A1EF7 changes to CANDIDATE, lastRpcTime:5064, electionTimeout:5064ms
2019-09-26 10:56:35,252 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown FollowerState
2019-09-26 10:56:35,252 [Thread-276] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,252 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderElection
2019-09-26 10:56:35,259 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20: begin an election at term 1 for -1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:35,259 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown LeaderElection
2019-09-26 10:56:35,259 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,259 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21: begin an election at term 1 for -1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:35,259 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: change Leader from null to 3a064774-b44e-45fe-8e32-0fdc3e241782 at term 1 for becomeLeader, leader elected after 5140ms
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown LeaderElection
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: change Leader from null to 3a064774-b44e-45fe-8e32-0fdc3e241782 at term 1 for becomeLeader, leader elected after 5079ms
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,260 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,261 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,262 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,265 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderState
2019-09-26 10:56:35,265 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderState
2019-09-26 10:56:35,265 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,265 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,266 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832: set configuration 0: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null at 0
2019-09-26 10:56:35,266 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7: set configuration 0: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null at 0
2019-09-26 10:56:35,330 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-8B970B6A1EF7-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/4d45a6d4-8e8a-4441-b4e3-8b970b6a1ef7/current/log_inprogress_0
2019-09-26 10:56:35,330 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-E35A4D7B4832-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/29937817-920f-4893-a1f3-e35a4d7b4832/current/log_inprogress_0
2019-09-26 10:56:35,443 [Thread-282] INFO  impl.FollowerState (FollowerState.java:run(106)) - b34661b1-4d86-427f-adca-7a29442b8d39:group-D177CA6AB445 changes to CANDIDATE, lastRpcTime:5007, electionTimeout:5007ms
2019-09-26 10:56:35,443 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown FollowerState
2019-09-26 10:56:35,443 [Thread-282] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,444 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderElection
2019-09-26 10:56:35,459 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22: begin an election at term 1 for -1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:35,460 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown LeaderElection
2019-09-26 10:56:35,460 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,460 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: change Leader from null to b34661b1-4d86-427f-adca-7a29442b8d39 at term 1 for becomeLeader, leader elected after 5173ms
2019-09-26 10:56:35,460 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,460 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,461 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,461 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,461 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,461 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,464 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderState
2019-09-26 10:56:35,465 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,465 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445: set configuration 0: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null at 0
2019-09-26 10:56:35,517 [b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-D177CA6AB445-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/21bdefff-6e14-4811-b1a6-d177ca6ab445/current/log_inprogress_0
2019-09-26 10:56:35,622 [Thread-286] INFO  impl.FollowerState (FollowerState.java:run(106)) - b34661b1-4d86-427f-adca-7a29442b8d39:group-58E549D56874 changes to CANDIDATE, lastRpcTime:5127, electionTimeout:5126ms
2019-09-26 10:56:35,622 [Thread-286] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown FollowerState
2019-09-26 10:56:35,622 [Thread-286] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,622 [Thread-286] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderElection
2019-09-26 10:56:35,625 [Thread-294] INFO  impl.FollowerState (FollowerState.java:run(106)) - b842eb89-c2cf-49c6-bf64-1aae636704d9:group-80C2E6C6E1A0 changes to CANDIDATE, lastRpcTime:5041, electionTimeout:5041ms
2019-09-26 10:56:35,625 [Thread-294] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown FollowerState
2019-09-26 10:56:35,625 [Thread-294] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,626 [Thread-294] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderElection
2019-09-26 10:56:35,639 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24: begin an election at term 1 for -1: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null
2019-09-26 10:56:35,639 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23: begin an election at term 1 for -1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:35,639 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: shutdown LeaderElection
2019-09-26 10:56:35,640 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown LeaderElection
2019-09-26 10:56:35,640 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,640 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,640 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: change Leader from null to b842eb89-c2cf-49c6-bf64-1aae636704d9 at term 1 for becomeLeader, leader elected after 5074ms
2019-09-26 10:56:35,640 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: change Leader from null to b34661b1-4d86-427f-adca-7a29442b8d39 at term 1 for becomeLeader, leader elected after 5154ms
2019-09-26 10:56:35,641 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,641 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,641 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,641 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,641 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,642 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,642 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,642 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,642 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,642 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,643 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,643 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,647 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b842eb89-c2cf-49c6-bf64-1aae636704d9: start LeaderState
2019-09-26 10:56:35,647 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,648 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0: set configuration 0: [b842eb89-c2cf-49c6-bf64-1aae636704d9:192.168.30.13:39351], old=null at 0
2019-09-26 10:56:35,690 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderState
2019-09-26 10:56:35,690 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,691 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874: set configuration 0: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null at 0
2019-09-26 10:56:35,731 [b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b842eb89-c2cf-49c6-bf64-1aae636704d9@group-80C2E6C6E1A0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-0/data/ratis/36e3c65a-c590-446b-a109-80c2e6c6e1a0/current/log_inprogress_0
2019-09-26 10:56:35,743 [b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-58E549D56874-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/0ecff0f0-7f08-46d1-8e85-58e549d56874/current/log_inprogress_0
2019-09-26 10:56:35,804 [Thread-305] INFO  impl.FollowerState (FollowerState.java:run(106)) - b34661b1-4d86-427f-adca-7a29442b8d39:group-1140DA02B3EB changes to CANDIDATE, lastRpcTime:5145, electionTimeout:5145ms
2019-09-26 10:56:35,804 [Thread-305] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown FollowerState
2019-09-26 10:56:35,804 [Thread-305] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,804 [Thread-305] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderElection
2019-09-26 10:56:35,821 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25: begin an election at term 1 for -1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:35,821 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown LeaderElection
2019-09-26 10:56:35,821 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,821 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: change Leader from null to b34661b1-4d86-427f-adca-7a29442b8d39 at term 1 for becomeLeader, leader elected after 5179ms
2019-09-26 10:56:35,821 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,822 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,822 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,822 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,822 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,822 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,826 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderState
2019-09-26 10:56:35,826 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,827 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB: set configuration 0: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null at 0
2019-09-26 10:56:35,881 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1140DA02B3EB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/75875cee-d4d7-4591-872d-1140da02b3eb/current/log_inprogress_0
2019-09-26 10:56:35,892 [Thread-312] INFO  impl.FollowerState (FollowerState.java:run(106)) - b34661b1-4d86-427f-adca-7a29442b8d39:group-1E67760E2FA3 changes to CANDIDATE, lastRpcTime:5166, electionTimeout:5166ms
2019-09-26 10:56:35,892 [Thread-312] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown FollowerState
2019-09-26 10:56:35,892 [Thread-312] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,893 [Thread-312] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderElection
2019-09-26 10:56:35,908 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26: begin an election at term 1 for -1: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null
2019-09-26 10:56:35,908 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b34661b1-4d86-427f-adca-7a29442b8d39: shutdown LeaderElection
2019-09-26 10:56:35,908 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,908 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: change Leader from null to b34661b1-4d86-427f-adca-7a29442b8d39 at term 1 for becomeLeader, leader elected after 5191ms
2019-09-26 10:56:35,909 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,909 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,909 [Thread-315] INFO  impl.FollowerState (FollowerState.java:run(106)) - 3a064774-b44e-45fe-8e32-0fdc3e241782:group-506CEC069BF4 changes to CANDIDATE, lastRpcTime:5129, electionTimeout:5129ms
2019-09-26 10:56:35,909 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,909 [Thread-315] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown FollowerState
2019-09-26 10:56:35,909 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,910 [Thread-315] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,910 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,910 [Thread-315] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderElection
2019-09-26 10:56:35,910 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,915 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b34661b1-4d86-427f-adca-7a29442b8d39: start LeaderState
2019-09-26 10:56:35,915 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,916 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3: set configuration 0: [b34661b1-4d86-427f-adca-7a29442b8d39:192.168.30.13:32886], old=null at 0
2019-09-26 10:56:35,954 [Thread-325] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62b65582-e5b2-40ae-adce-12d706872e71:group-42BA11FA4F5F changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5087ms
2019-09-26 10:56:35,955 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27: begin an election at term 1 for -1: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null
2019-09-26 10:56:35,955 [Thread-325] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown FollowerState
2019-09-26 10:56:35,955 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: shutdown LeaderElection
2019-09-26 10:56:35,955 [Thread-325] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:35,955 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:35,955 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: change Leader from null to 3a064774-b44e-45fe-8e32-0fdc3e241782 at term 1 for becomeLeader, leader elected after 5183ms
2019-09-26 10:56:35,955 [Thread-325] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderElection
2019-09-26 10:56:35,956 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:35,956 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:35,958 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:35,958 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:35,958 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:35,959 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:35,962 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3a064774-b44e-45fe-8e32-0fdc3e241782: start LeaderState
2019-09-26 10:56:35,962 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:35,963 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4: set configuration 0: [3a064774-b44e-45fe-8e32-0fdc3e241782:192.168.30.13:38957], old=null at 0
2019-09-26 10:56:36,005 [Thread-328] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62b65582-e5b2-40ae-adce-12d706872e71:group-141B930DDB55 changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5093ms
2019-09-26 10:56:36,005 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown FollowerState
2019-09-26 10:56:36,005 [b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b34661b1-4d86-427f-adca-7a29442b8d39@group-1E67760E2FA3-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-1/data/ratis/8ec126b3-142a-4315-ae57-1e67760e2fa3/current/log_inprogress_0
2019-09-26 10:56:36,005 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28: begin an election at term 1 for -1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:36,005 [Thread-328] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:36,006 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown LeaderElection
2019-09-26 10:56:36,006 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderElection
2019-09-26 10:56:36,006 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:36,006 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: change Leader from null to 62b65582-e5b2-40ae-adce-12d706872e71 at term 1 for becomeLeader, leader elected after 5158ms
2019-09-26 10:56:36,006 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:36,009 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:36,009 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:36,009 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:36,009 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:36,009 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:36,012 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderState
2019-09-26 10:56:36,013 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:36,013 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F: set configuration 0: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null at 0
2019-09-26 10:56:36,057 [Thread-334] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62b65582-e5b2-40ae-adce-12d706872e71:group-7AB4DD8F063C changes to CANDIDATE, lastRpcTime:5087, electionTimeout:5056ms
2019-09-26 10:56:36,057 [3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 3a064774-b44e-45fe-8e32-0fdc3e241782@group-506CEC069BF4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-3/data/ratis/aebcef6d-9318-4c24-bb60-506cec069bf4/current/log_inprogress_0
2019-09-26 10:56:36,057 [Thread-334] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown FollowerState
2019-09-26 10:56:36,057 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29: begin an election at term 1 for -1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:36,057 [Thread-334] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 10:56:36,058 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown LeaderElection
2019-09-26 10:56:36,058 [Thread-334] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderElection
2019-09-26 10:56:36,058 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:36,058 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: change Leader from null to 62b65582-e5b2-40ae-adce-12d706872e71 at term 1 for becomeLeader, leader elected after 5158ms
2019-09-26 10:56:36,059 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:36,061 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:36,061 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:36,061 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:36,061 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:36,062 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:36,065 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderState
2019-09-26 10:56:36,065 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:36,066 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55: set configuration 0: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null at 0
2019-09-26 10:56:36,101 [62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-42BA11FA4F5F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/9d6e58a9-fa8b-4454-9ce1-42ba11fa4f5f/current/log_inprogress_0
2019-09-26 10:56:36,101 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30: begin an election at term 1 for -1: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null
2019-09-26 10:56:36,102 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62b65582-e5b2-40ae-adce-12d706872e71: shutdown LeaderElection
2019-09-26 10:56:36,102 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 10:56:36,102 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: change Leader from null to 62b65582-e5b2-40ae-adce-12d706872e71 at term 1 for becomeLeader, leader elected after 5137ms
2019-09-26 10:56:36,102 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 10:56:36,102 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 10:56:36,102 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 10:56:36,103 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 10:56:36,103 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 10:56:36,103 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 10:56:36,106 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62b65582-e5b2-40ae-adce-12d706872e71: start LeaderState
2019-09-26 10:56:36,106 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 10:56:36,107 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C: set configuration 0: [62b65582-e5b2-40ae-adce-12d706872e71:192.168.30.13:40378], old=null at 0
2019-09-26 10:56:36,146 [62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-141B930DDB55-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/47de4b7f-212e-4f8d-95c3-141b930ddb55/current/log_inprogress_0
2019-09-26 10:56:36,159 [62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62b65582-e5b2-40ae-adce-12d706872e71@group-7AB4DD8F063C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-834d649f-86f3-4bd0-be0c-475154a92267/datanode-4/data/ratis/d32b1b63-6b54-4204-a181-7ab4dd8f063c/current/log_inprogress_0
2019-09-26 10:56:36,664 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:36,669 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:36,670 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:36,670 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:36,670 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:36,671 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:36,671 [IPC Server handler 0 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:36,671 [IPC Server handler 0 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:36,672 [IPC Server handler 0 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:36,676 [IPC Server handler 0 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:36,676 [IPC Server handler 0 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:36.679 [IPC Server handler 10 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:36,681 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000000_0
2019-09-26 10:56:36,681 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:36,682 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:56:36,689 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000001_0
2019-09-26 10:56:36,694 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:36,694 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:36,695 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:36,697 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:0+324
2019-09-26 10:56:36,697 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:36,698 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:56:36.719 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:36,721 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
10:56:36.729 [IPC Server handler 7 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:36,746 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:36,758 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1330272719_0001_m_000001_0 is done. And is in the process of committing
2019-09-26 10:56:36,760 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:36,760 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1330272719_0001_m_000001_0 is allowed to commit now
2019-09-26 10:56:36,762 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1330272719_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/_logs
2019-09-26 10:56:36,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-26 10:56:36,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1330272719_0001_m_000001_0' done.
2019-09-26 10:56:36,767 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1330272719_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=208165
		FILE: Number of bytes written=822611
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:36,767 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1330272719_0001_m_000001_0
2019-09-26 10:56:36,767 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:36,778 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:36,778 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:36,778 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:36,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:324+290
2019-09-26 10:56:36,780 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:36,780 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:36,801 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
10:56:36.809 [IPC Server handler 9 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:36,810 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:36,814 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:36,816 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:36,816 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:36,816 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:36,817 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:36,817 [IPC Server handler 18 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:36,817 [IPC Server handler 18 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:36,818 [IPC Server handler 18 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:36,818 [IPC Server handler 18 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:36,818 [IPC Server handler 18 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:36.823 [IPC Server handler 0 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:36,824 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:36,824 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:37,572 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 10:56:38,550 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:38,555 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:38,555 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:38,556 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:38,556 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:38,556 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:38,556 [IPC Server handler 11 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:38,557 [IPC Server handler 11 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:38,557 [IPC Server handler 11 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:38,558 [IPC Server handler 11 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:38,558 [IPC Server handler 11 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:38.561 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:38,563 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:38,563 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:43,721 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-26 10:56:44,106 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:44,112 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:44,112 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:44,112 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:44,113 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:44,113 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:44,113 [IPC Server handler 11 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:44,113 [IPC Server handler 11 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:44,114 [IPC Server handler 11 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:44,114 [IPC Server handler 11 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:44,115 [IPC Server handler 11 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:44.119 [IPC Server handler 1 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:44,120 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1330272719_0001_m_000002_0
2019-09-26 10:56:44,121 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:44,121 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:56:44,122 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000003_0
2019-09-26 10:56:44,124 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,124 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,124 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:44,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:614+278
2019-09-26 10:56:44,128 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,128 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,150 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
10:56:44.159 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:44,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,166 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1330272719_0001_m_000003_0 is done. And is in the process of committing
2019-09-26 10:56:44,167 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,167 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1330272719_0001_m_000003_0 is allowed to commit now
2019-09-26 10:56:44,169 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1330272719_0001_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/_logs
2019-09-26 10:56:44,170 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-26 10:56:44,170 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1330272719_0001_m_000003_0' done.
2019-09-26 10:56:44,171 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1330272719_0001_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=216979
		FILE: Number of bytes written=822627
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=18
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:44,171 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1330272719_0001_m_000003_0
2019-09-26 10:56:44,171 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000004_0
2019-09-26 10:56:44,172 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,172 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,173 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:44,174 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:1416+278
2019-09-26 10:56:44,175 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,175 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,195 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
10:56:44.202 [IPC Server handler 17 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:44,208 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,208 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1330272719_0001_m_000004_0 is done. And is in the process of committing
2019-09-26 10:56:44,209 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1330272719_0001_m_000004_0 is allowed to commit now
2019-09-26 10:56:44,211 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1330272719_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/_logs
2019-09-26 10:56:44,212 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-26 10:56:44,217 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1330272719_0001_m_000004_0' done.
2019-09-26 10:56:44,218 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1330272719_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=220874
		FILE: Number of bytes written=822635
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=20
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:44,218 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1330272719_0001_m_000004_0
2019-09-26 10:56:44,219 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000005_0
2019-09-26 10:56:44,220 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,220 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,220 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:44,222 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:892+262
2019-09-26 10:56:44,222 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,223 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,242 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-26 10:56:44,277 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,278 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1330272719_0001_m_000005_0 is done. And is in the process of committing
2019-09-26 10:56:44,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1330272719_0001_m_000005_0 is allowed to commit now
2019-09-26 10:56:44,281 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1330272719_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/_logs
2019-09-26 10:56:44,282 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-26 10:56:44,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1330272719_0001_m_000005_0' done.
2019-09-26 10:56:44,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1330272719_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=224769
		FILE: Number of bytes written=822643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=22
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:44,284 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1330272719_0001_m_000005_0
2019-09-26 10:56:44,284 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000006_0
2019-09-26 10:56:44,285 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,285 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:44,287 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:1154+262
2019-09-26 10:56:44,288 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,288 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,305 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-26 10:56:44,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,319 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1330272719_0001_m_000006_0 is done. And is in the process of committing
2019-09-26 10:56:44,320 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,320 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1330272719_0001_m_000006_0 is allowed to commit now
2019-09-26 10:56:44,322 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1330272719_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/_logs
2019-09-26 10:56:44,323 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-26 10:56:44,323 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1330272719_0001_m_000006_0' done.
2019-09-26 10:56:44,323 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1330272719_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=228664
		FILE: Number of bytes written=822651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=24
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:44,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1330272719_0001_m_000006_0
2019-09-26 10:56:44,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1330272719_0001_m_000007_0
2019-09-26 10:56:44,325 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,325 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,325 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:44,327 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/fileList.seq:1694+262
2019-09-26 10:56:44,327 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:44,328 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:44,344 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
10:56:44.351 [IPC Server handler 4 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91075, bucket=bucket79196, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91075 bucket: bucket79196 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:44,362 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,362 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1330272719_0001_m_000007_0 is done. And is in the process of committing
2019-09-26 10:56:44,363 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:44,364 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1330272719_0001_m_000007_0 is allowed to commit now
2019-09-26 10:56:44,365 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1330272719_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059/_logs
2019-09-26 10:56:44,366 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-26 10:56:44,366 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1330272719_0001_m_000007_0' done.
2019-09-26 10:56:44,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1330272719_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=232047
		FILE: Number of bytes written=822659
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=26
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:44,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1330272719_0001_m_000007_0
2019-09-26 10:56:44,367 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 10:56:44,408 [Thread-371] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000660457694/.staging/_distcp-973375059
2019-09-26 10:56:44,410 [Thread-371] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1330272719_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket79196.volume91075/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:56:44,577 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1330272719_0001 failed with state FAILED due to: NA
2019-09-26 10:56:44,666 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=1544070
		FILE: Number of bytes written=5758445
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=136
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=83
	Map-Reduce Framework
		Map input records=7
		Map output records=0
		Input split bytes=1099
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=14408482816
	File Input Format Counters 
		Bytes Read=21868
	File Output Format Counters 
		Bytes Written=56
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
]]></system-err>
  </testcase>
  <testcase name="testTrackDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="20.837">
    <error message="DistCp failure: Job job_local2046994200_0002 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local2046994200_0002 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testTrackDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-26 10:56:44,749 [Thread-479] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 10:56:44,786 [Thread-479] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume17973, with user36105 as owner.
2019-09-26 10:56:44,796 [IPC Server handler 4 on 37534] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume17973 for user:user36105
2019-09-26 10:56:44,801 [Thread-479] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume17973/bucket62715, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 10:56:44,873 [Thread-479] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket62715.volume17973 implemented by OzoneFileSystem{URI=o3fs://bucket62715.volume17973, workingDir=o3fs://bucket62715.volume17973/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 33 read ops, 0 large read ops, 14 write ops}
10:56:44.901 [IPC Server handler 14 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:44,905 [Thread-479] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-26 10:56:45,021 [Thread-479] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:56:45,034 [Thread-479] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
10:56:45.051 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:45,142 [Thread-479] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-26 10:56:45,143 [Thread-479] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 10:56:45,158 [Thread-479] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 10:56:45,171 [Thread-479] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 10:56:45,173 [Thread-479] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:56:45,194 [Thread-479] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 10:56:45,262 [Thread-479] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-26 10:56:45,314 [Thread-479] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local2046994200_0002
2019-09-26 10:56:45,314 [Thread-479] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 10:56:45,429 [Thread-479] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 10:56:45,430 [Thread-479] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local2046994200_0002
2019-09-26 10:56:45,433 [Thread-543] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 10:56:45,433 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local2046994200_0002
2019-09-26 10:56:45,433 [Thread-543] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:45,433 [Thread-543] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:45,434 [Thread-543] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 10:56:45,458 [Thread-543] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 10:56:45,458 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:45,459 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:45,459 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:45,460 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:45,461 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:2234+562
2019-09-26 10:56:45,461 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:45,461 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:56:45.484 [IPC Server handler 10 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:45,486 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
10:56:45.493 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:45,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:45,498 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:45,498 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:45,498 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:45,498 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:45,498 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:45,499 [IPC Server handler 12 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:45,499 [IPC Server handler 12 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:45,499 [IPC Server handler 12 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:45,500 [IPC Server handler 12 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:45,500 [IPC Server handler 12 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:45.502 [IPC Server handler 4 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:45,504 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:45,504 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:46,434 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local2046994200_0002 running in uber mode : false
2019-09-26 10:56:46,434 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 10:56:46,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:46,634 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:46,634 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:46,635 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:46,635 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:46,635 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:46,635 [IPC Server handler 0 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:46,636 [IPC Server handler 0 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:46,639 [IPC Server handler 0 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:46,639 [IPC Server handler 0 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:46,640 [IPC Server handler 0 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:46.643 [IPC Server handler 9 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:46,645 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:46,645 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:48,786 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-26 10:56:48,987 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:48,991 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:48,991 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:48,991 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:48,992 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:48,992 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:48,992 [IPC Server handler 11 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:48,992 [IPC Server handler 11 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:48,993 [IPC Server handler 11 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:48,993 [IPC Server handler 11 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:48,994 [IPC Server handler 11 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:48.997 [IPC Server handler 10 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:48,998 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000000_0
2019-09-26 10:56:48,999 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:48,999 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:56:49,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000001_0
2019-09-26 10:56:49,002 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:49,002 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:49,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:49,004 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:0+323
2019-09-26 10:56:49,004 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:49,005 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:56:49.024 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:49,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
10:56:49.034 [IPC Server handler 7 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:49,040 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:49,041 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2046994200_0002_m_000001_0 is done. And is in the process of committing
2019-09-26 10:56:49,042 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:49,042 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2046994200_0002_m_000001_0 is allowed to commit now
2019-09-26 10:56:49,044 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2046994200_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/_logs
2019-09-26 10:56:49,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-26 10:56:49,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2046994200_0002_m_000001_0' done.
2019-09-26 10:56:49,046 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2046994200_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=440745
		FILE: Number of bytes written=1645535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=44
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=21
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:49,046 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2046994200_0002_m_000001_0
2019-09-26 10:56:49,046 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:49,047 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:49,047 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:49,047 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:49,048 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:323+289
2019-09-26 10:56:49,049 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:49,049 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:49,068 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
10:56:49.076 [IPC Server handler 9 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:49,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:49,080 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:49,083 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:49,083 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:49,083 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:49,083 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:49,084 [IPC Server handler 12 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:49,084 [IPC Server handler 12 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:49,084 [IPC Server handler 12 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:49,085 [IPC Server handler 12 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:49,085 [IPC Server handler 12 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:49.088 [IPC Server handler 0 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:49,089 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:49,089 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:49,436 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 10:56:50,244 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:50,248 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:50,248 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:50,249 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:50,249 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:50,249 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:50,249 [IPC Server handler 16 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:50,250 [IPC Server handler 16 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:50,250 [IPC Server handler 16 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:50,251 [IPC Server handler 16 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:50,251 [IPC Server handler 16 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:50.255 [IPC Server handler 1 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:50,256 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:50,256 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:53,714 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:53,718 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:53,718 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:53,719 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:53,719 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:53,719 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:53,719 [IPC Server handler 18 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:53,720 [IPC Server handler 18 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:53,720 [IPC Server handler 18 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:53,720 [IPC Server handler 18 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:53,721 [IPC Server handler 18 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:53.724 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:53,725 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000002_0
2019-09-26 10:56:53,726 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:53,726 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:56:53,727 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:53,729 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:53,729 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:53,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:53,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:889+289
2019-09-26 10:56:53,732 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:53,732 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:53,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
10:56:53.761 [IPC Server handler 19 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:53,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:53,766 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:53,766 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:53,766 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:53,766 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:53,766 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:53,767 [IPC Server handler 11 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:53,767 [IPC Server handler 11 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:53,767 [IPC Server handler 11 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:53,768 [IPC Server handler 11 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:53,768 [IPC Server handler 11 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:53.771 [IPC Server handler 18 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:53,773 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:53,773 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:54,788 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-26 10:56:55,660 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:55,664 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:55,664 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:55,664 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:55,665 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:55,665 [IPC Server handler 18 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:55,665 [IPC Server handler 18 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:55,665 [IPC Server handler 18 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:55,666 [IPC Server handler 18 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:55,666 [IPC Server handler 18 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:55,666 [IPC Server handler 18 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:55.669 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:55,671 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:55,671 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:57,480 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-26 10:56:58,442 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-26 10:56:58,969 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:58,973 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:58,973 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:58,974 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:58,974 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:58,974 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:58,974 [IPC Server handler 12 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:58,975 [IPC Server handler 12 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:58,975 [IPC Server handler 12 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:58,976 [IPC Server handler 12 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:58,976 [IPC Server handler 12 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:58.979 [IPC Server handler 10 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:58,981 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000003_0
2019-09-26 10:56:58,981 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:58,981 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:56:58,982 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000004_0
2019-09-26 10:56:58,983 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:58,983 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:58,984 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:58,985 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:612+277
2019-09-26 10:56:58,985 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:58,986 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,003 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
10:56:59.010 [IPC Server handler 7 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:59,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2046994200_0002_m_000004_0 is done. And is in the process of committing
2019-09-26 10:56:59,016 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,016 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2046994200_0002_m_000004_0 is allowed to commit now
2019-09-26 10:56:59,018 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2046994200_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/_logs
2019-09-26 10:56:59,018 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-26 10:56:59,019 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2046994200_0002_m_000004_0' done.
2019-09-26 10:56:59,019 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2046994200_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=454315
		FILE: Number of bytes written=1645559
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=56
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:59,019 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2046994200_0002_m_000004_0
2019-09-26 10:56:59,019 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000005_0
2019-09-26 10:56:59,020 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,020 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,021 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:59,022 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:1696+277
2019-09-26 10:56:59,023 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,023 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,040 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
10:56:59.047 [IPC Server handler 9 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:59,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2046994200_0002_m_000005_0 is done. And is in the process of committing
2019-09-26 10:56:59,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2046994200_0002_m_000005_0 is allowed to commit now
2019-09-26 10:56:59,055 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2046994200_0002_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/_logs
2019-09-26 10:56:59,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-26 10:56:59,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2046994200_0002_m_000005_0' done.
2019-09-26 10:56:59,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2046994200_0002_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=458497
		FILE: Number of bytes written=1645567
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=58
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:59,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2046994200_0002_m_000005_0
2019-09-26 10:56:59,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000006_0
2019-09-26 10:56:59,057 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,057 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:59,059 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:1178+261
2019-09-26 10:56:59,059 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,059 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 10:56:59,115 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2046994200_0002_m_000006_0 is done. And is in the process of committing
2019-09-26 10:56:59,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2046994200_0002_m_000006_0 is allowed to commit now
2019-09-26 10:56:59,118 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2046994200_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/_logs
2019-09-26 10:56:59,119 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 10:56:59,119 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2046994200_0002_m_000006_0' done.
2019-09-26 10:56:59,119 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2046994200_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=462679
		FILE: Number of bytes written=1645575
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=60
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:59,119 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2046994200_0002_m_000006_0
2019-09-26 10:56:59,120 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000007_0
2019-09-26 10:56:59,121 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,121 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,121 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:59,123 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:1973+261
2019-09-26 10:56:59,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 10:56:59,153 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,153 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2046994200_0002_m_000007_0 is done. And is in the process of committing
2019-09-26 10:56:59,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2046994200_0002_m_000007_0 is allowed to commit now
2019-09-26 10:56:59,155 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2046994200_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/_logs
2019-09-26 10:56:59,156 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 10:56:59,156 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2046994200_0002_m_000007_0' done.
2019-09-26 10:56:59,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2046994200_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=466349
		FILE: Number of bytes written=1645583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=62
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:59,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2046994200_0002_m_000007_0
2019-09-26 10:56:59,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000008_0
2019-09-26 10:56:59,157 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,158 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,158 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:59,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:2796+261
2019-09-26 10:56:59,159 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,159 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,176 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
10:56:59.183 [IPC Server handler 17 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:59,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2046994200_0002_m_000008_0 is done. And is in the process of committing
2019-09-26 10:56:59,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:56:59,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2046994200_0002_m_000008_0 is allowed to commit now
2019-09-26 10:56:59,191 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2046994200_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/_logs
2019-09-26 10:56:59,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-26 10:56:59,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2046994200_0002_m_000008_0' done.
2019-09-26 10:56:59,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2046994200_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=470019
		FILE: Number of bytes written=1645591
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=64
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:56:59,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2046994200_0002_m_000008_0
2019-09-26 10:56:59,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2046994200_0002_m_000009_0
2019-09-26 10:56:59,193 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,193 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,193 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:56:59,194 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456/fileList.seq:1439+257
2019-09-26 10:56:59,194 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:56:59,195 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:56:59,211 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
10:56:59.219 [IPC Server handler 14 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:59,220 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
2019-09-26 10:56:59,228 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:56:59,231 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:56:59,231 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:56:59,231 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:56:59,232 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:56:59,232 [IPC Server handler 16 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:56:59,232 [IPC Server handler 16 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:59,246 [IPC Server handler 16 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:56:59,246 [IPC Server handler 16 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:56:59,247 [IPC Server handler 16 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:56:59.250 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:56:59,252 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
2019-09-26 10:56:59,252 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:56:59,443 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 10:57:01,065 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-26 10:57:01,190 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
2019-09-26 10:57:01,195 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:01,195 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:01,195 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:01,195 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:01,196 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:01,196 [IPC Server handler 16 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:01,196 [IPC Server handler 16 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:01,197 [IPC Server handler 16 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:01,198 [IPC Server handler 16 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:01,198 [IPC Server handler 16 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:01.201 [IPC Server handler 14 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:01,203 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
2019-09-26 10:57:01,203 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:01,445 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 75% reduce 0%
2019-09-26 10:57:04,533 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
2019-09-26 10:57:04,537 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:04,537 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:04,537 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:04,538 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:04,538 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:04,538 [IPC Server handler 17 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:04,538 [IPC Server handler 17 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:04,539 [IPC Server handler 17 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:04,540 [IPC Server handler 17 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:04,540 [IPC Server handler 17 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:04.543 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17973, bucket=bucket62715, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17973 bucket: bucket62715 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:04,544 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2046994200_0002_m_000009_0
2019-09-26 10:57:04,544 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:04,545 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:04,546 [Thread-543] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 10:57:04,572 [Thread-543] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10004048463/.staging/_distcp1975974456
2019-09-26 10:57:04,574 [Thread-543] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local2046994200_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket62715.volume17973/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:05,448 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local2046994200_0002 failed with state FAILED due to: NA
2019-09-26 10:57:05,519 [Thread-479] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=3676426
		FILE: Number of bytes written=13164560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=464
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=252
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1240
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16466837504
	File Input Format Counters 
		Bytes Read=24904
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
  </testcase>
  <testcase name="largeFilesToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="11.793">
    <error message="DistCp failure: Job job_local1894691876_0003 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1894691876_0003 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:534)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFilesToRemote(AbstractContractDistCpTest.java:452)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-26 10:57:05,583 [Thread-591] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 10:57:05,616 [Thread-591] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume53524, with user95158 as owner.
2019-09-26 10:57:05,619 [IPC Server handler 17 on 37534] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume53524 for user:user95158
2019-09-26 10:57:05,625 [Thread-591] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume53524/bucket82231, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 10:57:05,703 [Thread-591] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket82231.volume53524 implemented by OzoneFileSystem{URI=o3fs://bucket82231.volume53524, workingDir=o3fs://bucket82231.volume53524/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 76 read ops, 0 large read ops, 40 write ops}
10:57:05.728 [IPC Server handler 2 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:05,737 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-26 10:57:05,740 [Thread-591] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-26 10:57:05,749 [Thread-591] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-26 10:57:05,924 [Thread-591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:57:05,935 [Thread-591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
10:57:05.951 [IPC Server handler 3 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:05,994 [Thread-591] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-26 10:57:05,999 [Thread-591] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 10:57:06,014 [Thread-591] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-26 10:57:06,029 [Thread-591] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-26 10:57:06,031 [Thread-591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:57:06,042 [Thread-591] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 10:57:06,112 [Thread-591] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-26 10:57:06,188 [Thread-591] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1894691876_0003
2019-09-26 10:57:06,189 [Thread-591] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 10:57:06,303 [Thread-591] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 10:57:06,311 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 10:57:06,312 [Thread-591] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1894691876_0003
2019-09-26 10:57:06,312 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1894691876_0003
2019-09-26 10:57:06,312 [Thread-639] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:06,312 [Thread-639] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:06,313 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 10:57:06,333 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 10:57:06,333 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:06,334 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:06,335 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:06,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:06,338 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001481106887/.staging/_distcp676394388/fileList.seq:0+771
2019-09-26 10:57:06,340 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:06,341 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:57:06.364 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:06,365 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
10:57:06.374 [IPC Server handler 15 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:06,379 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
10:57:06.386 [IPC Server handler 17 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:06,388 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:06,393 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:06,393 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:06,393 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:06,394 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:06,394 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:06,394 [IPC Server handler 17 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:06,394 [IPC Server handler 17 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:06,395 [IPC Server handler 17 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:06,395 [IPC Server handler 17 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:06,395 [IPC Server handler 17 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:06.398 [IPC Server handler 16 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:06,399 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:06,401 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:07,313 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1894691876_0003 running in uber mode : false
2019-09-26 10:57:07,313 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 10:57:09,014 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:09,018 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:09,018 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:09,019 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:09,019 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:09,019 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:09,019 [IPC Server handler 16 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:09,020 [IPC Server handler 16 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:09,020 [IPC Server handler 16 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:09,021 [IPC Server handler 16 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:09,021 [IPC Server handler 16 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:09.024 [IPC Server handler 15 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:09,025 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:09,026 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:11,202 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-26 10:57:11,952 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:11,955 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:11,955 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:11,955 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:11,955 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:11,956 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:11,956 [IPC Server handler 12 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:11,956 [IPC Server handler 12 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:11,957 [IPC Server handler 12 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:11,957 [IPC Server handler 12 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:11,957 [IPC Server handler 12 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:11.960 [IPC Server handler 15 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:11,960 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000000_0
2019-09-26 10:57:11,961 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:11,961 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:11,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:11,963 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:11,963 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:11,964 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:11,965 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001481106887/.staging/_distcp676394388/fileList.seq:771+235
2019-09-26 10:57:11,965 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:11,965 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:11,984 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
10:57:11.991 [IPC Server handler 18 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:11,992 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:11,994 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:11,994 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:11,995 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:11,995 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:11,995 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:11,995 [IPC Server handler 16 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:11,996 [IPC Server handler 16 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:11,996 [IPC Server handler 16 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:11,997 [IPC Server handler 16 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:11,997 [IPC Server handler 16 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:11.999 [IPC Server handler 19 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:12,000 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:12,000 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:13,885 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:13,891 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:13,891 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:13,891 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:13,892 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:13,892 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:13,892 [IPC Server handler 12 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:13,892 [IPC Server handler 12 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:13,893 [IPC Server handler 12 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:13,893 [IPC Server handler 12 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:13,894 [IPC Server handler 12 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:13.897 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:13,899 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:13,899 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:17,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:17,195 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:17,195 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:17,195 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:17,196 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:17,196 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:17,196 [IPC Server handler 17 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:17,196 [IPC Server handler 17 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:17,197 [IPC Server handler 17 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:17,197 [IPC Server handler 17 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:17,197 [IPC Server handler 17 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:17.201 [IPC Server handler 13 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume53524, bucket=bucket82231, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume53524 bucket: bucket82231 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:17,202 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1894691876_0003_m_000001_0
2019-09-26 10:57:17,202 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:17,203 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:17,204 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 10:57:17,222 [Thread-639] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001481106887/.staging/_distcp676394388
2019-09-26 10:57:17,225 [Thread-639] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1894691876_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82231.volume53524/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:17,321 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1894691876_0003 failed with state FAILED due to: NA
2019-09-26 10:57:17,321 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 0
]]></system-out>
  </testcase>
  <testcase name="testLargeFilesFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.226">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:528)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testLargeFilesFromRemote(AbstractContractDistCpTest.java:464)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-26 10:57:17,379 [Thread-656] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 10:57:17,417 [Thread-656] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume69750, with user69975 as owner.
2019-09-26 10:57:17,419 [IPC Server handler 15 on 37534] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume69750 for user:user69975
2019-09-26 10:57:17,423 [Thread-656] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume69750/bucket90995, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 10:57:17,505 [Thread-656] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket90995.volume69750 implemented by OzoneFileSystem{URI=o3fs://bucket90995.volume69750, workingDir=o3fs://bucket90995.volume69750/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 98 read ops, 0 large read ops, 54 write ops}
10:57:17.534 [IPC Server handler 0 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume69750, bucket=bucket90995, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume69750 bucket: bucket90995 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:17,538 [Thread-656] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-26 10:57:17,541 [Thread-656] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-26 10:57:17,557 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:17,558 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:17,558 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:17,558 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:17,558 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:17,559 [IPC Server handler 2 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:17,559 [IPC Server handler 2 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:17,560 [IPC Server handler 2 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:17,560 [IPC Server handler 2 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:17,560 [IPC Server handler 2 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
]]></system-out>
  </testcase>
  <testcase name="testUpdateDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="25.599">
    <error message="DistCp failure: Job job_local1600518908_0004 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1600518908_0004 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-26 10:57:17,630 [Thread-661] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume31658, with user19432 as owner.
2019-09-26 10:57:17,632 [IPC Server handler 11 on 37534] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume31658 for user:user19432
2019-09-26 10:57:17,634 [Thread-661] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume31658/bucket66574, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 10:57:17,690 [Thread-661] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket66574.volume31658 implemented by OzoneFileSystem{URI=o3fs://bucket66574.volume31658, workingDir=o3fs://bucket66574.volume31658/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 104 read ops, 0 large read ops, 57 write ops}
10:57:17.712 [IPC Server handler 16 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:17,716 [Thread-661] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-26 10:57:17,805 [Thread-661] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:57:17,815 [Thread-661] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
10:57:17.828 [IPC Server handler 17 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:17,901 [Thread-661] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-26 10:57:17,903 [Thread-661] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 10:57:17,913 [Thread-661] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 10:57:17,923 [Thread-661] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 10:57:17,925 [Thread-661] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 10:57:17,933 [Thread-661] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 10:57:17,986 [Thread-661] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-26 10:57:18,022 [Thread-661] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1600518908_0004
2019-09-26 10:57:18,022 [Thread-661] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 10:57:18,119 [Thread-661] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 10:57:18,119 [Thread-661] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1600518908_0004
2019-09-26 10:57:18,122 [Thread-724] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 10:57:18,122 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1600518908_0004
2019-09-26 10:57:18,122 [Thread-724] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:18,122 [Thread-724] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:18,123 [Thread-724] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 10:57:18,151 [Thread-724] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 10:57:18,151 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:18,152 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:18,152 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:18,153 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:18,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:2210+580
2019-09-26 10:57:18,154 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:18,154 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:57:18.177 [IPC Server handler 19 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:18,179 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
10:57:18.186 [IPC Server handler 14 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:18,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:18,191 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:18,191 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:18,191 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:18,191 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:18,191 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:18,192 [IPC Server handler 17 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:18,192 [IPC Server handler 17 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:18,192 [IPC Server handler 17 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:18,193 [IPC Server handler 17 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:18,193 [IPC Server handler 17 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:18.195 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:18,196 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:18,196 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:18,344 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 > map
2019-09-26 10:57:19,123 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1600518908_0004 running in uber mode : false
2019-09-26 10:57:19,123 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 10:57:20,526 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:20,530 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:20,531 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:20,531 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:20,532 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:20,532 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:20,532 [IPC Server handler 2 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:20,532 [IPC Server handler 2 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:20,533 [IPC Server handler 2 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:20,533 [IPC Server handler 2 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:20,534 [IPC Server handler 2 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:20.537 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:20,539 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:20,539 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:23,587 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:23,591 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:23,591 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:23,591 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:23,591 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:23,592 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:23,592 [IPC Server handler 0 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:23,592 [IPC Server handler 0 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:23,593 [IPC Server handler 0 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:23,593 [IPC Server handler 0 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:23,593 [IPC Server handler 0 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:23.596 [IPC Server handler 4 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:23,598 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000000_0
2019-09-26 10:57:23,598 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:23,599 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:23,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000001_0
2019-09-26 10:57:23,613 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:23,613 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:23,614 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:23,616 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:0+324
2019-09-26 10:57:23,617 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:23,617 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
10:57:23.637 [IPC Server handler 6 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:23,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
10:57:23.647 [IPC Server handler 9 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:23,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:23,653 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1600518908_0004_m_000001_0 is done. And is in the process of committing
2019-09-26 10:57:23,653 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:23,653 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1600518908_0004_m_000001_0 is allowed to commit now
2019-09-26 10:57:23,655 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1600518908_0004_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/_logs
2019-09-26 10:57:23,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-26 10:57:23,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1600518908_0004_m_000001_0' done.
2019-09-26 10:57:23,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1600518908_0004_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=874440
		FILE: Number of bytes written=12793484
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=115
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=64
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1996488704
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:57:23,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1600518908_0004_m_000001_0
2019-09-26 10:57:23,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:23,657 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:23,657 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:23,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:23,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:1642+290
2019-09-26 10:57:23,659 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:23,659 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:23,676 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
10:57:23.682 [IPC Server handler 2 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:23,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:23,686 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:23,690 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:23,690 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:23,690 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:23,691 [IPC Server handler 11 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:23,691 [IPC Server handler 11 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:23,691 [IPC Server handler 11 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:23,692 [IPC Server handler 11 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:23,692 [IPC Server handler 11 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:23,692 [IPC Server handler 11 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:23.694 [IPC Server handler 3 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:23,696 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:23,696 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:23,972 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-26 10:57:24,126 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 10:57:26,408 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:26,411 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:26,412 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:26,412 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:26,412 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:26,412 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:26,413 [IPC Server handler 2 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:26,413 [IPC Server handler 2 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:26,414 [IPC Server handler 2 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:26,415 [IPC Server handler 2 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:26,415 [IPC Server handler 2 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:26.418 [IPC Server handler 12 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:26,419 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:26,419 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:30,162 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-26 10:57:30,929 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:30,933 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:30,934 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:30,934 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:30,934 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:30,934 [IPC Server handler 16 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:30,934 [IPC Server handler 16 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:30,935 [IPC Server handler 16 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:30,935 [IPC Server handler 16 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:30,936 [IPC Server handler 16 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:30,936 [IPC Server handler 16 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:30.938 [IPC Server handler 14 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:30,940 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000002_0
2019-09-26 10:57:30,940 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:30,940 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:30,941 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000003_0
2019-09-26 10:57:30,942 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:30,942 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:30,943 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:30,943 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:1932+278
2019-09-26 10:57:30,944 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:30,944 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:30,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
10:57:30.967 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:30,971 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:30,971 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1600518908_0004_m_000003_0 is done. And is in the process of committing
2019-09-26 10:57:30,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:30,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1600518908_0004_m_000003_0 is allowed to commit now
2019-09-26 10:57:30,973 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1600518908_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/_logs
2019-09-26 10:57:30,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-26 10:57:30,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1600518908_0004_m_000003_0' done.
2019-09-26 10:57:30,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1600518908_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=883870
		FILE: Number of bytes written=12793500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=122
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1996488704
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:57:30,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1600518908_0004_m_000003_0
2019-09-26 10:57:30,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000004_0
2019-09-26 10:57:30,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:30,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:30,975 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:30,976 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:2790+278
2019-09-26 10:57:30,976 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:30,976 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:30,990 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
10:57:30.996 [IPC Server handler 7 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:30,999 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:31,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1600518908_0004_m_000004_0 is done. And is in the process of committing
2019-09-26 10:57:31,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:31,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1600518908_0004_m_000004_0 is allowed to commit now
2019-09-26 10:57:31,001 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1600518908_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/_logs
2019-09-26 10:57:31,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-26 10:57:31,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1600518908_0004_m_000004_0' done.
2019-09-26 10:57:31,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1600518908_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=888073
		FILE: Number of bytes written=12793508
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=124
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1996488704
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:57:31,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1600518908_0004_m_000004_0
2019-09-26 10:57:31,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:31,003 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:31,003 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:31,003 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:31,004 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:1106+274
2019-09-26 10:57:31,004 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:31,005 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:31,018 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
10:57:31.024 [IPC Server handler 9 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:31,025 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:31,027 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:31,030 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:31,030 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:31,030 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:31,030 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:31,031 [IPC Server handler 17 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:31,031 [IPC Server handler 17 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:31,031 [IPC Server handler 17 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:31,032 [IPC Server handler 17 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:31,032 [IPC Server handler 17 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:31.033 [IPC Server handler 8 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:31,034 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:31,034 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:33,068 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:33,072 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:33,072 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:33,073 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:33,073 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:33,073 [IPC Server handler 2 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:33,073 [IPC Server handler 2 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:33,074 [IPC Server handler 2 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:33,075 [IPC Server handler 2 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:33,075 [IPC Server handler 2 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:33,075 [IPC Server handler 2 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:33.078 [IPC Server handler 1 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:33,080 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:33,080 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:35,675 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-26 10:57:36,133 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-26 10:57:36,588 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:36,592 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:36,592 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:36,593 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:36,593 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:36,593 [IPC Server handler 0 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:36,593 [IPC Server handler 0 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:36,594 [IPC Server handler 0 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:36,594 [IPC Server handler 0 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:36,595 [IPC Server handler 0 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:36,595 [IPC Server handler 0 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:36.597 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:36,599 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000005_0
2019-09-26 10:57:36,599 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:36,600 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:36,601 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000006_0
2019-09-26 10:57:36,602 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,602 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,603 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:36,604 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:582+262
2019-09-26 10:57:36,604 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,605 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,625 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 10:57:36,636 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:36,636 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1600518908_0004_m_000006_0 is done. And is in the process of committing
2019-09-26 10:57:36,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:36,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1600518908_0004_m_000006_0 is allowed to commit now
2019-09-26 10:57:36,639 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1600518908_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/_logs
2019-09-26 10:57:36,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 10:57:36,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1600518908_0004_m_000006_0' done.
2019-09-26 10:57:36,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1600518908_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=896479
		FILE: Number of bytes written=12793524
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=131
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1996488704
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:57:36,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1600518908_0004_m_000006_0
2019-09-26 10:57:36,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000007_0
2019-09-26 10:57:36,641 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,641 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:36,642 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:844+262
2019-09-26 10:57:36,642 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,642 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,663 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 10:57:36,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:36,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1600518908_0004_m_000007_0 is done. And is in the process of committing
2019-09-26 10:57:36,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:36,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1600518908_0004_m_000007_0 is allowed to commit now
2019-09-26 10:57:36,680 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1600518908_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/_logs
2019-09-26 10:57:36,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 10:57:36,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1600518908_0004_m_000007_0' done.
2019-09-26 10:57:36,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1600518908_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=900170
		FILE: Number of bytes written=12793532
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=133
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1996488704
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:57:36,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1600518908_0004_m_000007_0
2019-09-26 10:57:36,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000008_0
2019-09-26 10:57:36,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,683 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:36,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:1380+262
2019-09-26 10:57:36,684 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,685 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
10:57:36.708 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:36,711 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:36,712 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1600518908_0004_m_000008_0 is done. And is in the process of committing
2019-09-26 10:57:36,713 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 10:57:36,713 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1600518908_0004_m_000008_0 is allowed to commit now
2019-09-26 10:57:36,714 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1600518908_0004_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/_logs
2019-09-26 10:57:36,715 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-26 10:57:36,715 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1600518908_0004_m_000008_0' done.
2019-09-26 10:57:36,715 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1600518908_0004_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=903861
		FILE: Number of bytes written=12793540
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=135
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1996488704
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 10:57:36,716 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1600518908_0004_m_000008_0
2019-09-26 10:57:36,716 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:36,716 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,717 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,717 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 10:57:36,718 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485/fileList.seq:324+258
2019-09-26 10:57:36,718 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 10:57:36,719 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 10:57:36,733 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
10:57:36.740 [IPC Server handler 7 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:36,741 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:36,744 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:36,747 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:36,747 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:36,747 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:36,747 [IPC Server handler 12 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:36,748 [IPC Server handler 12 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:36,748 [IPC Server handler 12 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:36,749 [IPC Server handler 12 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:36,749 [IPC Server handler 12 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:36,749 [IPC Server handler 12 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:36.751 [IPC Server handler 6 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:36,753 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:36,753 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:37,134 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 10:57:39,441 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:39,444 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:39,445 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:39,445 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:39,445 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:39,445 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:39,446 [IPC Server handler 8 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:39,446 [IPC Server handler 8 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:39,446 [IPC Server handler 8 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:39,447 [IPC Server handler 8 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:39,447 [IPC Server handler 8 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:39.450 [IPC Server handler 5 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:39,451 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:39,451 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:41,677 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-26 10:57:42,137 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 75% reduce 0%
2019-09-26 10:57:42,942 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:42,949 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:42,950 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:42,950 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:42,950 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:42,951 [IPC Server handler 17 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:42,951 [IPC Server handler 17 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:42,951 [IPC Server handler 17 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:42,952 [IPC Server handler 17 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:42,953 [IPC Server handler 17 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:42,953 [IPC Server handler 17 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
10:57:42.957 [IPC Server handler 0 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31658, bucket=bucket66574, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31658 bucket: bucket66574 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:42,959 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1600518908_0004_m_000009_0
2019-09-26 10:57:42,960 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 10:57:42,961 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:42,963 [Thread-724] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 10:57:42,979 [Thread-724] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000547586336/.staging/_distcp559402485
2019-09-26 10:57:42,981 [Thread-724] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1600518908_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket66574.volume31658/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 10:57:43,010 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-26 10:57:43,138 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 85% reduce 0%
2019-09-26 10:57:43,139 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1600518908_0004 failed with state FAILED due to: NA
2019-09-26 10:57:43,145 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=8041152
		FILE: Number of bytes written=115141676
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1162
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=662
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Input split bytes=1404
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=17968398336
	File Input Format Counters 
		Bytes Read=28116
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
  </testcase>
  <testcase name="testDeepDirectoryStructureFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.182">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:488)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testDeepDirectoryStructureFromRemote(AbstractContractDistCpTest.java:458)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-26 10:57:43,210 [Thread-778] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 10:57:43,243 [Thread-778] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume76007, with user94502 as owner.
2019-09-26 10:57:43,246 [IPC Server handler 9 on 37534] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume76007 for user:user94502
2019-09-26 10:57:43,250 [Thread-778] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume76007/bucket40962, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 10:57:43,303 [Thread-778] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket40962.volume76007 implemented by OzoneFileSystem{URI=o3fs://bucket40962.volume76007, workingDir=o3fs://bucket40962.volume76007/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 147 read ops, 0 large read ops, 83 write ops}
10:57:43.326 [IPC Server handler 11 on 37534] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume76007, bucket=bucket40962, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume76007 bucket: bucket40962 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 10:57:43,329 [Thread-778] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-26 10:57:43,337 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b842eb89-c2cf-49c6-bf64-1aae636704d9 Heaviness: 6 limit: 5
2019-09-26 10:57:43,337 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 62b65582-e5b2-40ae-adce-12d706872e71 Heaviness: 6 limit: 5
2019-09-26 10:57:43,337 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 3a064774-b44e-45fe-8e32-0fdc3e241782 Heaviness: 6 limit: 5
2019-09-26 10:57:43,337 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b286dd73-ae46-4ddf-9a85-2d36f42ec21c Heaviness: 6 limit: 5
2019-09-26 10:57:43,338 [IPC Server handler 8 on 44642] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode b34661b1-4d86-427f-adca-7a29442b8d39 Heaviness: 6 limit: 5
2019-09-26 10:57:43,338 [IPC Server handler 8 on 44642] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 10:57:43,338 [IPC Server handler 8 on 44642] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:43,338 [IPC Server handler 8 on 44642] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 10:57:43,339 [IPC Server handler 8 on 44642] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 10:57:43,339 [IPC Server handler 8 on 44642] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
]]></system-out>
  </testcase>
</testsuite>
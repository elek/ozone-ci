2019-09-25 11:59:12,406 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:12,534 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:12,538 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:12,557 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @963ms
2019-09-25 11:59:12,669 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-25 11:59:12,670 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-25 11:59:12,670 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-25 11:59:12,671 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-25 11:59:12,671 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-25 11:59:12,671 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-25 11:59:12,684 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 11:59:12,684 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 11:59:12,686 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 11:59:12,918 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@dd05255
2019-09-25 11:59:12,921 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-25 11:59:13,006 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 11:59:13,008 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 11:59:13,011 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-25 11:59:13,149 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-25 11:59:13,168 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:13,235 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-25 11:59:13,240 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:13,336 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-25 11:59:13,769 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 11:59:13,900 [Socket Reader #1 for port 33368] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33368
2019-09-25 11:59:13,927 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 11:59:13,928 [Socket Reader #1 for port 37041] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37041
2019-09-25 11:59:13,936 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 11:59:13,937 [Socket Reader #1 for port 42244] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42244
2019-09-25 11:59:13,957 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-25 11:59:14,075 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:14,092 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:14,105 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:14,108 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-25 11:59:14,108 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:14,108 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:14,139 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42244
2019-09-25 11:59:14,193 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-25 11:59:14,206 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-25 11:59:14,206 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-25 11:59:14,411 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:42244
2019-09-25 11:59:14,412 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 11:59:14,412 [IPC Server listener on 42244] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42244: starting
2019-09-25 11:59:14,416 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37041
2019-09-25 11:59:14,418 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:37041
2019-09-25 11:59:14,418 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 11:59:14,418 [IPC Server listener on 37041] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37041: starting
2019-09-25 11:59:14,420 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33368
2019-09-25 11:59:14,421 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:33368
2019-09-25 11:59:14,421 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 11:59:14,421 [IPC Server listener on 33368] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33368: starting
2019-09-25 11:59:14,427 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42732
2019-09-25 11:59:14,429 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:14,474 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:14,475 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:14,557 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@aec50a1{/,file:///tmp/jetty-0.0.0.0-42732-scm-_-any-5321961403837627270.dir/webapp/,AVAILABLE}{/scm}
2019-09-25 11:59:14,563 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:42732}
2019-09-25 11:59:14,563 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @2970ms
2019-09-25 11:59:14,565 [JUnit] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-25 11:59:14,566 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-25 11:59:14,567 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:42732
2019-09-25 11:59:14,573 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c1fca1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 11:59:14,577 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:14,691 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:14,692 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:14,693 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(652)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-25 11:59:14,693 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(658)) - OM Node ID is not set. Setting it to the OmStorage's OmID: e9a5adac-b8ca-4926-b625-6c01527bee84
2019-09-25 11:59:14,695 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-25 11:59:15,474 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 11:59:15,486 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-25 11:59:15,486 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-25 11:59:15,487 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-25 11:59:15,487 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-25 11:59:15,487 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-25 11:59:15,487 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-25 11:59:15,487 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-25 11:59:15,488 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-25 11:59:15,488 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-25 11:59:15,488 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-25 11:59:15,488 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-25 11:59:15,489 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-25 11:59:15,489 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-25 11:59:15,489 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-25 11:59:15,489 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-25 11:59:15,489 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-25 11:59:15,490 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-25 11:59:15,490 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-25 11:59:15,490 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-25 11:59:15,490 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-25 11:59:15,491 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-25 11:59:15,491 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-25 11:59:15,491 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 11:59:15,491 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 11:59:15,491 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 11:59:15,981 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 11:59:15,982 [Socket Reader #1 for port 33801] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33801
2019-09-25 11:59:16,013 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:33801
2019-09-25 11:59:16,013 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-25 11:59:16,015 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 11:59:16,019 [IPC Server listener on 33801] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33801: starting
2019-09-25 11:59:16,024 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-25 11:59:16,027 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:16,027 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:16,031 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:16,032 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-25 11:59:16,032 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:16,033 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:16,035 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39860
2019-09-25 11:59:16,035 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:16,161 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:16,162 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:16,221 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7103ab0{/,file:///tmp/jetty-0.0.0.0-39860-ozoneManager-_-any-7537321169169472847.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-25 11:59:16,223 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:39860}
2019-09-25 11:59:16,223 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4630ms
2019-09-25 11:59:16,224 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 11:59:16,226 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:39860
2019-09-25 11:59:16,420 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 11:59:16,477 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-5gmkr-4255264070 ip:192.168.30.6
2019-09-25 11:59:16,518 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 11:59:16,521 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/containers/hdds to VolumeSet
2019-09-25 11:59:16,525 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-25 11:59:16,564 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-25 11:59:16,693 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 11:59:16,755 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 11:59:16,760 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 11:59:16,760 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 11:59:16,762 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:16,762 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 11:59:16,763 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 11:59:16,949 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:17,012 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 11:59:17,014 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:17,015 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:17,017 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:17,018 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 11:59:17,018 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:17,019 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:17,020 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45001
2019-09-25 11:59:17,020 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:17,023 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:17,023 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:17,053 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73844119{/,file:///tmp/jetty-0.0.0.0-45001-hddsDatanode-_-any-7350144663388863532.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 11:59:17,055 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:45001}
2019-09-25 11:59:17,055 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5462ms
2019-09-25 11:59:17,056 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 11:59:17,056 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45001
2019-09-25 11:59:17,057 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 11:59:17,060 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-5gmkr-4255264070 ip:192.168.30.6
2019-09-25 11:59:17,062 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@152ac37b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 11:59:17,068 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 11:59:17,068 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/containers/hdds to VolumeSet
2019-09-25 11:59:17,068 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@333c8791
2019-09-25 11:59:17,069 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@333c8791
2019-09-25 11:59:17,088 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 11:59:17,088 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 11:59:17,088 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 11:59:17,088 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 11:59:17,089 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:17,089 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 11:59:17,089 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 11:59:17,090 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:17,091 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 11:59:17,095 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:17,096 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:17,100 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:17,101 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 11:59:17,102 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:17,102 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:17,103 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41137
2019-09-25 11:59:17,104 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:17,108 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16727bf0{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:17,109 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@291373d3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:17,155 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48b4a043{/,file:///tmp/jetty-0.0.0.0-41137-hddsDatanode-_-any-7278272761939181946.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 11:59:17,156 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f5b8250{HTTP/1.1,[http/1.1]}{0.0.0.0:41137}
2019-09-25 11:59:17,157 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5563ms
2019-09-25 11:59:17,157 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 11:59:17,158 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41137
2019-09-25 11:59:17,158 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 11:59:17,161 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75fd743e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 11:59:17,161 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-5gmkr-4255264070 ip:192.168.30.6
2019-09-25 11:59:17,168 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 11:59:17,169 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/containers/hdds to VolumeSet
2019-09-25 11:59:17,169 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cf0a747
2019-09-25 11:59:17,170 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cf0a747
2019-09-25 11:59:17,182 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/meta/datanode.id
2019-09-25 11:59:17,187 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/meta/datanode.id
2019-09-25 11:59:17,197 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 11:59:17,197 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 11:59:17,198 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 11:59:17,198 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 11:59:17,198 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:17,199 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 11:59:17,199 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 11:59:17,201 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:17,205 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 11:59:17,207 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:17,208 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:17,211 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:17,213 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 11:59:17,213 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:17,213 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:17,214 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36800
2019-09-25 11:59:17,214 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:17,219 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@272ce069{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:17,220 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c26273d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:17,263 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29149030{/,file:///tmp/jetty-0.0.0.0-36800-hddsDatanode-_-any-3925612135769463572.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 11:59:17,265 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@38b8b6c0{HTTP/1.1,[http/1.1]}{0.0.0.0:36800}
2019-09-25 11:59:17,266 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5673ms
2019-09-25 11:59:17,267 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 11:59:17,268 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36800
2019-09-25 11:59:17,268 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 11:59:17,271 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d25d5ee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 11:59:17,273 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-5gmkr-4255264070 ip:192.168.30.6
2019-09-25 11:59:17,275 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/meta/datanode.id
2019-09-25 11:59:17,281 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 11:59:17,282 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/containers/hdds to VolumeSet
2019-09-25 11:59:17,282 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4437ac07
2019-09-25 11:59:17,283 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4437ac07
2019-09-25 11:59:17,312 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 11:59:17,312 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 11:59:17,313 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 11:59:17,313 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 11:59:17,313 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:17,314 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 11:59:17,314 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 11:59:17,315 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:17,317 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 11:59:17,319 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:17,320 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:17,321 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:17,322 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 11:59:17,322 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:17,322 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:17,323 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44572
2019-09-25 11:59:17,323 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:17,327 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e9469b8{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:17,327 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57272109{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:17,358 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@75181b50{/,file:///tmp/jetty-0.0.0.0-44572-hddsDatanode-_-any-8222927995225351546.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 11:59:17,358 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2d64160c{HTTP/1.1,[http/1.1]}{0.0.0.0:44572}
2019-09-25 11:59:17,360 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5766ms
2019-09-25 11:59:17,360 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 11:59:17,361 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44572
2019-09-25 11:59:17,361 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 11:59:17,364 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e6de8ad] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 11:59:17,364 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-5gmkr-4255264070 ip:192.168.30.6
2019-09-25 11:59:17,367 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/meta/datanode.id
2019-09-25 11:59:17,373 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 11:59:17,374 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/containers/hdds to VolumeSet
2019-09-25 11:59:17,374 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2a869a16
2019-09-25 11:59:17,374 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2a869a16
2019-09-25 11:59:17,396 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 11:59:17,396 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 11:59:17,397 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 11:59:17,397 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 11:59:17,397 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:17,398 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 11:59:17,398 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 11:59:17,398 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:17,400 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 11:59:17,403 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 11:59:17,404 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 11:59:17,407 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 11:59:17,408 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 11:59:17,409 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 11:59:17,409 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 11:59:17,410 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39281
2019-09-25 11:59:17,410 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 11:59:17,413 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e446d92{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 11:59:17,414 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d5c2745{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 11:59:17,453 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4cb2918c{/,file:///tmp/jetty-0.0.0.0-39281-hddsDatanode-_-any-2212881492477432897.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 11:59:17,454 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72e295cc{HTTP/1.1,[http/1.1]}{0.0.0.0:39281}
2019-09-25 11:59:17,454 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5861ms
2019-09-25 11:59:17,455 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 11:59:17,455 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39281
2019-09-25 11:59:17,458 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 11:59:17,458 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@217234c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 11:59:17,461 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/meta/datanode.id
2019-09-25 11:59:18,458 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 11:59:19,124 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 11:59:19,128 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 11:59:19,128 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b2a3572d-7c1f-4e75-8685-be52119dd02b at port 0
2019-09-25 11:59:19,157 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start RPC server
2019-09-25 11:59:19,180 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 11:59:19,185 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 11:59:19,185 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 806040c9-6be1-453b-a2ca-ad7e12880578 at port 0
2019-09-25 11:59:19,200 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start RPC server
2019-09-25 11:59:19,286 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 11:59:19,288 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 11:59:19,288 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis af790e72-8fcd-4cb0-b23c-d20e93858cf2 at port 0
2019-09-25 11:59:19,297 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start RPC server
2019-09-25 11:59:19,323 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: GrpcService started, listening on 0.0.0.0/0.0.0.0:43658
2019-09-25 11:59:19,323 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: GrpcService started, listening on 0.0.0.0/0.0.0.0:38937
2019-09-25 11:59:19,323 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 806040c9-6be1-453b-a2ca-ad7e12880578: GrpcService started, listening on 0.0.0.0/0.0.0.0:36253
2019-09-25 11:59:19,325 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis af790e72-8fcd-4cb0-b23c-d20e93858cf2 is started using port 43658
2019-09-25 11:59:19,325 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 806040c9-6be1-453b-a2ca-ad7e12880578 is started using port 36253
2019-09-25 11:59:19,325 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b2a3572d-7c1f-4e75-8685-be52119dd02b is started using port 38937
2019-09-25 11:59:19,333 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 806040c9-6be1-453b-a2ca-ad7e12880578 is started using port 33256
2019-09-25 11:59:19,333 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b2a3572d-7c1f-4e75-8685-be52119dd02b is started using port 43234
2019-09-25 11:59:19,333 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc af790e72-8fcd-4cb0-b23c-d20e93858cf2 is started using port 36118
2019-09-25 11:59:19,380 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 11:59:19,383 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 11:59:19,383 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis cbc7b4b8-8477-40ca-9cdc-b573f7732004 at port 0
2019-09-25 11:59:19,388 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start RPC server
2019-09-25 11:59:19,391 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: GrpcService started, listening on 0.0.0.0/0.0.0.0:39643
2019-09-25 11:59:19,391 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis cbc7b4b8-8477-40ca-9cdc-b573f7732004 is started using port 39643
2019-09-25 11:59:19,396 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc cbc7b4b8-8477-40ca-9cdc-b573f7732004 is started using port 44660
2019-09-25 11:59:19,459 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 11:59:19,479 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 11:59:19,485 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 11:59:19,486 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 0fe2c664-23d3-4023-9f8c-2687d201187c at port 0
2019-09-25 11:59:19,494 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start RPC server
2019-09-25 11:59:19,498 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: GrpcService started, listening on 0.0.0.0/0.0.0.0:40326
2019-09-25 11:59:19,499 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 0fe2c664-23d3-4023-9f8c-2687d201187c is started using port 40326
2019-09-25 11:59:19,502 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 0fe2c664-23d3-4023-9f8c-2687d201187c is started using port 34225
2019-09-25 11:59:20,462 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 11:59:21,111 [IPC Server handler 1 on 33368] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:21,111 [IPC Server handler 1 on 33368] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}
2019-09-25 11:59:21,116 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-25 11:59:21,116 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-25 11:59:21,116 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-25 11:59:21,167 [IPC Server handler 3 on 33368] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:21,167 [IPC Server handler 3 on 33368] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}
2019-09-25 11:59:21,274 [IPC Server handler 2 on 33368] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:21,274 [IPC Server handler 2 on 33368] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}
2019-09-25 11:59:21,367 [IPC Server handler 5 on 33368] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:21,367 [IPC Server handler 5 on 33368] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}
2019-09-25 11:59:21,463 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-25 11:59:21,463 [IPC Server handler 0 on 33368] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:21,464 [IPC Server handler 0 on 33368] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}
2019-09-25 11:59:21,696 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: addNew group-719336267CD4:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] returns group-719336267CD4:java.util.concurrent.CompletableFuture@14ac0fa2[Not completed]
2019-09-25 11:59:21,715 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: new RaftServerImpl for group-719336267CD4:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] with ContainerStateMachine:uninitialized
2019-09-25 11:59:21,717 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:21,718 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:21,719 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:21,720 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:21,721 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:21,728 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: ConfigurationManager, init=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:21,729 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:21,737 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/244ce72a-6bc9-49bb-963a-719336267cd4 does not exist. Creating ...
2019-09-25 11:59:21,754 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/244ce72a-6bc9-49bb-963a-719336267cd4/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:21,769 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/244ce72a-6bc9-49bb-963a-719336267cd4 has been successfully formatted.
2019-09-25 11:59:21,772 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-719336267CD4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:21,772 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:21,774 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:21,780 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:21,780 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:21,782 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:21,787 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:21,793 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/244ce72a-6bc9-49bb-963a-719336267cd4
2019-09-25 11:59:21,795 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-25 11:59:21,802 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-25 11:59:21,839 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:21,839 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:21,843 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:21,844 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:21,844 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:21,844 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:21,845 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:21,846 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:21,846 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:21,857 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:21,862 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:21,866 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:21,867 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:21,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:21,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:21,899 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: start as a follower, conf=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:21,900 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:21,902 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start FollowerState
2019-09-25 11:59:21,903 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-719336267CD4,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:21,972 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 244ce72a-6bc9-49bb-963a-719336267cd4, Nodes: b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:21,993 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: addNew group-C285669257DF:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] returns group-C285669257DF:java.util.concurrent.CompletableFuture@383a6996[Not completed]
2019-09-25 11:59:22,040 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: new RaftServerImpl for group-C285669257DF:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: ConfigurationManager, init=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:22,042 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/79195117-73f3-4821-b227-c285669257df does not exist. Creating ...
2019-09-25 11:59:22,076 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/79195117-73f3-4821-b227-c285669257df/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,106 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/79195117-73f3-4821-b227-c285669257df has been successfully formatted.
2019-09-25 11:59:22,109 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C285669257DF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,110 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,110 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,110 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,110 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,110 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,110 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,111 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/79195117-73f3-4821-b227-c285669257df
2019-09-25 11:59:22,116 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,116 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,116 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,117 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,117 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,117 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,117 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,117 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,117 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,118 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,118 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,118 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,119 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,119 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,119 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,123 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: start as a follower, conf=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:22,123 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,123 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start FollowerState
2019-09-25 11:59:22,125 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C285669257DF,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:22,140 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 79195117-73f3-4821-b227-c285669257df, Nodes: 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,158 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: addNew group-281E61757094:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] returns group-281E61757094:java.util.concurrent.CompletableFuture@3d92251f[Not completed]
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: new RaftServerImpl for group-281E61757094:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,160 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: ConfigurationManager, init=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,161 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:22,161 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/748448e3-f9d7-4af2-bcd9-281e61757094 does not exist. Creating ...
2019-09-25 11:59:22,175 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/748448e3-f9d7-4af2-bcd9-281e61757094/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,189 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/748448e3-f9d7-4af2-bcd9-281e61757094 has been successfully formatted.
2019-09-25 11:59:22,189 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-281E61757094: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,189 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/748448e3-f9d7-4af2-bcd9-281e61757094
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,190 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,191 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,192 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,192 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,192 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,192 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,193 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,193 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,197 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: start as a follower, conf=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:22,198 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,198 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start FollowerState
2019-09-25 11:59:22,198 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-281E61757094,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:22,207 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 748448e3-f9d7-4af2-bcd9-281e61757094, Nodes: 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,224 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 806040c9-6be1-453b-a2ca-ad7e12880578: addNew group-4C72D74F3069:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] returns group-4C72D74F3069:java.util.concurrent.CompletableFuture@41b66ebc[Not completed]
2019-09-25 11:59:22,240 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 806040c9-6be1-453b-a2ca-ad7e12880578: new RaftServerImpl for group-4C72D74F3069:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,241 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,241 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: ConfigurationManager, init=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,241 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:22,241 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/58f84323-73bd-4e4e-9b1c-4c72d74f3069 does not exist. Creating ...
2019-09-25 11:59:22,255 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/58f84323-73bd-4e4e-9b1c-4c72d74f3069/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,268 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/58f84323-73bd-4e4e-9b1c-4c72d74f3069 has been successfully formatted.
2019-09-25 11:59:22,269 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4C72D74F3069: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,270 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,270 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,270 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/58f84323-73bd-4e4e-9b1c-4c72d74f3069
2019-09-25 11:59:22,293 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,293 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,295 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,296 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,301 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: start as a follower, conf=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:22,302 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,302 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start FollowerState
2019-09-25 11:59:22,302 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4C72D74F3069,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:22,311 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 58f84323-73bd-4e4e-9b1c-4c72d74f3069, Nodes: 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,329 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 806040c9-6be1-453b-a2ca-ad7e12880578: addNew group-B166EF43A0B3:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] returns group-B166EF43A0B3:java.util.concurrent.CompletableFuture@5fa822e[Not completed]
2019-09-25 11:59:22,331 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 806040c9-6be1-453b-a2ca-ad7e12880578: new RaftServerImpl for group-B166EF43A0B3:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,331 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,332 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,332 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,332 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,332 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,332 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: ConfigurationManager, init=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,333 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:22,333 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/5c31f0fd-46e6-4362-8a70-b166ef43a0b3 does not exist. Creating ...
2019-09-25 11:59:22,346 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/5c31f0fd-46e6-4362-8a70-b166ef43a0b3/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,360 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/5c31f0fd-46e6-4362-8a70-b166ef43a0b3 has been successfully formatted.
2019-09-25 11:59:22,360 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B166EF43A0B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,362 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,362 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/5c31f0fd-46e6-4362-8a70-b166ef43a0b3
2019-09-25 11:59:22,362 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,362 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,363 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,364 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,364 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,365 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,365 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,365 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,365 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,373 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: start as a follower, conf=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:22,374 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,374 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start FollowerState
2019-09-25 11:59:22,375 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B166EF43A0B3,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:22,386 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5c31f0fd-46e6-4362-8a70-b166ef43a0b3, Nodes: 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,405 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: addNew group-8A7781F80F0A:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] returns group-8A7781F80F0A:java.util.concurrent.CompletableFuture@1912420b[Not completed]
2019-09-25 11:59:22,406 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: new RaftServerImpl for group-8A7781F80F0A:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: ConfigurationManager, init=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:22,408 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/aed6666a-fb0a-4a15-8211-8a7781f80f0a does not exist. Creating ...
2019-09-25 11:59:22,421 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/aed6666a-fb0a-4a15-8211-8a7781f80f0a/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,434 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/aed6666a-fb0a-4a15-8211-8a7781f80f0a has been successfully formatted.
2019-09-25 11:59:22,435 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-8A7781F80F0A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,435 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,435 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,436 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/aed6666a-fb0a-4a15-8211-8a7781f80f0a
2019-09-25 11:59:22,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,438 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,438 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,438 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,439 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,439 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,439 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,439 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,439 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,444 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: start as a follower, conf=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:22,444 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,444 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start FollowerState
2019-09-25 11:59:22,445 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8A7781F80F0A,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:22,458 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: aed6666a-fb0a-4a15-8211-8a7781f80f0a, Nodes: b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,463 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-25 11:59:22,470 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: addNew group-E509BFB4C8C2:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] returns group-E509BFB4C8C2:java.util.concurrent.CompletableFuture@256f2d66[Not completed]
2019-09-25 11:59:22,471 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: new RaftServerImpl for group-E509BFB4C8C2:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,472 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: ConfigurationManager, init=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,473 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:22,473 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/fa16a49b-cabe-47cc-82a8-e509bfb4c8c2 does not exist. Creating ...
2019-09-25 11:59:22,486 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/fa16a49b-cabe-47cc-82a8-e509bfb4c8c2/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,494 [Thread-227] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 11:59:22,500 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/fa16a49b-cabe-47cc-82a8-e509bfb4c8c2 has been successfully formatted.
2019-09-25 11:59:22,501 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E509BFB4C8C2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/fa16a49b-cabe-47cc-82a8-e509bfb4c8c2
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,504 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,504 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,504 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,504 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,504 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,508 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: start as a follower, conf=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:22,508 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,509 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start FollowerState
2019-09-25 11:59:22,509 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E509BFB4C8C2,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:22,528 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fa16a49b-cabe-47cc-82a8-e509bfb4c8c2, Nodes: 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,540 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: addNew group-8C5F2E78582D:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] returns group-8C5F2E78582D:java.util.concurrent.CompletableFuture@5d24e028[Not completed]
2019-09-25 11:59:22,543 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: new RaftServerImpl for group-8C5F2E78582D:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,543 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,543 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,544 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,544 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,544 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,544 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: ConfigurationManager, init=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,544 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:22,544 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/5f3d2986-fcaf-4aa9-9aaa-8c5f2e78582d does not exist. Creating ...
2019-09-25 11:59:22,606 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/5f3d2986-fcaf-4aa9-9aaa-8c5f2e78582d/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,635 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/5f3d2986-fcaf-4aa9-9aaa-8c5f2e78582d has been successfully formatted.
2019-09-25 11:59:22,637 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-8C5F2E78582D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,637 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,638 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,639 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,639 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/5f3d2986-fcaf-4aa9-9aaa-8c5f2e78582d
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,640 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,641 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,641 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,641 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,641 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,641 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,642 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,642 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,642 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,642 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,645 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: start as a follower, conf=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:22,645 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,645 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start FollowerState
2019-09-25 11:59:22,645 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C5F2E78582D,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:22,657 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5f3d2986-fcaf-4aa9-9aaa-8c5f2e78582d, Nodes: 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,668 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: addNew group-0FA7EEB8EEC0:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] returns group-0FA7EEB8EEC0:java.util.concurrent.CompletableFuture@5ca5dc72[Not completed]
2019-09-25 11:59:22,670 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: new RaftServerImpl for group-0FA7EEB8EEC0:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,670 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,670 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,670 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,670 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,670 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,671 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: ConfigurationManager, init=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,671 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:22,671 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/07087c10-349b-4af9-a5cf-0fa7eeb8eec0 does not exist. Creating ...
2019-09-25 11:59:22,684 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/07087c10-349b-4af9-a5cf-0fa7eeb8eec0/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,697 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/07087c10-349b-4af9-a5cf-0fa7eeb8eec0 has been successfully formatted.
2019-09-25 11:59:22,698 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0FA7EEB8EEC0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,698 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,698 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,698 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,698 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,698 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/07087c10-349b-4af9-a5cf-0fa7eeb8eec0
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,699 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,700 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,700 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,700 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,700 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,700 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,701 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,701 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,701 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,704 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: start as a follower, conf=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:22,704 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,704 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start FollowerState
2019-09-25 11:59:22,704 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FA7EEB8EEC0,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:22,713 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 07087c10-349b-4af9-a5cf-0fa7eeb8eec0, Nodes: 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,725 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: addNew group-447616BBE454:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] returns group-447616BBE454:java.util.concurrent.CompletableFuture@1ff976b4[Not completed]
2019-09-25 11:59:22,726 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: new RaftServerImpl for group-447616BBE454:[0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,726 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,726 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,726 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,727 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,727 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,727 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: ConfigurationManager, init=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,727 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis] (custom)
2019-09-25 11:59:22,727 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/780316a5-72ae-474d-88bb-447616bbe454 does not exist. Creating ...
2019-09-25 11:59:22,740 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/780316a5-72ae-474d-88bb-447616bbe454/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,754 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/780316a5-72ae-474d-88bb-447616bbe454 has been successfully formatted.
2019-09-25 11:59:22,754 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-447616BBE454: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,754 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/780316a5-72ae-474d-88bb-447616bbe454
2019-09-25 11:59:22,755 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,756 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,756 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,756 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,756 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,756 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,757 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,757 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,757 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,757 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,758 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,758 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,758 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,758 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,758 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,762 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: start as a follower, conf=-1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:22,762 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,762 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start FollowerState
2019-09-25 11:59:22,762 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-447616BBE454,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 11:59:22,772 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 780316a5-72ae-474d-88bb-447616bbe454, Nodes: 0fe2c664-23d3-4023-9f8c-2687d201187c{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,772 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:22,786 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 806040c9-6be1-453b-a2ca-ad7e12880578: addNew group-456089AB08CE:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] returns group-456089AB08CE:java.util.concurrent.CompletableFuture@37641be[Not completed]
2019-09-25 11:59:22,788 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 806040c9-6be1-453b-a2ca-ad7e12880578: new RaftServerImpl for group-456089AB08CE:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,788 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,788 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,788 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,788 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,789 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,789 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: ConfigurationManager, init=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,789 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:22,790 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/f3e02262-76ac-44dd-a5cb-456089ab08ce does not exist. Creating ...
2019-09-25 11:59:22,805 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/f3e02262-76ac-44dd-a5cb-456089ab08ce/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,819 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/f3e02262-76ac-44dd-a5cb-456089ab08ce has been successfully formatted.
2019-09-25 11:59:22,819 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-456089AB08CE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,819 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,819 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/f3e02262-76ac-44dd-a5cb-456089ab08ce
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,820 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,821 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,822 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,822 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,822 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,822 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,822 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,823 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,825 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: start as a follower, conf=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:22,825 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,826 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start FollowerState
2019-09-25 11:59:22,826 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-456089AB08CE,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:22,835 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f3e02262-76ac-44dd-a5cb-456089ab08ce, Nodes: 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,835 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:22,859 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: addNew group-4998A190C7EF:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] returns group-4998A190C7EF:java.util.concurrent.CompletableFuture@666a4eab[Not completed]
2019-09-25 11:59:22,864 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: new RaftServerImpl for group-4998A190C7EF:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,865 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,865 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,865 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: ConfigurationManager, init=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,865 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:22,865 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e8cf15fe-72f2-4e94-b85e-4998a190c7ef does not exist. Creating ...
2019-09-25 11:59:22,879 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e8cf15fe-72f2-4e94-b85e-4998a190c7ef/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,892 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e8cf15fe-72f2-4e94-b85e-4998a190c7ef has been successfully formatted.
2019-09-25 11:59:22,892 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4998A190C7EF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,893 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e8cf15fe-72f2-4e94-b85e-4998a190c7ef
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,897 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,898 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,898 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,898 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,898 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,900 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: start as a follower, conf=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:22,900 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,900 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start FollowerState
2019-09-25 11:59:22,901 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4998A190C7EF,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:22,910 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e8cf15fe-72f2-4e94-b85e-4998a190c7ef, Nodes: cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,910 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:22,921 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: addNew group-C2489467E579:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] returns group-C2489467E579:java.util.concurrent.CompletableFuture@77d947e6[Not completed]
2019-09-25 11:59:22,922 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: new RaftServerImpl for group-C2489467E579:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,923 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,923 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,923 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,923 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,923 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,923 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: ConfigurationManager, init=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,924 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:22,924 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/812a2d98-aa0d-438b-bf71-c2489467e579 does not exist. Creating ...
2019-09-25 11:59:22,937 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/812a2d98-aa0d-438b-bf71-c2489467e579/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:22,954 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/812a2d98-aa0d-438b-bf71-c2489467e579 has been successfully formatted.
2019-09-25 11:59:22,954 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C2489467E579: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/812a2d98-aa0d-438b-bf71-c2489467e579
2019-09-25 11:59:22,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:22,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:22,957 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:22,957 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:22,957 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:22,957 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:22,957 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:22,957 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:22,958 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:22,960 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: start as a follower, conf=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:22,960 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:22,960 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start FollowerState
2019-09-25 11:59:22,960 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2489467E579,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:22,968 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 812a2d98-aa0d-438b-bf71-c2489467e579, Nodes: b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:22,968 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:22,981 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 806040c9-6be1-453b-a2ca-ad7e12880578: addNew group-7BD4E3F55877:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] returns group-7BD4E3F55877:java.util.concurrent.CompletableFuture@7381ef9b[Not completed]
2019-09-25 11:59:22,983 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 806040c9-6be1-453b-a2ca-ad7e12880578: new RaftServerImpl for group-7BD4E3F55877:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] with ContainerStateMachine:uninitialized
2019-09-25 11:59:22,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:22,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:22,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:22,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:22,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:22,984 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: ConfigurationManager, init=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:22,985 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:22,985 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/4de0d0f9-0edf-425e-80c1-7bd4e3f55877 does not exist. Creating ...
2019-09-25 11:59:22,998 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/4de0d0f9-0edf-425e-80c1-7bd4e3f55877/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,013 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/4de0d0f9-0edf-425e-80c1-7bd4e3f55877 has been successfully formatted.
2019-09-25 11:59:23,013 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7BD4E3F55877: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,013 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,013 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/4de0d0f9-0edf-425e-80c1-7bd4e3f55877
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,014 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,015 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,016 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,016 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,016 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,016 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,016 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,019 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: start as a follower, conf=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:23,019 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,019 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start FollowerState
2019-09-25 11:59:23,019 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BD4E3F55877,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:23,028 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4de0d0f9-0edf-425e-80c1-7bd4e3f55877, Nodes: 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,028 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,042 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: addNew group-F8EB8B561257:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] returns group-F8EB8B561257:java.util.concurrent.CompletableFuture@1dea57d5[Not completed]
2019-09-25 11:59:23,043 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: new RaftServerImpl for group-F8EB8B561257:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,043 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,043 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,044 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,044 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,044 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,044 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: ConfigurationManager, init=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,044 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:23,044 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/b0f0bfc7-6779-495a-b4b1-f8eb8b561257 does not exist. Creating ...
2019-09-25 11:59:23,057 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/b0f0bfc7-6779-495a-b4b1-f8eb8b561257/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,071 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/b0f0bfc7-6779-495a-b4b1-f8eb8b561257 has been successfully formatted.
2019-09-25 11:59:23,071 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F8EB8B561257: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/b0f0bfc7-6779-495a-b4b1-f8eb8b561257
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,073 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,076 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: start as a follower, conf=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:23,076 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,076 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start FollowerState
2019-09-25 11:59:23,077 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F8EB8B561257,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:23,082 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0f0bfc7-6779-495a-b4b1-f8eb8b561257, Nodes: b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,082 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,094 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: addNew group-081B7A613759:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] returns group-081B7A613759:java.util.concurrent.CompletableFuture@2a5faaf3[Not completed]
2019-09-25 11:59:23,096 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: new RaftServerImpl for group-081B7A613759:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,099 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,100 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,102 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,102 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,103 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: ConfigurationManager, init=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:23,103 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/cbaa00d7-2d25-4740-8126-081b7a613759 does not exist. Creating ...
2019-09-25 11:59:23,117 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/cbaa00d7-2d25-4740-8126-081b7a613759/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,131 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/cbaa00d7-2d25-4740-8126-081b7a613759 has been successfully formatted.
2019-09-25 11:59:23,131 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-081B7A613759: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,131 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,133 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,134 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,135 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/cbaa00d7-2d25-4740-8126-081b7a613759
2019-09-25 11:59:23,139 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,139 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,141 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,141 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,141 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,142 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,142 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,142 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,142 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,149 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: start as a follower, conf=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:23,150 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,150 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start FollowerState
2019-09-25 11:59:23,150 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-081B7A613759,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:23,157 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: cbaa00d7-2d25-4740-8126-081b7a613759, Nodes: af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,157 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,168 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: addNew group-C3F88A4F5E32:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] returns group-C3F88A4F5E32:java.util.concurrent.CompletableFuture@6b6a0890[Not completed]
2019-09-25 11:59:23,169 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: new RaftServerImpl for group-C3F88A4F5E32:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,170 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,170 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,170 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: ConfigurationManager, init=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,170 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:23,170 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/22e3f352-2a38-4a35-8454-c3f88a4f5e32 does not exist. Creating ...
2019-09-25 11:59:23,189 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/22e3f352-2a38-4a35-8454-c3f88a4f5e32/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,200 [Thread-227] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume43517, with user52457 as owner.
2019-09-25 11:59:23,205 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/22e3f352-2a38-4a35-8454-c3f88a4f5e32 has been successfully formatted.
2019-09-25 11:59:23,205 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C3F88A4F5E32: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,205 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/22e3f352-2a38-4a35-8454-c3f88a4f5e32
2019-09-25 11:59:23,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,210 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,213 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: start as a follower, conf=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:23,213 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,213 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start FollowerState
2019-09-25 11:59:23,213 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3F88A4F5E32,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:23,220 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 22e3f352-2a38-4a35-8454-c3f88a4f5e32, Nodes: b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,220 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,235 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: addNew group-D16646313036:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] returns group-D16646313036:java.util.concurrent.CompletableFuture@1018113c[Not completed]
2019-09-25 11:59:23,237 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: new RaftServerImpl for group-D16646313036:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,237 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,237 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,237 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,237 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,237 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,238 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: ConfigurationManager, init=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,238 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:23,238 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/b0eb7fb1-e9bd-4749-9cfb-d16646313036 does not exist. Creating ...
2019-09-25 11:59:23,251 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/b0eb7fb1-e9bd-4749-9cfb-d16646313036/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,265 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/b0eb7fb1-e9bd-4749-9cfb-d16646313036 has been successfully formatted.
2019-09-25 11:59:23,265 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D16646313036: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,265 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,265 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,265 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,265 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/b0eb7fb1-e9bd-4749-9cfb-d16646313036
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,270 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: start as a follower, conf=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:23,270 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,270 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start FollowerState
2019-09-25 11:59:23,270 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D16646313036,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:23,280 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0eb7fb1-e9bd-4749-9cfb-d16646313036, Nodes: af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,280 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,291 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: addNew group-A89B179A7775:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] returns group-A89B179A7775:java.util.concurrent.CompletableFuture@741ddc3c[Not completed]
2019-09-25 11:59:23,295 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: new RaftServerImpl for group-A89B179A7775:[b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,295 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,295 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,295 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,295 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,296 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,296 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: ConfigurationManager, init=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,296 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis] (custom)
2019-09-25 11:59:23,297 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/1f3a111c-382d-4c49-a307-a89b179a7775 does not exist. Creating ...
2019-09-25 11:59:23,311 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/1f3a111c-382d-4c49-a307-a89b179a7775/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,326 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/1f3a111c-382d-4c49-a307-a89b179a7775 has been successfully formatted.
2019-09-25 11:59:23,326 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A89B179A7775: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,326 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,326 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,327 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/1f3a111c-382d-4c49-a307-a89b179a7775
2019-09-25 11:59:23,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,330 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,331 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,332 [IPC Server handler 3 on 33801] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume43517 for user:user52457
2019-09-25 11:59:23,334 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: start as a follower, conf=-1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:23,334 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,334 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start FollowerState
2019-09-25 11:59:23,609 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A89B179A7775,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 11:59:23,624 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1f3a111c-382d-4c49-a307-a89b179a7775, Nodes: b2a3572d-7c1f-4e75-8685-be52119dd02b{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,625 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,628 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:23,665 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: addNew group-A38E37A59148:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] returns group-A38E37A59148:java.util.concurrent.CompletableFuture@551b8b4c[Not completed]
2019-09-25 11:59:23,667 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: new RaftServerImpl for group-A38E37A59148:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,667 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,667 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,668 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,668 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,668 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,668 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: ConfigurationManager, init=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,668 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:23,669 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/5e689a4f-2899-48c9-b0b1-a38e37a59148 does not exist. Creating ...
2019-09-25 11:59:23,682 [Thread-227] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume43517/bucket26403, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 11:59:23,682 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/5e689a4f-2899-48c9-b0b1-a38e37a59148/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,696 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/5e689a4f-2899-48c9-b0b1-a38e37a59148 has been successfully formatted.
2019-09-25 11:59:23,696 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A38E37A59148: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,696 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,697 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/5e689a4f-2899-48c9-b0b1-a38e37a59148
2019-09-25 11:59:23,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,697 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,698 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,699 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,699 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,699 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,699 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,700 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,701 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,704 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: start as a follower, conf=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:23,704 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,704 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start FollowerState
2019-09-25 11:59:23,709 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A38E37A59148,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:23,722 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5e689a4f-2899-48c9-b0b1-a38e37a59148, Nodes: cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,723 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,723 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:23,733 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: addNew group-AEDF94CA4321:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] returns group-AEDF94CA4321:java.util.concurrent.CompletableFuture@91fea2a[Not completed]
2019-09-25 11:59:23,735 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: new RaftServerImpl for group-AEDF94CA4321:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,735 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,735 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,736 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: ConfigurationManager, init=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:23,737 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/b0d2ca51-1c31-4d77-8ed8-aedf94ca4321 does not exist. Creating ...
2019-09-25 11:59:23,783 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/b0d2ca51-1c31-4d77-8ed8-aedf94ca4321/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,802 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/b0d2ca51-1c31-4d77-8ed8-aedf94ca4321 has been successfully formatted.
2019-09-25 11:59:23,802 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AEDF94CA4321: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,804 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/b0d2ca51-1c31-4d77-8ed8-aedf94ca4321
2019-09-25 11:59:23,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,806 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,806 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,806 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,807 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,807 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,810 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: start as a follower, conf=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:23,810 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,810 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start FollowerState
2019-09-25 11:59:23,811 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AEDF94CA4321,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:23,818 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0d2ca51-1c31-4d77-8ed8-aedf94ca4321, Nodes: cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,818 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,818 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:23,829 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: addNew group-ADB1836EF94D:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] returns group-ADB1836EF94D:java.util.concurrent.CompletableFuture@5286e2c6[Not completed]
2019-09-25 11:59:23,830 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: new RaftServerImpl for group-ADB1836EF94D:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,830 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,830 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,831 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,831 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,831 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,831 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: ConfigurationManager, init=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,831 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:23,832 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e268c968-4668-444b-8a15-adb1836ef94d does not exist. Creating ...
2019-09-25 11:59:23,845 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e268c968-4668-444b-8a15-adb1836ef94d/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,858 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e268c968-4668-444b-8a15-adb1836ef94d has been successfully formatted.
2019-09-25 11:59:23,859 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-ADB1836EF94D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,859 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,861 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e268c968-4668-444b-8a15-adb1836ef94d
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,863 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,863 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,863 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,863 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,866 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,870 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: start as a follower, conf=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:23,870 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,871 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start FollowerState
2019-09-25 11:59:23,871 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADB1836EF94D,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:23,876 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e268c968-4668-444b-8a15-adb1836ef94d, Nodes: cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,877 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,877 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:23,887 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: addNew group-6703E43134CB:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] returns group-6703E43134CB:java.util.concurrent.CompletableFuture@7edfb6df[Not completed]
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: new RaftServerImpl for group-6703E43134CB:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,889 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: ConfigurationManager, init=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,890 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:23,890 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/d26503d6-c268-43a0-8e86-6703e43134cb does not exist. Creating ...
2019-09-25 11:59:23,902 [Thread-227] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket26403.volume43517 implemented by OzoneFileSystem{URI=o3fs://bucket26403.volume43517, workingDir=o3fs://bucket26403.volume43517/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-25 11:59:23,903 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/d26503d6-c268-43a0-8e86-6703e43134cb/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,917 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/d26503d6-c268-43a0-8e86-6703e43134cb has been successfully formatted.
2019-09-25 11:59:23,917 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6703E43134CB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,917 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,917 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,917 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,918 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,918 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,918 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,918 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/d26503d6-c268-43a0-8e86-6703e43134cb
2019-09-25 11:59:23,918 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,918 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,919 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,920 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,920 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,920 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,920 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,923 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: start as a follower, conf=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:23,924 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,924 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start FollowerState
2019-09-25 11:59:23,924 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6703E43134CB,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:23,930 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d26503d6-c268-43a0-8e86-6703e43134cb, Nodes: cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,930 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,930 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:23,941 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: addNew group-DCFAC63A4D33:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] returns group-DCFAC63A4D33:java.util.concurrent.CompletableFuture@32d5a4ef[Not completed]
2019-09-25 11:59:23,943 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: new RaftServerImpl for group-DCFAC63A4D33:[cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643] with ContainerStateMachine:uninitialized
2019-09-25 11:59:23,943 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:23,944 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:23,944 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:23,944 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:23,944 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:23,944 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: ConfigurationManager, init=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:23,944 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis] (custom)
2019-09-25 11:59:23,945 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/bcd9b15e-7274-4efe-93de-dcfac63a4d33 does not exist. Creating ...
2019-09-25 11:59:23,958 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/bcd9b15e-7274-4efe-93de-dcfac63a4d33/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:23,972 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/bcd9b15e-7274-4efe-93de-dcfac63a4d33 has been successfully formatted.
2019-09-25 11:59:23,972 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DCFAC63A4D33: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:23,973 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:23,973 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:23,973 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:23,973 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:23,974 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,974 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:23,974 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/bcd9b15e-7274-4efe-93de-dcfac63a4d33
2019-09-25 11:59:23,974 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:23,980 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:23,980 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:23,981 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:23,981 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:23,981 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:23,981 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:23,981 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:23,981 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:23,982 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:23,982 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:23,982 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:23,982 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:23,982 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:23,983 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:23,992 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: start as a follower, conf=-1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:23,993 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:23,993 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start FollowerState
2019-09-25 11:59:23,993 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DCFAC63A4D33,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 11:59:23,998 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bcd9b15e-7274-4efe-93de-dcfac63a4d33, Nodes: cbc7b4b8-8477-40ca-9cdc-b573f7732004{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:23,999 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:23,999 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:23,999 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,010 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 806040c9-6be1-453b-a2ca-ad7e12880578: addNew group-4B6341FF55C6:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] returns group-4B6341FF55C6:java.util.concurrent.CompletableFuture@37023bf[Not completed]
2019-09-25 11:59:24,011 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 806040c9-6be1-453b-a2ca-ad7e12880578: new RaftServerImpl for group-4B6341FF55C6:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] with ContainerStateMachine:uninitialized
2019-09-25 11:59:24,011 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:24,011 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:24,011 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:24,011 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:24,011 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:24,012 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: ConfigurationManager, init=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:24,012 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:24,012 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/eec50250-65a1-4a7a-817a-4b6341ff55c6 does not exist. Creating ...
2019-09-25 11:59:24,025 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/eec50250-65a1-4a7a-817a-4b6341ff55c6/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:24,039 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/eec50250-65a1-4a7a-817a-4b6341ff55c6 has been successfully formatted.
2019-09-25 11:59:24,039 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4B6341FF55C6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:24,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:24,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:24,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:24,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:24,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:24,040 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/eec50250-65a1-4a7a-817a-4b6341ff55c6
2019-09-25 11:59:24,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:24,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:24,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,041 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:24,041 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:24,042 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:24,042 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:24,042 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:24,042 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:24,042 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:24,042 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:24,043 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:24,043 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:24,043 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:24,044 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:24,046 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: start as a follower, conf=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:24,046 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:24,046 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start FollowerState
2019-09-25 11:59:24,047 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B6341FF55C6,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:24,052 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: eec50250-65a1-4a7a-817a-4b6341ff55c6, Nodes: 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:24,053 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,053 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,054 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,068 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 806040c9-6be1-453b-a2ca-ad7e12880578: addNew group-42300DDC6049:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] returns group-42300DDC6049:java.util.concurrent.CompletableFuture@4c8dd315[Not completed]
2019-09-25 11:59:24,069 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 806040c9-6be1-453b-a2ca-ad7e12880578: new RaftServerImpl for group-42300DDC6049:[806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253] with ContainerStateMachine:uninitialized
2019-09-25 11:59:24,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: ConfigurationManager, init=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis] (custom)
2019-09-25 11:59:24,070 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/0fe946cc-dcbc-4ff5-906b-42300ddc6049 does not exist. Creating ...
11:59:24.059 [IPC Server handler 1 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:24,090 [Thread-227] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-25 11:59:24,090 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/0fe946cc-dcbc-4ff5-906b-42300ddc6049/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:24,106 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/0fe946cc-dcbc-4ff5-906b-42300ddc6049 has been successfully formatted.
2019-09-25 11:59:24,109 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-42300DDC6049: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:24,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:24,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:24,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:24,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:24,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/0fe946cc-dcbc-4ff5-906b-42300ddc6049
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:24,110 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:24,111 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:24,111 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:24,111 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:24,111 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:24,111 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:24,112 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:24,112 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:24,117 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: start as a follower, conf=-1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:24,117 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:24,117 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start FollowerState
2019-09-25 11:59:24,118 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-42300DDC6049,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 11:59:24,132 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-25 11:59:24,133 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0fe946cc-dcbc-4ff5-906b-42300ddc6049, Nodes: 806040c9-6be1-453b-a2ca-ad7e12880578{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:24,133 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,133 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,133 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,134 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,134 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-25 11:59:24,150 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: addNew group-9C0AF7B870AE:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] returns group-9C0AF7B870AE:java.util.concurrent.CompletableFuture@1e09a83d[Not completed]
2019-09-25 11:59:24,151 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: new RaftServerImpl for group-9C0AF7B870AE:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] with ContainerStateMachine:uninitialized
2019-09-25 11:59:24,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:24,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:24,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:24,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:24,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:24,153 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: ConfigurationManager, init=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:24,153 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:24,153 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/54cbe843-90c4-4250-8675-9c0af7b870ae does not exist. Creating ...
2019-09-25 11:59:24,167 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/54cbe843-90c4-4250-8675-9c0af7b870ae/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:24,180 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/54cbe843-90c4-4250-8675-9c0af7b870ae has been successfully formatted.
2019-09-25 11:59:24,180 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-9C0AF7B870AE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:24,180 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:24,180 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:24,181 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:24,181 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:24,181 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,181 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:24,181 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/54cbe843-90c4-4250-8675-9c0af7b870ae
2019-09-25 11:59:24,181 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:24,183 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:24,184 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,184 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:24,185 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:24,185 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:24,185 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:24,185 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:24,185 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:24,185 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:24,186 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:24,186 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:24,186 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:24,186 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:24,195 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:24,201 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: start as a follower, conf=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:24,201 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:24,201 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start FollowerState
2019-09-25 11:59:24,201 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9C0AF7B870AE,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:24,214 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 54cbe843-90c4-4250-8675-9c0af7b870ae, Nodes: af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:24,214 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,214 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,215 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,215 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,254 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: addNew group-CCCF7FCC9F0C:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] returns group-CCCF7FCC9F0C:java.util.concurrent.CompletableFuture@68b0b1af[Not completed]
2019-09-25 11:59:24,390 [Thread-227] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 11:59:24,391 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: new RaftServerImpl for group-CCCF7FCC9F0C:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] with ContainerStateMachine:uninitialized
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: ConfigurationManager, init=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:24,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:24,393 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/9a2007f9-90d5-4321-8d71-cccf7fcc9f0c does not exist. Creating ...
2019-09-25 11:59:24,407 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/9a2007f9-90d5-4321-8d71-cccf7fcc9f0c/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:24,426 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/9a2007f9-90d5-4321-8d71-cccf7fcc9f0c has been successfully formatted.
2019-09-25 11:59:24,426 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-CCCF7FCC9F0C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:24,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:24,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:24,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:24,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:24,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/9a2007f9-90d5-4321-8d71-cccf7fcc9f0c
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:24,428 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:24,430 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:24,431 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:24,431 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:24,431 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:24,431 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:24,432 [Thread-227] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 11:59:24,432 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:24,432 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:24,432 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:24,432 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:24,435 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: start as a follower, conf=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:24,435 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:24,435 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start FollowerState
2019-09-25 11:59:24,435 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CCCF7FCC9F0C,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:24,443 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9a2007f9-90d5-4321-8d71-cccf7fcc9f0c, Nodes: af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:24,444 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,444 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,444 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,444 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,452 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: addNew group-6A5F078EEB6E:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] returns group-6A5F078EEB6E:java.util.concurrent.CompletableFuture@178f0136[Not completed]
2019-09-25 11:59:24,453 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: new RaftServerImpl for group-6A5F078EEB6E:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] with ContainerStateMachine:uninitialized
2019-09-25 11:59:24,453 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:24,453 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:24,453 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:24,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:24,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:24,454 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: ConfigurationManager, init=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:24,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:24,454 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/ba748c59-7232-465a-84b2-6a5f078eeb6e does not exist. Creating ...
2019-09-25 11:59:24,467 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/ba748c59-7232-465a-84b2-6a5f078eeb6e/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
2019-09-25 11:59:24,481 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/ba748c59-7232-465a-84b2-6a5f078eeb6e has been successfully formatted.
2019-09-25 11:59:24,481 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6A5F078EEB6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:24,481 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:24,481 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/ba748c59-7232-465a-84b2-6a5f078eeb6e
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:24,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:24,483 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:24,484 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:24,484 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:24,484 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:24,484 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:24,484 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:24,487 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: start as a follower, conf=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:24,487 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:24,487 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start FollowerState
2019-09-25 11:59:24,487 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A5F078EEB6E,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:24,505 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ba748c59-7232-465a-84b2-6a5f078eeb6e, Nodes: af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:24,505 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,505 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,505 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,506 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,515 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: addNew group-F82EA407D366:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] returns group-F82EA407D366:java.util.concurrent.CompletableFuture@e981687[Not completed]
2019-09-25 11:59:24,516 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: new RaftServerImpl for group-F82EA407D366:[af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658] with ContainerStateMachine:uninitialized
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: ConfigurationManager, init=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null, confs=<EMPTY_MAP>
2019-09-25 11:59:24,517 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis] (custom)
2019-09-25 11:59:24,518 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/7b654084-6b84-4a1a-9cdd-f82ea407d366 does not exist. Creating ...
2019-09-25 11:59:24,533 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/7b654084-6b84-4a1a-9cdd-f82ea407d366/in_use.lock acquired by nodename 7275@pr-hdds-1569-5gmkr-4255264070
11:59:24.534 [IPC Server handler 14 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:24,547 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/7b654084-6b84-4a1a-9cdd-f82ea407d366 has been successfully formatted.
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F82EA407D366: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/7b654084-6b84-4a1a-9cdd-f82ea407d366
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 11:59:24,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 11:59:24,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 11:59:24,550 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 11:59:24,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 11:59:24,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 11:59:24,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 11:59:24,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 11:59:24,552 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: start as a follower, conf=-1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:24,553 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 11:59:24,553 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start FollowerState
2019-09-25 11:59:24,553 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F82EA407D366,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 11:59:24,564 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7b654084-6b84-4a1a-9cdd-f82ea407d366, Nodes: af790e72-8fcd-4cb0-b23c-d20e93858cf2{ip: 192.168.30.6, host: pr-hdds-1569-5gmkr-4255264070, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 11:59:24,564 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,564 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:24,565 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,565 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,565 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,565 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:24,568 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:24,570 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,570 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:24,570 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,571 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,571 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,571 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:24,571 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:24,572 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:24,573 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:24,573 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:24,573 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:24,573 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:24,574 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:24,574 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:24,574 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:24,645 [Thread-227] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 11:59:24,645 [Thread-227] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 11:59:24,647 [Thread-227] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-25 11:59:24,647 [Thread-227] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-25 11:59:24,672 [Thread-227] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 11:59:24,683 [Thread-227] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 11:59:24,688 [Thread-227] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 11:59:24,713 [Thread-227] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 11:59:24,765 [Thread-227] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:11
2019-09-25 11:59:24,878 [Thread-227] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local484063999_0001
2019-09-25 11:59:24,879 [Thread-227] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 11:59:25,036 [Thread-227] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 11:59:25,037 [Thread-227] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local484063999_0001
2019-09-25 11:59:25,037 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local484063999_0001
2019-09-25 11:59:25,045 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 11:59:25,056 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:25,057 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:25,059 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 11:59:25,135 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 11:59:25,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000000_0
2019-09-25 11:59:25,189 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:25,191 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:25,216 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:25,220 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:0+324
2019-09-25 11:59:25,234 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:25,234 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
11:59:25.264 [IPC Server handler 14 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:25,266 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
11:59:25.273 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:25,289 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:25,297 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local484063999_0001_m_000000_0 is done. And is in the process of committing
2019-09-25 11:59:25,299 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:25,299 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local484063999_0001_m_000000_0 is allowed to commit now
2019-09-25 11:59:25,302 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local484063999_0001_m_000000_0' to file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/_logs
2019-09-25 11:59:25,302 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-25 11:59:25,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local484063999_0001_m_000000_0' done.
2019-09-25 11:59:25,306 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local484063999_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=204265
		FILE: Number of bytes written=820104
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=6
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 11:59:25,306 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local484063999_0001_m_000000_0
2019-09-25 11:59:25,306 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:25,309 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:25,309 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:25,310 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:25,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:860+290
2019-09-25 11:59:25,312 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:25,312 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:25,329 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
11:59:25.336 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:25,342 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:25,370 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:25,371 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:25,372 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:25,372 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:25,372 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:25,372 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:25,372 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:25,373 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:25,374 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:25,374 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:25.383 [IPC Server handler 8 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:25,385 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:25,386 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:26,043 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local484063999_0001 running in uber mode : false
2019-09-25 11:59:26,045 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 11:59:26,569 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:26,573 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:26,573 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:26,574 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:26,574 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:26,574 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:26,574 [IPC Server handler 13 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:26,575 [IPC Server handler 13 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:26,575 [IPC Server handler 13 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:26,575 [IPC Server handler 13 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:26,576 [IPC Server handler 13 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:26.583 [IPC Server handler 2 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:26,586 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:26,586 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:26,926 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2a3572d-7c1f-4e75-8685-be52119dd02b:group-719336267CD4 changes to CANDIDATE, lastRpcTime:5025, electionTimeout:5024ms
2019-09-25 11:59:26,932 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown FollowerState
2019-09-25 11:59:26,932 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:26,936 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderElection
2019-09-25 11:59:26,954 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1: begin an election at term 1 for -1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:26,956 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderElection
2019-09-25 11:59:26,957 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:26,957 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: change Leader from null to b2a3572d-7c1f-4e75-8685-be52119dd02b at term 1 for becomeLeader, leader elected after 5184ms
2019-09-25 11:59:26,965 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:26,966 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:26,969 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:26,972 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:26,972 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:26,973 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:26,985 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderState
2019-09-25 11:59:27,009 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,018 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: set configuration 0: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null at 0
2019-09-25 11:59:27,213 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/244ce72a-6bc9-49bb-963a-719336267cd4/current/log_inprogress_0
2019-09-25 11:59:27,258 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fe2c664-23d3-4023-9f8c-2687d201187c:group-281E61757094 changes to CANDIDATE, lastRpcTime:5060, electionTimeout:5060ms
2019-09-25 11:59:27,267 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown FollowerState
2019-09-25 11:59:27,268 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,268 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderElection
2019-09-25 11:59:27,294 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2: begin an election at term 1 for -1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:27,294 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderElection
2019-09-25 11:59:27,295 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,295 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: change Leader from null to 0fe2c664-23d3-4023-9f8c-2687d201187c at term 1 for becomeLeader, leader elected after 5105ms
2019-09-25 11:59:27,296 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,296 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,297 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,297 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,297 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,297 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,301 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderState
2019-09-25 11:59:27,301 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,302 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: set configuration 0: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null at 0
2019-09-25 11:59:27,340 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fe2c664-23d3-4023-9f8c-2687d201187c:group-C285669257DF changes to CANDIDATE, lastRpcTime:5216, electionTimeout:5193ms
2019-09-25 11:59:27,342 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown FollowerState
2019-09-25 11:59:27,342 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,342 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderElection
2019-09-25 11:59:27,353 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/748448e3-f9d7-4af2-bcd9-281e61757094/current/log_inprogress_0
2019-09-25 11:59:27,353 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3: begin an election at term 1 for -1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:27,355 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderElection
2019-09-25 11:59:27,355 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,355 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: change Leader from null to 0fe2c664-23d3-4023-9f8c-2687d201187c at term 1 for becomeLeader, leader elected after 5245ms
2019-09-25 11:59:27,355 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,355 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,356 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,356 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,356 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,356 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,360 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderState
2019-09-25 11:59:27,360 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,361 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: set configuration 0: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null at 0
2019-09-25 11:59:27,411 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/79195117-73f3-4821-b227-c285669257df/current/log_inprogress_0
2019-09-25 11:59:27,418 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 806040c9-6be1-453b-a2ca-ad7e12880578:group-4C72D74F3069 changes to CANDIDATE, lastRpcTime:5116, electionTimeout:5116ms
2019-09-25 11:59:27,419 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown FollowerState
2019-09-25 11:59:27,419 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,419 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderElection
2019-09-25 11:59:27,437 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4: begin an election at term 1 for -1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:27,437 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderElection
2019-09-25 11:59:27,437 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,437 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: change Leader from null to 806040c9-6be1-453b-a2ca-ad7e12880578 at term 1 for becomeLeader, leader elected after 5168ms
2019-09-25 11:59:27,439 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,439 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,439 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,440 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,440 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,440 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,443 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderState
2019-09-25 11:59:27,444 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,444 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: set configuration 0: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null at 0
2019-09-25 11:59:27,494 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/58f84323-73bd-4e4e-9b1c-4c72d74f3069/current/log_inprogress_0
2019-09-25 11:59:27,517 [Thread-225] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2a3572d-7c1f-4e75-8685-be52119dd02b:group-8A7781F80F0A changes to CANDIDATE, lastRpcTime:5072, electionTimeout:5072ms
2019-09-25 11:59:27,517 [Thread-225] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown FollowerState
2019-09-25 11:59:27,517 [Thread-225] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,517 [Thread-225] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderElection
2019-09-25 11:59:27,536 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5: begin an election at term 1 for -1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:27,536 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderElection
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: change Leader from null to b2a3572d-7c1f-4e75-8685-be52119dd02b at term 1 for becomeLeader, leader elected after 5101ms
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,537 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,538 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,540 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderState
2019-09-25 11:59:27,540 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,541 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: set configuration 0: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null at 0
2019-09-25 11:59:27,578 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - 806040c9-6be1-453b-a2ca-ad7e12880578:group-B166EF43A0B3 changes to CANDIDATE, lastRpcTime:5204, electionTimeout:5174ms
2019-09-25 11:59:27,579 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown FollowerState
2019-09-25 11:59:27,579 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,579 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderElection
2019-09-25 11:59:27,592 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/aed6666a-fb0a-4a15-8211-8a7781f80f0a/current/log_inprogress_0
2019-09-25 11:59:27,592 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6: begin an election at term 1 for -1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:27,592 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderElection
2019-09-25 11:59:27,592 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,592 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: change Leader from null to 806040c9-6be1-453b-a2ca-ad7e12880578 at term 1 for becomeLeader, leader elected after 5231ms
2019-09-25 11:59:27,592 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,593 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,593 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,593 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,593 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,593 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,597 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderState
2019-09-25 11:59:27,597 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,598 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: set configuration 0: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null at 0
2019-09-25 11:59:27,637 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fe2c664-23d3-4023-9f8c-2687d201187c:group-E509BFB4C8C2 changes to CANDIDATE, lastRpcTime:5128, electionTimeout:5097ms
2019-09-25 11:59:27,637 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown FollowerState
2019-09-25 11:59:27,637 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,637 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderElection
2019-09-25 11:59:27,650 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/5c31f0fd-46e6-4362-8a70-b166ef43a0b3/current/log_inprogress_0
2019-09-25 11:59:27,650 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7: begin an election at term 1 for -1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:27,650 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderElection
2019-09-25 11:59:27,650 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,651 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: change Leader from null to 0fe2c664-23d3-4023-9f8c-2687d201187c at term 1 for becomeLeader, leader elected after 5149ms
2019-09-25 11:59:27,651 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,651 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,651 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,651 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,651 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,652 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,655 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderState
2019-09-25 11:59:27,656 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,656 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: set configuration 0: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null at 0
2019-09-25 11:59:27,705 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/fa16a49b-cabe-47cc-82a8-e509bfb4c8c2/current/log_inprogress_0
2019-09-25 11:59:27,748 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fe2c664-23d3-4023-9f8c-2687d201187c:group-8C5F2E78582D changes to CANDIDATE, lastRpcTime:5103, electionTimeout:5103ms
2019-09-25 11:59:27,749 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown FollowerState
2019-09-25 11:59:27,749 [Thread-232] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,749 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderElection
2019-09-25 11:59:27,777 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8: begin an election at term 1 for -1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:27,777 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderElection
2019-09-25 11:59:27,777 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,777 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: change Leader from null to 0fe2c664-23d3-4023-9f8c-2687d201187c at term 1 for becomeLeader, leader elected after 5139ms
2019-09-25 11:59:27,777 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,777 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,778 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,778 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,778 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,778 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,781 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderState
2019-09-25 11:59:27,781 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,782 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: set configuration 0: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null at 0
2019-09-25 11:59:27,826 [Thread-238] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fe2c664-23d3-4023-9f8c-2687d201187c:group-447616BBE454 changes to CANDIDATE, lastRpcTime:5064, electionTimeout:5064ms
2019-09-25 11:59:27,827 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown FollowerState
2019-09-25 11:59:27,827 [Thread-238] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,827 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderElection
2019-09-25 11:59:27,834 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/5f3d2986-fcaf-4aa9-9aaa-8c5f2e78582d/current/log_inprogress_0
2019-09-25 11:59:27,834 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9: begin an election at term 1 for -1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:27,834 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderElection
2019-09-25 11:59:27,834 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,835 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: change Leader from null to 0fe2c664-23d3-4023-9f8c-2687d201187c at term 1 for becomeLeader, leader elected after 5080ms
2019-09-25 11:59:27,835 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,835 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,835 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,835 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,835 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,836 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,838 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderState
2019-09-25 11:59:27,839 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,839 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: set configuration 0: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null at 0
2019-09-25 11:59:27,878 [Thread-241] INFO  impl.FollowerState (FollowerState.java:run(106)) - 806040c9-6be1-453b-a2ca-ad7e12880578:group-456089AB08CE changes to CANDIDATE, lastRpcTime:5052, electionTimeout:5029ms
2019-09-25 11:59:27,878 [Thread-235] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fe2c664-23d3-4023-9f8c-2687d201187c:group-0FA7EEB8EEC0 changes to CANDIDATE, lastRpcTime:5173, electionTimeout:5151ms
2019-09-25 11:59:27,878 [Thread-241] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown FollowerState
2019-09-25 11:59:27,878 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown FollowerState
2019-09-25 11:59:27,878 [Thread-241] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,878 [Thread-235] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,878 [Thread-241] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderElection
2019-09-25 11:59:27,879 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderElection
2019-09-25 11:59:27,889 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/780316a5-72ae-474d-88bb-447616bbe454/current/log_inprogress_0
2019-09-25 11:59:27,891 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10: begin an election at term 1 for -1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:27,891 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11: begin an election at term 1 for -1: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null
2019-09-25 11:59:27,891 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderElection
2019-09-25 11:59:27,891 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderElection
2019-09-25 11:59:27,891 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,891 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,892 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: change Leader from null to 806040c9-6be1-453b-a2ca-ad7e12880578 at term 1 for becomeLeader, leader elected after 5072ms
2019-09-25 11:59:27,892 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: change Leader from null to 0fe2c664-23d3-4023-9f8c-2687d201187c at term 1 for becomeLeader, leader elected after 5193ms
2019-09-25 11:59:27,892 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,892 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,892 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,892 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,892 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,893 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,893 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,893 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,893 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,893 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,893 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,893 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,897 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderState
2019-09-25 11:59:27,897 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,897 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: start LeaderState
2019-09-25 11:59:27,898 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,898 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: set configuration 0: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null at 0
2019-09-25 11:59:27,931 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(106)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004:group-4998A190C7EF changes to CANDIDATE, lastRpcTime:5030, electionTimeout:5028ms
2019-09-25 11:59:27,931 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: set configuration 0: [0fe2c664-23d3-4023-9f8c-2687d201187c:192.168.30.6:40326], old=null at 0
2019-09-25 11:59:27,931 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown FollowerState
2019-09-25 11:59:27,961 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/f3e02262-76ac-44dd-a5cb-456089ab08ce/current/log_inprogress_0
2019-09-25 11:59:27,967 [Thread-245] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:27,968 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderElection
2019-09-25 11:59:27,980 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/ratis/07087c10-349b-4af9-a5cf-0fa7eeb8eec0/current/log_inprogress_0
2019-09-25 11:59:27,980 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12: begin an election at term 1 for -1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:27,980 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderElection
2019-09-25 11:59:27,980 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:27,980 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: change Leader from null to cbc7b4b8-8477-40ca-9cdc-b573f7732004 at term 1 for becomeLeader, leader elected after 5087ms
2019-09-25 11:59:27,982 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:27,982 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:27,983 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:27,983 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:27,983 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:27,983 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:27,986 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderState
2019-09-25 11:59:27,986 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:27,987 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: set configuration 0: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null at 0
2019-09-25 11:59:28,033 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e8cf15fe-72f2-4e94-b85e-4998a190c7ef/current/log_inprogress_0
2019-09-25 11:59:28,104 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2a3572d-7c1f-4e75-8685-be52119dd02b:group-F8EB8B561257 changes to CANDIDATE, lastRpcTime:5027, electionTimeout:5027ms
2019-09-25 11:59:28,104 [Thread-254] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown FollowerState
2019-09-25 11:59:28,104 [Thread-254] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,104 [Thread-254] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderElection
2019-09-25 11:59:28,123 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13: begin an election at term 1 for -1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:28,123 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderElection
2019-09-25 11:59:28,123 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,123 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: change Leader from null to b2a3572d-7c1f-4e75-8685-be52119dd02b at term 1 for becomeLeader, leader elected after 5052ms
2019-09-25 11:59:28,123 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,124 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,124 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,124 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,124 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,124 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,124 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2a3572d-7c1f-4e75-8685-be52119dd02b:group-C2489467E579 changes to CANDIDATE, lastRpcTime:5164, electionTimeout:5164ms
2019-09-25 11:59:28,125 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown FollowerState
2019-09-25 11:59:28,125 [Thread-248] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,125 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderElection
2019-09-25 11:59:28,131 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderState
2019-09-25 11:59:28,131 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,132 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: set configuration 0: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null at 0
2019-09-25 11:59:28,165 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14: begin an election at term 1 for -1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:28,165 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderElection
2019-09-25 11:59:28,166 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,166 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: change Leader from null to b2a3572d-7c1f-4e75-8685-be52119dd02b at term 1 for becomeLeader, leader elected after 5211ms
2019-09-25 11:59:28,166 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,166 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,166 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,167 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,167 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,167 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,170 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderState
2019-09-25 11:59:28,171 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,171 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: set configuration 0: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null at 0
2019-09-25 11:59:28,207 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/b0f0bfc7-6779-495a-b4b1-f8eb8b561257/current/log_inprogress_0
2019-09-25 11:59:28,211 [Thread-251] INFO  impl.FollowerState (FollowerState.java:run(106)) - 806040c9-6be1-453b-a2ca-ad7e12880578:group-7BD4E3F55877 changes to CANDIDATE, lastRpcTime:5192, electionTimeout:5192ms
2019-09-25 11:59:28,212 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown FollowerState
2019-09-25 11:59:28,212 [Thread-251] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,212 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderElection
2019-09-25 11:59:28,220 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/812a2d98-aa0d-438b-bf71-c2489467e579/current/log_inprogress_0
2019-09-25 11:59:28,220 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15: begin an election at term 1 for -1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:28,220 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderElection
2019-09-25 11:59:28,220 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,221 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: change Leader from null to 806040c9-6be1-453b-a2ca-ad7e12880578 at term 1 for becomeLeader, leader elected after 5207ms
2019-09-25 11:59:28,221 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,221 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,221 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,221 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,222 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,222 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,225 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderState
2019-09-25 11:59:28,225 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,226 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: set configuration 0: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null at 0
2019-09-25 11:59:28,261 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2a3572d-7c1f-4e75-8685-be52119dd02b:group-C3F88A4F5E32 changes to CANDIDATE, lastRpcTime:5047, electionTimeout:5026ms
2019-09-25 11:59:28,261 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown FollowerState
2019-09-25 11:59:28,261 [Thread-262] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,261 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderElection
2019-09-25 11:59:28,273 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/4de0d0f9-0edf-425e-80c1-7bd4e3f55877/current/log_inprogress_0
2019-09-25 11:59:28,273 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16: begin an election at term 1 for -1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:28,274 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderElection
2019-09-25 11:59:28,274 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,274 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: change Leader from null to b2a3572d-7c1f-4e75-8685-be52119dd02b at term 1 for becomeLeader, leader elected after 5068ms
2019-09-25 11:59:28,274 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,274 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,274 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,275 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,275 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,275 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,288 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderState
2019-09-25 11:59:28,289 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,289 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: set configuration 0: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null at 0
2019-09-25 11:59:28,335 [Thread-258] INFO  impl.FollowerState (FollowerState.java:run(106)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2:group-081B7A613759 changes to CANDIDATE, lastRpcTime:5185, electionTimeout:5185ms
2019-09-25 11:59:28,336 [Thread-258] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown FollowerState
2019-09-25 11:59:28,336 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/22e3f352-2a38-4a35-8454-c3f88a4f5e32/current/log_inprogress_0
2019-09-25 11:59:28,336 [Thread-258] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,336 [Thread-258] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderElection
2019-09-25 11:59:28,349 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17: begin an election at term 1 for -1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:28,349 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderElection
2019-09-25 11:59:28,349 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,350 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: change Leader from null to af790e72-8fcd-4cb0-b23c-d20e93858cf2 at term 1 for becomeLeader, leader elected after 5218ms
2019-09-25 11:59:28,352 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,352 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,352 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,352 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,352 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,352 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,355 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderState
2019-09-25 11:59:28,355 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,356 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: set configuration 0: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null at 0
2019-09-25 11:59:28,400 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/cbaa00d7-2d25-4740-8126-081b7a613759/current/log_inprogress_0
2019-09-25 11:59:28,420 [Thread-265] INFO  impl.FollowerState (FollowerState.java:run(106)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2:group-D16646313036 changes to CANDIDATE, lastRpcTime:5150, electionTimeout:5150ms
2019-09-25 11:59:28,421 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown FollowerState
2019-09-25 11:59:28,421 [Thread-265] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,421 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderElection
2019-09-25 11:59:28,432 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18: begin an election at term 1 for -1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:28,433 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderElection
2019-09-25 11:59:28,433 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,433 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: change Leader from null to af790e72-8fcd-4cb0-b23c-d20e93858cf2 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-25 11:59:28,433 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,433 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,433 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,434 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,434 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,434 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,437 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderState
2019-09-25 11:59:28,437 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,438 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: set configuration 0: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null at 0
2019-09-25 11:59:28,487 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/b0eb7fb1-e9bd-4749-9cfb-d16646313036/current/log_inprogress_0
2019-09-25 11:59:28,535 [Thread-268] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2a3572d-7c1f-4e75-8685-be52119dd02b:group-A89B179A7775 changes to CANDIDATE, lastRpcTime:5200, electionTimeout:5200ms
2019-09-25 11:59:28,535 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown FollowerState
2019-09-25 11:59:28,535 [Thread-268] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,536 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderElection
2019-09-25 11:59:28,553 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19: begin an election at term 1 for -1: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null
2019-09-25 11:59:28,554 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderElection
2019-09-25 11:59:28,554 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,554 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: change Leader from null to b2a3572d-7c1f-4e75-8685-be52119dd02b at term 1 for becomeLeader, leader elected after 5227ms
2019-09-25 11:59:28,554 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,554 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,555 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,555 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,555 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,555 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,559 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: start LeaderState
2019-09-25 11:59:28,559 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,560 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: set configuration 0: [b2a3572d-7c1f-4e75-8685-be52119dd02b:192.168.30.6:38937], old=null at 0
2019-09-25 11:59:28,610 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/ratis/1f3a111c-382d-4c49-a307-a89b179a7775/current/log_inprogress_0
2019-09-25 11:59:28,722 [Thread-272] INFO  impl.FollowerState (FollowerState.java:run(106)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004:group-A38E37A59148 changes to CANDIDATE, lastRpcTime:5017, electionTimeout:5017ms
2019-09-25 11:59:28,722 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown FollowerState
2019-09-25 11:59:28,722 [Thread-272] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,723 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderElection
2019-09-25 11:59:28,758 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20: begin an election at term 1 for -1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:28,759 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderElection
2019-09-25 11:59:28,759 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,759 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: change Leader from null to cbc7b4b8-8477-40ca-9cdc-b573f7732004 at term 1 for becomeLeader, leader elected after 5063ms
2019-09-25 11:59:28,759 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,760 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,760 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,760 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,760 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,761 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,763 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderState
2019-09-25 11:59:28,764 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,764 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: set configuration 0: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null at 0
2019-09-25 11:59:28,807 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/5e689a4f-2899-48c9-b0b1-a38e37a59148/current/log_inprogress_0
2019-09-25 11:59:28,877 [Thread-275] INFO  impl.FollowerState (FollowerState.java:run(106)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004:group-AEDF94CA4321 changes to CANDIDATE, lastRpcTime:5066, electionTimeout:5066ms
2019-09-25 11:59:28,877 [Thread-275] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown FollowerState
2019-09-25 11:59:28,878 [Thread-275] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:28,878 [Thread-275] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderElection
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21: begin an election at term 1 for -1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderElection
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: change Leader from null to cbc7b4b8-8477-40ca-9cdc-b573f7732004 at term 1 for becomeLeader, leader elected after 5091ms
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:28,894 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:28,895 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:28,895 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:28,895 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:28,896 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderState
2019-09-25 11:59:28,897 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:28,897 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: set configuration 0: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null at 0
2019-09-25 11:59:28,935 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/b0d2ca51-1c31-4d77-8ed8-aedf94ca4321/current/log_inprogress_0
2019-09-25 11:59:29,051 [Thread-279] INFO  impl.FollowerState (FollowerState.java:run(106)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004:group-ADB1836EF94D changes to CANDIDATE, lastRpcTime:5180, electionTimeout:5180ms
2019-09-25 11:59:29,052 [Thread-279] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown FollowerState
2019-09-25 11:59:29,052 [Thread-279] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,052 [Thread-279] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderElection
2019-09-25 11:59:29,069 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22: begin an election at term 1 for -1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:29,069 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderElection
2019-09-25 11:59:29,069 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,069 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: change Leader from null to cbc7b4b8-8477-40ca-9cdc-b573f7732004 at term 1 for becomeLeader, leader elected after 5210ms
2019-09-25 11:59:29,069 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,070 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,070 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,070 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,070 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,070 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,072 [Thread-291] INFO  impl.FollowerState (FollowerState.java:run(106)) - 806040c9-6be1-453b-a2ca-ad7e12880578:group-4B6341FF55C6 changes to CANDIDATE, lastRpcTime:5025, electionTimeout:5025ms
2019-09-25 11:59:29,072 [Thread-291] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown FollowerState
2019-09-25 11:59:29,072 [Thread-291] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,072 [Thread-291] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderElection
2019-09-25 11:59:29,075 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderState
2019-09-25 11:59:29,076 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,076 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: set configuration 0: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null at 0
2019-09-25 11:59:29,102 [Thread-282] INFO  impl.FollowerState (FollowerState.java:run(106)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004:group-6703E43134CB changes to CANDIDATE, lastRpcTime:5177, electionTimeout:5162ms
2019-09-25 11:59:29,102 [Thread-288] INFO  impl.FollowerState (FollowerState.java:run(106)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004:group-DCFAC63A4D33 changes to CANDIDATE, lastRpcTime:5108, electionTimeout:5094ms
2019-09-25 11:59:29,102 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown FollowerState
2019-09-25 11:59:29,102 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown FollowerState
2019-09-25 11:59:29,102 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23: begin an election at term 1 for -1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:29,102 [Thread-288] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,102 [Thread-282] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,102 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderElection
2019-09-25 11:59:29,103 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderElection
2019-09-25 11:59:29,102 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderElection
2019-09-25 11:59:29,103 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,103 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: change Leader from null to 806040c9-6be1-453b-a2ca-ad7e12880578 at term 1 for becomeLeader, leader elected after 5063ms
2019-09-25 11:59:29,103 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,103 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,107 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,107 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,107 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,107 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,109 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderState
2019-09-25 11:59:29,109 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,110 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: set configuration 0: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null at 0
2019-09-25 11:59:29,142 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/e268c968-4668-444b-8a15-adb1836ef94d/current/log_inprogress_0
2019-09-25 11:59:29,142 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24: begin an election at term 1 for -1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:29,142 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25: begin an election at term 1 for -1: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null
2019-09-25 11:59:29,143 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderElection
2019-09-25 11:59:29,143 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderElection
2019-09-25 11:59:29,143 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,143 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,143 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: change Leader from null to cbc7b4b8-8477-40ca-9cdc-b573f7732004 at term 1 for becomeLeader, leader elected after 5170ms
2019-09-25 11:59:29,143 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: change Leader from null to cbc7b4b8-8477-40ca-9cdc-b573f7732004 at term 1 for becomeLeader, leader elected after 5226ms
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,144 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,145 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,145 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,145 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,145 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,145 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,150 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderState
2019-09-25 11:59:29,150 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: start LeaderState
2019-09-25 11:59:29,151 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,151 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,151 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: set configuration 0: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null at 0
2019-09-25 11:59:29,184 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/eec50250-65a1-4a7a-817a-4b6341ff55c6/current/log_inprogress_0
2019-09-25 11:59:29,184 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: set configuration 0: [cbc7b4b8-8477-40ca-9cdc-b573f7732004:192.168.30.6:39643], old=null at 0
2019-09-25 11:59:29,217 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/bcd9b15e-7274-4efe-93de-dcfac63a4d33/current/log_inprogress_0
2019-09-25 11:59:29,217 [Thread-297] INFO  impl.FollowerState (FollowerState.java:run(106)) - 806040c9-6be1-453b-a2ca-ad7e12880578:group-42300DDC6049 changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5076ms
2019-09-25 11:59:29,217 [Thread-297] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown FollowerState
2019-09-25 11:59:29,218 [Thread-297] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,218 [Thread-297] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderElection
2019-09-25 11:59:29,230 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/ratis/d26503d6-c268-43a0-8e86-6703e43134cb/current/log_inprogress_0
2019-09-25 11:59:29,230 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26: begin an election at term 1 for -1: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null
2019-09-25 11:59:29,230 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderElection
2019-09-25 11:59:29,230 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,230 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: change Leader from null to 806040c9-6be1-453b-a2ca-ad7e12880578 at term 1 for becomeLeader, leader elected after 5121ms
2019-09-25 11:59:29,230 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,231 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,231 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,231 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,231 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,232 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,234 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 806040c9-6be1-453b-a2ca-ad7e12880578: start LeaderState
2019-09-25 11:59:29,235 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,235 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: set configuration 0: [806040c9-6be1-453b-a2ca-ad7e12880578:192.168.30.6:36253], old=null at 0
2019-09-25 11:59:29,284 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/ratis/0fe946cc-dcbc-4ff5-906b-42300ddc6049/current/log_inprogress_0
2019-09-25 11:59:29,384 [Thread-309] INFO  impl.FollowerState (FollowerState.java:run(106)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2:group-9C0AF7B870AE changes to CANDIDATE, lastRpcTime:5183, electionTimeout:5183ms
2019-09-25 11:59:29,385 [Thread-309] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown FollowerState
2019-09-25 11:59:29,385 [Thread-309] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,385 [Thread-309] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderElection
2019-09-25 11:59:29,402 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27: begin an election at term 1 for -1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:29,402 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderElection
2019-09-25 11:59:29,402 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: change Leader from null to af790e72-8fcd-4cb0-b23c-d20e93858cf2 at term 1 for becomeLeader, leader elected after 5222ms
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,403 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,406 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderState
2019-09-25 11:59:29,406 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,407 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: set configuration 0: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null at 0
2019-09-25 11:59:29,456 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/54cbe843-90c4-4250-8675-9c0af7b870ae/current/log_inprogress_0
2019-09-25 11:59:29,527 [Thread-323] INFO  impl.FollowerState (FollowerState.java:run(106)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2:group-CCCF7FCC9F0C changes to CANDIDATE, lastRpcTime:5091, electionTimeout:5091ms
2019-09-25 11:59:29,527 [Thread-323] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown FollowerState
2019-09-25 11:59:29,527 [Thread-323] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,527 [Thread-323] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderElection
2019-09-25 11:59:29,545 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28: begin an election at term 1 for -1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:29,545 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderElection
2019-09-25 11:59:29,545 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,545 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: change Leader from null to af790e72-8fcd-4cb0-b23c-d20e93858cf2 at term 1 for becomeLeader, leader elected after 5118ms
2019-09-25 11:59:29,545 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,546 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,546 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,546 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,546 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,546 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,549 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderState
2019-09-25 11:59:29,550 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,550 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: set configuration 0: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null at 0
2019-09-25 11:59:29,603 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/9a2007f9-90d5-4321-8d71-cccf7fcc9f0c/current/log_inprogress_0
2019-09-25 11:59:29,610 [Thread-328] INFO  impl.FollowerState (FollowerState.java:run(106)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2:group-6A5F078EEB6E changes to CANDIDATE, lastRpcTime:5122, electionTimeout:5122ms
2019-09-25 11:59:29,610 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown FollowerState
2019-09-25 11:59:29,610 [Thread-328] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,610 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderElection
2019-09-25 11:59:29,617 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29: begin an election at term 1 for -1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:29,617 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderElection
2019-09-25 11:59:29,617 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,617 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: change Leader from null to af790e72-8fcd-4cb0-b23c-d20e93858cf2 at term 1 for becomeLeader, leader elected after 5135ms
2019-09-25 11:59:29,617 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,617 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,618 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,618 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,618 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,618 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,621 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderState
2019-09-25 11:59:29,621 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,622 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: set configuration 0: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null at 0
2019-09-25 11:59:29,665 [Thread-331] INFO  impl.FollowerState (FollowerState.java:run(106)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2:group-F82EA407D366 changes to CANDIDATE, lastRpcTime:5112, electionTimeout:5071ms
2019-09-25 11:59:29,666 [Thread-331] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown FollowerState
2019-09-25 11:59:29,666 [Thread-331] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 11:59:29,666 [Thread-331] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderElection
2019-09-25 11:59:29,677 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/ba748c59-7232-465a-84b2-6a5f078eeb6e/current/log_inprogress_0
2019-09-25 11:59:29,677 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30: begin an election at term 1 for -1: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null
2019-09-25 11:59:29,677 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderElection
2019-09-25 11:59:29,677 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 11:59:29,677 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: change Leader from null to af790e72-8fcd-4cb0-b23c-d20e93858cf2 at term 1 for becomeLeader, leader elected after 5129ms
2019-09-25 11:59:29,678 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 11:59:29,678 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 11:59:29,678 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 11:59:29,678 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 11:59:29,678 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 11:59:29,678 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 11:59:29,681 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: start LeaderState
2019-09-25 11:59:29,682 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 11:59:29,682 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: set configuration 0: [af790e72-8fcd-4cb0-b23c-d20e93858cf2:192.168.30.6:43658], old=null at 0
2019-09-25 11:59:29,752 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/ratis/7b654084-6b84-4a1a-9cdd-f82ea407d366/current/log_inprogress_0
2019-09-25 11:59:32,089 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:32,097 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:32,098 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:32,098 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:32,098 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:32,098 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:32,099 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:32,099 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:32,100 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:32,100 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:32,100 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:32.104 [IPC Server handler 14 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:32,105 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000001_0
2019-09-25 11:59:32,106 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:32,106 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 11:59:32,108 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:32,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:32,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:32,124 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:32,125 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:2226+290
2019-09-25 11:59:32,126 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:32,126 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:32,146 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
11:59:32.154 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:32,155 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:32,159 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:32,159 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:32,159 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:32,159 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:32,159 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:32,160 [IPC Server handler 13 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:32,160 [IPC Server handler 13 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:32,160 [IPC Server handler 13 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:32,161 [IPC Server handler 13 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:32,161 [IPC Server handler 13 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:32.163 [IPC Server handler 10 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:32,165 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:32,165 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:34,840 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:34,845 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:34,845 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:34,845 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:34,846 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:34,846 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:34,846 [IPC Server handler 0 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:34,846 [IPC Server handler 0 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:34,847 [IPC Server handler 0 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:34,847 [IPC Server handler 0 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:34,847 [IPC Server handler 0 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:34.851 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:34,852 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:34,852 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:37,330 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 11:59:38,056 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 18% reduce 0%
2019-09-25 11:59:39,554 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:39,559 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:39,559 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:39,560 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:39,560 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:39,560 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:39,560 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:39,560 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:39,561 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:39,562 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:39,562 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:39.566 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:39,567 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000002_0
2019-09-25 11:59:39,568 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:39,569 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 11:59:39,570 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:39,571 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:39,571 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:39,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:39,575 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:2778+290
2019-09-25 11:59:39,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:39,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:39,594 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
11:59:39.600 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:39,602 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:39,605 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:39,606 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:39,606 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:39,606 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:39,606 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:39,607 [IPC Server handler 16 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:39,607 [IPC Server handler 16 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:39,607 [IPC Server handler 16 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:39,608 [IPC Server handler 16 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:39,608 [IPC Server handler 16 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:39.611 [IPC Server handler 16 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:39,612 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:39,612 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:41,011 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:41,017 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:41,017 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:41,018 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:41,018 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:41,018 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:41,018 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:41,018 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:41,019 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:41,020 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:41,020 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:41.023 [IPC Server handler 13 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:41,025 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:41,025 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:43,332 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 11:59:44,144 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 11:59:45,061 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 27% reduce 0%
2019-09-25 11:59:45,848 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:45,871 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:45,871 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:45,871 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:45,872 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:45,872 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:45,872 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:45,872 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:45,873 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:45,873 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:45,873 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:45.877 [IPC Server handler 13 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:45,878 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000003_0
2019-09-25 11:59:45,879 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:45,879 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 11:59:45,880 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000004_0
2019-09-25 11:59:45,882 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:45,882 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:45,883 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:45,884 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:582+278
2019-09-25 11:59:45,885 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:45,885 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:45,909 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
11:59:45.916 [IPC Server handler 0 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:45,924 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:45,924 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local484063999_0001_m_000004_0 is done. And is in the process of committing
2019-09-25 11:59:45,925 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:45,925 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local484063999_0001_m_000004_0 is allowed to commit now
2019-09-25 11:59:45,927 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local484063999_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/_logs
2019-09-25 11:59:45,928 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 11:59:45,928 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local484063999_0001_m_000004_0' done.
2019-09-25 11:59:45,929 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local484063999_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=223325
		FILE: Number of bytes written=820136
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=23
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 11:59:45,930 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local484063999_0001_m_000004_0
2019-09-25 11:59:45,930 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000005_0
2019-09-25 11:59:45,931 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:45,931 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:45,931 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:45,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:1948+278
2019-09-25 11:59:45,933 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:45,933 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:45,952 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
11:59:45.958 [IPC Server handler 1 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:45,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:45,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local484063999_0001_m_000005_0 is done. And is in the process of committing
2019-09-25 11:59:45,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:45,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local484063999_0001_m_000005_0 is allowed to commit now
2019-09-25 11:59:45,976 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local484063999_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/_logs
2019-09-25 11:59:45,977 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 11:59:45,977 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local484063999_0001_m_000005_0' done.
2019-09-25 11:59:45,978 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local484063999_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=227706
		FILE: Number of bytes written=820144
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=25
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 11:59:45,978 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local484063999_0001_m_000005_0
2019-09-25 11:59:45,978 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:45,979 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:45,979 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:45,980 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:45,981 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:1674+274
2019-09-25 11:59:45,982 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:45,982 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:46,004 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
11:59:46.011 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:46,012 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:46,017 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:46,019 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:46,019 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:46,019 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:46,019 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:46,019 [IPC Server handler 13 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:46,020 [IPC Server handler 13 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:46,020 [IPC Server handler 13 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:46,020 [IPC Server handler 13 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:46,021 [IPC Server handler 13 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:46.023 [IPC Server handler 10 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:46,025 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:46,025 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:46,062 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 11:59:48,610 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:48,614 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:48,615 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:48,615 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:48,615 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:48,616 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:48,616 [IPC Server handler 8 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:48,616 [IPC Server handler 8 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:48,617 [IPC Server handler 8 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:48,617 [IPC Server handler 8 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:48,617 [IPC Server handler 8 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:48.621 [IPC Server handler 17 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:48,622 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:48,622 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:50,145 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 11:59:51,066 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-25 11:59:51,591 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 11:59:52,066 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 55% reduce 0%
2019-09-25 11:59:53,481 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:53,485 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:53,486 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:53,486 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:53,486 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:53,487 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:53,487 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:53,487 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:53,488 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:53,488 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:53,488 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:53.493 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:53,495 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000006_0
2019-09-25 11:59:53,495 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:53,496 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 11:59:53,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000007_0
2019-09-25 11:59:53,500 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,500 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:53,503 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:1150+262
2019-09-25 11:59:53,504 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,505 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,527 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
11:59:53.535 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:53,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:53,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local484063999_0001_m_000007_0 is done. And is in the process of committing
2019-09-25 11:59:53,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:53,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local484063999_0001_m_000007_0 is allowed to commit now
2019-09-25 11:59:53,547 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local484063999_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/_logs
2019-09-25 11:59:53,548 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-25 11:59:53,548 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local484063999_0001_m_000007_0' done.
2019-09-25 11:59:53,549 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local484063999_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=235956
		FILE: Number of bytes written=820160
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=32
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 11:59:53,549 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local484063999_0001_m_000007_0
2019-09-25 11:59:53,549 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000008_0
2019-09-25 11:59:53,551 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,551 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,551 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:53,553 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:1412+262
2019-09-25 11:59:53,554 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,554 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-25 11:59:53,585 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:53,585 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local484063999_0001_m_000008_0 is done. And is in the process of committing
2019-09-25 11:59:53,586 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:53,586 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local484063999_0001_m_000008_0 is allowed to commit now
2019-09-25 11:59:53,588 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local484063999_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/_logs
2019-09-25 11:59:53,589 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-25 11:59:53,589 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local484063999_0001_m_000008_0' done.
2019-09-25 11:59:53,590 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local484063999_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=239825
		FILE: Number of bytes written=820168
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=34
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 11:59:53,590 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local484063999_0001_m_000008_0
2019-09-25 11:59:53,590 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000009_0
2019-09-25 11:59:53,598 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,599 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,599 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:53,600 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:2516+262
2019-09-25 11:59:53,601 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,601 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,618 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-25 11:59:53,629 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:53,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local484063999_0001_m_000009_0 is done. And is in the process of committing
2019-09-25 11:59:53,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 11:59:53,631 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local484063999_0001_m_000009_0 is allowed to commit now
2019-09-25 11:59:53,632 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local484063999_0001_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/_logs
2019-09-25 11:59:53,633 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-25 11:59:53,633 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local484063999_0001_m_000009_0' done.
2019-09-25 11:59:53,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local484063999_0001_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=243694
		FILE: Number of bytes written=820176
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=36
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 11:59:53,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local484063999_0001_m_000009_0
2019-09-25 11:59:53,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local484063999_0001_m_000010_0
2019-09-25 11:59:53,635 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,635 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,635 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 11:59:53,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851/fileList.seq:324+258
2019-09-25 11:59:53,637 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 11:59:53,638 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 11:59:53,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
11:59:53.664 [IPC Server handler 1 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:53,666 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
2019-09-25 11:59:53,669 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:53,672 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:53,672 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:53,673 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:53,673 [IPC Server handler 0 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:53,673 [IPC Server handler 0 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:53,673 [IPC Server handler 0 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:53,674 [IPC Server handler 0 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:53,674 [IPC Server handler 0 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:53,674 [IPC Server handler 0 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:53.677 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:53,678 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
2019-09-25 11:59:53,678 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:54,068 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 11:59:55,441 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
2019-09-25 11:59:55,445 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 11:59:55,445 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 11:59:55,445 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 11:59:55,445 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 11:59:55,446 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 11:59:55,446 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 11:59:55,446 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:55,447 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 11:59:55,447 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 11:59:55,447 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
11:59:55.450 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 11:59:55,451 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
2019-09-25 11:59:55,451 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 11:59:57,592 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 11:59:57,996 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-25 11:59:58,071 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 91% reduce 0%
2019-09-25 12:00:00,042 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
2019-09-25 12:00:00,046 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:00,046 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:00,047 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:00,047 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:00,047 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:00,047 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:00,048 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:00,048 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:00,049 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:00,049 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:00.052 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43517, bucket=bucket26403, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43517 bucket: bucket26403 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:00,053 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local484063999_0001_m_000010_0
2019-09-25 12:00:00,053 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:00,054 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:00,055 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:00:00,095 [Thread-371] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001247448634/.staging/_distcp1048792851
2019-09-25 12:00:00,097 [Thread-371] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local484063999_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket26403.volume43517/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:01,073 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local484063999_0001 failed with state FAILED due to: NA
2019-09-25 12:00:01,134 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=2319904
		FILE: Number of bytes written=8201536
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=285
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=212
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Input split bytes=1580
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=20583546880
	File Input Format Counters 
		Bytes Read=31240
	File Output Format Counters 
		Bytes Written=80
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-25 12:00:01,206 [Thread-491] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:00:01,238 [Thread-491] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume17212, with user81871 as owner.
2019-09-25 12:00:01,241 [IPC Server handler 8 on 33801] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume17212 for user:user81871
2019-09-25 12:00:01,244 [Thread-491] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume17212/bucket86926, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:00:01,298 [Thread-491] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket86926.volume17212 implemented by OzoneFileSystem{URI=o3fs://bucket86926.volume17212, workingDir=o3fs://bucket86926.volume17212/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 48 read ops, 0 large read ops, 32 write ops}
12:00:01.321 [IPC Server handler 1 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:01,325 [Thread-491] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-25 12:00:01,401 [Thread-491] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:00:01,408 [Thread-491] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
12:00:01.417 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:01,467 [Thread-491] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 12:00:01,467 [Thread-491] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:00:01,475 [Thread-491] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:00:01,482 [Thread-491] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:00:01,483 [Thread-491] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:00:01,490 [Thread-491] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:00:01,525 [Thread-491] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:11
2019-09-25 12:00:01,550 [Thread-491] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local321937552_0002
2019-09-25 12:00:01,550 [Thread-491] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:00:01,642 [Thread-491] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:00:01,644 [Thread-555] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:00:01,645 [Thread-491] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local321937552_0002
2019-09-25 12:00:01,645 [Thread-555] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:01,645 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local321937552_0002
2019-09-25 12:00:01,645 [Thread-555] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:01,645 [Thread-555] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:00:01,662 [Thread-555] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:00:01,662 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000000_0
2019-09-25 12:00:01,664 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:01,664 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:01,664 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:01,667 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:0+323
2019-09-25 12:00:01,669 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:01,669 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:00:01.686 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:01,688 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
12:00:01.693 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:01,698 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:01,698 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local321937552_0002_m_000000_0 is done. And is in the process of committing
2019-09-25 12:00:01,699 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:01,699 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local321937552_0002_m_000000_0 is allowed to commit now
2019-09-25 12:00:01,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local321937552_0002_m_000000_0' to file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/_logs
2019-09-25 12:00:01,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-25 12:00:01,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local321937552_0002_m_000000_0' done.
2019-09-25 12:00:01,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local321937552_0002_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=451228
		FILE: Number of bytes written=1640217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=54
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:00:01,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local321937552_0002_m_000000_0
2019-09-25 12:00:01,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:01,703 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:01,703 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:01,703 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:01,704 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:323+289
2019-09-25 12:00:01,704 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:01,705 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:01,717 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
12:00:01.721 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:01,722 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:01,731 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:01,733 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:01,733 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:01,733 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:01,733 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:01,733 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:01,733 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:01,739 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:01,739 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:01,739 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:01.742 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:01,743 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:01,744 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:02,645 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local321937552_0002 running in uber mode : false
2019-09-25 12:00:02,646 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:00:03,698 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:03,702 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:03,702 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:03,703 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:03,703 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:03,703 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:03,703 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:03,704 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:03,704 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:03,704 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:03,705 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:03.707 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:03,708 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:03,708 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:03,997 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-25 12:00:05,644 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-25 12:00:08,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:08,122 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:08,122 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:08,123 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:08,123 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:08,123 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:08,123 [IPC Server handler 16 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:08,124 [IPC Server handler 16 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:08,124 [IPC Server handler 16 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:08,125 [IPC Server handler 16 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:08,125 [IPC Server handler 16 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:08.129 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:08,131 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000001_0
2019-09-25 12:00:08,131 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:08,132 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:08,133 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:08,134 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:08,135 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:08,135 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:08,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:1423+289
2019-09-25 12:00:08,138 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:08,139 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:08,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
12:00:08.167 [IPC Server handler 16 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:08,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:08,171 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:08,171 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:08,172 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:08,172 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:08,172 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:08,172 [IPC Server handler 8 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:08,173 [IPC Server handler 8 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:08,173 [IPC Server handler 8 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:08,174 [IPC Server handler 8 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:08,174 [IPC Server handler 8 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:08.176 [IPC Server handler 13 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:08,178 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:08,178 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:10,624 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:10,627 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:10,628 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:10,628 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:10,628 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:10,628 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:10,628 [IPC Server handler 12 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:10,629 [IPC Server handler 12 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:10,629 [IPC Server handler 12 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:10,629 [IPC Server handler 12 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:10,630 [IPC Server handler 12 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:10.632 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:10,634 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:10,634 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:11,645 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-25 12:00:13,721 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 12:00:14,654 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 18% reduce 0%
2019-09-25 12:00:15,198 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:15,203 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:15,204 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:15,204 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:15,204 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:15,204 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:15,205 [IPC Server handler 12 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:15,205 [IPC Server handler 12 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:15,206 [IPC Server handler 12 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:15,206 [IPC Server handler 12 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:15,206 [IPC Server handler 12 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:15.210 [IPC Server handler 0 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:15,211 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000002_0
2019-09-25 12:00:15,211 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:15,212 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:15,214 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:15,215 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:15,215 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:15,216 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:15,217 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:1973+289
2019-09-25 12:00:15,217 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:15,217 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:15,235 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
12:00:15.243 [IPC Server handler 12 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:15,245 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:15,248 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:15,248 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:15,248 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:15,248 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:15,249 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:15,249 [IPC Server handler 5 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:15,249 [IPC Server handler 5 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:15,250 [IPC Server handler 5 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:15,251 [IPC Server handler 5 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:15,251 [IPC Server handler 5 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:15.253 [IPC Server handler 14 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:15,254 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:15,255 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:18,033 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:18,037 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:18,038 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:18,038 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:18,038 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:18,039 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:18,039 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:18,039 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:18,040 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:18,041 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:18,041 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:18.044 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:18,046 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:18,046 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:19,724 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 12:00:20,153 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 12:00:20,658 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 27% reduce 0%
2019-09-25 12:00:22,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:22,576 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:22,576 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:22,577 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:22,577 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:22,577 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:22,578 [IPC Server handler 11 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:22,578 [IPC Server handler 11 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:22,579 [IPC Server handler 11 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:22,579 [IPC Server handler 11 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:22,579 [IPC Server handler 11 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:22.582 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:22,583 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000003_0
2019-09-25 12:00:22,583 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:22,584 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:22,585 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000004_0
2019-09-25 12:00:22,586 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:22,586 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:22,586 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:22,588 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:1146+277
2019-09-25 12:00:22,588 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:22,589 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:22,605 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
12:00:22.611 [IPC Server handler 8 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:22,616 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:22,616 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local321937552_0002_m_000004_0 is done. And is in the process of committing
2019-09-25 12:00:22,617 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:22,617 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local321937552_0002_m_000004_0 is allowed to commit now
2019-09-25 12:00:22,619 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local321937552_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/_logs
2019-09-25 12:00:22,619 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 12:00:22,619 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local321937552_0002_m_000004_0' done.
2019-09-25 12:00:22,620 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local321937552_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=470156
		FILE: Number of bytes written=1640249
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=71
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:00:22,620 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local321937552_0002_m_000004_0
2019-09-25 12:00:22,620 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000005_0
2019-09-25 12:00:22,621 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:22,621 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:22,621 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:22,622 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:2523+277
2019-09-25 12:00:22,622 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:22,622 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:22,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
12:00:22.643 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:22,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:22,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local321937552_0002_m_000005_0 is done. And is in the process of committing
2019-09-25 12:00:22,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:22,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local321937552_0002_m_000005_0 is allowed to commit now
2019-09-25 12:00:22,651 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local321937552_0002_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/_logs
2019-09-25 12:00:22,651 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 12:00:22,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local321937552_0002_m_000005_0' done.
2019-09-25 12:00:22,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local321937552_0002_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=474504
		FILE: Number of bytes written=1640257
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=73
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:00:22,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local321937552_0002_m_000005_0
2019-09-25 12:00:22,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:22,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:22,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:22,653 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:22,654 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:873+273
2019-09-25 12:00:22,654 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:22,655 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:22,659 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:00:22,670 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
12:00:22.676 [IPC Server handler 4 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:22,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:22,685 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:22,685 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:22,685 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:22,685 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:22,686 [IPC Server handler 19 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:22,686 [IPC Server handler 19 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:22,686 [IPC Server handler 19 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:22,687 [IPC Server handler 19 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:22,687 [IPC Server handler 19 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:22,687 [IPC Server handler 19 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:22.689 [IPC Server handler 17 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:22,762 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:22,763 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:25,222 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:25,226 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:25,226 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:25,227 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:25,227 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:25,227 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:25,227 [IPC Server handler 5 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:25,227 [IPC Server handler 5 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:25,228 [IPC Server handler 5 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:25,228 [IPC Server handler 5 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:25,228 [IPC Server handler 5 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:25.231 [IPC Server handler 12 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:25,232 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:25,233 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:26,154 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 12:00:26,664 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-25 12:00:27,235 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 12:00:27,665 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 55% reduce 0%
2019-09-25 12:00:31,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:31,018 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:31,018 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:31,018 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:31,018 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:31,018 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:31,019 [IPC Server handler 13 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:31,019 [IPC Server handler 13 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:31,019 [IPC Server handler 13 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:31,019 [IPC Server handler 13 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:31,020 [IPC Server handler 13 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:31.022 [IPC Server handler 18 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:31,023 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000006_0
2019-09-25 12:00:31,024 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:31,024 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:31,025 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000007_0
2019-09-25 12:00:31,025 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,025 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:31,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:612+261
2019-09-25 12:00:31,027 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,027 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,039 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
12:00:31.044 [IPC Server handler 3 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:31,049 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:31,050 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local321937552_0002_m_000007_0 is done. And is in the process of committing
2019-09-25 12:00:31,050 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:31,050 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local321937552_0002_m_000007_0 is allowed to commit now
2019-09-25 12:00:31,051 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local321937552_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/_logs
2019-09-25 12:00:31,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 12:00:31,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local321937552_0002_m_000007_0' done.
2019-09-25 12:00:31,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local321937552_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=482688
		FILE: Number of bytes written=1640273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=80
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:00:31,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local321937552_0002_m_000007_0
2019-09-25 12:00:31,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000008_0
2019-09-25 12:00:31,053 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,053 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:31,054 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:1712+261
2019-09-25 12:00:31,054 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,054 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,066 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:00:31,074 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:31,074 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local321937552_0002_m_000008_0 is done. And is in the process of committing
2019-09-25 12:00:31,074 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:31,074 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local321937552_0002_m_000008_0 is allowed to commit now
2019-09-25 12:00:31,075 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local321937552_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/_logs
2019-09-25 12:00:31,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:00:31,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local321937552_0002_m_000008_0' done.
2019-09-25 12:00:31,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local321937552_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=486524
		FILE: Number of bytes written=1640281
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=82
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:00:31,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local321937552_0002_m_000008_0
2019-09-25 12:00:31,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000009_0
2019-09-25 12:00:31,077 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,077 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,078 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:31,079 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:2262+261
2019-09-25 12:00:31,079 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,079 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,092 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:00:31,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:31,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local321937552_0002_m_000009_0 is done. And is in the process of committing
2019-09-25 12:00:31,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:00:31,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local321937552_0002_m_000009_0 is allowed to commit now
2019-09-25 12:00:31,102 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local321937552_0002_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/_logs
2019-09-25 12:00:31,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:00:31,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local321937552_0002_m_000009_0' done.
2019-09-25 12:00:31,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local321937552_0002_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=490360
		FILE: Number of bytes written=1640289
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=84
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:00:31,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local321937552_0002_m_000009_0
2019-09-25 12:00:31,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:31,104 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,104 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,104 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:31,105 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677/fileList.seq:2800+257
2019-09-25 12:00:31,105 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:31,105 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:31,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
12:00:31.121 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:31,122 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:31,124 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:31,127 [IPC Server handler 16 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:31,128 [IPC Server handler 16 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:31,128 [IPC Server handler 16 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:31.130 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:31,131 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:31,131 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:31,667 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:00:33,236 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 12:00:33,621 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:33,625 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:33,626 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:33,626 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:33,626 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:33,626 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:33,627 [IPC Server handler 15 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:33,627 [IPC Server handler 15 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:33,628 [IPC Server handler 15 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:33,628 [IPC Server handler 15 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:33,628 [IPC Server handler 15 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:33.631 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:33,633 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:33,633 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:33,669 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 82% reduce 0%
2019-09-25 12:00:34,672 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-25 12:00:35,673 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 91% reduce 0%
2019-09-25 12:00:36,816 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:36,820 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:36,820 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:36,820 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:36,820 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:36,820 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:36,821 [IPC Server handler 13 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:36,821 [IPC Server handler 13 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:36,821 [IPC Server handler 13 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:36,822 [IPC Server handler 13 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:36,822 [IPC Server handler 13 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:36.825 [IPC Server handler 18 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume17212, bucket=bucket86926, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume17212 bucket: bucket86926 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:36,826 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local321937552_0002_m_000010_0
2019-09-25 12:00:36,826 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:36,827 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:36,841 [Thread-555] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:00:36,858 [Thread-555] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000152447700/.staging/_distcp932723677
2019-09-25 12:00:36,862 [Thread-555] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local321937552_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket86926.volume17212/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:37,674 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local321937552_0002 failed with state FAILED due to: NA
2019-09-25 12:00:37,736 [Thread-491] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=4787488
		FILE: Number of bytes written=16402666
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=764
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=530
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Input split bytes=1560
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=210
		Total committed heap usage (bytes)=20155727872
	File Input Format Counters 
		Bytes Read=31130
	File Output Format Counters 
		Bytes Written=80
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-25 12:00:37,797 [Thread-613] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:00:37,844 [Thread-613] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume01017, with user31596 as owner.
2019-09-25 12:00:37,847 [IPC Server handler 2 on 33801] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume01017 for user:user31596
2019-09-25 12:00:37,854 [Thread-613] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume01017/bucket44417, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:00:37,924 [Thread-613] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket44417.volume01017 implemented by OzoneFileSystem{URI=o3fs://bucket44417.volume01017, workingDir=o3fs://bucket44417.volume01017/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 96 read ops, 0 large read ops, 64 write ops}
12:00:37.945 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:37,949 [Thread-613] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-25 12:00:37,955 [Thread-613] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-25 12:00:38,080 [Thread-613] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:00:38,089 [Thread-613] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
12:00:38.100 [IPC Server handler 10 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:38,139 [Thread-613] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-25 12:00:38,140 [Thread-613] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:00:38,151 [Thread-613] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-25 12:00:38,161 [Thread-613] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-25 12:00:38,162 [Thread-613] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:00:38,172 [Thread-613] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:00:38,211 [Thread-613] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-25 12:00:38,272 [Thread-613] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1966837874_0003
2019-09-25 12:00:38,272 [Thread-613] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:00:38,395 [Thread-613] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:00:38,398 [Thread-613] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1966837874_0003
2019-09-25 12:00:38,398 [Thread-661] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:00:38,399 [Thread-613] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1966837874_0003
2019-09-25 12:00:38,399 [Thread-661] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:38,399 [Thread-661] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:38,400 [Thread-661] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:00:38,419 [Thread-661] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:00:38,419 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:38,420 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:38,420 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:38,420 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:38,422 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000646514429/.staging/_distcp-1094473855/fileList.seq:0+771
2019-09-25 12:00:38,422 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:38,422 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:00:38.443 [IPC Server handler 8 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:38,445 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
12:00:38.451 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:38,455 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
12:00:38.461 [IPC Server handler 2 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:38,462 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:38,465 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:38,465 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:38,466 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:38,466 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:38,466 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:38,466 [IPC Server handler 11 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:38,467 [IPC Server handler 11 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:38,468 [IPC Server handler 11 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:38,468 [IPC Server handler 11 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:38,468 [IPC Server handler 11 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:38.471 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:38,472 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:38,472 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:39,399 [Thread-613] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1966837874_0003 running in uber mode : false
2019-09-25 12:00:39,400 [Thread-613] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 12:00:40,673 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-25 12:00:41,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:41,146 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:41,146 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:41,146 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:41,147 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:41,147 [IPC Server handler 8 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:41,147 [IPC Server handler 8 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:41,147 [IPC Server handler 8 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:41,148 [IPC Server handler 8 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:41,148 [IPC Server handler 8 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:41,148 [IPC Server handler 8 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:41.150 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:41,152 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:41,152 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:43,120 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-25 12:00:43,626 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:43,629 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:43,630 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:43,630 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:43,630 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:43,630 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:43,631 [IPC Server handler 15 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:43,631 [IPC Server handler 15 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:43,631 [IPC Server handler 15 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:43,632 [IPC Server handler 15 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:43,632 [IPC Server handler 15 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:43.635 [IPC Server handler 16 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:43,636 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000000_0
2019-09-25 12:00:43,636 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:43,637 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:43,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:43,638 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:43,639 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:43,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:43,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000646514429/.staging/_distcp-1094473855/fileList.seq:771+235
2019-09-25 12:00:43,641 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:43,641 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:43,657 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
12:00:43.663 [IPC Server handler 13 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:43,664 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:43,667 [IPC Server handler 2 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:43,668 [IPC Server handler 2 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:43,668 [IPC Server handler 2 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:43,668 [IPC Server handler 2 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:43,668 [IPC Server handler 2 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:43,668 [IPC Server handler 2 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:43,669 [IPC Server handler 2 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:43,669 [IPC Server handler 2 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:43,670 [IPC Server handler 2 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:43,670 [IPC Server handler 2 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:43.672 [IPC Server handler 0 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:43,673 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:43,674 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:45,032 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:45,036 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:45,036 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:45,037 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:45,037 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:45,037 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:45,037 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:45,037 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:45,038 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:45,038 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:45,039 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:45.042 [IPC Server handler 8 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:45,043 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:45,043 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:49,693 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:49,697 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:49,697 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:49,697 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:49,698 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:49,698 [IPC Server handler 13 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:49,698 [IPC Server handler 13 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:49,698 [IPC Server handler 13 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:49,699 [IPC Server handler 13 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:49,699 [IPC Server handler 13 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:49,700 [IPC Server handler 13 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:49.702 [IPC Server handler 12 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume01017, bucket=bucket44417, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume01017 bucket: bucket44417 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:49,704 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1966837874_0003_m_000001_0
2019-09-25 12:00:49,704 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:49,704 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:49,706 [Thread-661] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:00:49,719 [Thread-661] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000646514429/.staging/_distcp-1094473855
2019-09-25 12:00:49,720 [Thread-661] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1966837874_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket44417.volume01017/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:50,407 [Thread-613] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1966837874_0003 failed with state FAILED due to: NA
2019-09-25 12:00:50,408 [Thread-613] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 0
2019-09-25 12:00:50,440 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-25 12:00:50,477 [Thread-678] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:00:50,521 [Thread-678] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume43355, with user71418 as owner.
2019-09-25 12:00:50,525 [IPC Server handler 0 on 33801] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume43355 for user:user71418
2019-09-25 12:00:50,527 [Thread-678] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume43355/bucket35237, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:00:50,581 [Thread-678] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket35237.volume43355 implemented by OzoneFileSystem{URI=o3fs://bucket35237.volume43355, workingDir=o3fs://bucket35237.volume43355/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 118 read ops, 0 large read ops, 78 write ops}
12:00:50.605 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43355, bucket=bucket35237, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43355 bucket: bucket35237 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:50,609 [Thread-678] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-25 12:00:50,612 [Thread-678] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-25 12:00:50,631 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:50,631 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:50,631 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:50,632 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:50,632 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:50,632 [IPC Server handler 15 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:50,632 [IPC Server handler 15 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:50,633 [IPC Server handler 15 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:50,633 [IPC Server handler 15 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:50,634 [IPC Server handler 15 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-25 12:00:50,701 [Thread-683] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume60449, with user91958 as owner.
2019-09-25 12:00:50,703 [IPC Server handler 9 on 33801] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume60449 for user:user91958
2019-09-25 12:00:50,704 [Thread-683] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume60449/bucket15513, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:00:50,751 [Thread-683] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket15513.volume60449 implemented by OzoneFileSystem{URI=o3fs://bucket15513.volume60449, workingDir=o3fs://bucket15513.volume60449/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 124 read ops, 0 large read ops, 81 write ops}
12:00:50.770 [IPC Server handler 3 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:50,774 [Thread-683] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-25 12:00:50,851 [Thread-683] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:00:50,859 [Thread-683] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
12:00:50.869 [IPC Server handler 1 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:50,922 [Thread-683] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 12:00:50,924 [Thread-683] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:00:50,933 [Thread-683] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:00:50,941 [Thread-683] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:00:50,942 [Thread-683] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:00:50,951 [Thread-683] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:00:50,992 [Thread-683] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-25 12:00:51,025 [Thread-683] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1526661110_0004
2019-09-25 12:00:51,025 [Thread-683] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:00:51,111 [Thread-683] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:00:51,116 [Thread-746] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:00:51,116 [Thread-683] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1526661110_0004
2019-09-25 12:00:51,116 [Thread-746] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:51,116 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1526661110_0004
2019-09-25 12:00:51,116 [Thread-746] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:51,117 [Thread-746] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:00:51,138 [Thread-746] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:00:51,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:51,139 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:51,139 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:51,139 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:51,140 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:2226+580
2019-09-25 12:00:51,140 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:51,140 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:00:51.160 [IPC Server handler 14 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:51,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
12:00:51.166 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:51,167 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:51,169 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:51,169 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:51,170 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:51,170 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:51,170 [IPC Server handler 12 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:51,170 [IPC Server handler 12 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:51,170 [IPC Server handler 12 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:51,171 [IPC Server handler 12 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:51,171 [IPC Server handler 12 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:51,171 [IPC Server handler 12 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:51.173 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:51,173 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:51,173 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:52,117 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1526661110_0004 running in uber mode : false
2019-09-25 12:00:52,117 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 12:00:53,018 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:53,022 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:53,022 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:53,022 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:53,022 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:53,023 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:53,023 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:53,023 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:53,023 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:53,024 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:53,024 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:53.027 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:53,028 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:53,028 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:55,656 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-25 12:00:57,012 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:57,016 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:57,017 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:57,017 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:57,017 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:57,017 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:57,018 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:57,018 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:57,018 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:57,019 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:57,019 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:57.021 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:57,023 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000000_0
2019-09-25 12:00:57,023 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:57,024 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:00:57,025 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000001_0
2019-09-25 12:00:57,025 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:57,026 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:00:57,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:00:57,027 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:1384+564
2019-09-25 12:00:57,028 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:00:57,028 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:00:57.043 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:57,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
12:00:57.051 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:57,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
2019-09-25 12:00:57,055 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:57,055 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:57,055 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:57,055 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:57,056 [IPC Server handler 16 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:57,056 [IPC Server handler 16 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:57,056 [IPC Server handler 16 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:57,056 [IPC Server handler 16 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:57,057 [IPC Server handler 16 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:57,057 [IPC Server handler 16 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:57.059 [IPC Server handler 8 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:57,060 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
2019-09-25 12:00:57,061 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:00:58,545 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
2019-09-25 12:00:58,548 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:00:58,549 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:00:58,549 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:00:58,549 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:00:58,549 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:00:58,550 [IPC Server handler 15 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:00:58,550 [IPC Server handler 15 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:58,550 [IPC Server handler 15 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:00:58,551 [IPC Server handler 15 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:00:58,551 [IPC Server handler 15 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:00:58.554 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:00:58,555 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
2019-09-25 12:00:58,555 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:01,657 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-25 12:01:02,004 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
2019-09-25 12:01:02,007 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:02,007 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:02,008 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:02,008 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:02,008 [IPC Server handler 17 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:02,008 [IPC Server handler 17 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:02,009 [IPC Server handler 17 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:02,009 [IPC Server handler 17 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:02,009 [IPC Server handler 17 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:01:02,010 [IPC Server handler 17 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:01:02.012 [IPC Server handler 11 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,013 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000001_0
2019-09-25 12:01:02,013 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:02,013 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:01:02,014 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000002_0
2019-09-25 12:01:02,014 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,014 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:0+324
2019-09-25 12:01:02,015 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,015 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:01:02.040 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,041 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
12:01:02.048 [IPC Server handler 9 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1526661110_0004_m_000002_0 is done. And is in the process of committing
2019-09-25 12:01:02,054 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,054 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1526661110_0004_m_000002_0 is allowed to commit now
2019-09-25 12:01:02,055 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1526661110_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/_logs
2019-09-25 12:01:02,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-25 12:01:02,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1526661110_0004_m_000002_0' done.
2019-09-25 12:01:02,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1526661110_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=898694
		FILE: Number of bytes written=12788044
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=140
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:01:02,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1526661110_0004_m_000002_0
2019-09-25 12:01:02,056 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000003_0
2019-09-25 12:01:02,057 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,057 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:582+278
2019-09-25 12:01:02,059 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,059 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,073 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
12:01:02.078 [IPC Server handler 7 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,082 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,082 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1526661110_0004_m_000003_0 is done. And is in the process of committing
2019-09-25 12:01:02,083 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,083 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1526661110_0004_m_000003_0 is allowed to commit now
2019-09-25 12:01:02,084 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1526661110_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/_logs
2019-09-25 12:01:02,085 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 12:01:02,085 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1526661110_0004_m_000003_0' done.
2019-09-25 12:01:02,085 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1526661110_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=903258
		FILE: Number of bytes written=12788052
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=142
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:01:02,085 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1526661110_0004_m_000003_0
2019-09-25 12:01:02,085 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000004_0
2019-09-25 12:01:02,086 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,086 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,086 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,087 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:1948+278
2019-09-25 12:01:02,088 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,088 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,100 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
12:01:02.105 [IPC Server handler 19 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,108 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,109 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1526661110_0004_m_000004_0 is done. And is in the process of committing
2019-09-25 12:01:02,109 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,110 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1526661110_0004_m_000004_0 is allowed to commit now
2019-09-25 12:01:02,111 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1526661110_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/_logs
2019-09-25 12:01:02,111 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 12:01:02,111 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1526661110_0004_m_000004_0' done.
2019-09-25 12:01:02,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1526661110_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=907310
		FILE: Number of bytes written=12788060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=144
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:01:02,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1526661110_0004_m_000004_0
2019-09-25 12:01:02,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000005_0
2019-09-25 12:01:02,112 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,112 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:860+262
2019-09-25 12:01:02,114 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,114 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,122 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:01:02,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:01:02,135 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,135 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1526661110_0004_m_000005_0 is done. And is in the process of committing
2019-09-25 12:01:02,136 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,136 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1526661110_0004_m_000005_0 is allowed to commit now
2019-09-25 12:01:02,137 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1526661110_0004_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/_logs
2019-09-25 12:01:02,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:01:02,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1526661110_0004_m_000005_0' done.
2019-09-25 12:01:02,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1526661110_0004_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=911362
		FILE: Number of bytes written=12788068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=146
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:01:02,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1526661110_0004_m_000005_0
2019-09-25 12:01:02,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000006_0
2019-09-25 12:01:02,139 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,139 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,139 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,140 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:1122+262
2019-09-25 12:01:02,140 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,140 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,152 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:01:02,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1526661110_0004_m_000006_0 is done. And is in the process of committing
2019-09-25 12:01:02,160 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,160 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1526661110_0004_m_000006_0 is allowed to commit now
2019-09-25 12:01:02,161 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1526661110_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/_logs
2019-09-25 12:01:02,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:01:02,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1526661110_0004_m_000006_0' done.
2019-09-25 12:01:02,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1526661110_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=915414
		FILE: Number of bytes written=12788076
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=148
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:01:02,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1526661110_0004_m_000006_0
2019-09-25 12:01:02,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000007_0
2019-09-25 12:01:02,163 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,163 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,163 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,164 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:2806+262
2019-09-25 12:01:02,164 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,164 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,176 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
12:01:02.182 [IPC Server handler 1 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,186 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,186 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1526661110_0004_m_000007_0 is done. And is in the process of committing
2019-09-25 12:01:02,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:01:02,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1526661110_0004_m_000007_0 is allowed to commit now
2019-09-25 12:01:02,188 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1526661110_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/_logs
2019-09-25 12:01:02,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 12:01:02,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1526661110_0004_m_000007_0' done.
2019-09-25 12:01:02,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1526661110_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=918954
		FILE: Number of bytes written=12788084
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=150
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1987051520
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:01:02,190 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1526661110_0004_m_000007_0
2019-09-25 12:01:02,190 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:02,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:01:02,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395/fileList.seq:324+258
2019-09-25 12:01:02,192 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:01:02,192 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:01:02,204 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
12:01:02.209 [IPC Server handler 15 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:02,213 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:02,215 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:02,215 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:02,216 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:02,216 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:02,216 [IPC Server handler 5 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:02,216 [IPC Server handler 5 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:02,217 [IPC Server handler 5 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:02,217 [IPC Server handler 5 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:01:02,217 [IPC Server handler 5 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:01:02.220 [IPC Server handler 10 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:02,221 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:02,221 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:03,157 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 12:01:04,125 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 72% reduce 0%
2019-09-25 12:01:04,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:04,319 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:04,320 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:04,320 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:04,320 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:04,321 [IPC Server handler 11 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:04,321 [IPC Server handler 11 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:04,321 [IPC Server handler 11 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:04,322 [IPC Server handler 11 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:04,322 [IPC Server handler 11 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:01:04,322 [IPC Server handler 11 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:01:04.326 [IPC Server handler 6 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:04,327 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:04,328 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:09,045 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 12:01:09,128 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 78% reduce 0%
2019-09-25 12:01:10,198 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:10,201 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:10,202 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:10,202 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:10,202 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:10,203 [IPC Server handler 5 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:10,203 [IPC Server handler 5 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:10,203 [IPC Server handler 5 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:10,217 [IPC Server handler 5 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:10,217 [IPC Server handler 5 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:01:10,217 [IPC Server handler 5 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:01:10.220 [IPC Server handler 10 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60449, bucket=bucket15513, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60449 bucket: bucket15513 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:10,221 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1526661110_0004_m_000008_0
2019-09-25 12:01:10,221 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:10,222 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:01:10,223 [Thread-746] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:01:10,236 [Thread-746] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000852960288/.staging/_distcp2035946395
2019-09-25 12:01:10,238 [Thread-746] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1526661110_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket15513.volume60449/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:01:11,129 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1526661110_0004 failed with state FAILED due to: NA
2019-09-25 12:01:11,186 [Thread-683] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=7299980
		FILE: Number of bytes written=102304568
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1177
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=758
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1256
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=15896412160
	File Input Format Counters 
		Bytes Read=24992
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-25 12:01:11,234 [Thread-790] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:01:11,264 [Thread-790] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume37694, with user04417 as owner.
2019-09-25 12:01:11,266 [IPC Server handler 0 on 33801] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume37694 for user:user04417
2019-09-25 12:01:11,269 [Thread-790] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume37694/bucket12005, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:01:11,330 [Thread-790] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket12005.volume37694 implemented by OzoneFileSystem{URI=o3fs://bucket12005.volume37694, workingDir=o3fs://bucket12005.volume37694/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 162 read ops, 0 large read ops, 101 write ops}
12:01:11.349 [IPC Server handler 5 on 33801] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37694, bucket=bucket12005, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume37694 bucket: bucket12005 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:01:11,353 [Thread-790] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-25 12:01:11,359 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:11,360 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:11,360 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:11,360 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:11,360 [IPC Server handler 15 on 37041] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:11,361 [IPC Server handler 15 on 37041] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:11,361 [IPC Server handler 15 on 37041] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:11,362 [IPC Server handler 15 on 37041] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:01:11,362 [IPC Server handler 15 on 37041] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:01:11,362 [IPC Server handler 15 on 37041] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-25 12:01:11,379 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-25 12:01:11,380 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-25 12:01:11,380 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-25 12:01:11,380 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33801
2019-09-25 12:01:11,386 [IPC Server listener on 33801] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33801
2019-09-25 12:01:11,388 [JUnit] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-25 12:01:11,392 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 12:01:11,395 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-25 12:01:11,408 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-25 12:01:11,412 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7103ab0{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-25 12:01:11,417 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:11,417 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:11,418 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:11,422 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-25 12:01:12,217 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 12:01:12,288 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 12:01:14,199 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-25 12:01:16,425 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 12:01:16,425 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 12:01:16,427 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: close
2019-09-25 12:01:16,427 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 806040c9-6be1-453b-a2ca-ad7e12880578: close
2019-09-25 12:01:16,431 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: shutdown
2019-09-25 12:01:16,431 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: shutdown
2019-09-25 12:01:16,432 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D16646313036,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 12:01:16,432 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4C72D74F3069,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 12:01:16,432 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderState
2019-09-25 12:01:16,432 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderState
2019-09-25 12:01:16,435 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,435 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 806040c9-6be1-453b-a2ca-ad7e12880578-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,440 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,440 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,443 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069: closes. applyIndex: 0
2019-09-25 12:01:16,443 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036: closes. applyIndex: 0
2019-09-25 12:01:16,446 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,446 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,450 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4C72D74F3069-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,450 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-D16646313036-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,455 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: shutdown
2019-09-25 12:01:16,457 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: shutdown
2019-09-25 12:01:16,457 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-42300DDC6049,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 12:01:16,458 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9C0AF7B870AE,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 12:01:16,458 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderState
2019-09-25 12:01:16,458 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderState
2019-09-25 12:01:16,458 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 806040c9-6be1-453b-a2ca-ad7e12880578-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,459 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,459 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,460 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,460 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049: closes. applyIndex: 0
2019-09-25 12:01:16,460 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE: closes. applyIndex: 0
2019-09-25 12:01:16,460 [806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,461 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,463 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-42300DDC6049-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,464 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-9C0AF7B870AE-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,468 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: shutdown
2019-09-25 12:01:16,471 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: shutdown
2019-09-25 12:01:16,472 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-456089AB08CE,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 12:01:16,472 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CCCF7FCC9F0C,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 12:01:16,472 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderState
2019-09-25 12:01:16,473 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderState
2019-09-25 12:01:16,473 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 806040c9-6be1-453b-a2ca-ad7e12880578-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,473 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,473 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,474 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,474 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE: closes. applyIndex: 0
2019-09-25 12:01:16,474 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C: closes. applyIndex: 0
2019-09-25 12:01:16,475 [806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,475 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,477 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-456089AB08CE-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,478 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-CCCF7FCC9F0C-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,482 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: shutdown
2019-09-25 12:01:16,485 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: shutdown
2019-09-25 12:01:16,485 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B166EF43A0B3,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 12:01:16,486 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A5F078EEB6E,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 12:01:16,486 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderState
2019-09-25 12:01:16,486 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderState
2019-09-25 12:01:16,486 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 806040c9-6be1-453b-a2ca-ad7e12880578-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,487 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,487 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,487 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,487 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3: closes. applyIndex: 0
2019-09-25 12:01:16,489 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E: closes. applyIndex: 0
2019-09-25 12:01:16,490 [806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,490 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,492 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-B166EF43A0B3-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,493 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-6A5F078EEB6E-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,496 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: shutdown
2019-09-25 12:01:16,499 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: shutdown
2019-09-25 12:01:16,499 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B6341FF55C6,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 12:01:16,499 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-081B7A613759,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 12:01:16,499 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderState
2019-09-25 12:01:16,499 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderState
2019-09-25 12:01:16,500 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 806040c9-6be1-453b-a2ca-ad7e12880578-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,500 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,500 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,501 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,501 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6: closes. applyIndex: 0
2019-09-25 12:01:16,501 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759: closes. applyIndex: 0
2019-09-25 12:01:16,501 [806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,502 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,503 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-4B6341FF55C6-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,504 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-081B7A613759-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,507 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: shutdown
2019-09-25 12:01:16,515 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: shutdown
2019-09-25 12:01:16,516 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BD4E3F55877,id=806040c9-6be1-453b-a2ca-ad7e12880578
2019-09-25 12:01:16,516 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F82EA407D366,id=af790e72-8fcd-4cb0-b23c-d20e93858cf2
2019-09-25 12:01:16,516 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown LeaderState
2019-09-25 12:01:16,516 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown LeaderState
2019-09-25 12:01:16,517 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 806040c9-6be1-453b-a2ca-ad7e12880578-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,517 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:16,517 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,517 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:16,518 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877: closes. applyIndex: 0
2019-09-25 12:01:16,519 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366: closes. applyIndex: 0
2019-09-25 12:01:16,520 [806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,520 [af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:16,520 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 806040c9-6be1-453b-a2ca-ad7e12880578@group-7BD4E3F55877-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,520 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2@group-F82EA407D366-SegmentedRaftLogWorker close()
2019-09-25 12:01:16,523 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown server with port 36253 now
2019-09-25 12:01:16,523 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown server with port 43658 now
2019-09-25 12:01:16,527 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - af790e72-8fcd-4cb0-b23c-d20e93858cf2: shutdown server with port 43658 successfully
2019-09-25 12:01:16,528 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 806040c9-6be1-453b-a2ca-ad7e12880578: shutdown server with port 36253 successfully
2019-09-25 12:01:16,532 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 12:01:16,532 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 12:01:16,566 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 12:01:16,567 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 12:01:16,573 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 12:01:16,573 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 12:01:16,577 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29149030{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 12:01:16,578 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48b4a043{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 12:01:16,578 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@38b8b6c0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:16,578 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2f5b8250{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:16,579 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c26273d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:16,580 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@291373d3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:16,580 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@272ce069{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:16,581 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16727bf0{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:16,676 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 12:01:17,079 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 12:01:20,200 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-25 12:01:21,583 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 12:01:21,583 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 12:01:21,584 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: close
2019-09-25 12:01:21,584 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: close
2019-09-25 12:01:21,585 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: shutdown
2019-09-25 12:01:21,585 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: shutdown
2019-09-25 12:01:21,585 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8A7781F80F0A,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 12:01:21,586 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-281E61757094,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 12:01:21,586 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderState
2019-09-25 12:01:21,586 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderState
2019-09-25 12:01:21,587 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2a3572d-7c1f-4e75-8685-be52119dd02b-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,587 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fe2c664-23d3-4023-9f8c-2687d201187c-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,587 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,588 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,588 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A: closes. applyIndex: 0
2019-09-25 12:01:21,588 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094: closes. applyIndex: 0
2019-09-25 12:01:21,589 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,589 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,589 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-8A7781F80F0A-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,590 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-281E61757094-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,592 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: shutdown
2019-09-25 12:01:21,593 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: shutdown
2019-09-25 12:01:21,594 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A89B179A7775,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 12:01:21,594 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderState
2019-09-25 12:01:21,594 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-447616BBE454,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 12:01:21,595 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2a3572d-7c1f-4e75-8685-be52119dd02b-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,595 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderState
2019-09-25 12:01:21,595 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,596 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fe2c664-23d3-4023-9f8c-2687d201187c-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,596 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775: closes. applyIndex: 0
2019-09-25 12:01:21,597 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,597 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454: closes. applyIndex: 0
2019-09-25 12:01:21,597 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,598 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,610 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-A89B179A7775-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,610 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-447616BBE454-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,612 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: shutdown
2019-09-25 12:01:21,613 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: shutdown
2019-09-25 12:01:21,613 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2489467E579,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 12:01:21,614 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C285669257DF,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 12:01:21,614 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderState
2019-09-25 12:01:21,614 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderState
2019-09-25 12:01:21,615 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fe2c664-23d3-4023-9f8c-2687d201187c-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,615 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2a3572d-7c1f-4e75-8685-be52119dd02b-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,616 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,616 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,616 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF: closes. applyIndex: 0
2019-09-25 12:01:21,617 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,617 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579: closes. applyIndex: 0
2019-09-25 12:01:21,617 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-C285669257DF-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,618 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,620 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: shutdown
2019-09-25 12:01:21,620 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C2489467E579-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,620 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E509BFB4C8C2,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 12:01:21,621 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: shutdown
2019-09-25 12:01:21,622 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderState
2019-09-25 12:01:21,622 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3F88A4F5E32,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 12:01:21,622 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fe2c664-23d3-4023-9f8c-2687d201187c-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,622 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderState
2019-09-25 12:01:21,623 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,623 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2a3572d-7c1f-4e75-8685-be52119dd02b-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,623 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2: closes. applyIndex: 0
2019-09-25 12:01:21,624 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,624 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,624 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32: closes. applyIndex: 0
2019-09-25 12:01:21,624 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-E509BFB4C8C2-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,625 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,626 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: shutdown
2019-09-25 12:01:21,626 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-C3F88A4F5E32-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,627 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FA7EEB8EEC0,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 12:01:21,631 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: shutdown
2019-09-25 12:01:21,631 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderState
2019-09-25 12:01:21,632 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-719336267CD4,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 12:01:21,632 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fe2c664-23d3-4023-9f8c-2687d201187c-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,632 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderState
2019-09-25 12:01:21,632 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,633 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2a3572d-7c1f-4e75-8685-be52119dd02b-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,634 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0: closes. applyIndex: 0
2019-09-25 12:01:21,634 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,635 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4: closes. applyIndex: 0
2019-09-25 12:01:21,635 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,635 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,635 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-0FA7EEB8EEC0-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,635 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-719336267CD4-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,636 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: shutdown
2019-09-25 12:01:21,636 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: shutdown
2019-09-25 12:01:21,636 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C5F2E78582D,id=0fe2c664-23d3-4023-9f8c-2687d201187c
2019-09-25 12:01:21,636 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F8EB8B561257,id=b2a3572d-7c1f-4e75-8685-be52119dd02b
2019-09-25 12:01:21,637 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown LeaderState
2019-09-25 12:01:21,637 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown LeaderState
2019-09-25 12:01:21,637 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fe2c664-23d3-4023-9f8c-2687d201187c-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,638 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2a3572d-7c1f-4e75-8685-be52119dd02b-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:21,638 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,638 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:21,639 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D: closes. applyIndex: 0
2019-09-25 12:01:21,640 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257: closes. applyIndex: 0
2019-09-25 12:01:21,640 [0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,640 [b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:21,640 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fe2c664-23d3-4023-9f8c-2687d201187c@group-8C5F2E78582D-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,641 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2a3572d-7c1f-4e75-8685-be52119dd02b@group-F8EB8B561257-SegmentedRaftLogWorker close()
2019-09-25 12:01:21,641 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown server with port 40326 now
2019-09-25 12:01:21,641 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown server with port 38937 now
2019-09-25 12:01:21,643 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0fe2c664-23d3-4023-9f8c-2687d201187c: shutdown server with port 40326 successfully
2019-09-25 12:01:21,643 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - b2a3572d-7c1f-4e75-8685-be52119dd02b: shutdown server with port 38937 successfully
2019-09-25 12:01:21,647 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 12:01:21,648 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 12:01:21,680 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 12:01:21,683 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 12:01:21,685 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4cb2918c{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 12:01:21,685 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72e295cc{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:21,686 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d5c2745{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:21,686 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e446d92{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:21,686 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 12:01:21,690 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 12:01:21,693 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73844119{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 12:01:21,693 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:21,694 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:21,695 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:22,680 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 12:01:24,575 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:24,575 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:24,575 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:24,576 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:24,576 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:24,576 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:24,576 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:24,577 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0fe2c664-23d3-4023-9f8c-2687d201187c Heaviness: 6 limit: 5
2019-09-25 12:01:24,577 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： af790e72-8fcd-4cb0-b23c-d20e93858cf2 Heaviness: 6 limit: 5
2019-09-25 12:01:24,577 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2a3572d-7c1f-4e75-8685-be52119dd02b Heaviness: 6 limit: 5
2019-09-25 12:01:24,577 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 806040c9-6be1-453b-a2ca-ad7e12880578 Heaviness: 6 limit: 5
2019-09-25 12:01:24,577 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： cbc7b4b8-8477-40ca-9cdc-b573f7732004 Heaviness: 6 limit: 5
2019-09-25 12:01:24,578 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:01:24,578 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:01:26,688 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 12:01:26,689 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: close
2019-09-25 12:01:26,689 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: shutdown
2019-09-25 12:01:26,689 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: shutdown
2019-09-25 12:01:26,690 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADB1836EF94D,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 12:01:26,690 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AEDF94CA4321,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 12:01:26,690 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderState
2019-09-25 12:01:26,690 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderState
2019-09-25 12:01:26,690 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:26,690 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:26,691 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:26,691 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:26,691 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D: closes. applyIndex: 0
2019-09-25 12:01:26,693 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321: closes. applyIndex: 0
2019-09-25 12:01:26,693 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:26,693 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:26,694 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-ADB1836EF94D-SegmentedRaftLogWorker close()
2019-09-25 12:01:26,694 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: shutdown
2019-09-25 12:01:26,695 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6703E43134CB,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 12:01:26,695 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderState
2019-09-25 12:01:26,695 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:26,696 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:26,696 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB: closes. applyIndex: 0
2019-09-25 12:01:26,697 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:26,707 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-6703E43134CB-SegmentedRaftLogWorker close()
2019-09-25 12:01:26,707 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-AEDF94CA4321-SegmentedRaftLogWorker close()
2019-09-25 12:01:26,707 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: shutdown
2019-09-25 12:01:26,707 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: shutdown
2019-09-25 12:01:26,708 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A38E37A59148,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 12:01:26,708 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4998A190C7EF,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 12:01:26,708 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderState
2019-09-25 12:01:26,708 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderState
2019-09-25 12:01:26,708 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:26,709 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:26,709 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:26,709 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:26,709 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148: closes. applyIndex: 0
2019-09-25 12:01:26,710 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF: closes. applyIndex: 0
2019-09-25 12:01:26,710 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:26,710 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:26,710 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-A38E37A59148-SegmentedRaftLogWorker close()
2019-09-25 12:01:26,710 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-4998A190C7EF-SegmentedRaftLogWorker close()
2019-09-25 12:01:26,711 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: shutdown
2019-09-25 12:01:26,711 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DCFAC63A4D33,id=cbc7b4b8-8477-40ca-9cdc-b573f7732004
2019-09-25 12:01:26,711 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown LeaderState
2019-09-25 12:01:26,712 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004-PendingRequests: sendNotLeaderResponses
2019-09-25 12:01:26,712 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-StateMachineUpdater: set stopIndex = 0
2019-09-25 12:01:26,713 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33: closes. applyIndex: 0
2019-09-25 12:01:26,713 [cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 12:01:26,714 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004@group-DCFAC63A4D33-SegmentedRaftLogWorker close()
2019-09-25 12:01:26,714 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown server with port 39643 now
2019-09-25 12:01:26,716 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - cbc7b4b8-8477-40ca-9cdc-b573f7732004: shutdown server with port 39643 successfully
2019-09-25 12:01:26,720 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f1b1c3e7-44e6-47c9-bd9c-19191e8ec116/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 12:01:26,742 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 12:01:26,745 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 12:01:26,746 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@75181b50{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 12:01:26,747 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2d64160c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:26,747 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57272109{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:26,748 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e9469b8{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:26,748 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-25 12:01:26,748 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-25 12:01:26,749 [JUnit] INFO  container.ReplicationManager (ReplicationManager.java:stop(204)) - Stopping Replication Monitor Thread.
2019-09-25 12:01:26,749 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-25 12:01:26,749 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-25 12:01:26,749 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-25 12:01:26,749 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33368
2019-09-25 12:01:26,750 [IPC Server listener on 33368] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33368
2019-09-25 12:01:26,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 12:01:26,758 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-25 12:01:26,758 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-25 12:01:26,758 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-25 12:01:26,758 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37041
2019-09-25 12:01:26,759 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-25 12:01:26,759 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-25 12:01:26,759 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42244
2019-09-25 12:01:26,760 [IPC Server listener on 42244] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42244
2019-09-25 12:01:26,760 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-25 12:01:26,761 [IPC Server listener on 37041] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37041
2019-09-25 12:01:26,762 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 12:01:26,762 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 12:01:26,763 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@aec50a1{/,null,UNAVAILABLE}{/scm}
2019-09-25 12:01:26,763 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 12:01:26,764 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 12:01:26,764 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-25 12:01:26,765 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-25 12:01:26,765 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-25 12:01:26,765 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-25 12:01:26,765 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-25 12:01:26,770 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JobTracker metrics system...
2019-09-25 12:01:26,781 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-25 12:01:26,781 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JobTracker metrics system stopped.

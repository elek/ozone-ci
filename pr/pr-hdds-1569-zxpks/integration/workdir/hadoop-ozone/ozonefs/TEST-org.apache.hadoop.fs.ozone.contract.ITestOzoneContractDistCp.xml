<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="107.725" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter2702212487276490782.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-09-25T04-01-08_071-jvmRun1 surefire5685227985127891369tmp surefire_1033649573923646175755tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter2702212487276490782.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpdateDeepDirectoryStructureNoChange" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="28.458">
    <error message="DistCp failure: Job job_local1468691963_0001 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1468691963_0001 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureNoChange(AbstractContractDistCpTest.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 05:49:08,260 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:08,356 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:08,359 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:08,376 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @869ms
2019-09-25 05:49:08,464 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-25 05:49:08,465 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-25 05:49:08,465 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-25 05:49:08,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-25 05:49:08,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-25 05:49:08,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-25 05:49:08,476 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 05:49:08,477 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 05:49:08,478 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 05:49:08,712 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@dd05255
2019-09-25 05:49:08,714 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-25 05:49:08,775 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 05:49:08,777 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 05:49:08,779 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-25 05:49:08,899 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(60)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-25 05:49:08,913 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:08,968 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-25 05:49:08,970 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:09,062 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-25 05:49:09,383 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 05:49:09,547 [Socket Reader #1 for port 41998] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41998
2019-09-25 05:49:09,591 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 05:49:09,592 [Socket Reader #1 for port 38285] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38285
2019-09-25 05:49:09,605 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 05:49:09,607 [Socket Reader #1 for port 36454] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36454
2019-09-25 05:49:09,635 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-25 05:49:09,776 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:09,791 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:09,801 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:09,803 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-25 05:49:09,803 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:09,804 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:09,829 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36454
2019-09-25 05:49:09,877 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-25 05:49:09,889 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-25 05:49:09,889 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-25 05:49:10,151 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:36454
2019-09-25 05:49:10,151 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 05:49:10,151 [IPC Server listener on 36454] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36454: starting
2019-09-25 05:49:10,154 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38285
2019-09-25 05:49:10,156 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:38285
2019-09-25 05:49:10,156 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 05:49:10,156 [IPC Server listener on 38285] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38285: starting
2019-09-25 05:49:10,159 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41998
2019-09-25 05:49:10,159 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:41998
2019-09-25 05:49:10,160 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 05:49:10,160 [IPC Server listener on 41998] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41998: starting
2019-09-25 05:49:10,164 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40268
2019-09-25 05:49:10,165 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:10,199 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:10,200 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:10,271 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@aec50a1{/,file:///tmp/jetty-0.0.0.0-40268-scm-_-any-8450848756311618715.dir/webapp/,AVAILABLE}{/scm}
2019-09-25 05:49:10,276 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:40268}
2019-09-25 05:49:10,277 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @2770ms
2019-09-25 05:49:10,279 [JUnit] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-25 05:49:10,279 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-25 05:49:10,281 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:40268
2019-09-25 05:49:10,289 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c1fca1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 05:49:10,295 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:10,410 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:10,411 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:10,412 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(652)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-25 05:49:10,412 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(658)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 50e254fb-96fc-4f08-ae06-0ad35d01972e
2019-09-25 05:49:10,414 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-25 05:49:11,228 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 05:49:11,238 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-25 05:49:11,238 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-25 05:49:11,238 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-25 05:49:11,238 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-25 05:49:11,239 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-25 05:49:11,239 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-25 05:49:11,239 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-25 05:49:11,239 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-25 05:49:11,240 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-25 05:49:11,240 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-25 05:49:11,240 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-25 05:49:11,240 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-25 05:49:11,241 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-25 05:49:11,241 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-25 05:49:11,241 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-25 05:49:11,241 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-25 05:49:11,242 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-25 05:49:11,242 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-25 05:49:11,242 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-25 05:49:11,242 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-25 05:49:11,243 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-25 05:49:11,243 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-25 05:49:11,243 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 05:49:11,243 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 05:49:11,243 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 05:49:11,627 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 05:49:11,628 [Socket Reader #1 for port 33070] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33070
2019-09-25 05:49:11,657 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:33070
2019-09-25 05:49:11,658 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-25 05:49:11,659 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 05:49:11,659 [IPC Server listener on 33070] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33070: starting
2019-09-25 05:49:11,664 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-25 05:49:11,842 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:11,843 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:11,848 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:11,850 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-25 05:49:11,851 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:11,851 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:11,854 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41589
2019-09-25 05:49:11,857 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:11,859 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:11,860 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:11,909 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7103ab0{/,file:///tmp/jetty-0.0.0.0-41589-ozoneManager-_-any-6182577438461480810.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-25 05:49:11,910 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:41589}
2019-09-25 05:49:11,910 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4404ms
2019-09-25 05:49:11,911 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 05:49:11,912 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:41589
2019-09-25 05:49:12,077 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 05:49:12,135 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-zxpks-796972592 ip:192.168.5.161
2019-09-25 05:49:12,171 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 05:49:12,173 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/containers/hdds to VolumeSet
2019-09-25 05:49:12,175 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-25 05:49:12,194 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-25 05:49:12,314 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 05:49:12,388 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 05:49:12,393 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 05:49:12,394 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 05:49:12,395 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:12,396 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 05:49:12,397 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 05:49:12,597 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:12,653 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 05:49:12,655 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:12,657 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:12,659 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:12,660 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 05:49:12,660 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:12,660 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:12,661 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33636
2019-09-25 05:49:12,662 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:12,664 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:12,665 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:12,690 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73844119{/,file:///tmp/jetty-0.0.0.0-33636-hddsDatanode-_-any-5517770989249960290.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 05:49:12,691 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:33636}
2019-09-25 05:49:12,691 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5185ms
2019-09-25 05:49:12,692 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 05:49:12,693 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33636
2019-09-25 05:49:12,694 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 05:49:12,699 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-zxpks-796972592 ip:192.168.5.161
2019-09-25 05:49:12,702 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18273972] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 05:49:12,708 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 05:49:12,709 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/containers/hdds to VolumeSet
2019-09-25 05:49:12,710 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@333c8791
2019-09-25 05:49:12,710 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@333c8791
2019-09-25 05:49:12,731 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 05:49:12,731 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 05:49:12,732 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 05:49:12,732 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 05:49:12,732 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:12,732 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 05:49:12,732 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 05:49:12,733 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:12,734 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 05:49:12,736 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:12,737 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:12,738 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:12,739 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 05:49:12,739 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:12,739 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:12,740 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45462
2019-09-25 05:49:12,740 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:12,744 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16727bf0{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:12,744 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@291373d3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:12,769 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48b4a043{/,file:///tmp/jetty-0.0.0.0-45462-hddsDatanode-_-any-3912061999782991978.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 05:49:12,770 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f5b8250{HTTP/1.1,[http/1.1]}{0.0.0.0:45462}
2019-09-25 05:49:12,770 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5264ms
2019-09-25 05:49:12,772 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 05:49:12,773 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45462
2019-09-25 05:49:12,773 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 05:49:12,776 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-zxpks-796972592 ip:192.168.5.161
2019-09-25 05:49:12,776 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3337ebe4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 05:49:12,783 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 05:49:12,784 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/containers/hdds to VolumeSet
2019-09-25 05:49:12,784 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@534180a2
2019-09-25 05:49:12,784 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@534180a2
2019-09-25 05:49:12,805 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 05:49:12,806 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 05:49:12,806 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 05:49:12,806 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 05:49:12,806 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:12,807 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 05:49:12,807 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 05:49:12,807 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:12,810 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 05:49:12,811 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:12,812 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:12,814 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:12,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 05:49:12,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:12,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:12,816 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45294
2019-09-25 05:49:12,816 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:12,818 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c83468e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:12,819 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d7fb838{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:12,836 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/meta/datanode.id
2019-09-25 05:49:12,845 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/meta/datanode.id
2019-09-25 05:49:12,853 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6812fa3a{/,file:///tmp/jetty-0.0.0.0-45294-hddsDatanode-_-any-2774176607565944194.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 05:49:12,853 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@29149030{HTTP/1.1,[http/1.1]}{0.0.0.0:45294}
2019-09-25 05:49:12,854 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5348ms
2019-09-25 05:49:12,855 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 05:49:12,856 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45294
2019-09-25 05:49:12,857 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 05:49:12,860 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@650c90d4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 05:49:12,860 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-zxpks-796972592 ip:192.168.5.161
2019-09-25 05:49:12,862 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/meta/datanode.id
2019-09-25 05:49:12,869 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 05:49:12,869 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/containers/hdds to VolumeSet
2019-09-25 05:49:12,869 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-25 05:49:12,870 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-25 05:49:12,890 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 05:49:12,890 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 05:49:12,890 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 05:49:12,891 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 05:49:12,891 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:12,891 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 05:49:12,891 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 05:49:12,892 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:12,893 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 05:49:12,895 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:12,895 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:12,897 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:12,897 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 05:49:12,897 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:12,898 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:12,898 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35515
2019-09-25 05:49:12,899 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:12,902 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26350ea2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:12,903 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a08efdc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:12,927 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cd3ad8a{/,file:///tmp/jetty-0.0.0.0-35515-hddsDatanode-_-any-5816499773792032104.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 05:49:12,928 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@75181b50{HTTP/1.1,[http/1.1]}{0.0.0.0:35515}
2019-09-25 05:49:12,929 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5423ms
2019-09-25 05:49:12,929 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 05:49:12,931 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35515
2019-09-25 05:49:12,931 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 05:49:12,937 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67dad618] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 05:49:12,938 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-zxpks-796972592 ip:192.168.5.161
2019-09-25 05:49:12,940 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/meta/datanode.id
2019-09-25 05:49:12,947 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 05:49:12,947 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/containers/hdds to VolumeSet
2019-09-25 05:49:12,948 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@46aa712c
2019-09-25 05:49:12,948 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@46aa712c
2019-09-25 05:49:12,971 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 05:49:12,971 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 05:49:12,971 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 05:49:12,971 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 05:49:12,972 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:12,972 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 05:49:12,972 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 05:49:12,973 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:12,974 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 05:49:12,976 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 05:49:12,977 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 05:49:12,979 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 05:49:12,980 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 05:49:12,981 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 05:49:12,981 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 05:49:12,981 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37113
2019-09-25 05:49:12,982 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 05:49:12,984 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d5c2745{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 05:49:12,985 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1947596f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 05:49:13,011 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c2584d3{/,file:///tmp/jetty-0.0.0.0-37113-hddsDatanode-_-any-4220082538383385703.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 05:49:13,012 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6fa0450e{HTTP/1.1,[http/1.1]}{0.0.0.0:37113}
2019-09-25 05:49:13,013 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5507ms
2019-09-25 05:49:13,013 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 05:49:13,015 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37113
2019-09-25 05:49:13,017 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 05:49:13,019 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7e2a9d94] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 05:49:13,022 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/meta/datanode.id
2019-09-25 05:49:14,018 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 05:49:14,769 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 05:49:14,773 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 05:49:14,774 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e82d6518-db45-4664-aef7-ce30608e98c3 at port 0
2019-09-25 05:49:14,794 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 05:49:14,803 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 05:49:14,804 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e1c44be8-c290-4a84-9591-5999c64dd189 at port 0
2019-09-25 05:49:14,818 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e82d6518-db45-4664-aef7-ce30608e98c3: start RPC server
2019-09-25 05:49:14,819 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e1c44be8-c290-4a84-9591-5999c64dd189: start RPC server
2019-09-25 05:49:14,877 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 05:49:14,879 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 05:49:14,879 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at port 0
2019-09-25 05:49:14,889 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start RPC server
2019-09-25 05:49:14,950 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 05:49:14,951 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 05:49:14,951 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 035834f9-24a4-45b4-a769-10efa83e6a02 at port 0
2019-09-25 05:49:14,971 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start RPC server
2019-09-25 05:49:15,020 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 05:49:15,031 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e1c44be8-c290-4a84-9591-5999c64dd189: GrpcService started, listening on 0.0.0.0/0.0.0.0:37616
2019-09-25 05:49:15,031 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 035834f9-24a4-45b4-a769-10efa83e6a02: GrpcService started, listening on 0.0.0.0/0.0.0.0:38201
2019-09-25 05:49:15,031 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e82d6518-db45-4664-aef7-ce30608e98c3: GrpcService started, listening on 0.0.0.0/0.0.0.0:46619
2019-09-25 05:49:15,031 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: GrpcService started, listening on 0.0.0.0/0.0.0.0:35538
2019-09-25 05:49:15,033 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e82d6518-db45-4664-aef7-ce30608e98c3 is started using port 46619
2019-09-25 05:49:15,033 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 035834f9-24a4-45b4-a769-10efa83e6a02 is started using port 38201
2019-09-25 05:49:15,033 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e1c44be8-c290-4a84-9591-5999c64dd189 is started using port 37616
2019-09-25 05:49:15,034 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 is started using port 35538
2019-09-25 05:49:15,043 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 05:49:15,050 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 05:49:15,050 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 is started using port 33300
2019-09-25 05:49:15,051 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e1c44be8-c290-4a84-9591-5999c64dd189 is started using port 41881
2019-09-25 05:49:15,051 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 8de7fa9b-0de9-4341-a74c-363f9809b22f at port 0
2019-09-25 05:49:15,051 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 035834f9-24a4-45b4-a769-10efa83e6a02 is started using port 41226
2019-09-25 05:49:15,050 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e82d6518-db45-4664-aef7-ce30608e98c3 is started using port 39177
2019-09-25 05:49:15,064 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start RPC server
2019-09-25 05:49:15,067 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: GrpcService started, listening on 0.0.0.0/0.0.0.0:39776
2019-09-25 05:49:15,067 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 8de7fa9b-0de9-4341-a74c-363f9809b22f is started using port 39776
2019-09-25 05:49:15,070 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 8de7fa9b-0de9-4341-a74c-363f9809b22f is started using port 34926
2019-09-25 05:49:16,023 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 05:49:16,750 [IPC Server handler 0 on 41998] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:16,750 [IPC Server handler 0 on 41998] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}
2019-09-25 05:49:16,756 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-25 05:49:16,756 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-25 05:49:16,757 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-25 05:49:16,780 [IPC Server handler 1 on 41998] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:16,781 [IPC Server handler 1 on 41998] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}
2019-09-25 05:49:16,866 [IPC Server handler 3 on 41998] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:16,867 [IPC Server handler 3 on 41998] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}
2019-09-25 05:49:16,938 [IPC Server handler 4 on 41998] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:16,939 [IPC Server handler 4 on 41998] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}
2019-09-25 05:49:17,023 [IPC Server handler 5 on 41998] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:17,023 [IPC Server handler 5 on 41998] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}
2019-09-25 05:49:17,024 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-25 05:49:17,061 [Thread-209] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 05:49:17,392 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e82d6518-db45-4664-aef7-ce30608e98c3: addNew group-9BAAD5DC590B:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] returns group-9BAAD5DC590B:java.util.concurrent.CompletableFuture@5198f783[Not completed]
2019-09-25 05:49:17,428 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e82d6518-db45-4664-aef7-ce30608e98c3: new RaftServerImpl for group-9BAAD5DC590B:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] with ContainerStateMachine:uninitialized
2019-09-25 05:49:17,430 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:17,432 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:17,432 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:17,433 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:17,434 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:17,446 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: ConfigurationManager, init=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:17,446 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:17,456 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/6e826d0c-5366-4cf5-a796-9baad5dc590b does not exist. Creating ...
2019-09-25 05:49:17,474 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/6e826d0c-5366-4cf5-a796-9baad5dc590b/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:17,490 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/6e826d0c-5366-4cf5-a796-9baad5dc590b has been successfully formatted.
2019-09-25 05:49:17,493 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-9BAAD5DC590B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:17,493 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:17,495 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:17,502 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:17,502 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:17,505 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:17,510 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:17,516 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/6e826d0c-5366-4cf5-a796-9baad5dc590b
2019-09-25 05:49:17,518 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-25 05:49:17,526 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-25 05:49:17,668 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:17,668 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:17,673 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:17,674 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:17,674 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:17,675 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:17,676 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:17,676 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:17,677 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:17,689 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:17,694 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:17,699 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:17,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:17,701 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:17,702 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:17,735 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: start as a follower, conf=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:17,737 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:17,748 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start FollowerState
2019-09-25 05:49:17,749 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9BAAD5DC590B,id=e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:17,826 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6e826d0c-5366-4cf5-a796-9baad5dc590b, Nodes: e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:17,848 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e1c44be8-c290-4a84-9591-5999c64dd189: addNew group-6D8522E0AD8F:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] returns group-6D8522E0AD8F:java.util.concurrent.CompletableFuture@16b970bc[Not completed]
2019-09-25 05:49:17,894 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e1c44be8-c290-4a84-9591-5999c64dd189: new RaftServerImpl for group-6D8522E0AD8F:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] with ContainerStateMachine:uninitialized
2019-09-25 05:49:17,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:17,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:17,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:17,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:17,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:17,897 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: ConfigurationManager, init=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:17,897 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:17,897 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/216216d5-1a3c-480c-8ab3-6d8522e0ad8f does not exist. Creating ...
2019-09-25 05:49:17,901 [Thread-209] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume14558, with user41564 as owner.
2019-09-25 05:49:17,911 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/216216d5-1a3c-480c-8ab3-6d8522e0ad8f/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:17,926 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/216216d5-1a3c-480c-8ab3-6d8522e0ad8f has been successfully formatted.
2019-09-25 05:49:17,928 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6D8522E0AD8F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:17,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:17,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:17,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:17,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:17,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:17,931 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:17,931 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/216216d5-1a3c-480c-8ab3-6d8522e0ad8f
2019-09-25 05:49:17,938 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:17,938 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:17,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:17,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:17,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:17,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:17,940 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:17,940 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:17,940 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:17,940 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:17,941 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:17,941 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:17,941 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:17,942 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:17,942 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:17,947 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: start as a follower, conf=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:17,947 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:17,948 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start FollowerState
2019-09-25 05:49:17,950 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D8522E0AD8F,id=e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:17,971 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 216216d5-1a3c-480c-8ab3-6d8522e0ad8f, Nodes: e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,000 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e82d6518-db45-4664-aef7-ce30608e98c3: addNew group-66E77176A6ED:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] returns group-66E77176A6ED:java.util.concurrent.CompletableFuture@1c1c7199[Not completed]
2019-09-25 05:49:18,030 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e82d6518-db45-4664-aef7-ce30608e98c3: new RaftServerImpl for group-66E77176A6ED:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,031 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: ConfigurationManager, init=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,032 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:18,032 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/c9a7c654-9ecd-47e8-b490-66e77176a6ed does not exist. Creating ...
2019-09-25 05:49:18,045 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/c9a7c654-9ecd-47e8-b490-66e77176a6ed/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,058 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/c9a7c654-9ecd-47e8-b490-66e77176a6ed has been successfully formatted.
2019-09-25 05:49:18,059 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-66E77176A6ED: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,059 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,059 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,059 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,060 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,060 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,060 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,060 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/c9a7c654-9ecd-47e8-b490-66e77176a6ed
2019-09-25 05:49:18,061 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,061 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,061 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,061 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,062 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,062 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,062 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,062 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,062 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,063 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,063 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,064 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,064 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,064 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,064 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,092 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: start as a follower, conf=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:18,092 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,093 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start FollowerState
2019-09-25 05:49:18,093 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-66E77176A6ED,id=e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:18,104 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c9a7c654-9ecd-47e8-b490-66e77176a6ed, Nodes: e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,109 [IPC Server handler 1 on 33070] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume14558 for user:user41564
2019-09-25 05:49:18,134 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 035834f9-24a4-45b4-a769-10efa83e6a02: addNew group-84255A3F1626:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] returns group-84255A3F1626:java.util.concurrent.CompletableFuture@22271b3c[Not completed]
2019-09-25 05:49:18,137 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 035834f9-24a4-45b4-a769-10efa83e6a02: new RaftServerImpl for group-84255A3F1626:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,138 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,138 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,138 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,138 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,139 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,139 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: ConfigurationManager, init=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,141 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:18,141 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/c9cf1951-e243-47d7-b262-84255a3f1626 does not exist. Creating ...
2019-09-25 05:49:18,155 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/c9cf1951-e243-47d7-b262-84255a3f1626/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,169 [Thread-209] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume14558/bucket05012, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 05:49:18,176 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/c9cf1951-e243-47d7-b262-84255a3f1626 has been successfully formatted.
2019-09-25 05:49:18,177 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-84255A3F1626: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,177 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,177 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,177 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,179 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,179 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/c9cf1951-e243-47d7-b262-84255a3f1626
2019-09-25 05:49:18,187 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,189 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,189 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,189 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,189 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,190 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,191 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,192 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,192 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,192 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,193 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,199 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: start as a follower, conf=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:18,199 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,199 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start FollowerState
2019-09-25 05:49:18,200 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-84255A3F1626,id=035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:18,212 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c9cf1951-e243-47d7-b262-84255a3f1626, Nodes: 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,233 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 035834f9-24a4-45b4-a769-10efa83e6a02: addNew group-361E396E7C71:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] returns group-361E396E7C71:java.util.concurrent.CompletableFuture@6886f6ab[Not completed]
2019-09-25 05:49:18,235 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 035834f9-24a4-45b4-a769-10efa83e6a02: new RaftServerImpl for group-361E396E7C71:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,235 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,235 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,235 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,235 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,236 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,236 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: ConfigurationManager, init=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,240 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:18,240 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/97524661-5984-4c10-b48a-361e396e7c71 does not exist. Creating ...
2019-09-25 05:49:18,253 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/97524661-5984-4c10-b48a-361e396e7c71/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,549 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/97524661-5984-4c10-b48a-361e396e7c71 has been successfully formatted.
2019-09-25 05:49:18,557 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-361E396E7C71: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,560 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,560 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,560 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,561 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,561 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,562 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,562 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/97524661-5984-4c10-b48a-361e396e7c71
2019-09-25 05:49:18,562 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,562 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,563 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,563 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,563 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,563 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,563 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,564 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,564 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,564 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,565 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,565 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,565 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,566 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,566 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,572 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: start as a follower, conf=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:18,573 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,573 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start FollowerState
2019-09-25 05:49:18,574 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-361E396E7C71,id=035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:18,586 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 97524661-5984-4c10-b48a-361e396e7c71, Nodes: 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,612 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: addNew group-31134F79082F:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] returns group-31134F79082F:java.util.concurrent.CompletableFuture@b68628d[Not completed]
2019-09-25 05:49:18,614 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: new RaftServerImpl for group-31134F79082F:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,614 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,615 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,615 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,615 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,615 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,616 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: ConfigurationManager, init=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,616 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:18,617 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/5bc0fc9b-63c5-409d-b227-31134f79082f does not exist. Creating ...
2019-09-25 05:49:18,630 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/5bc0fc9b-63c5-409d-b227-31134f79082f/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,644 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/5bc0fc9b-63c5-409d-b227-31134f79082f has been successfully formatted.
2019-09-25 05:49:18,644 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-31134F79082F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,644 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,644 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,645 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,645 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,645 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,645 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,646 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/5bc0fc9b-63c5-409d-b227-31134f79082f
2019-09-25 05:49:18,650 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,652 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,652 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,652 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,652 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,653 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,653 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,654 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,654 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,654 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,654 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,659 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: start as a follower, conf=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:18,659 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,659 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start FollowerState
2019-09-25 05:49:18,660 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-31134F79082F,id=846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:18,677 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5bc0fc9b-63c5-409d-b227-31134f79082f, Nodes: 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,697 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e82d6518-db45-4664-aef7-ce30608e98c3: addNew group-5F578A7CB528:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] returns group-5F578A7CB528:java.util.concurrent.CompletableFuture@ef163e5[Not completed]
2019-09-25 05:49:18,699 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e82d6518-db45-4664-aef7-ce30608e98c3: new RaftServerImpl for group-5F578A7CB528:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,701 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: ConfigurationManager, init=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,701 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:18,711 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/f19a6a5d-e480-4f91-8475-5f578a7cb528 does not exist. Creating ...
2019-09-25 05:49:18,732 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/f19a6a5d-e480-4f91-8475-5f578a7cb528/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,745 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/f19a6a5d-e480-4f91-8475-5f578a7cb528 has been successfully formatted.
2019-09-25 05:49:18,747 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5F578A7CB528: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,747 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,747 [Thread-209] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket05012.volume14558 implemented by OzoneFileSystem{URI=o3fs://bucket05012.volume14558, workingDir=o3fs://bucket05012.volume14558/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-25 05:49:18,747 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,747 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,748 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,748 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,748 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,748 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/f19a6a5d-e480-4f91-8475-5f578a7cb528
2019-09-25 05:49:18,748 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,750 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,750 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,750 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,751 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,751 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,751 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,751 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,755 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: start as a follower, conf=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:18,756 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,756 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start FollowerState
2019-09-25 05:49:18,756 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F578A7CB528,id=e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:18,773 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f19a6a5d-e480-4f91-8475-5f578a7cb528, Nodes: e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,789 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: addNew group-5A13AF058694:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] returns group-5A13AF058694:java.util.concurrent.CompletableFuture@264d0d4d[Not completed]
2019-09-25 05:49:18,792 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: new RaftServerImpl for group-5A13AF058694:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,792 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,792 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,792 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,793 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,793 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,793 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: ConfigurationManager, init=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,793 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:18,794 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/052f1953-d056-49e7-9336-5a13af058694 does not exist. Creating ...
2019-09-25 05:49:18,806 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/052f1953-d056-49e7-9336-5a13af058694/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,822 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/052f1953-d056-49e7-9336-5a13af058694 has been successfully formatted.
2019-09-25 05:49:18,822 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5A13AF058694: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,822 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,824 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/052f1953-d056-49e7-9336-5a13af058694
2019-09-25 05:49:18,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,825 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,832 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,832 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,832 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,832 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,833 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,833 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,834 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,834 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,834 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,834 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,844 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: start as a follower, conf=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:18,844 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,844 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start FollowerState
2019-09-25 05:49:18,848 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5A13AF058694,id=846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:18,865 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 052f1953-d056-49e7-9336-5a13af058694, Nodes: 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:18,882 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 035834f9-24a4-45b4-a769-10efa83e6a02: addNew group-DD5716897406:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] returns group-DD5716897406:java.util.concurrent.CompletableFuture@502693b0[Not completed]
2019-09-25 05:49:18,885 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 035834f9-24a4-45b4-a769-10efa83e6a02: new RaftServerImpl for group-DD5716897406:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,885 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,885 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,886 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,886 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,886 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,886 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: ConfigurationManager, init=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,887 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:18,887 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/d8386dfd-33de-4fed-97b9-dd5716897406 does not exist. Creating ...
2019-09-25 05:49:18,902 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/d8386dfd-33de-4fed-97b9-dd5716897406/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,921 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/d8386dfd-33de-4fed-97b9-dd5716897406 has been successfully formatted.
2019-09-25 05:49:18,922 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DD5716897406: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:18,922 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:18,922 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:18,922 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:18,922 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:18,924 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,924 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:18,924 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/d8386dfd-33de-4fed-97b9-dd5716897406
2019-09-25 05:49:18,924 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:18,924 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:18,925 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:18,925 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:18,925 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:18,925 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:18,925 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:18,925 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:18,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:18,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:18,926 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:18,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:18,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:18,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:18,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:18,930 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: start as a follower, conf=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:18,930 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:18,931 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start FollowerState
2019-09-25 05:49:18,931 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD5716897406,id=035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:18,941 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d8386dfd-33de-4fed-97b9-dd5716897406, Nodes: 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
05:49:18.928 [IPC Server handler 13 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:18,955 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: addNew group-89792DDFDFC9:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] returns group-89792DDFDFC9:java.util.concurrent.CompletableFuture@3b2352ee[Not completed]
2019-09-25 05:49:18,956 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: new RaftServerImpl for group-89792DDFDFC9:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] with ContainerStateMachine:uninitialized
2019-09-25 05:49:18,956 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:18,956 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:18,957 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:18,957 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:18,957 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:18,957 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: ConfigurationManager, init=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:18,957 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:18,958 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/330a0665-ce65-4700-8c1a-89792ddfdfc9 does not exist. Creating ...
2019-09-25 05:49:18,959 [Thread-209] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-25 05:49:18,971 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/330a0665-ce65-4700-8c1a-89792ddfdfc9/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:18,996 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/330a0665-ce65-4700-8c1a-89792ddfdfc9 has been successfully formatted.
2019-09-25 05:49:19,007 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-89792DDFDFC9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,009 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,009 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,009 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,009 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,009 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,010 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,010 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/330a0665-ce65-4700-8c1a-89792ddfdfc9
2019-09-25 05:49:19,010 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,010 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,010 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,011 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,011 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,011 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,011 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,011 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,011 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,012 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,023 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,025 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,025 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,025 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,026 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,037 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: start as a follower, conf=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:19,037 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,037 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start FollowerState
2019-09-25 05:49:19,038 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-89792DDFDFC9,id=846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:19,050 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 330a0665-ce65-4700-8c1a-89792ddfdfc9, Nodes: 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,069 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 035834f9-24a4-45b4-a769-10efa83e6a02: addNew group-243D13FE3DCF:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] returns group-243D13FE3DCF:java.util.concurrent.CompletableFuture@6368517c[Not completed]
2019-09-25 05:49:19,070 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 035834f9-24a4-45b4-a769-10efa83e6a02: new RaftServerImpl for group-243D13FE3DCF:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,070 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,071 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,071 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,071 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,071 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,071 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: ConfigurationManager, init=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,071 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:19,072 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/9d00cb4f-dbb1-4c0d-ba1b-243d13fe3dcf does not exist. Creating ...
2019-09-25 05:49:19,084 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/9d00cb4f-dbb1-4c0d-ba1b-243d13fe3dcf/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,098 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/9d00cb4f-dbb1-4c0d-ba1b-243d13fe3dcf has been successfully formatted.
2019-09-25 05:49:19,098 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-243D13FE3DCF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,100 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/9d00cb4f-dbb1-4c0d-ba1b-243d13fe3dcf
2019-09-25 05:49:19,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,101 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,101 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,101 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,110 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,110 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,111 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,111 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,111 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,112 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,112 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,112 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,119 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: start as a follower, conf=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:19,119 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,119 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start FollowerState
2019-09-25 05:49:19,123 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-243D13FE3DCF,id=035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:19,137 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9d00cb4f-dbb1-4c0d-ba1b-243d13fe3dcf, Nodes: 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,162 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e82d6518-db45-4664-aef7-ce30608e98c3: addNew group-C7549E606CE5:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] returns group-C7549E606CE5:java.util.concurrent.CompletableFuture@67611c8a[Not completed]
2019-09-25 05:49:19,164 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e82d6518-db45-4664-aef7-ce30608e98c3: new RaftServerImpl for group-C7549E606CE5:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,164 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,164 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,164 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,165 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,165 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,165 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: ConfigurationManager, init=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,165 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:19,166 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/769cf43f-80e7-4156-b146-c7549e606ce5 does not exist. Creating ...
2019-09-25 05:49:19,192 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/769cf43f-80e7-4156-b146-c7549e606ce5/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,205 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/769cf43f-80e7-4156-b146-c7549e606ce5 has been successfully formatted.
2019-09-25 05:49:19,206 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C7549E606CE5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,207 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:49:19,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,207 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/769cf43f-80e7-4156-b146-c7549e606ce5
2019-09-25 05:49:19,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,210 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,211 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,211 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,211 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,215 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: start as a follower, conf=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:19,215 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,215 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start FollowerState
2019-09-25 05:49:19,220 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7549E606CE5,id=e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:19,238 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 769cf43f-80e7-4156-b146-c7549e606ce5, Nodes: e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,263 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:49:19,272 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: addNew group-4CB4AD9202B0:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] returns group-4CB4AD9202B0:java.util.concurrent.CompletableFuture@7e659647[Not completed]
2019-09-25 05:49:19,277 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: new RaftServerImpl for group-4CB4AD9202B0:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,277 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,277 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,277 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,278 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,278 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,278 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: ConfigurationManager, init=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,278 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:19,279 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/0fdefd2b-c0e0-4110-a0f7-4cb4ad9202b0 does not exist. Creating ...
2019-09-25 05:49:19,292 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/0fdefd2b-c0e0-4110-a0f7-4cb4ad9202b0/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,295 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/0fdefd2b-c0e0-4110-a0f7-4cb4ad9202b0 has been successfully formatted.
2019-09-25 05:49:19,296 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4CB4AD9202B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,296 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,296 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,296 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,297 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/0fdefd2b-c0e0-4110-a0f7-4cb4ad9202b0
2019-09-25 05:49:19,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,299 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,299 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,299 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,299 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,300 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,300 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,300 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,300 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,301 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,304 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: start as a follower, conf=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:19,305 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,305 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start FollowerState
2019-09-25 05:49:19,305 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4CB4AD9202B0,id=846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:19,317 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0fdefd2b-c0e0-4110-a0f7-4cb4ad9202b0, Nodes: 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,335 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e1c44be8-c290-4a84-9591-5999c64dd189: addNew group-A4F15421AD66:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] returns group-A4F15421AD66:java.util.concurrent.CompletableFuture@730d618b[Not completed]
2019-09-25 05:49:19,337 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e1c44be8-c290-4a84-9591-5999c64dd189: new RaftServerImpl for group-A4F15421AD66:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,338 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,338 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,338 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,338 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,338 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,339 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: ConfigurationManager, init=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,339 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:19,339 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/2001cd1e-3033-4a96-9bf3-a4f15421ad66 does not exist. Creating ...
2019-09-25 05:49:19,353 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/2001cd1e-3033-4a96-9bf3-a4f15421ad66/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,356 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/2001cd1e-3033-4a96-9bf3-a4f15421ad66 has been successfully formatted.
2019-09-25 05:49:19,357 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A4F15421AD66: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,358 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/2001cd1e-3033-4a96-9bf3-a4f15421ad66
2019-09-25 05:49:19,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,360 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,360 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,360 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,361 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,365 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: start as a follower, conf=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:19,365 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,365 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start FollowerState
2019-09-25 05:49:19,365 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A4F15421AD66,id=e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:19,375 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2001cd1e-3033-4a96-9bf3-a4f15421ad66, Nodes: e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
05:49:19.389 [IPC Server handler 15 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:19,393 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e82d6518-db45-4664-aef7-ce30608e98c3: addNew group-7E28FE559D98:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] returns group-7E28FE559D98:java.util.concurrent.CompletableFuture@40b57784[Not completed]
2019-09-25 05:49:19,395 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e82d6518-db45-4664-aef7-ce30608e98c3: new RaftServerImpl for group-7E28FE559D98:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,396 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: ConfigurationManager, init=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:19,397 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/1f0186ab-90fa-4fcf-b1f6-7e28fe559d98 does not exist. Creating ...
2019-09-25 05:49:19,409 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/1f0186ab-90fa-4fcf-b1f6-7e28fe559d98/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,441 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/1f0186ab-90fa-4fcf-b1f6-7e28fe559d98 has been successfully formatted.
2019-09-25 05:49:19,441 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7E28FE559D98: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,443 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/1f0186ab-90fa-4fcf-b1f6-7e28fe559d98
2019-09-25 05:49:19,443 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,443 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,443 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,443 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,445 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,445 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,446 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,446 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,446 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,446 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,453 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: start as a follower, conf=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:19,453 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,454 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start FollowerState
2019-09-25 05:49:19,454 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E28FE559D98,id=e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:19,463 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1f0186ab-90fa-4fcf-b1f6-7e28fe559d98, Nodes: e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,486 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e82d6518-db45-4664-aef7-ce30608e98c3: addNew group-DF8321418F27:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] returns group-DF8321418F27:java.util.concurrent.CompletableFuture@951813[Not completed]
2019-09-25 05:49:19,488 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e82d6518-db45-4664-aef7-ce30608e98c3: new RaftServerImpl for group-DF8321418F27:[e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,489 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,489 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: ConfigurationManager, init=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,489 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis] (custom)
2019-09-25 05:49:19,489 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/bd67e41b-577c-4f63-9859-df8321418f27 does not exist. Creating ...
2019-09-25 05:49:19,503 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/bd67e41b-577c-4f63-9859-df8321418f27/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,516 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/bd67e41b-577c-4f63-9859-df8321418f27 has been successfully formatted.
2019-09-25 05:49:19,517 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DF8321418F27: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,518 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/bd67e41b-577c-4f63-9859-df8321418f27
2019-09-25 05:49:19,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,520 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,520 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,520 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,521 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,521 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,524 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: start as a follower, conf=-1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:19,524 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,525 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start FollowerState
2019-09-25 05:49:19,525 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DF8321418F27,id=e82d6518-db45-4664-aef7-ce30608e98c3
2019-09-25 05:49:19,533 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bd67e41b-577c-4f63-9859-df8321418f27, Nodes: e82d6518-db45-4664-aef7-ce30608e98c3{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,533 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:19,539 [Thread-209] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 05:49:19,540 [Thread-209] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 05:49:19,544 [Thread-209] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-25 05:49:19,544 [Thread-209] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-25 05:49:19,544 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e1c44be8-c290-4a84-9591-5999c64dd189: addNew group-D0A1250C64B1:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] returns group-D0A1250C64B1:java.util.concurrent.CompletableFuture@5179a8d9[Not completed]
2019-09-25 05:49:19,546 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e1c44be8-c290-4a84-9591-5999c64dd189: new RaftServerImpl for group-D0A1250C64B1:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,546 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,547 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,547 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,547 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,547 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,547 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: ConfigurationManager, init=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,547 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:19,548 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/268504ee-9fa1-44ba-8ccb-d0a1250c64b1 does not exist. Creating ...
2019-09-25 05:49:19,560 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/268504ee-9fa1-44ba-8ccb-d0a1250c64b1/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,573 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/268504ee-9fa1-44ba-8ccb-d0a1250c64b1 has been successfully formatted.
2019-09-25 05:49:19,573 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D0A1250C64B1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,573 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,573 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,574 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/268504ee-9fa1-44ba-8ccb-d0a1250c64b1
2019-09-25 05:49:19,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,576 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,580 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: start as a follower, conf=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:19,580 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,580 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start FollowerState
2019-09-25 05:49:19,580 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D0A1250C64B1,id=e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:19,587 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 268504ee-9fa1-44ba-8ccb-d0a1250c64b1, Nodes: e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,587 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:19,588 [Thread-209] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 05:49:19,599 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: addNew group-9116C338D4E6:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] returns group-9116C338D4E6:java.util.concurrent.CompletableFuture@4ddb6930[Not completed]
2019-09-25 05:49:19,603 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: new RaftServerImpl for group-9116C338D4E6:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,603 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,603 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,603 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,603 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,603 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,604 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: ConfigurationManager, init=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,604 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:19,604 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/75ee619d-354e-40d4-bc77-9116c338d4e6 does not exist. Creating ...
2019-09-25 05:49:19,605 [Thread-209] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 05:49:19,611 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:49:19,617 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/75ee619d-354e-40d4-bc77-9116c338d4e6/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,630 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/75ee619d-354e-40d4-bc77-9116c338d4e6 has been successfully formatted.
2019-09-25 05:49:19,630 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-9116C338D4E6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,630 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,630 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,630 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,631 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,631 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,631 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,631 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/75ee619d-354e-40d4-bc77-9116c338d4e6
2019-09-25 05:49:19,634 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,634 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,634 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,634 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,635 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,635 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,635 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,635 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,635 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,635 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,636 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,636 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,636 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,636 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,637 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,639 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: start as a follower, conf=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:19,639 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,639 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start FollowerState
2019-09-25 05:49:19,640 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9116C338D4E6,id=8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:19,645 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 75ee619d-354e-40d4-bc77-9116c338d4e6, Nodes: 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,645 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:19,650 [Thread-209] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 05:49:19,656 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 035834f9-24a4-45b4-a769-10efa83e6a02: addNew group-C373D29CFBA2:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] returns group-C373D29CFBA2:java.util.concurrent.CompletableFuture@407403c5[Not completed]
2019-09-25 05:49:19,657 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 035834f9-24a4-45b4-a769-10efa83e6a02: new RaftServerImpl for group-C373D29CFBA2:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,658 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,658 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,658 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,658 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,658 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,658 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: ConfigurationManager, init=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,659 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:19,659 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/3d122b05-4351-403f-a202-c373d29cfba2 does not exist. Creating ...
2019-09-25 05:49:19,671 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/3d122b05-4351-403f-a202-c373d29cfba2/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,688 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/3d122b05-4351-403f-a202-c373d29cfba2 has been successfully formatted.
2019-09-25 05:49:19,688 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C373D29CFBA2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,689 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,689 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,689 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,689 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,689 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,690 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/3d122b05-4351-403f-a202-c373d29cfba2
2019-09-25 05:49:19,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,692 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,692 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,692 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,692 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,693 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,695 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: start as a follower, conf=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:19,696 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,696 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start FollowerState
2019-09-25 05:49:19,696 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C373D29CFBA2,id=035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:19,702 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3d122b05-4351-403f-a202-c373d29cfba2, Nodes: 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,703 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:19,730 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: addNew group-AE710C1E1782:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] returns group-AE710C1E1782:java.util.concurrent.CompletableFuture@1ebd8f9[Not completed]
2019-09-25 05:49:19,732 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: new RaftServerImpl for group-AE710C1E1782:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,732 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,732 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,732 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,733 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,733 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,733 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: ConfigurationManager, init=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,733 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:19,734 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/b6846886-bc94-4cfe-bca2-ae710c1e1782 does not exist. Creating ...
2019-09-25 05:49:19,747 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/b6846886-bc94-4cfe-bca2-ae710c1e1782/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,755 [Thread-209] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-25 05:49:19,759 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/b6846886-bc94-4cfe-bca2-ae710c1e1782 has been successfully formatted.
2019-09-25 05:49:19,760 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AE710C1E1782: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,760 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,760 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,760 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,760 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,760 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,761 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,761 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/b6846886-bc94-4cfe-bca2-ae710c1e1782
2019-09-25 05:49:19,761 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,763 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,765 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-25 05:49:19,765 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,766 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-25 05:49:19,768 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: start as a follower, conf=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:19,768 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,769 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start FollowerState
2019-09-25 05:49:19,775 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE710C1E1782,id=846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:19,793 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b6846886-bc94-4cfe-bca2-ae710c1e1782, Nodes: 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,794 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:19,805 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 035834f9-24a4-45b4-a769-10efa83e6a02: addNew group-4551CCD3A56E:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] returns group-4551CCD3A56E:java.util.concurrent.CompletableFuture@71f03588[Not completed]
2019-09-25 05:49:19,807 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 035834f9-24a4-45b4-a769-10efa83e6a02: new RaftServerImpl for group-4551CCD3A56E:[035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,807 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,807 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,808 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,808 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,808 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,808 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: ConfigurationManager, init=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,808 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis] (custom)
2019-09-25 05:49:19,809 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/6e5e7358-b51f-489f-a376-4551ccd3a56e does not exist. Creating ...
2019-09-25 05:49:19,821 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/6e5e7358-b51f-489f-a376-4551ccd3a56e/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,834 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/6e5e7358-b51f-489f-a376-4551ccd3a56e has been successfully formatted.
2019-09-25 05:49:19,835 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4551CCD3A56E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,835 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,835 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,835 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,835 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,835 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/6e5e7358-b51f-489f-a376-4551ccd3a56e
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,836 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,837 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,837 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,837 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,837 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,837 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,838 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,838 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,838 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,838 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,838 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:19,841 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: start as a follower, conf=-1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:19,841 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:19,841 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start FollowerState
2019-09-25 05:49:19,841 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4551CCD3A56E,id=035834f9-24a4-45b4-a769-10efa83e6a02
2019-09-25 05:49:19,848 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6e5e7358-b51f-489f-a376-4551ccd3a56e, Nodes: 035834f9-24a4-45b4-a769-10efa83e6a02{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:19,848 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:19,848 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:19,859 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e1c44be8-c290-4a84-9591-5999c64dd189: addNew group-2C99518DA95F:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] returns group-2C99518DA95F:java.util.concurrent.CompletableFuture@44082c34[Not completed]
2019-09-25 05:49:19,860 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e1c44be8-c290-4a84-9591-5999c64dd189: new RaftServerImpl for group-2C99518DA95F:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] with ContainerStateMachine:uninitialized
2019-09-25 05:49:19,861 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:19,861 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:19,873 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:19,873 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:19,873 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:19,873 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: ConfigurationManager, init=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:19,874 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:19,874 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/a36bd38d-6b67-46e6-99d2-2c99518da95f does not exist. Creating ...
2019-09-25 05:49:19,887 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/a36bd38d-6b67-46e6-99d2-2c99518da95f/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:19,899 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/a36bd38d-6b67-46e6-99d2-2c99518da95f has been successfully formatted.
2019-09-25 05:49:19,913 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-2C99518DA95F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:19,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:19,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:19,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:19,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:19,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/a36bd38d-6b67-46e6-99d2-2c99518da95f
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:19,917 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:19,918 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:19,918 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:19,918 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:19,918 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:19,918 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:19,919 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:19,919 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:19,919 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,069 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: start as a follower, conf=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:20,069 [Thread-209] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1468691963_0001
2019-09-25 05:49:20,069 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,070 [Thread-209] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 05:49:20,070 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start FollowerState
2019-09-25 05:49:20,071 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C99518DA95F,id=e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:20,077 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a36bd38d-6b67-46e6-99d2-2c99518da95f, Nodes: e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,077 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,077 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,089 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e1c44be8-c290-4a84-9591-5999c64dd189: addNew group-10CFB719E01D:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] returns group-10CFB719E01D:java.util.concurrent.CompletableFuture@762eebff[Not completed]
2019-09-25 05:49:20,092 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e1c44be8-c290-4a84-9591-5999c64dd189: new RaftServerImpl for group-10CFB719E01D:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,092 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,092 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,092 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,092 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,093 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,093 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: ConfigurationManager, init=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,093 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:20,094 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/cd550a4f-ae79-4ee2-a98e-10cfb719e01d does not exist. Creating ...
2019-09-25 05:49:20,107 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/cd550a4f-ae79-4ee2-a98e-10cfb719e01d/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,120 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/cd550a4f-ae79-4ee2-a98e-10cfb719e01d has been successfully formatted.
2019-09-25 05:49:20,120 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-10CFB719E01D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,121 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,121 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,121 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,121 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,121 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,122 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/cd550a4f-ae79-4ee2-a98e-10cfb719e01d
2019-09-25 05:49:20,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,123 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,123 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,123 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,123 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,123 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,123 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,124 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,124 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,124 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,125 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,125 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,128 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: start as a follower, conf=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:20,128 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,128 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start FollowerState
2019-09-25 05:49:20,128 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-10CFB719E01D,id=e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:20,137 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: cd550a4f-ae79-4ee2-a98e-10cfb719e01d, Nodes: e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,137 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,139 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,150 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: addNew group-083A5A6151B3:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] returns group-083A5A6151B3:java.util.concurrent.CompletableFuture@30677392[Not completed]
2019-09-25 05:49:20,152 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: new RaftServerImpl for group-083A5A6151B3:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,153 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,153 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,153 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,153 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,154 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,154 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: ConfigurationManager, init=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,154 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:20,155 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/1ceee3af-083b-4d40-8d26-083a5a6151b3 does not exist. Creating ...
2019-09-25 05:49:20,167 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/1ceee3af-083b-4d40-8d26-083a5a6151b3/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,180 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/1ceee3af-083b-4d40-8d26-083a5a6151b3 has been successfully formatted.
2019-09-25 05:49:20,180 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-083A5A6151B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,180 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,181 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,181 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,181 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,181 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,181 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,181 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/1ceee3af-083b-4d40-8d26-083a5a6151b3
2019-09-25 05:49:20,182 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,182 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,182 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,182 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,182 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,182 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,183 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,183 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,183 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,183 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,183 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,184 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,184 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,184 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,184 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,187 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: start as a follower, conf=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:20,187 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,187 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start FollowerState
2019-09-25 05:49:20,188 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-083A5A6151B3,id=8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:20,195 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1ceee3af-083b-4d40-8d26-083a5a6151b3, Nodes: 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,196 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,196 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,206 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: addNew group-4DA3556BDC30:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] returns group-4DA3556BDC30:java.util.concurrent.CompletableFuture@2113d56e[Not completed]
2019-09-25 05:49:20,208 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: new RaftServerImpl for group-4DA3556BDC30:[846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,209 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,209 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,209 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: ConfigurationManager, init=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,209 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis] (custom)
2019-09-25 05:49:20,210 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/acfdde39-6e4a-4236-b174-4da3556bdc30 does not exist. Creating ...
2019-09-25 05:49:20,222 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/acfdde39-6e4a-4236-b174-4da3556bdc30/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,238 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/acfdde39-6e4a-4236-b174-4da3556bdc30 has been successfully formatted.
2019-09-25 05:49:20,239 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4DA3556BDC30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,239 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,239 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,239 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,239 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,240 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,240 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,240 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/acfdde39-6e4a-4236-b174-4da3556bdc30
2019-09-25 05:49:20,240 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,240 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,241 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,241 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,241 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,241 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,241 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,242 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,242 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,242 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,242 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,243 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,243 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,243 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,243 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,247 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: start as a follower, conf=-1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:20,247 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,248 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start FollowerState
2019-09-25 05:49:20,248 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4DA3556BDC30,id=846429a6-4dd4-4152-b8dd-d8abbf5dfe58
2019-09-25 05:49:20,254 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: acfdde39-6e4a-4236-b174-4da3556bdc30, Nodes: 846429a6-4dd4-4152-b8dd-d8abbf5dfe58{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,254 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,254 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,255 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,264 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e1c44be8-c290-4a84-9591-5999c64dd189: addNew group-66007F40F961:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] returns group-66007F40F961:java.util.concurrent.CompletableFuture@438507f0[Not completed]
2019-09-25 05:49:20,268 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e1c44be8-c290-4a84-9591-5999c64dd189: new RaftServerImpl for group-66007F40F961:[e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,269 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,269 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: ConfigurationManager, init=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,270 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis] (custom)
2019-09-25 05:49:20,270 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/44d954fe-4c82-4900-8377-66007f40f961 does not exist. Creating ...
2019-09-25 05:49:20,303 [Thread-209] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 05:49:20,303 [Thread-209] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1468691963_0001
2019-09-25 05:49:20,305 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1468691963_0001
2019-09-25 05:49:20,314 [Thread-347] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 05:49:20,314 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/44d954fe-4c82-4900-8377-66007f40f961/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,327 [Thread-347] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:20,327 [Thread-347] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:20,330 [Thread-347] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 05:49:20,353 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/44d954fe-4c82-4900-8377-66007f40f961 has been successfully formatted.
2019-09-25 05:49:20,354 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-66007F40F961: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,354 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,354 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,354 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,355 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,355 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,355 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,355 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/44d954fe-4c82-4900-8377-66007f40f961
2019-09-25 05:49:20,356 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,356 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,356 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,356 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,356 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,356 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,357 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,358 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,358 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,362 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: start as a follower, conf=-1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:20,362 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,363 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start FollowerState
2019-09-25 05:49:20,363 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-66007F40F961,id=e1c44be8-c290-4a84-9591-5999c64dd189
2019-09-25 05:49:20,369 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 44d954fe-4c82-4900-8377-66007f40f961, Nodes: e1c44be8-c290-4a84-9591-5999c64dd189{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,369 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,369 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,369 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,370 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,380 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: addNew group-3E820A3EF2DE:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] returns group-3E820A3EF2DE:java.util.concurrent.CompletableFuture@414021ce[Not completed]
2019-09-25 05:49:20,382 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: new RaftServerImpl for group-3E820A3EF2DE:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: ConfigurationManager, init=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,383 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:20,384 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/ad132220-80c7-4160-b747-3e820a3ef2de does not exist. Creating ...
2019-09-25 05:49:20,393 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/ad132220-80c7-4160-b747-3e820a3ef2de/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,409 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/ad132220-80c7-4160-b747-3e820a3ef2de has been successfully formatted.
2019-09-25 05:49:20,409 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-3E820A3EF2DE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,409 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,409 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,409 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,410 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,410 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,410 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,410 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/ad132220-80c7-4160-b747-3e820a3ef2de
2019-09-25 05:49:20,410 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,410 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,411 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,411 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,411 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,411 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,412 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,412 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,412 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,412 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,413 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,413 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,414 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,414 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,414 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,414 [Thread-347] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 05:49:20,416 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:20,420 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: start as a follower, conf=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:20,420 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,420 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start FollowerState
2019-09-25 05:49:20,421 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3E820A3EF2DE,id=8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:20,426 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ad132220-80c7-4160-b747-3e820a3ef2de, Nodes: 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,427 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,427 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,427 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,427 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,437 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: addNew group-D5FC006143C1:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] returns group-D5FC006143C1:java.util.concurrent.CompletableFuture@4a302f4c[Not completed]
2019-09-25 05:49:20,438 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: new RaftServerImpl for group-D5FC006143C1:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,439 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,439 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,439 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,439 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,439 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,439 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: ConfigurationManager, init=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,440 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:20,440 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/a5f784e3-578e-45a1-8bee-d5fc006143c1 does not exist. Creating ...
2019-09-25 05:49:20,453 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/a5f784e3-578e-45a1-8bee-d5fc006143c1/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,467 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/a5f784e3-578e-45a1-8bee-d5fc006143c1 has been successfully formatted.
2019-09-25 05:49:20,468 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D5FC006143C1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,470 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,470 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/a5f784e3-578e-45a1-8bee-d5fc006143c1
2019-09-25 05:49:20,470 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,470 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,470 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,471 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,471 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,471 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,471 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,471 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,471 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,472 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,472 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,473 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,473 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,473 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:20,475 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:20,477 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: start as a follower, conf=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:20,477 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,477 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start FollowerState
2019-09-25 05:49:20,478 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5FC006143C1,id=8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:20,484 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a5f784e3-578e-45a1-8bee-d5fc006143c1, Nodes: 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,485 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,485 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,485 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,485 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,496 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: addNew group-EAFADE5E7C06:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] returns group-EAFADE5E7C06:java.util.concurrent.CompletableFuture@4da03aa6[Not completed]
2019-09-25 05:49:20,497 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: new RaftServerImpl for group-EAFADE5E7C06:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: ConfigurationManager, init=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,498 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:20,499 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/d75cf51b-d15f-4357-a074-eafade5e7c06 does not exist. Creating ...
2019-09-25 05:49:20,505 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:20,509 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:2488+580
2019-09-25 05:49:20,512 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/d75cf51b-d15f-4357-a074-eafade5e7c06/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,520 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:20,520 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:20,524 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/d75cf51b-d15f-4357-a074-eafade5e7c06 has been successfully formatted.
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-EAFADE5E7C06: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,525 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/d75cf51b-d15f-4357-a074-eafade5e7c06
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,526 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,527 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,527 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,527 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,527 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,527 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,528 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,528 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,528 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,530 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: start as a follower, conf=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:20,531 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,531 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start FollowerState
2019-09-25 05:49:20,531 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EAFADE5E7C06,id=8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:20,537 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d75cf51b-d15f-4357-a074-eafade5e7c06, Nodes: 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,537 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,537 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,537 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,538 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
05:49:20.548 [IPC Server handler 14 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:20,551 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-25 05:49:20,551 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: addNew group-D21C52FD77BF:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] returns group-D21C52FD77BF:java.util.concurrent.CompletableFuture@2f594523[Not completed]
2019-09-25 05:49:20,552 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: new RaftServerImpl for group-D21C52FD77BF:[8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776] with ContainerStateMachine:uninitialized
2019-09-25 05:49:20,552 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 05:49:20,552 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 05:49:20,552 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 05:49:20,552 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 05:49:20,553 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 05:49:20,553 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: ConfigurationManager, init=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null, confs=<EMPTY_MAP>
2019-09-25 05:49:20,553 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis] (custom)
2019-09-25 05:49:20,553 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/f419aca0-1ca2-4f99-beff-d21c52fd77bf does not exist. Creating ...
05:49:20.556 [IPC Server handler 16 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:20,562 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:20,568 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/f419aca0-1ca2-4f99-beff-d21c52fd77bf/in_use.lock acquired by nodename 10654@pr-hdds-1569-zxpks-796972592
2019-09-25 05:49:20,581 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/f419aca0-1ca2-4f99-beff-d21c52fd77bf has been successfully formatted.
2019-09-25 05:49:20,582 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D21C52FD77BF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 05:49:20,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 05:49:20,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 05:49:20,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 05:49:20,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 05:49:20,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 05:49:20,583 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/f419aca0-1ca2-4f99-beff-d21c52fd77bf
2019-09-25 05:49:20,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 05:49:20,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 05:49:20,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 05:49:20,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 05:49:20,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 05:49:20,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 05:49:20,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 05:49:20,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 05:49:20,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 05:49:20,585 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 05:49:20,585 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 05:49:20,585 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 05:49:20,586 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 05:49:20,586 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 05:49:20,586 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 05:49:20,589 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: start as a follower, conf=-1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:20,589 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 05:49:20,589 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start FollowerState
2019-09-25 05:49:20,590 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D21C52FD77BF,id=8de7fa9b-0de9-4341-a74c-363f9809b22f
2019-09-25 05:49:20,594 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f419aca0-1ca2-4f99-beff-d21c52fd77bf, Nodes: 8de7fa9b-0de9-4341-a74c-363f9809b22f{ip: 192.168.5.161, host: pr-hdds-1569-zxpks-796972592, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 05:49:20,595 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:20,595 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,595 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,595 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,596 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,596 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:20,598 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:20,600 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:20,600 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,600 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,600 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,601 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,601 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:20,601 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:20,603 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:20,603 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,603 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,604 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,604 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,604 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:20,604 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:20,605 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:20,605 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,605 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,605 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,606 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,606 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:20,606 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:20,606 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:20,607 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:20,607 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:20,607 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:20,607 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:20,607 [IPC Server handler 0 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:20,607 [IPC Server handler 0 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:20,608 [IPC Server handler 0 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:20,608 [IPC Server handler 0 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:20,608 [IPC Server handler 0 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:20.614 [IPC Server handler 18 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:20,615 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:20,615 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:21,314 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1468691963_0001 running in uber mode : false
2019-09-25 05:49:21,317 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 05:49:22,788 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - e82d6518-db45-4664-aef7-ce30608e98c3:group-9BAAD5DC590B changes to CANDIDATE, lastRpcTime:5049, electionTimeout:5040ms
2019-09-25 05:49:22,791 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown FollowerState
2019-09-25 05:49:22,792 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:22,800 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderElection
2019-09-25 05:49:22,832 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1: begin an election at term 1 for -1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:22,835 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown LeaderElection
2019-09-25 05:49:22,835 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:22,836 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: change Leader from null to e82d6518-db45-4664-aef7-ce30608e98c3 at term 1 for becomeLeader, leader elected after 5342ms
2019-09-25 05:49:22,850 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:22,851 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:22,856 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:22,859 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:22,860 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:22,861 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:22,875 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderState
2019-09-25 05:49:22,905 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:22,915 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B: set configuration 0: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null at 0
2019-09-25 05:49:23,042 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(106)) - e1c44be8-c290-4a84-9591-5999c64dd189:group-6D8522E0AD8F changes to CANDIDATE, lastRpcTime:5093, electionTimeout:5092ms
2019-09-25 05:49:23,050 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown FollowerState
2019-09-25 05:49:23,050 [Thread-217] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,050 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderElection
2019-09-25 05:49:23,068 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2: begin an election at term 1 for -1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:23,068 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown LeaderElection
2019-09-25 05:49:23,068 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:23,068 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: change Leader from null to e1c44be8-c290-4a84-9591-5999c64dd189 at term 1 for becomeLeader, leader elected after 5138ms
2019-09-25 05:49:23,070 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:23,070 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:23,070 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:23,071 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:23,071 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:23,071 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:23,075 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderState
2019-09-25 05:49:23,075 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:23,076 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F: set configuration 0: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null at 0
2019-09-25 05:49:23,095 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:23,100 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:23,100 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:23,100 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:23,101 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:23,101 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:23,101 [IPC Server handler 11 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:23,101 [IPC Server handler 11 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:23,102 [IPC Server handler 11 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:23,103 [IPC Server handler 11 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:23,103 [IPC Server handler 11 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:23.123 [IPC Server handler 14 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:23,124 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:23,125 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:23,138 [e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-9BAAD5DC590B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/6e826d0c-5366-4cf5-a796-9baad5dc590b/current/log_inprogress_0
2019-09-25 05:49:23,138 [e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-6D8522E0AD8F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/216216d5-1a3c-480c-8ab3-6d8522e0ad8f/current/log_inprogress_0
2019-09-25 05:49:23,247 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(106)) - e82d6518-db45-4664-aef7-ce30608e98c3:group-66E77176A6ED changes to CANDIDATE, lastRpcTime:5154, electionTimeout:5154ms
2019-09-25 05:49:23,250 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown FollowerState
2019-09-25 05:49:23,250 [Thread-220] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,250 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderElection
2019-09-25 05:49:23,268 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3: begin an election at term 1 for -1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:23,270 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown LeaderElection
2019-09-25 05:49:23,270 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:23,270 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: change Leader from null to e82d6518-db45-4664-aef7-ce30608e98c3 at term 1 for becomeLeader, leader elected after 5211ms
2019-09-25 05:49:23,271 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:23,271 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:23,271 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:23,271 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:23,271 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:23,272 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:23,275 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderState
2019-09-25 05:49:23,276 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:23,276 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED: set configuration 0: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null at 0
2019-09-25 05:49:23,332 [e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-66E77176A6ED-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/c9a7c654-9ecd-47e8-b490-66e77176a6ed/current/log_inprogress_0
2019-09-25 05:49:23,399 [Thread-224] INFO  impl.FollowerState (FollowerState.java:run(106)) - 035834f9-24a4-45b4-a769-10efa83e6a02:group-84255A3F1626 changes to CANDIDATE, lastRpcTime:5199, electionTimeout:5199ms
2019-09-25 05:49:23,399 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown FollowerState
2019-09-25 05:49:23,399 [Thread-224] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,400 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderElection
2019-09-25 05:49:23,417 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4: begin an election at term 1 for -1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:23,417 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown LeaderElection
2019-09-25 05:49:23,417 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:23,417 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: change Leader from null to 035834f9-24a4-45b4-a769-10efa83e6a02 at term 1 for becomeLeader, leader elected after 5240ms
2019-09-25 05:49:23,419 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:23,420 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:23,420 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:23,420 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:23,420 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:23,420 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:23,425 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderState
2019-09-25 05:49:23,425 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:23,426 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626: set configuration 0: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null at 0
2019-09-25 05:49:23,479 [035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-84255A3F1626-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/c9cf1951-e243-47d7-b262-84255a3f1626/current/log_inprogress_0
2019-09-25 05:49:23,582 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 035834f9-24a4-45b4-a769-10efa83e6a02:group-361E396E7C71 changes to CANDIDATE, lastRpcTime:5008, electionTimeout:5008ms
2019-09-25 05:49:23,582 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown FollowerState
2019-09-25 05:49:23,582 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,583 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderElection
2019-09-25 05:49:23,599 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5: begin an election at term 1 for -1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:23,599 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown LeaderElection
2019-09-25 05:49:23,600 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:23,600 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: change Leader from null to 035834f9-24a4-45b4-a769-10efa83e6a02 at term 1 for becomeLeader, leader elected after 5040ms
2019-09-25 05:49:23,600 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:23,600 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:23,600 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:23,601 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:23,601 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:23,601 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:23,605 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderState
2019-09-25 05:49:23,606 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:23,606 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71: set configuration 0: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null at 0
2019-09-25 05:49:23,676 [035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-361E396E7C71-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/97524661-5984-4c10-b48a-361e396e7c71/current/log_inprogress_0
2019-09-25 05:49:23,741 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58:group-31134F79082F changes to CANDIDATE, lastRpcTime:5081, electionTimeout:5081ms
2019-09-25 05:49:23,741 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown FollowerState
2019-09-25 05:49:23,741 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,742 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderElection
2019-09-25 05:49:23,759 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6: begin an election at term 1 for -1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:23,760 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown LeaderElection
2019-09-25 05:49:23,760 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:23,760 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: change Leader from null to 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at term 1 for becomeLeader, leader elected after 5115ms
2019-09-25 05:49:23,762 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:23,762 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:23,762 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:23,763 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:23,763 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:23,763 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:23,767 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderState
2019-09-25 05:49:23,768 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:23,769 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F: set configuration 0: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null at 0
2019-09-25 05:49:23,809 [Thread-234] INFO  impl.FollowerState (FollowerState.java:run(106)) - e82d6518-db45-4664-aef7-ce30608e98c3:group-5F578A7CB528 changes to CANDIDATE, lastRpcTime:5053, electionTimeout:5037ms
2019-09-25 05:49:23,812 [Thread-234] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown FollowerState
2019-09-25 05:49:23,812 [Thread-234] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,812 [Thread-234] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderElection
2019-09-25 05:49:23,833 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-31134F79082F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/5bc0fc9b-63c5-409d-b227-31134f79082f/current/log_inprogress_0
2019-09-25 05:49:23,833 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7: begin an election at term 1 for -1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:23,834 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown LeaderElection
2019-09-25 05:49:23,834 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:23,834 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: change Leader from null to e82d6518-db45-4664-aef7-ce30608e98c3 at term 1 for becomeLeader, leader elected after 5087ms
2019-09-25 05:49:23,834 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:23,834 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:23,835 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:23,835 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:23,835 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:23,835 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:23,839 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderState
2019-09-25 05:49:23,840 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:23,840 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528: set configuration 0: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null at 0
2019-09-25 05:49:23,894 [e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-5F578A7CB528-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/f19a6a5d-e480-4f91-8475-5f578a7cb528/current/log_inprogress_0
2019-09-25 05:49:23,986 [Thread-240] INFO  impl.FollowerState (FollowerState.java:run(106)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58:group-5A13AF058694 changes to CANDIDATE, lastRpcTime:5141, electionTimeout:5138ms
2019-09-25 05:49:23,986 [Thread-240] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown FollowerState
2019-09-25 05:49:23,987 [Thread-240] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:23,987 [Thread-240] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderElection
2019-09-25 05:49:24,005 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8: begin an election at term 1 for -1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:24,005 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown LeaderElection
2019-09-25 05:49:24,006 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,006 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: change Leader from null to 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at term 1 for becomeLeader, leader elected after 5183ms
2019-09-25 05:49:24,006 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,006 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,006 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,007 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,007 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,007 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,010 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderState
2019-09-25 05:49:24,010 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,011 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694: set configuration 0: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null at 0
2019-09-25 05:49:24,065 [Thread-243] INFO  impl.FollowerState (FollowerState.java:run(106)) - 035834f9-24a4-45b4-a769-10efa83e6a02:group-DD5716897406 changes to CANDIDATE, lastRpcTime:5134, electionTimeout:5134ms
2019-09-25 05:49:24,066 [Thread-243] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown FollowerState
2019-09-25 05:49:24,066 [Thread-243] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,066 [Thread-243] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderElection
2019-09-25 05:49:24,073 [Thread-251] INFO  impl.FollowerState (FollowerState.java:run(106)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58:group-89792DDFDFC9 changes to CANDIDATE, lastRpcTime:5035, electionTimeout:5029ms
2019-09-25 05:49:24,073 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown FollowerState
2019-09-25 05:49:24,074 [Thread-251] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,074 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderElection
2019-09-25 05:49:24,079 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-5A13AF058694-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/052f1953-d056-49e7-9336-5a13af058694/current/log_inprogress_0
2019-09-25 05:49:24,096 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9: begin an election at term 1 for -1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:24,096 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10: begin an election at term 1 for -1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:24,097 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown LeaderElection
2019-09-25 05:49:24,097 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown LeaderElection
2019-09-25 05:49:24,097 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,097 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,097 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: change Leader from null to 035834f9-24a4-45b4-a769-10efa83e6a02 at term 1 for becomeLeader, leader elected after 5175ms
2019-09-25 05:49:24,097 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: change Leader from null to 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at term 1 for becomeLeader, leader elected after 5088ms
2019-09-25 05:49:24,097 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,097 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,098 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,098 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,098 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,098 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,098 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,098 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,098 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,099 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,099 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,099 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,102 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderState
2019-09-25 05:49:24,103 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,103 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderState
2019-09-25 05:49:24,103 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406: set configuration 0: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null at 0
2019-09-25 05:49:24,103 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,145 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9: set configuration 0: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null at 0
2019-09-25 05:49:24,182 [035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-DD5716897406-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/d8386dfd-33de-4fed-97b9-dd5716897406/current/log_inprogress_0
2019-09-25 05:49:24,206 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-89792DDFDFC9-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/330a0665-ce65-4700-8c1a-89792ddfdfc9/current/log_inprogress_0
2019-09-25 05:49:24,263 [Thread-270] INFO  impl.FollowerState (FollowerState.java:run(106)) - e82d6518-db45-4664-aef7-ce30608e98c3:group-C7549E606CE5 changes to CANDIDATE, lastRpcTime:5048, electionTimeout:5043ms
2019-09-25 05:49:24,264 [Thread-270] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown FollowerState
2019-09-25 05:49:24,264 [Thread-270] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,264 [Thread-270] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderElection
2019-09-25 05:49:24,269 [Thread-260] INFO  impl.FollowerState (FollowerState.java:run(106)) - 035834f9-24a4-45b4-a769-10efa83e6a02:group-243D13FE3DCF changes to CANDIDATE, lastRpcTime:5150, electionTimeout:5146ms
2019-09-25 05:49:24,270 [Thread-260] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown FollowerState
2019-09-25 05:49:24,270 [Thread-260] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,270 [Thread-260] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderElection
2019-09-25 05:49:24,294 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11: begin an election at term 1 for -1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:24,294 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12: begin an election at term 1 for -1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:24,294 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown LeaderElection
2019-09-25 05:49:24,294 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown LeaderElection
2019-09-25 05:49:24,294 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,294 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,294 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: change Leader from null to e82d6518-db45-4664-aef7-ce30608e98c3 at term 1 for becomeLeader, leader elected after 5088ms
2019-09-25 05:49:24,295 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: change Leader from null to 035834f9-24a4-45b4-a769-10efa83e6a02 at term 1 for becomeLeader, leader elected after 5195ms
2019-09-25 05:49:24,295 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,295 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,295 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,295 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,295 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,295 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,295 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,296 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,296 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,296 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,296 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,296 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,299 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderState
2019-09-25 05:49:24,300 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,300 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5: set configuration 0: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null at 0
2019-09-25 05:49:24,300 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderState
2019-09-25 05:49:24,337 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,338 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF: set configuration 0: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null at 0
2019-09-25 05:49:24,374 [e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-C7549E606CE5-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/769cf43f-80e7-4156-b146-c7549e606ce5/current/log_inprogress_0
2019-09-25 05:49:24,374 [Thread-279] INFO  impl.FollowerState (FollowerState.java:run(106)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58:group-4CB4AD9202B0 changes to CANDIDATE, lastRpcTime:5069, electionTimeout:5036ms
2019-09-25 05:49:24,374 [Thread-279] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown FollowerState
2019-09-25 05:49:24,374 [Thread-279] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,375 [Thread-279] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderElection
2019-09-25 05:49:24,379 [035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-243D13FE3DCF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/9d00cb4f-dbb1-4c0d-ba1b-243d13fe3dcf/current/log_inprogress_0
2019-09-25 05:49:24,394 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13: begin an election at term 1 for -1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:24,394 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown LeaderElection
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: change Leader from null to 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at term 1 for becomeLeader, leader elected after 5098ms
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,395 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,398 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderState
2019-09-25 05:49:24,398 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,398 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0: set configuration 0: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null at 0
2019-09-25 05:49:24,451 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4CB4AD9202B0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/0fdefd2b-c0e0-4110-a0f7-4cb4ad9202b0/current/log_inprogress_0
2019-09-25 05:49:24,529 [Thread-290] INFO  impl.FollowerState (FollowerState.java:run(106)) - e82d6518-db45-4664-aef7-ce30608e98c3:group-7E28FE559D98 changes to CANDIDATE, lastRpcTime:5075, electionTimeout:5075ms
2019-09-25 05:49:24,530 [Thread-290] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown FollowerState
2019-09-25 05:49:24,530 [Thread-290] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,531 [Thread-290] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderElection
2019-09-25 05:49:24,536 [Thread-282] INFO  impl.FollowerState (FollowerState.java:run(106)) - e1c44be8-c290-4a84-9591-5999c64dd189:group-A4F15421AD66 changes to CANDIDATE, lastRpcTime:5170, electionTimeout:5170ms
2019-09-25 05:49:24,536 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown FollowerState
2019-09-25 05:49:24,536 [Thread-282] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,536 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderElection
2019-09-25 05:49:24,562 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15: begin an election at term 1 for -1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:24,562 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14: begin an election at term 1 for -1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:24,562 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown LeaderElection
2019-09-25 05:49:24,562 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown LeaderElection
2019-09-25 05:49:24,563 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,563 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,563 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: change Leader from null to e1c44be8-c290-4a84-9591-5999c64dd189 at term 1 for becomeLeader, leader elected after 5206ms
2019-09-25 05:49:24,563 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: change Leader from null to e82d6518-db45-4664-aef7-ce30608e98c3 at term 1 for becomeLeader, leader elected after 5121ms
2019-09-25 05:49:24,563 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,563 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,564 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,564 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,564 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,564 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,564 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,565 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,565 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,565 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,565 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,565 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,570 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderState
2019-09-25 05:49:24,570 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderState
2019-09-25 05:49:24,570 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,571 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,571 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66: set configuration 0: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null at 0
2019-09-25 05:49:24,571 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98: set configuration 0: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null at 0
2019-09-25 05:49:24,627 [Thread-306] INFO  impl.FollowerState (FollowerState.java:run(106)) - e1c44be8-c290-4a84-9591-5999c64dd189:group-D0A1250C64B1 changes to CANDIDATE, lastRpcTime:5047, electionTimeout:5016ms
2019-09-25 05:49:24,627 [Thread-300] INFO  impl.FollowerState (FollowerState.java:run(106)) - e82d6518-db45-4664-aef7-ce30608e98c3:group-DF8321418F27 changes to CANDIDATE, lastRpcTime:5102, electionTimeout:5084ms
2019-09-25 05:49:24,629 [Thread-306] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown FollowerState
2019-09-25 05:49:24,630 [Thread-300] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown FollowerState
2019-09-25 05:49:24,630 [Thread-306] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,630 [Thread-300] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,630 [Thread-306] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderElection
2019-09-25 05:49:24,630 [Thread-300] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderElection
2019-09-25 05:49:24,640 [e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-A4F15421AD66-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/2001cd1e-3033-4a96-9bf3-a4f15421ad66/current/log_inprogress_0
2019-09-25 05:49:24,640 [e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-7E28FE559D98-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/1f0186ab-90fa-4fcf-b1f6-7e28fe559d98/current/log_inprogress_0
2019-09-25 05:49:24,665 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17: begin an election at term 1 for -1: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null
2019-09-25 05:49:24,665 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16: begin an election at term 1 for -1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:24,666 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e82d6518-db45-4664-aef7-ce30608e98c3: shutdown LeaderElection
2019-09-25 05:49:24,666 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown LeaderElection
2019-09-25 05:49:24,666 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,666 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,666 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: change Leader from null to e82d6518-db45-4664-aef7-ce30608e98c3 at term 1 for becomeLeader, leader elected after 5149ms
2019-09-25 05:49:24,666 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: change Leader from null to e1c44be8-c290-4a84-9591-5999c64dd189 at term 1 for becomeLeader, leader elected after 5093ms
2019-09-25 05:49:24,667 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,667 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,667 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,667 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,667 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,667 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,667 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,668 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,668 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,668 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,668 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,668 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,672 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e82d6518-db45-4664-aef7-ce30608e98c3: start LeaderState
2019-09-25 05:49:24,672 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,673 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderState
2019-09-25 05:49:24,673 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27: set configuration 0: [e82d6518-db45-4664-aef7-ce30608e98c3:192.168.5.161:46619], old=null at 0
2019-09-25 05:49:24,673 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,712 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1: set configuration 0: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null at 0
2019-09-25 05:49:24,753 [e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e82d6518-db45-4664-aef7-ce30608e98c3@group-DF8321418F27-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-0/data/ratis/bd67e41b-577c-4f63-9859-df8321418f27/current/log_inprogress_0
2019-09-25 05:49:24,766 [e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-D0A1250C64B1-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/268504ee-9fa1-44ba-8ccb-d0a1250c64b1/current/log_inprogress_0
2019-09-25 05:49:24,784 [Thread-314] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f:group-9116C338D4E6 changes to CANDIDATE, lastRpcTime:5144, electionTimeout:5144ms
2019-09-25 05:49:24,784 [Thread-314] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown FollowerState
2019-09-25 05:49:24,784 [Thread-314] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,785 [Thread-314] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderElection
2019-09-25 05:49:24,804 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18: begin an election at term 1 for -1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:24,804 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown LeaderElection
2019-09-25 05:49:24,805 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,805 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: change Leader from null to 8de7fa9b-0de9-4341-a74c-363f9809b22f at term 1 for becomeLeader, leader elected after 5174ms
2019-09-25 05:49:24,807 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,807 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,807 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,807 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,808 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,808 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,811 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderState
2019-09-25 05:49:24,812 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,812 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6: set configuration 0: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null at 0
2019-09-25 05:49:24,854 [Thread-323] INFO  impl.FollowerState (FollowerState.java:run(106)) - 035834f9-24a4-45b4-a769-10efa83e6a02:group-C373D29CFBA2 changes to CANDIDATE, lastRpcTime:5158, electionTimeout:5126ms
2019-09-25 05:49:24,854 [Thread-323] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown FollowerState
2019-09-25 05:49:24,855 [Thread-323] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,855 [Thread-323] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderElection
2019-09-25 05:49:24,878 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-9116C338D4E6-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/75ee619d-354e-40d4-bc77-9116c338d4e6/current/log_inprogress_0
2019-09-25 05:49:24,878 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19: begin an election at term 1 for -1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:24,879 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown LeaderElection
2019-09-25 05:49:24,879 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,879 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: change Leader from null to 035834f9-24a4-45b4-a769-10efa83e6a02 at term 1 for becomeLeader, leader elected after 5190ms
2019-09-25 05:49:24,879 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,879 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,879 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,880 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,880 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,880 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,883 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderState
2019-09-25 05:49:24,884 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,884 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2: set configuration 0: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null at 0
2019-09-25 05:49:24,929 [Thread-336] INFO  impl.FollowerState (FollowerState.java:run(106)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58:group-AE710C1E1782 changes to CANDIDATE, lastRpcTime:5159, electionTimeout:5132ms
2019-09-25 05:49:24,929 [Thread-336] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown FollowerState
2019-09-25 05:49:24,929 [Thread-336] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,929 [Thread-336] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderElection
2019-09-25 05:49:24,951 [035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-C373D29CFBA2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/3d122b05-4351-403f-a202-c373d29cfba2/current/log_inprogress_0
2019-09-25 05:49:24,954 [Thread-342] INFO  impl.FollowerState (FollowerState.java:run(106)) - 035834f9-24a4-45b4-a769-10efa83e6a02:group-4551CCD3A56E changes to CANDIDATE, lastRpcTime:5112, electionTimeout:5112ms
2019-09-25 05:49:24,954 [Thread-342] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown FollowerState
2019-09-25 05:49:24,954 [Thread-342] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:24,954 [Thread-342] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderElection
2019-09-25 05:49:24,965 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20: begin an election at term 1 for -1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:24,965 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21: begin an election at term 1 for -1: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null
2019-09-25 05:49:24,966 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown LeaderElection
2019-09-25 05:49:24,966 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 035834f9-24a4-45b4-a769-10efa83e6a02: shutdown LeaderElection
2019-09-25 05:49:24,966 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,966 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:24,966 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: change Leader from null to 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at term 1 for becomeLeader, leader elected after 5206ms
2019-09-25 05:49:24,966 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: change Leader from null to 035834f9-24a4-45b4-a769-10efa83e6a02 at term 1 for becomeLeader, leader elected after 5131ms
2019-09-25 05:49:24,966 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,967 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:24,967 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,967 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:24,967 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,967 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:24,967 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,967 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:24,968 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,968 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:24,968 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,968 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:24,972 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderState
2019-09-25 05:49:24,973 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,973 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 035834f9-24a4-45b4-a769-10efa83e6a02: start LeaderState
2019-09-25 05:49:24,973 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:24,973 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782: set configuration 0: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null at 0
2019-09-25 05:49:25,015 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E: set configuration 0: [035834f9-24a4-45b4-a769-10efa83e6a02:192.168.5.161:38201], old=null at 0
2019-09-25 05:49:25,053 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-AE710C1E1782-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/b6846886-bc94-4cfe-bca2-ae710c1e1782/current/log_inprogress_0
2019-09-25 05:49:25,066 [035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 035834f9-24a4-45b4-a769-10efa83e6a02@group-4551CCD3A56E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-3/data/ratis/6e5e7358-b51f-489f-a376-4551ccd3a56e/current/log_inprogress_0
2019-09-25 05:49:25,098 [Thread-345] INFO  impl.FollowerState (FollowerState.java:run(106)) - e1c44be8-c290-4a84-9591-5999c64dd189:group-2C99518DA95F changes to CANDIDATE, lastRpcTime:5027, electionTimeout:5027ms
2019-09-25 05:49:25,098 [Thread-345] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown FollowerState
2019-09-25 05:49:25,098 [Thread-345] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,098 [Thread-345] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderElection
2019-09-25 05:49:25,114 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22: begin an election at term 1 for -1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:25,115 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown LeaderElection
2019-09-25 05:49:25,115 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,115 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: change Leader from null to e1c44be8-c290-4a84-9591-5999c64dd189 at term 1 for becomeLeader, leader elected after 5199ms
2019-09-25 05:49:25,115 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,115 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,116 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,116 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,116 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,116 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,119 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderState
2019-09-25 05:49:25,120 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,120 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F: set configuration 0: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null at 0
2019-09-25 05:49:25,151 [Thread-352] INFO  impl.FollowerState (FollowerState.java:run(106)) - e1c44be8-c290-4a84-9591-5999c64dd189:group-10CFB719E01D changes to CANDIDATE, lastRpcTime:5023, electionTimeout:5015ms
2019-09-25 05:49:25,152 [Thread-352] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown FollowerState
2019-09-25 05:49:25,152 [Thread-352] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,152 [Thread-352] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderElection
2019-09-25 05:49:25,175 [e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-2C99518DA95F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/a36bd38d-6b67-46e6-99d2-2c99518da95f/current/log_inprogress_0
2019-09-25 05:49:25,175 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23: begin an election at term 1 for -1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:25,176 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown LeaderElection
2019-09-25 05:49:25,176 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,176 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: change Leader from null to e1c44be8-c290-4a84-9591-5999c64dd189 at term 1 for becomeLeader, leader elected after 5055ms
2019-09-25 05:49:25,176 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,176 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,176 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,177 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,177 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,177 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,180 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderState
2019-09-25 05:49:25,181 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,181 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D: set configuration 0: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null at 0
2019-09-25 05:49:25,218 [Thread-355] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f:group-083A5A6151B3 changes to CANDIDATE, lastRpcTime:5030, electionTimeout:5011ms
2019-09-25 05:49:25,219 [Thread-355] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown FollowerState
2019-09-25 05:49:25,219 [Thread-355] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,219 [Thread-355] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderElection
2019-09-25 05:49:25,243 [e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-10CFB719E01D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/cd550a4f-ae79-4ee2-a98e-10cfb719e01d/current/log_inprogress_0
2019-09-25 05:49:25,243 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24: begin an election at term 1 for -1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:25,243 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown LeaderElection
2019-09-25 05:49:25,244 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,244 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: change Leader from null to 8de7fa9b-0de9-4341-a74c-363f9809b22f at term 1 for becomeLeader, leader elected after 5063ms
2019-09-25 05:49:25,244 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,244 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,244 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,245 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,245 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,245 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,249 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderState
2019-09-25 05:49:25,249 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,250 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3: set configuration 0: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null at 0
2019-09-25 05:49:25,315 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-083A5A6151B3-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/1ceee3af-083b-4d40-8d26-083a5a6151b3/current/log_inprogress_0
2019-09-25 05:49:25,386 [Thread-369] INFO  impl.FollowerState (FollowerState.java:run(106)) - e1c44be8-c290-4a84-9591-5999c64dd189:group-66007F40F961 changes to CANDIDATE, lastRpcTime:5023, electionTimeout:5023ms
2019-09-25 05:49:25,387 [Thread-369] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown FollowerState
2019-09-25 05:49:25,387 [Thread-369] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,387 [Thread-369] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderElection
2019-09-25 05:49:25,403 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25: begin an election at term 1 for -1: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null
2019-09-25 05:49:25,403 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e1c44be8-c290-4a84-9591-5999c64dd189: shutdown LeaderElection
2019-09-25 05:49:25,403 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,404 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: change Leader from null to e1c44be8-c290-4a84-9591-5999c64dd189 at term 1 for becomeLeader, leader elected after 5049ms
2019-09-25 05:49:25,404 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,404 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,404 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,404 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,405 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,405 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,408 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e1c44be8-c290-4a84-9591-5999c64dd189: start LeaderState
2019-09-25 05:49:25,408 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,409 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961: set configuration 0: [e1c44be8-c290-4a84-9591-5999c64dd189:192.168.5.161:37616], old=null at 0
2019-09-25 05:49:25,440 [Thread-363] INFO  impl.FollowerState (FollowerState.java:run(106)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58:group-4DA3556BDC30 changes to CANDIDATE, lastRpcTime:5192, electionTimeout:5190ms
2019-09-25 05:49:25,440 [Thread-363] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown FollowerState
2019-09-25 05:49:25,440 [Thread-363] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,440 [Thread-363] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderElection
2019-09-25 05:49:25,453 [e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e1c44be8-c290-4a84-9591-5999c64dd189@group-66007F40F961-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-1/data/ratis/44d954fe-4c82-4900-8377-66007f40f961/current/log_inprogress_0
2019-09-25 05:49:25,453 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26: begin an election at term 1 for -1: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null
2019-09-25 05:49:25,453 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: shutdown LeaderElection
2019-09-25 05:49:25,454 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,454 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: change Leader from null to 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 at term 1 for becomeLeader, leader elected after 5214ms
2019-09-25 05:49:25,454 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,454 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,454 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,455 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,455 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,455 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,458 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58: start LeaderState
2019-09-25 05:49:25,458 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,458 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30: set configuration 0: [846429a6-4dd4-4152-b8dd-d8abbf5dfe58:192.168.5.161:35538], old=null at 0
2019-09-25 05:49:25,520 [846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 846429a6-4dd4-4152-b8dd-d8abbf5dfe58@group-4DA3556BDC30-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-2/data/ratis/acfdde39-6e4a-4236-b174-4da3556bdc30/current/log_inprogress_0
2019-09-25 05:49:25,547 [Thread-375] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f:group-D5FC006143C1 changes to CANDIDATE, lastRpcTime:5069, electionTimeout:5069ms
2019-09-25 05:49:25,547 [Thread-375] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown FollowerState
2019-09-25 05:49:25,548 [Thread-375] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,548 [Thread-375] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderElection
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27: begin an election at term 1 for -1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown LeaderElection
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: change Leader from null to 8de7fa9b-0de9-4341-a74c-363f9809b22f at term 1 for becomeLeader, leader elected after 5094ms
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,563 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,564 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,564 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,564 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,566 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderState
2019-09-25 05:49:25,567 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,567 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1: set configuration 0: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null at 0
2019-09-25 05:49:25,605 [Thread-372] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f:group-3E820A3EF2DE changes to CANDIDATE, lastRpcTime:5184, electionTimeout:5152ms
2019-09-25 05:49:25,605 [Thread-372] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown FollowerState
2019-09-25 05:49:25,606 [Thread-372] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,606 [Thread-372] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderElection
2019-09-25 05:49:25,630 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D5FC006143C1-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/a5f784e3-578e-45a1-8bee-d5fc006143c1/current/log_inprogress_0
2019-09-25 05:49:25,630 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28: begin an election at term 1 for -1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:25,630 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown LeaderElection
2019-09-25 05:49:25,630 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,630 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: change Leader from null to 8de7fa9b-0de9-4341-a74c-363f9809b22f at term 1 for becomeLeader, leader elected after 5221ms
2019-09-25 05:49:25,631 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,631 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,631 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,631 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,631 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,632 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,635 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderState
2019-09-25 05:49:25,635 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,636 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE: set configuration 0: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null at 0
2019-09-25 05:49:25,676 [Thread-383] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f:group-EAFADE5E7C06 changes to CANDIDATE, lastRpcTime:5145, electionTimeout:5115ms
2019-09-25 05:49:25,676 [Thread-383] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown FollowerState
2019-09-25 05:49:25,676 [Thread-383] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,677 [Thread-383] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderElection
2019-09-25 05:49:25,689 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-3E820A3EF2DE-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/ad132220-80c7-4160-b747-3e820a3ef2de/current/log_inprogress_0
2019-09-25 05:49:25,689 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29: begin an election at term 1 for -1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:25,690 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown LeaderElection
2019-09-25 05:49:25,690 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,690 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: change Leader from null to 8de7fa9b-0de9-4341-a74c-363f9809b22f at term 1 for becomeLeader, leader elected after 5165ms
2019-09-25 05:49:25,690 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,690 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,691 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,691 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,691 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,691 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,695 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderState
2019-09-25 05:49:25,695 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,696 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06: set configuration 0: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null at 0
2019-09-25 05:49:25,723 [Thread-388] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f:group-D21C52FD77BF changes to CANDIDATE, lastRpcTime:5133, electionTimeout:5130ms
2019-09-25 05:49:25,723 [Thread-388] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown FollowerState
2019-09-25 05:49:25,724 [Thread-388] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 05:49:25,724 [Thread-388] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderElection
2019-09-25 05:49:25,748 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-EAFADE5E7C06-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/d75cf51b-d15f-4357-a074-eafade5e7c06/current/log_inprogress_0
2019-09-25 05:49:25,748 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30: begin an election at term 1 for -1: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null
2019-09-25 05:49:25,748 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: shutdown LeaderElection
2019-09-25 05:49:25,748 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 05:49:25,748 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: change Leader from null to 8de7fa9b-0de9-4341-a74c-363f9809b22f at term 1 for becomeLeader, leader elected after 5166ms
2019-09-25 05:49:25,748 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 05:49:25,749 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 05:49:25,749 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 05:49:25,749 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 05:49:25,749 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 05:49:25,749 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 05:49:25,753 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f: start LeaderState
2019-09-25 05:49:25,753 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 05:49:25,753 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF: set configuration 0: [8de7fa9b-0de9-4341-a74c-363f9809b22f:192.168.5.161:39776], old=null at 0
2019-09-25 05:49:25,799 [8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8de7fa9b-0de9-4341-a74c-363f9809b22f@group-D21C52FD77BF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-e41a7d48-8936-4adc-ab5c-ecba2c667159/datanode-4/data/ratis/f419aca0-1ca2-4f99-beff-d21c52fd77bf/current/log_inprogress_0
2019-09-25 05:49:28,388 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:28,395 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:28,395 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:28,395 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:28,396 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:28,396 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:28,396 [IPC Server handler 0 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:28,396 [IPC Server handler 0 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:28,397 [IPC Server handler 0 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:28,398 [IPC Server handler 0 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:28,398 [IPC Server handler 0 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:28.401 [IPC Server handler 17 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:28,403 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000000_0
2019-09-25 05:49:28,403 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:28,404 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:28,411 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000001_0
2019-09-25 05:49:28,425 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:28,425 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:28,426 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:28,428 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:0+324
2019-09-25 05:49:28,428 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:28,429 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:49:28.447 [IPC Server handler 11 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:28,449 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
05:49:28.457 [IPC Server handler 10 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:28,475 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:28,486 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1468691963_0001_m_000001_0 is done. And is in the process of committing
2019-09-25 05:49:28,488 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:28,488 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1468691963_0001_m_000001_0 is allowed to commit now
2019-09-25 05:49:28,490 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1468691963_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/_logs
2019-09-25 05:49:28,491 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-25 05:49:28,491 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1468691963_0001_m_000001_0' done.
2019-09-25 05:49:28,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1468691963_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=208855
		FILE: Number of bytes written=822977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:28,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1468691963_0001_m_000001_0
2019-09-25 05:49:28,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:28,496 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:28,496 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:28,496 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:28,497 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:324+290
2019-09-25 05:49:28,498 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:28,498 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:28,516 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
05:49:28.523 [IPC Server handler 3 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:28,527 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:28,531 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:28,533 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:28,533 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:28,533 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:28,533 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:28,534 [IPC Server handler 11 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:28,534 [IPC Server handler 11 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:28,534 [IPC Server handler 11 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:28,535 [IPC Server handler 11 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:28,535 [IPC Server handler 11 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:28.540 [IPC Server handler 0 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:28,544 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:28,544 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:29,340 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 05:49:29,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:29,692 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:29,692 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:29,692 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:29,693 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:29,693 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:29,693 [IPC Server handler 1 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:29,694 [IPC Server handler 1 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:29,695 [IPC Server handler 1 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:29,695 [IPC Server handler 1 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:29,696 [IPC Server handler 1 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:29.701 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:29,705 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:29,705 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:31,948 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:31,955 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:31,955 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:31,956 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:31,956 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:31,956 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:31,957 [IPC Server handler 2 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:31,957 [IPC Server handler 2 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:31,958 [IPC Server handler 2 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:31,959 [IPC Server handler 2 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:31,959 [IPC Server handler 2 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:31.967 [IPC Server handler 15 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:31,969 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000002_0
2019-09-25 05:49:31,970 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:31,971 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:31,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000003_0
2019-09-25 05:49:31,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:31,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:31,976 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:31,980 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:614+278
2019-09-25 05:49:31,981 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:31,981 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:32,003 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
05:49:32.011 [IPC Server handler 16 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:32,019 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:32,020 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1468691963_0001_m_000003_0 is done. And is in the process of committing
2019-09-25 05:49:32,021 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:32,021 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1468691963_0001_m_000003_0 is allowed to commit now
2019-09-25 05:49:32,023 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1468691963_0001_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/_logs
2019-09-25 05:49:32,024 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 05:49:32,025 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1468691963_0001_m_000003_0' done.
2019-09-25 05:49:32,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1468691963_0001_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=218345
		FILE: Number of bytes written=822993
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=18
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:32,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1468691963_0001_m_000003_0
2019-09-25 05:49:32,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000004_0
2019-09-25 05:49:32,027 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:32,027 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:32,028 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:32,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:1948+278
2019-09-25 05:49:32,030 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:32,030 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:32,049 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
05:49:32.056 [IPC Server handler 10 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:32,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:32,063 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1468691963_0001_m_000004_0 is done. And is in the process of committing
2019-09-25 05:49:32,064 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:32,064 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1468691963_0001_m_000004_0 is allowed to commit now
2019-09-25 05:49:32,066 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1468691963_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/_logs
2019-09-25 05:49:32,066 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 05:49:32,067 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1468691963_0001_m_000004_0' done.
2019-09-25 05:49:32,067 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1468691963_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=222578
		FILE: Number of bytes written=823001
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=20
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:32,067 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1468691963_0001_m_000004_0
2019-09-25 05:49:32,067 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:32,068 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:32,068 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:32,069 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:32,070 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:1154+274
2019-09-25 05:49:32,071 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:32,071 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:32,087 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
05:49:32.094 [IPC Server handler 3 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:32,095 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:32,117 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:32,121 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:32,121 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:32,122 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:32,122 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:32,122 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:32,122 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:32,123 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:32,123 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:32,123 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:32.126 [IPC Server handler 0 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:32,128 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:32,128 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:32,499 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 05:49:33,344 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 35% reduce 0%
2019-09-25 05:49:34,431 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:34,437 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:34,437 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:34,437 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:34,438 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:34,438 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:34,438 [IPC Server handler 11 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:34,438 [IPC Server handler 11 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:34,439 [IPC Server handler 11 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:34,439 [IPC Server handler 11 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:34,439 [IPC Server handler 11 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:34.443 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:34,444 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:34,444 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:37,486 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:37,497 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:37,498 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:37,498 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:37,498 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:37,498 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:37,499 [IPC Server handler 1 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:37,499 [IPC Server handler 1 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:37,500 [IPC Server handler 1 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:37,500 [IPC Server handler 1 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:37,500 [IPC Server handler 1 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:37.516 [IPC Server handler 8 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:37,517 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000005_0
2019-09-25 05:49:37,518 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:37,518 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:37,519 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000006_0
2019-09-25 05:49:37,521 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,521 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,522 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:37,523 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:892+262
2019-09-25 05:49:37,524 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,524 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-25 05:49:37,556 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:37,557 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1468691963_0001_m_000006_0 is done. And is in the process of committing
2019-09-25 05:49:37,558 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:37,558 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1468691963_0001_m_000006_0 is allowed to commit now
2019-09-25 05:49:37,560 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1468691963_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/_logs
2019-09-25 05:49:37,561 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-25 05:49:37,561 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1468691963_0001_m_000006_0' done.
2019-09-25 05:49:37,562 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1468691963_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=231044
		FILE: Number of bytes written=823017
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=27
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:37,562 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1468691963_0001_m_000006_0
2019-09-25 05:49:37,562 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000007_0
2019-09-25 05:49:37,563 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,564 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,564 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:37,566 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:1428+262
2019-09-25 05:49:37,566 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,566 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,584 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
05:49:37.591 [IPC Server handler 13 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:37,597 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:37,597 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1468691963_0001_m_000007_0 is done. And is in the process of committing
2019-09-25 05:49:37,598 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:37,598 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1468691963_0001_m_000007_0 is allowed to commit now
2019-09-25 05:49:37,600 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1468691963_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/_logs
2019-09-25 05:49:37,601 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-25 05:49:37,601 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1468691963_0001_m_000007_0' done.
2019-09-25 05:49:37,602 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1468691963_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=234765
		FILE: Number of bytes written=823025
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=29
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:37,602 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1468691963_0001_m_000007_0
2019-09-25 05:49:37,602 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000008_0
2019-09-25 05:49:37,603 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,603 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,604 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:37,605 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:2226+262
2019-09-25 05:49:37,605 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,606 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,627 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-25 05:49:37,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:37,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1468691963_0001_m_000008_0 is done. And is in the process of committing
2019-09-25 05:49:37,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:37,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1468691963_0001_m_000008_0 is allowed to commit now
2019-09-25 05:49:37,643 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1468691963_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/_logs
2019-09-25 05:49:37,643 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-25 05:49:37,644 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1468691963_0001_m_000008_0' done.
2019-09-25 05:49:37,644 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1468691963_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=238486
		FILE: Number of bytes written=823033
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=31
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:37,644 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1468691963_0001_m_000008_0
2019-09-25 05:49:37,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:37,645 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,645 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:37,647 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283/fileList.seq:1690+258
2019-09-25 05:49:37,648 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:37,648 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:37,664 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
05:49:37.670 [IPC Server handler 10 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:37,671 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:37,675 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:37,677 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:37,678 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:37,678 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:37,678 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:37,679 [IPC Server handler 2 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:37,679 [IPC Server handler 2 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:37,679 [IPC Server handler 2 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:37,680 [IPC Server handler 2 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:37,680 [IPC Server handler 2 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:37.683 [IPC Server handler 19 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:37,685 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:37,685 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:38,348 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 05:49:38,502 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 05:49:39,349 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 65% reduce 0%
2019-09-25 05:49:40,036 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:40,041 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:40,041 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:40,041 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:40,042 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:40,042 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:40,042 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:40,043 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:40,043 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:40,044 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:40,044 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:40.047 [IPC Server handler 1 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:40,048 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:40,048 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:40,516 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 05:49:41,351 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 75% reduce 0%
2019-09-25 05:49:44,090 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-25 05:49:44,353 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 85% reduce 0%
2019-09-25 05:49:44,833 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:44,839 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:44,839 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:44,839 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:44,839 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:44,840 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:44,840 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:44,840 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:44,841 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:44,841 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:44,841 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:44.846 [IPC Server handler 1 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume14558, bucket=bucket05012, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume14558 bucket: bucket05012 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:44,848 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1468691963_0001_m_000009_0
2019-09-25 05:49:44,848 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:44,849 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 --> o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:44,850 [Thread-347] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 05:49:44,902 [Thread-347] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001151059971/.staging/_distcp-1922378283
2019-09-25 05:49:44,904 [Thread-347] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1468691963_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket05012.volume14558/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:45,355 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1468691963_0001 failed with state FAILED due to: NA
2019-09-25 05:49:45,429 [Thread-209] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=2080694
		FILE: Number of bytes written=7407169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=240
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=157
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Input split bytes=1431
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=18525192192
	File Input Format Counters 
		Bytes Read=28116
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
]]></system-err>
  </testcase>
  <testcase name="testTrackDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="19.753">
    <error message="DistCp failure: Job job_local1289640850_0002 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1289640850_0002 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testTrackDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 05:49:45,520 [Thread-486] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 05:49:45,561 [Thread-486] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume29389, with user72955 as owner.
2019-09-25 05:49:45,564 [IPC Server handler 3 on 33070] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume29389 for user:user72955
2019-09-25 05:49:45,569 [Thread-486] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume29389/bucket96430, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 05:49:45,635 [Thread-486] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket96430.volume29389 implemented by OzoneFileSystem{URI=o3fs://bucket96430.volume29389, workingDir=o3fs://bucket96430.volume29389/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 43 read ops, 0 large read ops, 26 write ops}
05:49:45.659 [IPC Server handler 16 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:45,664 [Thread-486] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-25 05:49:45,758 [Thread-486] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:49:45,769 [Thread-486] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
05:49:45.784 [IPC Server handler 11 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:45,861 [Thread-486] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 05:49:45,862 [Thread-486] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 05:49:45,875 [Thread-486] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 05:49:45,888 [Thread-486] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 05:49:45,890 [Thread-486] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:49:45,900 [Thread-486] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 05:49:45,955 [Thread-486] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-25 05:49:46,003 [Thread-486] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1289640850_0002
2019-09-25 05:49:46,003 [Thread-486] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 05:49:46,116 [Thread-486] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 05:49:46,119 [Thread-550] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 05:49:46,119 [Thread-486] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1289640850_0002
2019-09-25 05:49:46,120 [Thread-550] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:46,120 [Thread-486] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1289640850_0002
2019-09-25 05:49:46,120 [Thread-550] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:46,121 [Thread-550] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 05:49:46,149 [Thread-550] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 05:49:46,149 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:46,150 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:46,151 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:46,151 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:46,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:584+835
2019-09-25 05:49:46,157 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:46,157 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:49:46.178 [IPC Server handler 10 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:46,180 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
05:49:46.189 [IPC Server handler 18 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:46,190 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:46,195 [IPC Server handler 12 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:46,196 [IPC Server handler 12 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:46,196 [IPC Server handler 12 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:46,196 [IPC Server handler 12 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:46,196 [IPC Server handler 12 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:46,197 [IPC Server handler 12 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:46,197 [IPC Server handler 12 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:46,197 [IPC Server handler 12 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:46,198 [IPC Server handler 12 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:46,198 [IPC Server handler 12 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:46.201 [IPC Server handler 3 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:46,202 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:46,203 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:47,120 [Thread-486] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1289640850_0002 running in uber mode : false
2019-09-25 05:49:47,121 [Thread-486] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 05:49:47,254 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:47,258 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:47,258 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:47,259 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:47,259 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:47,259 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:47,259 [IPC Server handler 0 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:47,260 [IPC Server handler 0 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:47,260 [IPC Server handler 0 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:47,261 [IPC Server handler 0 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:47,261 [IPC Server handler 0 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:47.264 [IPC Server handler 0 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:47,266 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:47,266 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:49,656 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-25 05:49:52,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:52,637 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:52,637 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:52,638 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:52,638 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:52,638 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:52,638 [IPC Server handler 2 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:52,639 [IPC Server handler 2 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:52,639 [IPC Server handler 2 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:52,640 [IPC Server handler 2 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:52,640 [IPC Server handler 2 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:52.644 [IPC Server handler 6 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:52,646 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000000_0
2019-09-25 05:49:52,646 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:52,647 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:52,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000001_0
2019-09-25 05:49:52,650 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:52,650 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:52,650 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:52,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:0+323
2019-09-25 05:49:52,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:52,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:49:52.679 [IPC Server handler 11 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:52,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
05:49:52.688 [IPC Server handler 10 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:52,695 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:52,696 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1289640850_0002_m_000001_0 is done. And is in the process of committing
2019-09-25 05:49:52,697 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:52,697 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1289640850_0002_m_000001_0 is allowed to commit now
2019-09-25 05:49:52,699 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1289640850_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/_logs
2019-09-25 05:49:52,700 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-25 05:49:52,700 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1289640850_0002_m_000001_0' done.
2019-09-25 05:49:52,700 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1289640850_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=450652
		FILE: Number of bytes written=1645809
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=54
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:52,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1289640850_0002_m_000001_0
2019-09-25 05:49:52,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:52,702 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:52,702 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:52,703 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:52,704 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:2768+289
2019-09-25 05:49:52,704 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:52,704 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:52,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
05:49:52.730 [IPC Server handler 3 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:52,732 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:52,743 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:52,746 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:52,746 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:52,747 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:52,747 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:52,747 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:52,747 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:52,758 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:52,759 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:52,759 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:52.762 [IPC Server handler 0 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:52,763 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:52,763 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:53,125 [Thread-486] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 05:49:55,657 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-25 05:49:55,692 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:55,699 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:55,699 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:55,700 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:55,700 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:55,700 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:55,700 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:55,701 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:55,701 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:55,702 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:55,702 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:55.706 [IPC Server handler 3 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:55,707 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:55,707 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:58,169 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 05:49:58,411 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:58,416 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:58,416 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:58,417 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:58,417 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:58,417 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:58,418 [IPC Server handler 11 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:58,418 [IPC Server handler 11 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:58,418 [IPC Server handler 11 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:58,419 [IPC Server handler 11 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:58,419 [IPC Server handler 11 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:58.422 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:58,424 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000002_0
2019-09-25 05:49:58,424 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:49:58,425 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:49:58,426 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000003_0
2019-09-25 05:49:58,427 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:58,427 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:58,428 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:58,430 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:2214+277
2019-09-25 05:49:58,431 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:58,431 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:58,450 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
05:49:58.457 [IPC Server handler 7 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:58,464 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:58,464 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1289640850_0002_m_000003_0 is done. And is in the process of committing
2019-09-25 05:49:58,465 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:58,465 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1289640850_0002_m_000003_0 is allowed to commit now
2019-09-25 05:49:58,466 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1289640850_0002_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/_logs
2019-09-25 05:49:58,467 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 05:49:58,467 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1289640850_0002_m_000003_0' done.
2019-09-25 05:49:58,467 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1289640850_0002_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=459794
		FILE: Number of bytes written=1645825
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=61
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:58,468 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1289640850_0002_m_000003_0
2019-09-25 05:49:58,468 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000004_0
2019-09-25 05:49:58,469 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:58,469 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:58,469 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:58,470 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:2491+277
2019-09-25 05:49:58,471 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:58,471 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:58,488 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
05:49:58.494 [IPC Server handler 5 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:58,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:58,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1289640850_0002_m_000004_0 is done. And is in the process of committing
2019-09-25 05:49:58,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:49:58,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1289640850_0002_m_000004_0 is allowed to commit now
2019-09-25 05:49:58,503 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1289640850_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/_logs
2019-09-25 05:49:58,503 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 05:49:58,503 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1289640850_0002_m_000004_0' done.
2019-09-25 05:49:58,504 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1289640850_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=463853
		FILE: Number of bytes written=1645833
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=63
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:49:58,504 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1289640850_0002_m_000004_0
2019-09-25 05:49:58,504 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000005_0
2019-09-25 05:49:58,505 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:58,505 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:58,506 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:49:58,507 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:1941+273
2019-09-25 05:49:58,508 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:49:58,508 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:49:58,524 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
05:49:58.531 [IPC Server handler 13 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:58,532 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
2019-09-25 05:49:58,535 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:49:58,539 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:49:58,539 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:49:58,539 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:49:58,540 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:49:58,540 [IPC Server handler 2 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:49:58,540 [IPC Server handler 2 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:58,541 [IPC Server handler 2 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:49:58,542 [IPC Server handler 2 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:49:58,542 [IPC Server handler 2 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:49:58.544 [IPC Server handler 16 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:49:58,546 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
2019-09-25 05:49:58,546 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:01,158 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
2019-09-25 05:50:01,161 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:01,162 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:01,162 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:01,162 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:01,162 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:01,163 [IPC Server handler 6 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:01,163 [IPC Server handler 6 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:01,164 [IPC Server handler 6 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:01,164 [IPC Server handler 6 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:01,164 [IPC Server handler 6 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:01.167 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:01,168 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
2019-09-25 05:50:01,168 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:04,172 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 05:50:04,664 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
2019-09-25 05:50:04,668 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:04,668 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:04,669 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:04,669 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:04,669 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:04,669 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:04,670 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:04,670 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:04,671 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:04,671 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:04.674 [IPC Server handler 11 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:04,676 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1289640850_0002_m_000005_0
2019-09-25 05:50:04,676 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:04,677 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:04,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000006_0
2019-09-25 05:50:04,680 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:04,680 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:04,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:04,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:323+261
2019-09-25 05:50:04,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:04,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:04,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 05:50:04,722 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
05:50:04.723 [IPC Server handler 1 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29389, bucket=bucket96430, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29389 bucket: bucket96430 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:04,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:04,732 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1289640850_0002_m_000006_0 is done. And is in the process of committing
2019-09-25 05:50:04,733 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:04,733 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1289640850_0002_m_000006_0 is allowed to commit now
2019-09-25 05:50:04,736 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1289640850_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/_logs
2019-09-25 05:50:04,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 05:50:04,737 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1289640850_0002_m_000006_0' done.
2019-09-25 05:50:04,737 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1289640850_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=471971
		FILE: Number of bytes written=1645849
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=70
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:04,737 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1289640850_0002_m_000006_0
2019-09-25 05:50:04,738 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000007_0
2019-09-25 05:50:04,739 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:04,739 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:04,739 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:04,741 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:1419+261
2019-09-25 05:50:04,741 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:04,741 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:04,760 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 05:50:04,772 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:04,772 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1289640850_0002_m_000007_0 is done. And is in the process of committing
2019-09-25 05:50:04,773 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:04,773 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1289640850_0002_m_000007_0 is allowed to commit now
2019-09-25 05:50:04,775 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1289640850_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/_logs
2019-09-25 05:50:04,776 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 05:50:04,776 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1289640850_0002_m_000007_0' done.
2019-09-25 05:50:04,776 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1289640850_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=475518
		FILE: Number of bytes written=1645857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=72
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:04,776 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1289640850_0002_m_000007_0
2019-09-25 05:50:04,777 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1289640850_0002_m_000008_0
2019-09-25 05:50:04,777 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:04,777 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:04,778 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:04,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/fileList.seq:1680+261
2019-09-25 05:50:04,780 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:04,780 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:04,796 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 05:50:04,807 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:04,807 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1289640850_0002_m_000008_0 is done. And is in the process of committing
2019-09-25 05:50:04,809 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:04,809 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1289640850_0002_m_000008_0 is allowed to commit now
2019-09-25 05:50:04,810 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1289640850_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368/_logs
2019-09-25 05:50:04,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 05:50:04,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1289640850_0002_m_000008_0' done.
2019-09-25 05:50:04,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1289640850_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=479065
		FILE: Number of bytes written=1645865
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=74
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:04,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1289640850_0002_m_000008_0
2019-09-25 05:50:04,812 [Thread-550] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 05:50:04,830 [Thread-550] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001687970883/.staging/_distcp-1682656368
2019-09-25 05:50:04,836 [Thread-550] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1289640850_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket96430.volume29389/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:05,133 [Thread-486] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1289640850_0002 failed with state FAILED due to: NA
2019-09-25 05:50:05,201 [Thread-486] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=3740736
		FILE: Number of bytes written=13166728
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=530
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=334
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1272
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16466837504
	File Input Format Counters 
		Bytes Read=24904
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
  </testcase>
  <testcase name="largeFilesToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="14.82">
    <error message="DistCp failure: Job job_local1599339980_0003 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1599339980_0003 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:534)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFilesToRemote(AbstractContractDistCpTest.java:452)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 05:50:05,274 [Thread-594] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 05:50:05,309 [Thread-594] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume00653, with user97520 as owner.
2019-09-25 05:50:05,311 [IPC Server handler 9 on 33070] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume00653 for user:user97520
2019-09-25 05:50:05,318 [Thread-594] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume00653/bucket05194, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 05:50:05,378 [Thread-594] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket05194.volume00653 implemented by OzoneFileSystem{URI=o3fs://bucket05194.volume00653, workingDir=o3fs://bucket05194.volume00653/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 81 read ops, 0 large read ops, 46 write ops}
05:50:05.402 [IPC Server handler 1 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:05,405 [Thread-594] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-25 05:50:05,414 [Thread-594] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-25 05:50:05,544 [Thread-594] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:50:05,554 [Thread-594] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
05:50:05.565 [IPC Server handler 4 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:05,607 [Thread-594] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-25 05:50:05,608 [Thread-594] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 05:50:05,619 [Thread-594] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-25 05:50:05,629 [Thread-594] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-25 05:50:05,630 [Thread-594] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:50:05,639 [Thread-594] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 05:50:05,689 [Thread-594] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-25 05:50:05,874 [Thread-594] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1599339980_0003
2019-09-25 05:50:05,881 [Thread-594] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 05:50:06,025 [Thread-594] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 05:50:06,026 [Thread-594] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1599339980_0003
2019-09-25 05:50:06,028 [Thread-642] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 05:50:06,028 [Thread-594] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1599339980_0003
2019-09-25 05:50:06,029 [Thread-642] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:06,029 [Thread-642] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:06,029 [Thread-642] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 05:50:06,060 [Thread-642] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 05:50:06,060 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:06,062 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:06,062 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:06,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:06,064 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000486259652/.staging/_distcp1634172169/fileList.seq:0+771
2019-09-25 05:50:06,064 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:06,064 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:50:06.085 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:06,087 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
05:50:06.094 [IPC Server handler 8 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:06,098 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
05:50:06.104 [IPC Server handler 9 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:06,106 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:06,109 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:06,109 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:06,110 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:06,110 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:06,110 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:06,110 [IPC Server handler 6 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:06,111 [IPC Server handler 6 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:06,111 [IPC Server handler 6 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:06,111 [IPC Server handler 6 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:06,112 [IPC Server handler 6 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:06.114 [IPC Server handler 5 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:06,115 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:06,115 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:07,029 [Thread-594] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1599339980_0003 running in uber mode : false
2019-09-25 05:50:07,030 [Thread-594] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 05:50:08,356 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:08,359 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:08,360 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:08,360 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:08,360 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:08,360 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:08,361 [IPC Server handler 11 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:08,361 [IPC Server handler 11 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:08,361 [IPC Server handler 11 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:08,362 [IPC Server handler 11 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:08,362 [IPC Server handler 11 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:08.364 [IPC Server handler 13 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:08,366 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:08,366 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:10,516 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-25 05:50:11,741 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:11,745 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:11,745 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:11,746 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:11,746 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:11,746 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:11,746 [IPC Server handler 6 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:11,746 [IPC Server handler 6 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:11,747 [IPC Server handler 6 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:11,747 [IPC Server handler 6 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:11,748 [IPC Server handler 6 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:11.751 [IPC Server handler 8 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:11,752 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000000_0
2019-09-25 05:50:11,752 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:11,754 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:11,755 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:11,756 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:11,756 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:11,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:11,758 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000486259652/.staging/_distcp1634172169/fileList.seq:771+235
2019-09-25 05:50:11,758 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:11,759 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:11,778 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
05:50:11.786 [IPC Server handler 9 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:11,787 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:11,790 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:11,791 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:11,791 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:11,791 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:11,791 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:11,792 [IPC Server handler 8 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:11,792 [IPC Server handler 8 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:11,792 [IPC Server handler 8 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:11,793 [IPC Server handler 8 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:11,793 [IPC Server handler 8 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:11.795 [IPC Server handler 5 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:11,796 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:11,797 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:13,752 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:13,756 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:13,756 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:13,757 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:13,757 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:13,757 [IPC Server handler 8 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:13,757 [IPC Server handler 8 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:13,757 [IPC Server handler 8 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:13,758 [IPC Server handler 8 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:13,758 [IPC Server handler 8 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:13,758 [IPC Server handler 8 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:13.761 [IPC Server handler 9 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:13,763 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:13,763 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:16,517 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-25 05:50:18,071 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-25 05:50:19,036 [Thread-594] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 33% reduce 0%
2019-09-25 05:50:19,693 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:19,699 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:19,700 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:19,700 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:19,700 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:19,700 [IPC Server handler 6 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:19,701 [IPC Server handler 6 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:19,701 [IPC Server handler 6 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:19,701 [IPC Server handler 6 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:19,702 [IPC Server handler 6 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:19,702 [IPC Server handler 6 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:19.706 [IPC Server handler 8 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume00653, bucket=bucket05194, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume00653 bucket: bucket05194 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:19,707 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1599339980_0003_m_000001_0
2019-09-25 05:50:19,707 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:19,708 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:19,723 [Thread-642] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 05:50:19,740 [Thread-642] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000486259652/.staging/_distcp1634172169
2019-09-25 05:50:19,741 [Thread-642] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1599339980_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket05194.volume00653/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:20,039 [Thread-594] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1599339980_0003 failed with state FAILED due to: NA
2019-09-25 05:50:20,041 [Thread-594] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=671021
		FILE: Number of bytes written=11970821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=95
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=1046
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
]]></system-out>
  </testcase>
  <testcase name="testLargeFilesFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.184">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:528)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testLargeFilesFromRemote(AbstractContractDistCpTest.java:464)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 05:50:20,087 [Thread-665] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 05:50:20,121 [Thread-665] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume83374, with user87002 as owner.
2019-09-25 05:50:20,125 [IPC Server handler 19 on 33070] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume83374 for user:user87002
2019-09-25 05:50:20,129 [Thread-665] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume83374/bucket57448, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 05:50:20,188 [Thread-665] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket57448.volume83374 implemented by OzoneFileSystem{URI=o3fs://bucket57448.volume83374, workingDir=o3fs://bucket57448.volume83374/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 103 read ops, 0 large read ops, 60 write ops}
05:50:20.207 [IPC Server handler 14 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume83374, bucket=bucket57448, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume83374 bucket: bucket57448 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:20,210 [Thread-665] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-25 05:50:20,213 [Thread-665] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-25 05:50:20,230 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:20,231 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:20,231 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:20,231 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:20,231 [IPC Server handler 0 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:20,231 [IPC Server handler 0 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:20,231 [IPC Server handler 0 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:20,232 [IPC Server handler 0 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:20,232 [IPC Server handler 0 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:20,232 [IPC Server handler 0 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
]]></system-out>
  </testcase>
  <testcase name="testUpdateDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="19.613">
    <error message="DistCp failure: Job job_local1393590398_0004 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1393590398_0004 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 05:50:20,285 [Thread-670] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume35199, with user81301 as owner.
2019-09-25 05:50:20,286 [IPC Server handler 7 on 33070] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume35199 for user:user81301
2019-09-25 05:50:20,288 [Thread-670] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume35199/bucket27080, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 05:50:20,333 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket27080.volume35199 implemented by OzoneFileSystem{URI=o3fs://bucket27080.volume35199, workingDir=o3fs://bucket27080.volume35199/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 109 read ops, 0 large read ops, 63 write ops}
05:50:20.354 [IPC Server handler 3 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:20,358 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-25 05:50:20,438 [Thread-670] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:50:20,447 [Thread-670] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
05:50:20.458 [IPC Server handler 0 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:20,527 [Thread-670] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 05:50:20,530 [Thread-670] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 05:50:20,546 [Thread-670] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 05:50:20,560 [Thread-670] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 05:50:20,563 [Thread-670] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 05:50:20,577 [Thread-670] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 05:50:20,641 [Thread-670] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-25 05:50:20,688 [Thread-670] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1393590398_0004
2019-09-25 05:50:20,688 [Thread-670] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 05:50:20,804 [Thread-670] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 05:50:20,809 [Thread-733] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 05:50:20,809 [Thread-670] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1393590398_0004
2019-09-25 05:50:20,809 [Thread-733] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:20,809 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1393590398_0004
2019-09-25 05:50:20,809 [Thread-733] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:20,810 [Thread-733] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 05:50:20,837 [Thread-733] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 05:50:20,837 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:20,838 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:20,839 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:20,839 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:20,841 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:2488+580
2019-09-25 05:50:20,842 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:20,842 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:50:20.867 [IPC Server handler 4 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:20,868 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
05:50:20.874 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:20,876 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:20,879 [IPC Server handler 5 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:20,879 [IPC Server handler 5 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:20,879 [IPC Server handler 5 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:20,879 [IPC Server handler 5 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:20,879 [IPC Server handler 5 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:20,880 [IPC Server handler 5 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:20,880 [IPC Server handler 5 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:20,880 [IPC Server handler 5 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:20,881 [IPC Server handler 5 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:20,881 [IPC Server handler 5 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:20.883 [IPC Server handler 7 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:20,884 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:20,884 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:21,810 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1393590398_0004 running in uber mode : false
2019-09-25 05:50:21,810 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 05:50:22,558 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:22,563 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:22,564 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:22,564 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:22,565 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:22,565 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:22,565 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:22,565 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:22,566 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:22,566 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:22,566 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:22.570 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:22,571 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:22,571 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:23,767 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-25 05:50:27,398 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:27,401 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:27,402 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:27,402 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:27,402 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:27,402 [IPC Server handler 1 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:27,403 [IPC Server handler 1 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:27,403 [IPC Server handler 1 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:27,403 [IPC Server handler 1 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:27,404 [IPC Server handler 1 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:27,404 [IPC Server handler 1 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:27.407 [IPC Server handler 4 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:27,408 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000000_0
2019-09-25 05:50:27,408 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:27,409 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:27,410 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:27,411 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:27,411 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:27,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:27,413 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:324+548
2019-09-25 05:50:27,413 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:27,414 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:50:27.430 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:27,431 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
05:50:27.438 [IPC Server handler 8 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:27,439 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:27,442 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:27,442 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:27,442 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:27,443 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:27,443 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:27,443 [IPC Server handler 2 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:27,444 [IPC Server handler 2 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:27,444 [IPC Server handler 2 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:27,444 [IPC Server handler 2 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:27,445 [IPC Server handler 2 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:27.447 [IPC Server handler 9 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:27,448 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:27,448 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:29,276 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:29,281 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:29,281 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:29,281 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:29,281 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:29,282 [IPC Server handler 11 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:29,282 [IPC Server handler 11 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:29,282 [IPC Server handler 11 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:29,283 [IPC Server handler 11 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:29,283 [IPC Server handler 11 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:29,283 [IPC Server handler 11 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:29.286 [IPC Server handler 5 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:29,288 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:29,288 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:29,768 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-25 05:50:31,403 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:31,409 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:31,409 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:31,410 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:31,410 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:31,410 [IPC Server handler 2 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:31,410 [IPC Server handler 2 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:31,411 [IPC Server handler 2 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:31,411 [IPC Server handler 2 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:31,412 [IPC Server handler 2 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:31,412 [IPC Server handler 2 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:31.417 [IPC Server handler 2 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,419 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000001_0
2019-09-25 05:50:31,419 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:31,420 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:31,421 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000002_0
2019-09-25 05:50:31,422 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,422 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,423 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:31,424 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:0+324
2019-09-25 05:50:31,425 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,425 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
05:50:31.443 [IPC Server handler 7 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,444 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
05:50:31.452 [IPC Server handler 6 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,457 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:31,458 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1393590398_0004_m_000002_0 is done. And is in the process of committing
2019-09-25 05:50:31,459 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:31,459 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1393590398_0004_m_000002_0 is allowed to commit now
2019-09-25 05:50:31,460 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1393590398_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/_logs
2019-09-25 05:50:31,461 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-25 05:50:31,461 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1393590398_0004_m_000002_0' done.
2019-09-25 05:50:31,462 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1393590398_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=884071
		FILE: Number of bytes written=12793604
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=125
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:31,462 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1393590398_0004_m_000002_0
2019-09-25 05:50:31,462 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000003_0
2019-09-25 05:50:31,463 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,463 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,463 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:31,464 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:872+278
2019-09-25 05:50:31,465 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,465 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,482 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
05:50:31.489 [IPC Server handler 15 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:31,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1393590398_0004_m_000003_0 is done. And is in the process of committing
2019-09-25 05:50:31,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:31,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1393590398_0004_m_000003_0 is allowed to commit now
2019-09-25 05:50:31,497 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1393590398_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/_logs
2019-09-25 05:50:31,497 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 05:50:31,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1393590398_0004_m_000003_0' done.
2019-09-25 05:50:31,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1393590398_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=888635
		FILE: Number of bytes written=12793612
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=127
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:31,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1393590398_0004_m_000003_0
2019-09-25 05:50:31,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000004_0
2019-09-25 05:50:31,499 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,499 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:31,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:1150+278
2019-09-25 05:50:31,501 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,501 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,519 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
05:50:31.525 [IPC Server handler 16 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,530 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:31,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1393590398_0004_m_000004_0 is done. And is in the process of committing
2019-09-25 05:50:31,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:31,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1393590398_0004_m_000004_0 is allowed to commit now
2019-09-25 05:50:31,533 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1393590398_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/_logs
2019-09-25 05:50:31,533 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 05:50:31,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1393590398_0004_m_000004_0' done.
2019-09-25 05:50:31,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1393590398_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=892687
		FILE: Number of bytes written=12793620
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=129
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:31,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1393590398_0004_m_000004_0
2019-09-25 05:50:31,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:31,535 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,535 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,536 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:31,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:1952+274
2019-09-25 05:50:31,537 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:31,537 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:31,554 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
05:50:31.560 [IPC Server handler 10 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,561 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:31,567 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:31,573 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:31,574 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:31,574 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:31,574 [IPC Server handler 4 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:31,575 [IPC Server handler 4 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:31,575 [IPC Server handler 4 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:31,576 [IPC Server handler 4 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:31,576 [IPC Server handler 4 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:31,577 [IPC Server handler 4 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:31.582 [IPC Server handler 19 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:31,583 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:31,584 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:31,819 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 05:50:32,863 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 05:50:33,820 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 39% reduce 0%
2019-09-25 05:50:34,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:34,191 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:34,192 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:34,192 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:34,192 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:34,192 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:34,192 [IPC Server handler 15 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:34,193 [IPC Server handler 15 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:34,193 [IPC Server handler 15 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:34,193 [IPC Server handler 15 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:34,193 [IPC Server handler 15 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:34.196 [IPC Server handler 1 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:34,197 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:34,197 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:38,866 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 05:50:39,213 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:39,218 [IPC Server handler 17 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:39,218 [IPC Server handler 17 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:39,218 [IPC Server handler 17 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:39,218 [IPC Server handler 17 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:39,219 [IPC Server handler 17 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:39,219 [IPC Server handler 17 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:39,219 [IPC Server handler 17 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:39,220 [IPC Server handler 17 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:39,220 [IPC Server handler 17 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:39,221 [IPC Server handler 17 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
05:50:39.224 [IPC Server handler 4 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:39,225 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1393590398_0004_m_000005_0
2019-09-25 05:50:39,225 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 05:50:39,226 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:39,227 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000006_0
2019-09-25 05:50:39,229 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:39,229 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:39,230 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:39,231 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:1428+262
2019-09-25 05:50:39,231 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:39,231 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:39,247 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 05:50:39,257 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:39,258 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1393590398_0004_m_000006_0 is done. And is in the process of committing
2019-09-25 05:50:39,258 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:39,258 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1393590398_0004_m_000006_0 is allowed to commit now
2019-09-25 05:50:39,259 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1393590398_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/_logs
2019-09-25 05:50:39,260 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 05:50:39,260 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1393590398_0004_m_000006_0' done.
2019-09-25 05:50:39,261 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1393590398_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=900791
		FILE: Number of bytes written=12793636
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=136
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:39,261 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1393590398_0004_m_000006_0
2019-09-25 05:50:39,261 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000007_0
2019-09-25 05:50:39,262 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:39,262 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:39,262 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:39,263 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:1690+262
2019-09-25 05:50:39,263 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:39,264 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:39,277 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
05:50:39.282 [IPC Server handler 6 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume35199, bucket=bucket27080, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume35199 bucket: bucket27080 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:39,285 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:39,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1393590398_0004_m_000007_0 is done. And is in the process of committing
2019-09-25 05:50:39,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:39,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1393590398_0004_m_000007_0 is allowed to commit now
2019-09-25 05:50:39,287 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1393590398_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/_logs
2019-09-25 05:50:39,288 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 05:50:39,288 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1393590398_0004_m_000007_0' done.
2019-09-25 05:50:39,288 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1393590398_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=904331
		FILE: Number of bytes written=12793644
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=138
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:39,288 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1393590398_0004_m_000007_0
2019-09-25 05:50:39,289 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1393590398_0004_m_000008_0
2019-09-25 05:50:39,289 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:39,289 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:39,290 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 05:50:39,290 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/fileList.seq:2226+262
2019-09-25 05:50:39,291 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 05:50:39,291 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 05:50:39,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 05:50:39,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:39,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1393590398_0004_m_000008_0 is done. And is in the process of committing
2019-09-25 05:50:39,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 05:50:39,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1393590398_0004_m_000008_0 is allowed to commit now
2019-09-25 05:50:39,313 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1393590398_0004_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469/_logs
2019-09-25 05:50:39,313 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 05:50:39,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1393590398_0004_m_000008_0' done.
2019-09-25 05:50:39,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1393590398_0004_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=907871
		FILE: Number of bytes written=12793652
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=140
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2000158720
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 05:50:39,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1393590398_0004_m_000008_0
2019-09-25 05:50:39,314 [Thread-733] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 05:50:39,330 [Thread-733] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001607866232/.staging/_distcp647666469
2019-09-25 05:50:39,332 [Thread-733] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1393590398_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket27080.volume35199/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 05:50:39,415 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 05:50:39,823 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 78% reduce 0%
2019-09-25 05:50:39,824 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1393590398_0004 failed with state FAILED due to: NA
2019-09-25 05:50:39,830 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=7182996
		FILE: Number of bytes written=102349048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1072
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=636
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1256
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16001269760
	File Input Format Counters 
		Bytes Read=24992
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
  </testcase>
  <testcase name="testDeepDirectoryStructureFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.236">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:488)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testDeepDirectoryStructureFromRemote(AbstractContractDistCpTest.java:458)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 05:50:39,893 [Thread-777] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 05:50:39,961 [Thread-777] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume20762, with user00612 as owner.
2019-09-25 05:50:39,964 [IPC Server handler 16 on 33070] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume20762 for user:user00612
2019-09-25 05:50:39,976 [Thread-777] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume20762/bucket97601, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 05:50:40,043 [Thread-777] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket97601.volume20762 implemented by OzoneFileSystem{URI=o3fs://bucket97601.volume20762, workingDir=o3fs://bucket97601.volume20762/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 147 read ops, 0 large read ops, 83 write ops}
05:50:40.066 [IPC Server handler 6 on 33070] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume20762, bucket=bucket97601, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume20762 bucket: bucket97601 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 05:50:40,070 [Thread-777] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-25 05:50:40,076 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 8de7fa9b-0de9-4341-a74c-363f9809b22f Heaviness: 6 limit: 5
2019-09-25 05:50:40,077 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e1c44be8-c290-4a84-9591-5999c64dd189 Heaviness: 6 limit: 5
2019-09-25 05:50:40,077 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 846429a6-4dd4-4152-b8dd-d8abbf5dfe58 Heaviness: 6 limit: 5
2019-09-25 05:50:40,077 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode 035834f9-24a4-45b4-a769-10efa83e6a02 Heaviness: 6 limit: 5
2019-09-25 05:50:40,077 [IPC Server handler 15 on 38285] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode e82d6518-db45-4664-aef7-ce30608e98c3 Heaviness: 6 limit: 5
2019-09-25 05:50:40,078 [IPC Server handler 15 on 38285] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 05:50:40,078 [IPC Server handler 15 on 38285] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:40,079 [IPC Server handler 15 on 38285] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 05:50:40,079 [IPC Server handler 15 on 38285] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 05:50:40,079 [IPC Server handler 15 on 38285] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
]]></system-out>
  </testcase>
</testsuite>
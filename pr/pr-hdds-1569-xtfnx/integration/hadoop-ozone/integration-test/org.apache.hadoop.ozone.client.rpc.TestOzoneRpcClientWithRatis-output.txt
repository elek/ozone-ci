2019-09-12 10:28:26,493 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:26,608 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:26,612 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:26,633 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @932ms
2019-09-12 10:28:26,774 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-12 10:28:26,775 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-12 10:28:26,775 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-12 10:28:26,776 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-12 10:28:26,776 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-12 10:28:26,776 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-12 10:28:26,795 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 10:28:26,795 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 10:28:26,797 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 10:28:26,986 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5ffead27
2019-09-12 10:28:26,988 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-12 10:28:27,081 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 10:28:27,083 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 10:28:27,085 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-12 10:28:27,162 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-12 10:28:27,177 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:27,234 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-12 10:28:27,237 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:27,331 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-12 10:28:28,020 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:28:28,058 [Socket Reader #1 for port 46331] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46331
2019-09-12 10:28:28,086 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:28:28,087 [Socket Reader #1 for port 33084] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33084
2019-09-12 10:28:28,095 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:28:28,096 [Socket Reader #1 for port 36871] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36871
2019-09-12 10:28:28,117 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-12 10:28:28,283 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:28:28,291 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:28:28,299 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:28:28,301 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-12 10:28:28,302 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:28:28,302 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:28:28,331 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36871
2019-09-12 10:28:28,393 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-12 10:28:28,405 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-12 10:28:28,405 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-12 10:28:28,641 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:36871
2019-09-12 10:28:28,642 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:28:28,642 [IPC Server listener on 36871] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36871: starting
2019-09-12 10:28:28,645 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33084
2019-09-12 10:28:28,645 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:33084
2019-09-12 10:28:28,645 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:28:28,645 [IPC Server listener on 33084] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33084: starting
2019-09-12 10:28:28,647 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:46331
2019-09-12 10:28:28,648 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:46331
2019-09-12 10:28:28,648 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:28:28,648 [IPC Server listener on 46331] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46331: starting
2019-09-12 10:28:28,652 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34332
2019-09-12 10:28:28,654 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:28:28,694 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:28:28,694 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-12 10:28:28,728 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43c67247{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-12 10:28:28,734 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:34332}
2019-09-12 10:28:28,734 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3034ms
2019-09-12 10:28:28,737 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:34332
2019-09-12 10:28:28,742 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24f43aa3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:28:28,744 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:28,849 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:28,850 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:28,851 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-12 10:28:28,851 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: cfd49e03-3682-4409-a0c3-4ec0743be209
2019-09-12 10:28:28,852 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-12 10:28:29,111 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-12 10:28:29,590 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:28:29,597 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-12 10:28:29,597 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-12 10:28:29,598 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-12 10:28:29,598 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-12 10:28:29,598 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-12 10:28:29,598 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-12 10:28:29,599 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-12 10:28:29,599 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-12 10:28:29,599 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-12 10:28:29,599 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-12 10:28:29,600 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-12 10:28:29,600 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-12 10:28:29,600 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-12 10:28:29,600 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-12 10:28:29,601 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-12 10:28:29,601 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-12 10:28:29,601 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-12 10:28:29,601 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-12 10:28:29,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-12 10:28:29,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-12 10:28:29,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-12 10:28:29,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-12 10:28:29,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 10:28:29,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 10:28:29,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 10:28:30,024 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3406)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-12 10:28:30,218 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-12 10:28:30,248 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: omServiceIdDefault and Raft Peers: localhost:9872
2019-09-12 10:28:30,278 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:28:30,348 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:28:30,358 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9872 (custom)
2019-09-12 10:28:30,362 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-12 10:28:30,365 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:30,366 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:28:30,367 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:28:30,543 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis] (custom)
2019-09-12 10:28:30,549 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cfd49e03-3682-4409-a0c3-4ec0743be209: addNew group-C5BA1605619E:[cfd49e03-3682-4409-a0c3-4ec0743be209:localhost:9872] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@5496c165[Not completed]
2019-09-12 10:28:30,550 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1398)) - OzoneManager Ratis server initialized at port 9872
2019-09-12 10:28:30,553 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-12 10:28:30,554 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-12 10:28:30,568 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:28:30,569 [Socket Reader #1 for port 38663] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38663
2019-09-12 10:28:30,570 [pool-22-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - cfd49e03-3682-4409-a0c3-4ec0743be209: new RaftServerImpl for group-C5BA1605619E:[cfd49e03-3682-4409-a0c3-4ec0743be209:localhost:9872] with OzoneManagerStateMachine:uninitialized
2019-09-12 10:28:30,573 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-12 10:28:30,574 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-12 10:28:30,574 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:30,575 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:30,577 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:30,587 [pool-22-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E ConfigurationManager, init=-1: [cfd49e03-3682-4409-a0c3-4ec0743be209:localhost:9872], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:30,588 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis] (custom)
2019-09-12 10:28:30,590 [main] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:38663
2019-09-12 10:28:30,590 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-12 10:28:30,590 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer cfd49e03-3682-4409-a0c3-4ec0743be209 at port 9872
2019-09-12 10:28:30,601 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2019-09-12 10:28:30,615 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:30,630 [pool-22-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2019-09-12 10:28:30,633 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:30,637 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:30,641 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:30,642 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:30,643 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-12 10:28:30,647 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:30,652 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2019-09-12 10:28:30,662 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-12 10:28:30,662 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-12 10:28:30,666 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-12 10:28:30,666 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:30,667 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-12 10:28:30,667 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:30,668 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:30,668 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:30,669 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:30,676 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-12 10:28:30,681 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:30,685 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:30,686 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-12 10:28:30,687 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:30,705 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - cfd49e03-3682-4409-a0c3-4ec0743be209: start group-C5BA1605619E
2019-09-12 10:28:30,708 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:30,709 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cfd49e03-3682-4409-a0c3-4ec0743be209: start FollowerState
2019-09-12 10:28:30,710 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=cfd49e03-3682-4409-a0c3-4ec0743be209
2019-09-12 10:28:30,711 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cfd49e03-3682-4409-a0c3-4ec0743be209: start RPC server
2019-09-12 10:28:30,800 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - cfd49e03-3682-4409-a0c3-4ec0743be209: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
2019-09-12 10:28:30,813 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:28:30,813 [IPC Server listener on 38663] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38663: starting
2019-09-12 10:28:30,820 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-12 10:28:30,824 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:28:30,825 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:28:30,828 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:28:30,830 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-12 10:28:30,830 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:28:30,830 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:28:30,833 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35850
2019-09-12 10:28:30,834 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:28:30,837 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:28:30,838 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-12 10:28:30,845 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1debc91c{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-12 10:28:30,846 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:35850}
2019-09-12 10:28:30,846 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5146ms
2019-09-12 10:28:30,848 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:35850
2019-09-12 10:28:31,011 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 10:28:31,102 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 10:28:31,136 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 10:28:31,139 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/containers/hdds to VolumeSet
2019-09-12 10:28:31,144 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-12 10:28:31,174 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-12 10:28:31,241 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:28:31,242 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:28:31,242 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 10:28:31,242 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 10:28:31,243 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:31,243 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:28:31,243 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:28:31,244 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:31,279 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 10:28:31,292 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 10:28:31,294 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:28:31,295 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:28:31,298 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:28:31,300 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 10:28:31,300 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:28:31,300 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:28:31,301 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43586
2019-09-12 10:28:31,302 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:28:31,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:28:31,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 10:28:31,352 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a87026{/,file:///tmp/jetty-0.0.0.0-43586-hddsDatanode-_-any-8066811330139919859.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 10:28:31,353 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:43586}
2019-09-12 10:28:31,354 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5654ms
2019-09-12 10:28:31,356 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43586
Sep 12, 2019 10:28:31 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-12 10:28:31,878 [Thread-94] INFO  impl.FollowerState (FollowerState.java:run(106)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E changes to CANDIDATE, lastRpcTime:1169, electionTimeout:1168ms
2019-09-12 10:28:31,878 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cfd49e03-3682-4409-a0c3-4ec0743be209: shutdown FollowerState
2019-09-12 10:28:31,879 [Thread-94] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:31,882 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cfd49e03-3682-4409-a0c3-4ec0743be209: start LeaderElection
2019-09-12 10:28:31,899 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1: begin an election at term 1 for -1: [cfd49e03-3682-4409-a0c3-4ec0743be209:localhost:9872], old=null
2019-09-12 10:28:31,902 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cfd49e03-3682-4409-a0c3-4ec0743be209: shutdown LeaderElection
2019-09-12 10:28:31,903 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:31,903 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E change Leader from null to cfd49e03-3682-4409-a0c3-4ec0743be209 at term 1 for becomeLeader, leader elected after 1269ms
2019-09-12 10:28:31,911 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:31,911 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:31,914 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:31,918 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:31,918 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:31,919 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:31,933 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cfd49e03-3682-4409-a0c3-4ec0743be209: start LeaderState
2019-09-12 10:28:31,969 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Starting segment from index:0
2019-09-12 10:28:31,990 [cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E set configuration 0: [cfd49e03-3682-4409-a0c3-4ec0743be209:localhost:9872], old=null at 0
2019-09-12 10:28:32,166 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2019-09-12 10:28:32,413 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:39804 |  
2019-09-12 10:28:32,414 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-12 10:28:32,415 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 10:28:32,418 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 10:28:32,420 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f341c4a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:28:32,429 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 10:28:32,429 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/containers/hdds to VolumeSet
2019-09-12 10:28:32,430 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@26c77f54
2019-09-12 10:28:32,430 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@26c77f54
2019-09-12 10:28:32,447 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:28:32,447 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:28:32,447 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 10:28:32,447 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 10:28:32,448 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:32,448 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:28:32,448 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:28:32,449 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:32,449 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 10:28:32,450 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 10:28:32,452 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:28:32,453 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:28:32,454 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:28:32,455 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 10:28:32,455 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:28:32,455 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:28:32,456 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45624
2019-09-12 10:28:32,456 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:28:32,461 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4be490da{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:28:32,461 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@353e6389{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 10:28:32,491 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73f6e07{/,file:///tmp/jetty-0.0.0.0-45624-hddsDatanode-_-any-1437456167087277620.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 10:28:32,491 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c9d90fc{HTTP/1.1,[http/1.1]}{0.0.0.0:45624}
2019-09-12 10:28:32,492 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6792ms
2019-09-12 10:28:32,494 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45624
Sep 12, 2019 10:28:32 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-12 10:28:32,552 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/meta/datanode.id
2019-09-12 10:28:32,653 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:38045 |  
2019-09-12 10:28:32,653 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@747f6c5a
2019-09-12 10:28:32,653 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 10:28:32,656 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 10:28:32,657 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d4b045d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:28:32,663 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/meta/datanode.id
2019-09-12 10:28:32,667 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 10:28:32,667 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/containers/hdds to VolumeSet
2019-09-12 10:28:32,667 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5dbab232
2019-09-12 10:28:32,668 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5dbab232
2019-09-12 10:28:32,684 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:28:32,684 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:28:32,684 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 10:28:32,685 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 10:28:32,685 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:32,685 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:28:32,685 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:28:32,686 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:32,687 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 10:28:32,688 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 10:28:32,689 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:28:32,690 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:28:32,691 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:28:32,692 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 10:28:32,692 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:28:32,692 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:28:32,693 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36321
2019-09-12 10:28:32,693 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:28:32,695 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52ba685a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:28:32,696 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71d55b7e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 10:28:32,725 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c18942{/,file:///tmp/jetty-0.0.0.0-36321-hddsDatanode-_-any-7766271073346174310.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 10:28:32,725 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@743c3520{HTTP/1.1,[http/1.1]}{0.0.0.0:36321}
2019-09-12 10:28:32,726 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7026ms
2019-09-12 10:28:32,728 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36321
Sep 12, 2019 10:28:32 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-12 10:28:32,902 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:45925 |  
2019-09-12 10:28:32,902 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@79add732
2019-09-12 10:28:32,904 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:28:32,905 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d9c76eb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:28:32,908 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/meta/datanode.id
2019-09-12 10:28:33,904 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:28:34,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 10:28:34,475 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 10:28:34,476 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 10:28:34,477 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 969f621b-625a-4660-bcba-147498526acd at port 0
2019-09-12 10:28:34,485 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 969f621b-625a-4660-bcba-147498526acd: start RPC server
2019-09-12 10:28:34,489 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 969f621b-625a-4660-bcba-147498526acd: GrpcService started, listening on 0.0.0.0/0.0.0.0:44966
2019-09-12 10:28:34,490 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 969f621b-625a-4660-bcba-147498526acd is started using port 44966
2019-09-12 10:28:34,492 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 969f621b-625a-4660-bcba-147498526acd is started using port 36227
2019-09-12 10:28:34,659 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 10:28:34,673 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 10:28:34,675 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 10:28:34,675 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 349939a8-0e84-4617-9a16-3efaa8718099 at port 0
2019-09-12 10:28:34,685 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 349939a8-0e84-4617-9a16-3efaa8718099: start RPC server
2019-09-12 10:28:34,688 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 349939a8-0e84-4617-9a16-3efaa8718099: GrpcService started, listening on 0.0.0.0/0.0.0.0:43393
2019-09-12 10:28:34,689 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 349939a8-0e84-4617-9a16-3efaa8718099 is started using port 43393
2019-09-12 10:28:34,691 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 349939a8-0e84-4617-9a16-3efaa8718099 is started using port 33880
2019-09-12 10:28:34,905 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:28:34,907 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 10:28:34,931 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 10:28:34,933 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 10:28:34,933 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis bdedf58a-a481-4a9e-93e6-4446fa864847 at port 0
2019-09-12 10:28:35,007 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start RPC server
2019-09-12 10:28:35,009 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - bdedf58a-a481-4a9e-93e6-4446fa864847: GrpcService started, listening on 0.0.0.0/0.0.0.0:42442
2019-09-12 10:28:35,010 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis bdedf58a-a481-4a9e-93e6-4446fa864847 is started using port 42442
2019-09-12 10:28:35,012 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc bdedf58a-a481-4a9e-93e6-4446fa864847 is started using port 43304
2019-09-12 10:28:35,907 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:28:36,464 [IPC Server handler 2 on 46331] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:36,465 [IPC Server handler 2 on 46331] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 10:28:36,470 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-12 10:28:36,470 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-12 10:28:36,470 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-12 10:28:36,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 10:28:36,934 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 3 DN Heartbeats.
2019-09-12 10:28:36,941 [IPC Server handler 2 on 46331] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:36,941 [IPC Server handler 1 on 46331] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:36,941 [IPC Server handler 2 on 46331] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 10:28:36,941 [IPC Server handler 1 on 46331] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 10:28:36,942 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 10:28:36,942 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 10:28:37,304 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969f621b-625a-4660-bcba-147498526acd: addNew group-1F01F129F436:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] returns group-1F01F129F436:java.util.concurrent.CompletableFuture@605c567a[Not completed]
2019-09-12 10:28:37,314 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 969f621b-625a-4660-bcba-147498526acd: new RaftServerImpl for group-1F01F129F436:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,316 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,316 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,316 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,316 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,317 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,317 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 ConfigurationManager, init=-1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,317 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:37,318 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436 does not exist. Creating ...
2019-09-12 10:28:37,331 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,345 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436 has been successfully formatted.
2019-09-12 10:28:37,347 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1F01F129F436: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,347 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,347 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,347 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,348 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,348 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,348 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,348 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436
2019-09-12 10:28:37,348 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,349 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,349 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,349 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,349 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,350 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,350 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,350 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,350 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,351 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,351 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,352 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,352 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,352 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,352 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 969f621b-625a-4660-bcba-147498526acd: start group-1F01F129F436
2019-09-12 10:28:37,353 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,353 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start FollowerState
2019-09-12 10:28:37,353 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1F01F129F436,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:37,423 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2a28ef1f-5de8-4be3-ae76-1f01f129f436, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,446 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 349939a8-0e84-4617-9a16-3efaa8718099: addNew group-F1321AAFF4A4:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] returns group-F1321AAFF4A4:java.util.concurrent.CompletableFuture@55fea1e4[Not completed]
2019-09-12 10:28:37,477 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 349939a8-0e84-4617-9a16-3efaa8718099: new RaftServerImpl for group-F1321AAFF4A4:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,478 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,478 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,478 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,479 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,479 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,479 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 ConfigurationManager, init=-1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,479 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:37,480 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4 does not exist. Creating ...
2019-09-12 10:28:37,493 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,521 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4 has been successfully formatted.
2019-09-12 10:28:37,521 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F1321AAFF4A4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,522 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,522 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,523 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,523 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,523 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,523 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,524 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4
2019-09-12 10:28:37,524 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,524 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,524 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,525 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,525 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,525 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,525 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,526 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,526 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,526 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,527 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,527 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,528 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,528 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,528 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 349939a8-0e84-4617-9a16-3efaa8718099: start group-F1321AAFF4A4
2019-09-12 10:28:37,529 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,529 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start FollowerState
2019-09-12 10:28:37,529 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F1321AAFF4A4,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:37,541 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: cb42bced-e0e3-4b06-8a26-f1321aaff4a4, Nodes: 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,558 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969f621b-625a-4660-bcba-147498526acd: addNew group-C524CC0FC1F5:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] returns group-C524CC0FC1F5:java.util.concurrent.CompletableFuture@4b5a4530[Not completed]
2019-09-12 10:28:37,566 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 969f621b-625a-4660-bcba-147498526acd: new RaftServerImpl for group-C524CC0FC1F5:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,566 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,566 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,566 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,567 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,567 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,567 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 ConfigurationManager, init=-1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,567 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:37,568 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5 does not exist. Creating ...
2019-09-12 10:28:37,581 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,594 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5 has been successfully formatted.
2019-09-12 10:28:37,595 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C524CC0FC1F5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,595 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,595 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,595 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,595 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,596 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,596 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,596 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5
2019-09-12 10:28:37,596 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,596 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,597 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,597 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,597 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,597 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,597 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,598 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,598 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,598 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,598 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,599 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,599 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,599 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,600 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 969f621b-625a-4660-bcba-147498526acd: start group-C524CC0FC1F5
2019-09-12 10:28:37,600 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,600 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start FollowerState
2019-09-12 10:28:37,601 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C524CC0FC1F5,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:37,611 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,628 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdedf58a-a481-4a9e-93e6-4446fa864847: addNew group-E6C7178570C6:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] returns group-E6C7178570C6:java.util.concurrent.CompletableFuture@49e24615[Not completed]
2019-09-12 10:28:37,630 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bdedf58a-a481-4a9e-93e6-4446fa864847: new RaftServerImpl for group-E6C7178570C6:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,631 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,631 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,631 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,631 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,632 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,632 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 ConfigurationManager, init=-1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,632 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:37,633 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6 does not exist. Creating ...
2019-09-12 10:28:37,645 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,658 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6 has been successfully formatted.
2019-09-12 10:28:37,658 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-E6C7178570C6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,659 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,659 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,659 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,659 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,659 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,659 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,660 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6
2019-09-12 10:28:37,660 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,660 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,660 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,660 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,661 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,661 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,661 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,661 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,661 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,662 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,662 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,663 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,663 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,663 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,663 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start group-E6C7178570C6
2019-09-12 10:28:37,663 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,664 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start FollowerState
2019-09-12 10:28:37,664 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E6C7178570C6,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:37,675 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 55a88f07-3f34-4613-8002-e6c7178570c6, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,692 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 349939a8-0e84-4617-9a16-3efaa8718099: addNew group-26600E4E4539:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] returns group-26600E4E4539:java.util.concurrent.CompletableFuture@5f917c13[Not completed]
2019-09-12 10:28:37,694 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 349939a8-0e84-4617-9a16-3efaa8718099: new RaftServerImpl for group-26600E4E4539:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,694 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,694 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,695 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,695 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,695 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,695 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 ConfigurationManager, init=-1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,695 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:37,696 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539 does not exist. Creating ...
2019-09-12 10:28:37,708 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,721 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539 has been successfully formatted.
2019-09-12 10:28:37,721 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-26600E4E4539: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,722 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,722 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,722 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,722 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,722 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,723 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,723 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539
2019-09-12 10:28:37,723 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,723 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,723 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,725 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,725 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,725 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,726 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,726 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,726 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 349939a8-0e84-4617-9a16-3efaa8718099: start group-26600E4E4539
2019-09-12 10:28:37,726 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,726 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start FollowerState
2019-09-12 10:28:37,727 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-26600E4E4539,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:37,741 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fe89e5bd-39a7-4ea9-9c0c-26600e4e4539, Nodes: 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,758 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdedf58a-a481-4a9e-93e6-4446fa864847: addNew group-1AEBB147EF01:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] returns group-1AEBB147EF01:java.util.concurrent.CompletableFuture@20922e5c[Not completed]
2019-09-12 10:28:37,760 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bdedf58a-a481-4a9e-93e6-4446fa864847: new RaftServerImpl for group-1AEBB147EF01:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,760 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,760 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,760 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,760 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,761 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,761 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 ConfigurationManager, init=-1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,761 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:37,761 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01 does not exist. Creating ...
2019-09-12 10:28:37,774 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,792 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01 has been successfully formatted.
2019-09-12 10:28:37,793 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1AEBB147EF01: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,793 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,793 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,793 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,794 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,794 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,794 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,794 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01
2019-09-12 10:28:37,794 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,795 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,795 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,795 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,795 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,795 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,795 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,796 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,796 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,796 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,796 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,797 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,797 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,797 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,797 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start group-1AEBB147EF01
2019-09-12 10:28:37,798 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,798 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start FollowerState
2019-09-12 10:28:37,798 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1AEBB147EF01,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:37,808 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3378cb60-8523-4838-a4d7-1aebb147ef01, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,829 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 349939a8-0e84-4617-9a16-3efaa8718099: addNew group-CFB584CB038C:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] returns group-CFB584CB038C:java.util.concurrent.CompletableFuture@63e6f694[Not completed]
2019-09-12 10:28:37,831 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 349939a8-0e84-4617-9a16-3efaa8718099: new RaftServerImpl for group-CFB584CB038C:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,831 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,831 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,831 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,831 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,832 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,832 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C ConfigurationManager, init=-1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,832 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:37,832 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c does not exist. Creating ...
2019-09-12 10:28:37,845 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,858 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c has been successfully formatted.
2019-09-12 10:28:37,858 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-CFB584CB038C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,859 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,859 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,859 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,859 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,860 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,860 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,860 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c
2019-09-12 10:28:37,860 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,860 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,861 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,861 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,861 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,861 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,861 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,862 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,862 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,862 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,862 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,863 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,863 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,863 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,863 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 349939a8-0e84-4617-9a16-3efaa8718099: start group-CFB584CB038C
2019-09-12 10:28:37,863 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,864 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start FollowerState
2019-09-12 10:28:37,864 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFB584CB038C,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:37,876 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f95f9786-fb71-46c3-a70a-cfb584cb038c, Nodes: 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,889 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 349939a8-0e84-4617-9a16-3efaa8718099: addNew group-849E74F7B3CB:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] returns group-849E74F7B3CB:java.util.concurrent.CompletableFuture@71618405[Not completed]
2019-09-12 10:28:37,891 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 349939a8-0e84-4617-9a16-3efaa8718099: new RaftServerImpl for group-849E74F7B3CB:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,891 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,891 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,891 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,891 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,892 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,892 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB ConfigurationManager, init=-1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,892 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:37,892 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb does not exist. Creating ...
2019-09-12 10:28:37,905 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,919 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb has been successfully formatted.
2019-09-12 10:28:37,919 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-849E74F7B3CB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,919 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,919 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,919 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,919 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,920 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb
2019-09-12 10:28:37,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,921 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,921 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,921 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,921 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,921 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,921 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,922 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,922 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,922 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,922 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,923 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,923 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,923 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 349939a8-0e84-4617-9a16-3efaa8718099: start group-849E74F7B3CB
2019-09-12 10:28:37,923 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,923 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start FollowerState
2019-09-12 10:28:37,924 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-849E74F7B3CB,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:37,933 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f287a6bd-6b22-404e-96eb-849e74f7b3cb, Nodes: 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:37,934 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-12 10:28:37,947 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969f621b-625a-4660-bcba-147498526acd: addNew group-4E0965901142:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] returns group-4E0965901142:java.util.concurrent.CompletableFuture@9a4d779[Not completed]
2019-09-12 10:28:37,949 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 969f621b-625a-4660-bcba-147498526acd: new RaftServerImpl for group-4E0965901142:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] with ContainerStateMachine:uninitialized
2019-09-12 10:28:37,949 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:37,950 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:37,950 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:37,950 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:37,950 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:37,950 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 ConfigurationManager, init=-1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:37,951 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:37,951 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142 does not exist. Creating ...
2019-09-12 10:28:37,964 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:37,977 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142 has been successfully formatted.
2019-09-12 10:28:37,978 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-4E0965901142: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:37,978 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:37,978 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:37,978 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:37,978 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:37,979 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,979 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:37,979 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142
2019-09-12 10:28:37,979 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:37,979 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:37,980 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:37,980 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:37,980 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:37,980 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:37,980 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:37,981 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:37,981 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:37,981 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:37,982 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:37,982 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:37,982 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:37,982 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:37,983 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 969f621b-625a-4660-bcba-147498526acd: start group-4E0965901142
2019-09-12 10:28:37,983 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:37,983 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start FollowerState
2019-09-12 10:28:37,983 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E0965901142,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:37,993 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c280e1db-3360-42e4-9770-4e0965901142, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,015 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969f621b-625a-4660-bcba-147498526acd: addNew group-E7A6A1456DBD:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] returns group-E7A6A1456DBD:java.util.concurrent.CompletableFuture@31f92cd7[Not completed]
2019-09-12 10:28:38,016 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 969f621b-625a-4660-bcba-147498526acd: new RaftServerImpl for group-E7A6A1456DBD:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,017 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,017 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,017 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,017 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,017 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,018 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD ConfigurationManager, init=-1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,018 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:38,018 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd does not exist. Creating ...
2019-09-12 10:28:38,031 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,056 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd has been successfully formatted.
2019-09-12 10:28:38,056 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-E7A6A1456DBD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,056 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,057 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,057 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,057 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,057 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,057 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,057 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,058 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,059 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,060 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 969f621b-625a-4660-bcba-147498526acd: start group-E7A6A1456DBD
2019-09-12 10:28:38,060 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,061 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start FollowerState
2019-09-12 10:28:38,061 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E7A6A1456DBD,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:38,070 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 998e4c04-750d-4fb5-9091-e7a6a1456dbd, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,091 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 349939a8-0e84-4617-9a16-3efaa8718099: addNew group-C014B0813831:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] returns group-C014B0813831:java.util.concurrent.CompletableFuture@5560676b[Not completed]
2019-09-12 10:28:38,093 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 349939a8-0e84-4617-9a16-3efaa8718099: new RaftServerImpl for group-C014B0813831:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,093 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,093 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,093 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,093 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,094 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,094 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 ConfigurationManager, init=-1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,094 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:38,095 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831 does not exist. Creating ...
2019-09-12 10:28:38,108 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,120 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831 has been successfully formatted.
2019-09-12 10:28:38,120 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C014B0813831: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,120 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,121 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,121 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,121 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,121 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,121 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,121 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831
2019-09-12 10:28:38,122 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,122 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,122 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,122 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,122 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,123 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,123 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,123 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,123 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,123 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,124 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,124 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,124 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,124 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,125 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 349939a8-0e84-4617-9a16-3efaa8718099: start group-C014B0813831
2019-09-12 10:28:38,125 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,125 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start FollowerState
2019-09-12 10:28:38,125 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C014B0813831,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:38,133 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 74d04d19-7649-4420-bcc3-c014b0813831, Nodes: 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,146 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969f621b-625a-4660-bcba-147498526acd: addNew group-6EEB257C2850:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] returns group-6EEB257C2850:java.util.concurrent.CompletableFuture@4fe71aea[Not completed]
2019-09-12 10:28:38,148 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 969f621b-625a-4660-bcba-147498526acd: new RaftServerImpl for group-6EEB257C2850:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,148 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,148 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,148 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,148 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,149 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,149 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 ConfigurationManager, init=-1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,149 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:38,149 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850 does not exist. Creating ...
2019-09-12 10:28:38,162 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,175 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850 has been successfully formatted.
2019-09-12 10:28:38,175 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6EEB257C2850: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,176 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,176 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,176 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,176 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,176 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,177 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,177 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850
2019-09-12 10:28:38,177 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,177 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,177 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,178 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,178 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,178 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,178 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,178 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,178 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,179 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,179 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,179 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,180 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,180 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,180 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 969f621b-625a-4660-bcba-147498526acd: start group-6EEB257C2850
2019-09-12 10:28:38,180 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,180 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start FollowerState
2019-09-12 10:28:38,181 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6EEB257C2850,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:38,189 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 235368e5-9c0f-4999-ac47-6eeb257c2850, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,203 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdedf58a-a481-4a9e-93e6-4446fa864847: addNew group-D38D0E46E828:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] returns group-D38D0E46E828:java.util.concurrent.CompletableFuture@60012314[Not completed]
2019-09-12 10:28:38,205 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bdedf58a-a481-4a9e-93e6-4446fa864847: new RaftServerImpl for group-D38D0E46E828:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,205 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,205 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,205 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,205 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,205 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,206 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 ConfigurationManager, init=-1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,206 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:38,206 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828 does not exist. Creating ...
2019-09-12 10:28:38,219 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,231 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828 has been successfully formatted.
2019-09-12 10:28:38,231 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D38D0E46E828: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,231 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,232 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,232 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,232 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,232 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,232 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,232 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,233 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,234 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,234 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,234 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,234 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,235 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,235 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,235 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,235 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start group-D38D0E46E828
2019-09-12 10:28:38,235 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,236 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start FollowerState
2019-09-12 10:28:38,236 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D38D0E46E828,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:38,251 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e16c15e4-8484-4070-a9b8-d38d0e46e828, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,264 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 349939a8-0e84-4617-9a16-3efaa8718099: addNew group-7206917E1AC6:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] returns group-7206917E1AC6:java.util.concurrent.CompletableFuture@204b3a43[Not completed]
2019-09-12 10:28:38,265 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 349939a8-0e84-4617-9a16-3efaa8718099: new RaftServerImpl for group-7206917E1AC6:[349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,266 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,266 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,266 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,266 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,266 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,266 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 ConfigurationManager, init=-1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,267 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis] (custom)
2019-09-12 10:28:38,267 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6 does not exist. Creating ...
2019-09-12 10:28:38,279 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,299 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:getStorageContainerLocationClient(241)) - Creating StorageContainerLocationProtocol RPC client with address /0.0.0.0:36871
2019-09-12 10:28:38,309 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6 has been successfully formatted.
2019-09-12 10:28:38,309 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7206917E1AC6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,309 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6
2019-09-12 10:28:38,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,312 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,313 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,313 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,313 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 349939a8-0e84-4617-9a16-3efaa8718099: start group-7206917E1AC6
2019-09-12 10:28:38,313 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,313 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start FollowerState
2019-09-12 10:28:38,314 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7206917E1AC6,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:28:38,328 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9b955dda-cf86-45ed-b931-7206917e1ac6, Nodes: 349939a8-0e84-4617-9a16-3efaa8718099{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,329 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,341 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 270b7139-bc5f-45c9-930c-a9b03e0f82f8, with jenkins1000 as owner.
2019-09-12 10:28:38,342 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969f621b-625a-4660-bcba-147498526acd: addNew group-51CC9BFFB349:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] returns group-51CC9BFFB349:java.util.concurrent.CompletableFuture@1d6fe316[Not completed]
2019-09-12 10:28:38,345 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 969f621b-625a-4660-bcba-147498526acd: new RaftServerImpl for group-51CC9BFFB349:[969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,345 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,346 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,346 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,346 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,346 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,347 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 ConfigurationManager, init=-1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,347 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis] (custom)
2019-09-12 10:28:38,348 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349 does not exist. Creating ...
2019-09-12 10:28:38,361 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,383 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349 has been successfully formatted.
2019-09-12 10:28:38,384 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-51CC9BFFB349: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,384 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,384 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,385 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,386 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,386 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,386 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,386 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,386 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,386 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,387 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,387 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,387 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,388 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,388 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,389 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,389 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 969f621b-625a-4660-bcba-147498526acd: start group-51CC9BFFB349
2019-09-12 10:28:38,389 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,389 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start FollowerState
2019-09-12 10:28:38,390 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-51CC9BFFB349,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:28:38,396 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 568e3496-d263-48bf-a1e2-51cc9bffb349, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,397 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,398 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,410 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdedf58a-a481-4a9e-93e6-4446fa864847: addNew group-8C6BC10213CE:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] returns group-8C6BC10213CE:java.util.concurrent.CompletableFuture@3c5b2d57[Not completed]
2019-09-12 10:28:38,412 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bdedf58a-a481-4a9e-93e6-4446fa864847: new RaftServerImpl for group-8C6BC10213CE:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,412 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,412 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,412 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,412 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,413 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,413 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE ConfigurationManager, init=-1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,413 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:38,413 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce does not exist. Creating ...
2019-09-12 10:28:38,425 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,437 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,439 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce has been successfully formatted.
2019-09-12 10:28:38,440 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8C6BC10213CE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,440 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,440 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,441 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,441 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,441 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,441 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,442 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce
2019-09-12 10:28:38,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,443 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,443 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,443 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,443 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,443 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,444 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,444 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,444 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,444 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,445 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,445 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start group-8C6BC10213CE
2019-09-12 10:28:38,445 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,445 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start FollowerState
2019-09-12 10:28:38,446 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C6BC10213CE,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:38,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=270b7139-bc5f-45c9-930c-a9b03e0f82f8, creationTime=1568284118386, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:38,452 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2a08fba6-2ea0-4046-9d8c-8c6bc10213ce, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,453 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,455 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,459 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=270b7139-bc5f-45c9-930c-a9b03e0f82f8} | ret=SUCCESS |  
2019-09-12 10:28:38,467 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdedf58a-a481-4a9e-93e6-4446fa864847: addNew group-50887C8F1A38:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] returns group-50887C8F1A38:java.util.concurrent.CompletableFuture@40348be5[Not completed]
2019-09-12 10:28:38,468 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bdedf58a-a481-4a9e-93e6-4446fa864847: new RaftServerImpl for group-50887C8F1A38:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,468 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,469 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,469 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,469 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 270b7139-bc5f-45c9-930c-a9b03e0f82f8/da1b749e-d539-4876-8bd7-6a8a155be4f9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:38,469 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,469 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,469 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 ConfigurationManager, init=-1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,469 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:38,470 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38 does not exist. Creating ...
2019-09-12 10:28:38,483 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,488 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=270b7139-bc5f-45c9-930c-a9b03e0f82f8, bucket=da1b749e-d539-4876-8bd7-6a8a155be4f9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284118478} | ret=SUCCESS |  
2019-09-12 10:28:38,494 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=270b7139-bc5f-45c9-930c-a9b03e0f82f8, bucket=da1b749e-d539-4876-8bd7-6a8a155be4f9} | ret=SUCCESS |  
2019-09-12 10:28:38,496 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38 has been successfully formatted.
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-50887C8F1A38: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,497 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,498 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,499 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,499 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,499 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,499 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,499 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,500 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start group-50887C8F1A38
2019-09-12 10:28:38,500 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,500 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start FollowerState
2019-09-12 10:28:38,500 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-50887C8F1A38,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:38,505 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 15a42196-928e-4aff-9dca-50887c8f1a38, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,506 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,506 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,515 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdedf58a-a481-4a9e-93e6-4446fa864847: addNew group-5BC15ABAABA1:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] returns group-5BC15ABAABA1:java.util.concurrent.CompletableFuture@b1628f8[Not completed]
2019-09-12 10:28:38,516 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bdedf58a-a481-4a9e-93e6-4446fa864847: new RaftServerImpl for group-5BC15ABAABA1:[bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442] with ContainerStateMachine:uninitialized
2019-09-12 10:28:38,517 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:28:38,517 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:28:38,517 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:28:38,517 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:28:38,517 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:28:38,517 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 ConfigurationManager, init=-1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null, confs=<EMPTY_MAP>
2019-09-12 10:28:38,518 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis] (custom)
2019-09-12 10:28:38,518 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1 does not exist. Creating ...
2019-09-12 10:28:38,531 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1/in_use.lock acquired by nodename 26413@pr-hdds-1569-xtfnx-3545843844
2019-09-12 10:28:38,556 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1 has been successfully formatted.
2019-09-12 10:28:38,556 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-5BC15ABAABA1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:28:38,556 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:28:38,556 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:28:38,556 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:28:38,557 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:28:38,558 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:28:38,558 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:28:38,558 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:28:38,558 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:28:38,558 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:28:38,558 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:28:38,559 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:28:38,559 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:28:38,559 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:28:38,559 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start group-5BC15ABAABA1
2019-09-12 10:28:38,559 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:28:38,559 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start FollowerState
2019-09-12 10:28:38,560 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BC15ABAABA1,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:28:38,564 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 33cdbc17-6036-4c6c-923f-5bc15abaaba1, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,568 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,568 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,568 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,569 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,570 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,570 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,570 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,570 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,570 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,570 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,571 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,572 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,573 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,573 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,574 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,574 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,574 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,574 [IPC Server handler 2 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,574 [IPC Server handler 2 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,575 [IPC Server handler 2 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,575 [IPC Server handler 2 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,575 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,580 [IPC Server handler 17 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 38663, call Call#14 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,585 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663. Trying to failover immediately.
2019-09-12 10:28:38,589 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,589 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,589 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,590 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,590 [IPC Server handler 7 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,590 [IPC Server handler 7 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,590 [IPC Server handler 7 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,591 [IPC Server handler 7 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,591 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,592 [IPC Server handler 19 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 38663, call Call#14 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,595 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,598 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,598 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,598 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,598 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,598 [IPC Server handler 3 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,599 [IPC Server handler 3 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,599 [IPC Server handler 3 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,599 [IPC Server handler 3 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,599 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,600 [IPC Server handler 18 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 38663, call Call#14 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,601 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,609 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,609 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,609 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,609 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,610 [IPC Server handler 1 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,610 [IPC Server handler 1 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,610 [IPC Server handler 1 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,610 [IPC Server handler 1 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,611 [IPC Server handler 9 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38663, call Call#14 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,613 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,616 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,617 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,617 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,617 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,617 [IPC Server handler 4 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,617 [IPC Server handler 4 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,618 [IPC Server handler 4 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,618 [IPC Server handler 4 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,618 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,619 [IPC Server handler 11 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38663, call Call#14 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,621 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,624 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,624 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,624 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,624 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,624 [IPC Server handler 6 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,624 [IPC Server handler 6 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,625 [IPC Server handler 6 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,625 [IPC Server handler 6 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,625 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,626 [IPC Server handler 8 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38663, call Call#14 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,628 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,632 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,632 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,632 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,632 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,632 [IPC Server handler 11 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,633 [IPC Server handler 11 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,633 [IPC Server handler 11 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,633 [IPC Server handler 11 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,633 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,634 [IPC Server handler 10 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38663, call Call#14 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,636 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,639 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,639 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,639 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,640 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,640 [IPC Server handler 5 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,640 [IPC Server handler 5 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,640 [IPC Server handler 5 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,641 [IPC Server handler 5 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,641 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,641 [IPC Server handler 7 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38663, call Call#14 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,644 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,647 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,647 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,648 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,648 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,648 [IPC Server handler 8 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,648 [IPC Server handler 8 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,649 [IPC Server handler 8 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,649 [IPC Server handler 8 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,649 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,650 [IPC Server handler 6 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38663, call Call#14 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,651 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,654 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,655 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,655 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,655 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,655 [IPC Server handler 13 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,656 [IPC Server handler 13 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,656 [IPC Server handler 13 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,657 [IPC Server handler 13 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,657 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,658 [IPC Server handler 4 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38663, call Call#14 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,659 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,663 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,663 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,663 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,663 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,664 [IPC Server handler 9 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,664 [IPC Server handler 9 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,664 [IPC Server handler 9 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,664 [IPC Server handler 9 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,664 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,665 [IPC Server handler 3 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 38663, call Call#14 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,667 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:28:38,677 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055, with jenkins1000 as owner.
2019-09-12 10:28:38,693 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055, creationTime=1568284118680, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:38,696 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055} | ret=SUCCESS |  
2019-09-12 10:28:38,698 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055/026bdedc-4693-484e-8cef-60f1d3cd48fa, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:38,704 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055, bucket=026bdedc-4693-484e-8cef-60f1d3cd48fa, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284118700} | ret=SUCCESS |  
2019-09-12 10:28:38,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055, bucket=026bdedc-4693-484e-8cef-60f1d3cd48fa} | ret=SUCCESS |  
2019-09-12 10:28:38,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055, bucket=026bdedc-4693-484e-8cef-60f1d3cd48fa, key=e0caaaf3-ebe0-45cd-84b2-ad5daff4fc1e, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=90fa9e8b-99c0-43fa-9aa2-ef90c7a4c055, bucket=026bdedc-4693-484e-8cef-60f1d3cd48fa, key=e0caaaf3-ebe0-45cd-84b2-ad5daff4fc1e, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,780 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,780 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,780 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,780 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,780 [IPC Server handler 15 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,781 [IPC Server handler 15 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,781 [IPC Server handler 15 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,781 [IPC Server handler 15 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,781 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,782 [IPC Server handler 13 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 38663, call Call#32 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,783 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663. Trying to failover immediately.
2019-09-12 10:28:38,785 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,785 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,785 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,786 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,786 [IPC Server handler 10 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,786 [IPC Server handler 10 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,786 [IPC Server handler 10 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,786 [IPC Server handler 10 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,786 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,787 [IPC Server handler 16 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38663, call Call#32 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,790 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,792 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,792 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,793 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,793 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,793 [IPC Server handler 12 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,793 [IPC Server handler 12 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,794 [IPC Server handler 12 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,794 [IPC Server handler 12 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,794 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,795 [IPC Server handler 15 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 38663, call Call#32 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,797 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,799 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,799 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,799 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,800 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,800 [IPC Server handler 14 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,800 [IPC Server handler 14 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,800 [IPC Server handler 14 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,801 [IPC Server handler 14 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,801 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,802 [IPC Server handler 17 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 38663, call Call#32 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,804 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,806 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,807 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,807 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,807 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,807 [IPC Server handler 16 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,807 [IPC Server handler 16 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,808 [IPC Server handler 16 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,808 [IPC Server handler 16 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,809 [IPC Server handler 19 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 38663, call Call#32 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,811 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,813 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,813 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,813 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,814 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,814 [IPC Server handler 17 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,814 [IPC Server handler 17 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,814 [IPC Server handler 17 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,814 [IPC Server handler 17 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,814 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,815 [IPC Server handler 18 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 38663, call Call#32 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,818 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,820 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,820 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,820 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,820 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,820 [IPC Server handler 18 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,821 [IPC Server handler 18 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,821 [IPC Server handler 18 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,821 [IPC Server handler 18 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,821 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,822 [IPC Server handler 9 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38663, call Call#32 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,824 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,826 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,826 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,826 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,827 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,827 [IPC Server handler 19 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,827 [IPC Server handler 19 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,827 [IPC Server handler 19 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,827 [IPC Server handler 19 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,828 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,828 [IPC Server handler 11 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38663, call Call#32 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,834 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,836 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,836 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,837 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,837 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,837 [IPC Server handler 0 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,837 [IPC Server handler 0 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,840 [IPC Server handler 0 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,840 [IPC Server handler 0 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,841 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,841 [IPC Server handler 8 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38663, call Call#32 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,846 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,848 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,848 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,848 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,848 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,848 [IPC Server handler 2 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,849 [IPC Server handler 2 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,849 [IPC Server handler 2 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,849 [IPC Server handler 2 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,849 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,850 [IPC Server handler 10 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38663, call Call#32 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,854 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:28:38,856 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,856 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,856 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:38,856 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,856 [IPC Server handler 7 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:38,857 [IPC Server handler 7 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,857 [IPC Server handler 7 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:38,857 [IPC Server handler 7 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:38,857 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:38,858 [IPC Server handler 7 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38663, call Call#32 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:38,860 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:28:38,861 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUpload(TestOzoneRpcClientAbstract.java:1833)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:28:38,863 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 717e5449-4028-4472-a493-f9cb94703833, with jenkins1000 as owner.
2019-09-12 10:28:38,883 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=717e5449-4028-4472-a493-f9cb94703833, creationTime=1568284118864, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:38,885 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=717e5449-4028-4472-a493-f9cb94703833} | ret=SUCCESS |  
2019-09-12 10:28:38,886 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 717e5449-4028-4472-a493-f9cb94703833/75049f97-a9bf-4fa4-830f-e1f2271027b7, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:38,895 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=717e5449-4028-4472-a493-f9cb94703833, bucket=75049f97-a9bf-4fa4-830f-e1f2271027b7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284118887} | ret=SUCCESS |  
2019-09-12 10:28:38,896 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=717e5449-4028-4472-a493-f9cb94703833, bucket=75049f97-a9bf-4fa4-830f-e1f2271027b7} | ret=SUCCESS |  
2019-09-12 10:28:38,917 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=717e5449-4028-4472-a493-f9cb94703833, bucket=75049f97-a9bf-4fa4-830f-e1f2271027b7, key=b3fe23cc-602b-4033-ae77-d995d9041616, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,929 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=717e5449-4028-4472-a493-f9cb94703833, bucket=75049f97-a9bf-4fa4-830f-e1f2271027b7, key=b3fe23cc-602b-4033-ae77-d995d9041616, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,930 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 367e18b5-946d-4a86-9b94-7d239f440150, with jenkins1000 as owner.
2019-09-12 10:28:38,935 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:38,944 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=367e18b5-946d-4a86-9b94-7d239f440150, creationTime=1568284118931, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:38,946 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=367e18b5-946d-4a86-9b94-7d239f440150} | ret=SUCCESS |  
2019-09-12 10:28:38,946 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 367e18b5-946d-4a86-9b94-7d239f440150/059b0c58-aebe-4df9-8953-219df1f59997, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:38,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284118947} | ret=SUCCESS |  
2019-09-12 10:28:38,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997} | ret=SUCCESS |  
2019-09-12 10:28:38,961 [IPC Server handler 3 on 33084] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b7bad135-f2a1-48f5-99de-8146aaeeff1b, Nodes: bdedf58a-a481-4a9e-93e6-4446fa864847{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
2019-09-12 10:28:38,975 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:39,007 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=8e96e4b4-1073-4be0-87f3-018bb79f62da, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068021014532
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,033 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-09-12 10:28:39,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,245 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068021014532 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:39,332 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068021014532 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:39,369 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=8e96e4b4-1073-4be0-87f3-018bb79f62da, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068021014532
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,381 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:39,399 [IPC Server handler 1 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:39,400 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:39,402 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=8e96e4b4-1073-4be0-87f3-018bb79f62da, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:39,422 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,424 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=8e96e4b4-1073-4be0-87f3-018bb79f62da, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | INVALID_KEY_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Key name is empty
	at org.apache.hadoop.ozone.om.request.key.OMKeyRenameRequest.validateAndUpdateCache(OMKeyRenameRequest.java:117)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:39,426 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRenameRequest (OMKeyRenameRequest.java:validateAndUpdateCache(194)) - Rename key failed for volume:367e18b5-946d-4a86-9b94-7d239f440150 bucket:059b0c58-aebe-4df9-8953-219df1f59997 fromKey:8e96e4b4-1073-4be0-87f3-018bb79f62da toKey:. Key: 8e96e4b4-1073-4be0-87f3-018bb79f62da not found.
2019-09-12 10:28:39,437 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=8e96e4b4-1073-4be0-87f3-018bb79f62da, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,439 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=8e96e4b4-1073-4be0-87f3-018bb79f62da, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-12 10:28:39,443 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:39,445 [IPC Server handler 4 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:39,446 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:39,446 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=367e18b5-946d-4a86-9b94-7d239f440150, bucket=059b0c58-aebe-4df9-8953-219df1f59997, key=4039dfc0-b281-44b6-80a1-18742081c757, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:39,448 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e98d5634-877d-4859-af6a-6c7157b23be8, with jenkins1000 as owner.
2019-09-12 10:28:39,461 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e98d5634-877d-4859-af6a-6c7157b23be8, creationTime=1568284119449, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:39,463 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e98d5634-877d-4859-af6a-6c7157b23be8} | ret=SUCCESS |  
2019-09-12 10:28:39,464 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e98d5634-877d-4859-af6a-6c7157b23be8/053b7e5f-a02f-4a90-8026-7f41db8826d4, with Versioning true and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:39,472 [Thread-182] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-12 10:28:39,474 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e98d5634-877d-4859-af6a-6c7157b23be8, bucket=053b7e5f-a02f-4a90-8026-7f41db8826d4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=true, storageType=DISK, creationTime=1568284119465} | ret=SUCCESS |  
2019-09-12 10:28:39,474 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2019-09-12 10:28:39,476 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e98d5634-877d-4859-af6a-6c7157b23be8, bucket=053b7e5f-a02f-4a90-8026-7f41db8826d4} | ret=SUCCESS |  
2019-09-12 10:28:39,498 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {jenkins1000=username, 66ee13f8-818d-49d1-8ccb-ffa5df63d76a=s3Bucket} | ret=SUCCESS |  
2019-09-12 10:28:39,505 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3jenkins1000} | ret=SUCCESS |  
2019-09-12 10:28:39,507 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3jenkins1000, bucket=66ee13f8-818d-49d1-8ccb-ffa5df63d76a} | ret=SUCCESS |  
2019-09-12 10:28:39,508 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: eddc6c3a-8c30-427a-8c18-6b575c4f6634, with jenkins1000 as owner.
2019-09-12 10:28:39,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, creationTime=1568284119509, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:39,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634} | ret=SUCCESS |  
2019-09-12 10:28:39,525 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: eddc6c3a-8c30-427a-8c18-6b575c4f6634/0ff124f7-4a84-4d1e-9242-2a28b36b53ce, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:39,538 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284119526} | ret=SUCCESS |  
2019-09-12 10:28:39,540 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce} | ret=SUCCESS |  
2019-09-12 10:28:39,554 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,567 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,575 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:39,588 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068059287559} | ret=SUCCESS |  
2019-09-12 10:28:39,597 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068060467208 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:39,603 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068060467208 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:39,634 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068060467208
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,657 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=19, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,661 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:39,668 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=19, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068064530441} | ret=SUCCESS |  
2019-09-12 10:28:39,674 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068066103306 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:39,678 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068066103306 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:28:39,696 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=eddc6c3a-8c30-427a-8c18-6b575c4f6634, bucket=0ff124f7-4a84-4d1e-9242-2a28b36b53ce, key=fe1a9b10-06bb-41a0-8368-564d9c64e94a, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068066103306
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,697 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4fc4945f-23f3-4d7a-9271-628cb5a748bb, with jenkins1000 as owner.
2019-09-12 10:28:39,706 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, creationTime=1568284119698, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:39,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb} | ret=SUCCESS |  
2019-09-12 10:28:39,708 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 4fc4945f-23f3-4d7a-9271-628cb5a748bb/37a60284-3e96-4841-a015-606f704509aa, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:39,721 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284119709} | ret=SUCCESS |  
2019-09-12 10:28:39,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa} | ret=SUCCESS |  
2019-09-12 10:28:39,725 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:39,740 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068070297611
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,752 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068070297611 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:39,755 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068070297611 bcsId: 0,size=2358]} | ret=SUCCESS |  
2019-09-12 10:28:39,773 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=2358, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068070297611
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2358
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,775 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:39,783 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20b9ffc57-b624-4e96-b145-25f3e9d1e71e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068073574413
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,790 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068073574413 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:39,795 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068073574413 bcsId: 0,size=2362]} | ret=SUCCESS |  
2019-09-12 10:28:39,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20b9ffc57-b624-4e96-b145-25f3e9d1e71e, dataSize=2362, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068073574413
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2362
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:39,853 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,860 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,880 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,882 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,884 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,910 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,936 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,954 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:39,997 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:39,999 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:40,015 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068088254479
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:40,022 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068088254479 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:40,026 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068088254479 bcsId: 0,size=2350]} | ret=SUCCESS |  
2019-09-12 10:28:40,043 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=2350, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068088254479
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2350
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:40,045 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=null} | ret=SUCCESS |  
2019-09-12 10:28:40,047 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:40,078 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/} | ret=SUCCESS |  
2019-09-12 10:28:40,094 [IPC Server handler 15 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-0_96 to index:96
2019-09-12 10:28:40,096 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_0-96
2019-09-12 10:28:40,100 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97
2019-09-12 10:28:40,111 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:40,113 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:40,118 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068095725585
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:40,123 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068095725585 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:40,126 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068095725585 bcsId: 0,size=2367]} | ret=SUCCESS |  
2019-09-12 10:28:40,138 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e, dataSize=2367, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068095725585
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2367
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:40,140 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/} | ret=SUCCESS |  
2019-09-12 10:28:40,142 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4fc4945f-23f3-4d7a-9271-628cb5a748bb, bucket=37a60284-3e96-4841-a015-606f704509aa, key=dir1/dir20199b688-2422-4861-9c47-59f2bd943a3e} | ret=SUCCESS |  
2019-09-12 10:28:40,143 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 899d1352-6994-4d63-b6dd-297a16d34ac2, with jenkins1000 as owner.
2019-09-12 10:28:40,165 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=899d1352-6994-4d63-b6dd-297a16d34ac2, creationTime=1568284120144, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:40,166 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=899d1352-6994-4d63-b6dd-297a16d34ac2} | ret=SUCCESS |  
2019-09-12 10:28:40,167 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 899d1352-6994-4d63-b6dd-297a16d34ac2/428cc993-fc97-40c3-985a-012d5f53eafd, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:40,181 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=899d1352-6994-4d63-b6dd-297a16d34ac2, bucket=428cc993-fc97-40c3-985a-012d5f53eafd, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284120168} | ret=SUCCESS |  
2019-09-12 10:28:40,183 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=899d1352-6994-4d63-b6dd-297a16d34ac2, bucket=428cc993-fc97-40c3-985a-012d5f53eafd} | ret=SUCCESS |  
2019-09-12 10:28:40,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=899d1352-6994-4d63-b6dd-297a16d34ac2, bucket=428cc993-fc97-40c3-985a-012d5f53eafd} | ret=SUCCESS |  
2019-09-12 10:28:40,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=899d1352-6994-4d63-b6dd-297a16d34ac2, bucket=428cc993-fc97-40c3-985a-012d5f53eafd, key=null} | ret=SUCCESS |  
2019-09-12 10:28:40,197 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: fa9120f1-3182-421a-aeeb-74846de9fa00, with jenkins1000 as owner.
2019-09-12 10:28:40,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:40,211 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=fa9120f1-3182-421a-aeeb-74846de9fa00, creationTime=1568284120199, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:40,213 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=fa9120f1-3182-421a-aeeb-74846de9fa00} | ret=SUCCESS |  
2019-09-12 10:28:40,214 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: fa9120f1-3182-421a-aeeb-74846de9fa00/630e8f37-0b9f-4d3b-a1ff-23550c894f04, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:40,223 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=fa9120f1-3182-421a-aeeb-74846de9fa00, bucket=630e8f37-0b9f-4d3b-a1ff-23550c894f04, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284120215} | ret=SUCCESS |  
2019-09-12 10:28:40,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=fa9120f1-3182-421a-aeeb-74846de9fa00, bucket=630e8f37-0b9f-4d3b-a1ff-23550c894f04} | ret=SUCCESS |  
2019-09-12 10:28:40,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:40,245 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=fa9120f1-3182-421a-aeeb-74846de9fa00, bucket=630e8f37-0b9f-4d3b-a1ff-23550c894f04, key=d8e427be-35c6-47c9-b04d-1e65bb1e1cc4, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779068103327763
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:40,315 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=18, FAILED org.apache.ratis.protocol.NotLeaderException: Server 969f621b-625a-4660-bcba-147498526acd is not the leader (null). Request must be sent to leader., logIndex=0, commits[969f621b-625a-4660-bcba-147498526acd:c-1]
2019-09-12 10:28:40,421 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:40,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:41,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:41,422 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:41,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:42,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:42,340 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=18, FAILED org.apache.ratis.protocol.NotLeaderException: Server 969f621b-625a-4660-bcba-147498526acd is not the leader (null). Request must be sent to leader., logIndex=0, commits[969f621b-625a-4660-bcba-147498526acd:c-1]
2019-09-12 10:28:42,413 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 changes to CANDIDATE, lastRpcTime:5059, electionTimeout:5059ms
2019-09-12 10:28:42,414 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969f621b-625a-4660-bcba-147498526acd: shutdown FollowerState
2019-09-12 10:28:42,415 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,415 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderElection
2019-09-12 10:28:42,422 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:42,432 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2: begin an election at term 1 for -1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null
2019-09-12 10:28:42,433 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderElection
2019-09-12 10:28:42,433 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:42,433 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 change Leader from null to 969f621b-625a-4660-bcba-147498526acd at term 1 for becomeLeader, leader elected after 5086ms
2019-09-12 10:28:42,434 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:42,434 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:42,434 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:42,434 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:42,434 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:42,434 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:42,435 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderState
2019-09-12 10:28:42,435 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436: Starting segment from index:0
2019-09-12 10:28:42,436 [969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 set configuration 0: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null at 0
2019-09-12 10:28:42,484 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436/current/log_inprogress_0
2019-09-12 10:28:42,684 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(106)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 changes to CANDIDATE, lastRpcTime:5155, electionTimeout:5155ms
2019-09-12 10:28:42,685 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown FollowerState
2019-09-12 10:28:42,685 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,685 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderElection
2019-09-12 10:28:42,703 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3: begin an election at term 1 for -1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null
2019-09-12 10:28:42,703 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderElection
2019-09-12 10:28:42,703 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:42,703 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 change Leader from null to 349939a8-0e84-4617-9a16-3efaa8718099 at term 1 for becomeLeader, leader elected after 5181ms
2019-09-12 10:28:42,703 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:42,704 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:42,704 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:42,704 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:42,704 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:42,704 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:42,705 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderState
2019-09-12 10:28:42,705 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4: Starting segment from index:0
2019-09-12 10:28:42,705 [349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 set configuration 0: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null at 0
2019-09-12 10:28:42,751 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4/current/log_inprogress_0
2019-09-12 10:28:42,754 [Thread-190] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 changes to CANDIDATE, lastRpcTime:5153, electionTimeout:5153ms
2019-09-12 10:28:42,754 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969f621b-625a-4660-bcba-147498526acd: shutdown FollowerState
2019-09-12 10:28:42,754 [Thread-190] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,754 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderElection
2019-09-12 10:28:42,765 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4: begin an election at term 1 for -1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null
2019-09-12 10:28:42,765 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderElection
2019-09-12 10:28:42,765 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:42,765 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 change Leader from null to 969f621b-625a-4660-bcba-147498526acd at term 1 for becomeLeader, leader elected after 5170ms
2019-09-12 10:28:42,765 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:42,766 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:42,766 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:42,766 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:42,766 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:42,766 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:42,767 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderState
2019-09-12 10:28:42,767 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5: Starting segment from index:0
2019-09-12 10:28:42,767 [969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 set configuration 0: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null at 0
2019-09-12 10:28:42,809 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5/current/log_inprogress_0
2019-09-12 10:28:42,814 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(106)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 changes to CANDIDATE, lastRpcTime:5150, electionTimeout:5150ms
2019-09-12 10:28:42,814 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown FollowerState
2019-09-12 10:28:42,814 [Thread-193] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,815 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderElection
2019-09-12 10:28:42,827 [Thread-196] INFO  impl.FollowerState (FollowerState.java:run(106)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 changes to CANDIDATE, lastRpcTime:5100, electionTimeout:5100ms
2019-09-12 10:28:42,827 [Thread-196] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown FollowerState
2019-09-12 10:28:42,827 [Thread-196] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,828 [Thread-196] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderElection
2019-09-12 10:28:42,831 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5: begin an election at term 1 for -1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null
2019-09-12 10:28:42,831 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderElection
2019-09-12 10:28:42,831 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:42,831 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 change Leader from null to bdedf58a-a481-4a9e-93e6-4446fa864847 at term 1 for becomeLeader, leader elected after 5172ms
2019-09-12 10:28:42,831 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:42,832 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:42,832 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:42,832 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:42,832 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:42,832 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:42,833 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderState
2019-09-12 10:28:42,833 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6: Starting segment from index:0
2019-09-12 10:28:42,833 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 set configuration 0: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null at 0
2019-09-12 10:28:42,861 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6: begin an election at term 1 for -1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null
2019-09-12 10:28:42,861 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderElection
2019-09-12 10:28:42,861 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:42,861 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 change Leader from null to 349939a8-0e84-4617-9a16-3efaa8718099 at term 1 for becomeLeader, leader elected after 5139ms
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderState
2019-09-12 10:28:42,862 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539: Starting segment from index:0
2019-09-12 10:28:42,863 [349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 set configuration 0: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null at 0
2019-09-12 10:28:42,896 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6/current/log_inprogress_0
2019-09-12 10:28:42,909 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539/current/log_inprogress_0
2019-09-12 10:28:42,933 [Thread-205] INFO  impl.FollowerState (FollowerState.java:run(106)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB changes to CANDIDATE, lastRpcTime:5009, electionTimeout:5009ms
2019-09-12 10:28:42,933 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown FollowerState
2019-09-12 10:28:42,933 [Thread-205] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,933 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderElection
2019-09-12 10:28:42,939 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:42,962 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7: begin an election at term 1 for -1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null
2019-09-12 10:28:42,963 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderElection
2019-09-12 10:28:42,963 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:42,963 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB change Leader from null to 349939a8-0e84-4617-9a16-3efaa8718099 at term 1 for becomeLeader, leader elected after 5043ms
2019-09-12 10:28:42,963 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:42,963 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:42,963 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:42,964 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:42,964 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:42,964 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:42,964 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderState
2019-09-12 10:28:42,964 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb: Starting segment from index:0
2019-09-12 10:28:42,965 [349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB set configuration 0: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null at 0
2019-09-12 10:28:42,993 [Thread-199] INFO  impl.FollowerState (FollowerState.java:run(106)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 changes to CANDIDATE, lastRpcTime:5195, electionTimeout:5172ms
2019-09-12 10:28:42,994 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown FollowerState
2019-09-12 10:28:42,994 [Thread-199] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:42,994 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderElection
2019-09-12 10:28:43,006 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb/current/log_inprogress_0
2019-09-12 10:28:43,006 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8: begin an election at term 1 for -1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderElection
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 change Leader from null to bdedf58a-a481-4a9e-93e6-4446fa864847 at term 1 for becomeLeader, leader elected after 5214ms
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,007 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,008 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,008 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,008 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderState
2019-09-12 10:28:43,008 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01: Starting segment from index:0
2019-09-12 10:28:43,009 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 set configuration 0: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null at 0
2019-09-12 10:28:43,040 [Thread-202] INFO  impl.FollowerState (FollowerState.java:run(106)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C changes to CANDIDATE, lastRpcTime:5175, electionTimeout:5175ms
2019-09-12 10:28:43,040 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown FollowerState
2019-09-12 10:28:43,040 [Thread-202] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,040 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderElection
2019-09-12 10:28:43,052 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01/current/log_inprogress_0
2019-09-12 10:28:43,053 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9: begin an election at term 1 for -1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null
2019-09-12 10:28:43,053 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderElection
2019-09-12 10:28:43,053 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,053 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C change Leader from null to 349939a8-0e84-4617-9a16-3efaa8718099 at term 1 for becomeLeader, leader elected after 5194ms
2019-09-12 10:28:43,053 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,054 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,054 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,054 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,054 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,054 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,055 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderState
2019-09-12 10:28:43,055 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c: Starting segment from index:0
2019-09-12 10:28:43,056 [349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C set configuration 0: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null at 0
2019-09-12 10:28:43,102 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c/current/log_inprogress_0
2019-09-12 10:28:43,106 [Thread-208] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 changes to CANDIDATE, lastRpcTime:5122, electionTimeout:5122ms
2019-09-12 10:28:43,106 [Thread-208] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969f621b-625a-4660-bcba-147498526acd: shutdown FollowerState
2019-09-12 10:28:43,106 [Thread-208] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,106 [Thread-208] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderElection
2019-09-12 10:28:43,115 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10: begin an election at term 1 for -1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null
2019-09-12 10:28:43,115 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderElection
2019-09-12 10:28:43,115 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,115 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 change Leader from null to 969f621b-625a-4660-bcba-147498526acd at term 1 for becomeLeader, leader elected after 5137ms
2019-09-12 10:28:43,115 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,116 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,116 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,116 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,116 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,116 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,116 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderState
2019-09-12 10:28:43,117 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142: Starting segment from index:0
2019-09-12 10:28:43,117 [969f621b-625a-4660-bcba-147498526acd:group-4E0965901142:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 set configuration 0: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null at 0
2019-09-12 10:28:43,155 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142/current/log_inprogress_0
2019-09-12 10:28:43,208 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD changes to CANDIDATE, lastRpcTime:5147, electionTimeout:5147ms
2019-09-12 10:28:43,208 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969f621b-625a-4660-bcba-147498526acd: shutdown FollowerState
2019-09-12 10:28:43,208 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,209 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderElection
2019-09-12 10:28:43,212 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:43,225 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11: begin an election at term 1 for -1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null
2019-09-12 10:28:43,225 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderElection
2019-09-12 10:28:43,225 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,226 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD change Leader from null to 969f621b-625a-4660-bcba-147498526acd at term 1 for becomeLeader, leader elected after 5169ms
2019-09-12 10:28:43,226 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,226 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,226 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,226 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,226 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,227 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,227 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderState
2019-09-12 10:28:43,227 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd: Starting segment from index:0
2019-09-12 10:28:43,228 [969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD set configuration 0: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null at 0
2019-09-12 10:28:43,265 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd/current/log_inprogress_0
2019-09-12 10:28:43,291 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 changes to CANDIDATE, lastRpcTime:5166, electionTimeout:5166ms
2019-09-12 10:28:43,292 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown FollowerState
2019-09-12 10:28:43,292 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,292 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderElection
2019-09-12 10:28:43,299 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 changes to CANDIDATE, lastRpcTime:5063, electionTimeout:5063ms
2019-09-12 10:28:43,299 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown FollowerState
2019-09-12 10:28:43,299 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,300 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderElection
2019-09-12 10:28:43,307 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12: begin an election at term 1 for -1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null
2019-09-12 10:28:43,307 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13: begin an election at term 1 for -1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null
2019-09-12 10:28:43,307 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderElection
2019-09-12 10:28:43,307 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderElection
2019-09-12 10:28:43,308 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,308 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,308 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 change Leader from null to 349939a8-0e84-4617-9a16-3efaa8718099 at term 1 for becomeLeader, leader elected after 5187ms
2019-09-12 10:28:43,308 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 change Leader from null to bdedf58a-a481-4a9e-93e6-4446fa864847 at term 1 for becomeLeader, leader elected after 5076ms
2019-09-12 10:28:43,308 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,308 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,308 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,308 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,308 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,309 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,309 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,309 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,309 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,309 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,309 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,309 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,309 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderState
2019-09-12 10:28:43,309 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderState
2019-09-12 10:28:43,310 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831: Starting segment from index:0
2019-09-12 10:28:43,310 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828: Starting segment from index:0
2019-09-12 10:28:43,310 [349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 set configuration 0: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null at 0
2019-09-12 10:28:43,310 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 set configuration 0: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null at 0
2019-09-12 10:28:43,348 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 changes to CANDIDATE, lastRpcTime:5167, electionTimeout:5149ms
2019-09-12 10:28:43,349 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969f621b-625a-4660-bcba-147498526acd: shutdown FollowerState
2019-09-12 10:28:43,350 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,351 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderElection
2019-09-12 10:28:43,360 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831/current/log_inprogress_0
2019-09-12 10:28:43,360 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14: begin an election at term 1 for -1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null
2019-09-12 10:28:43,360 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828/current/log_inprogress_0
2019-09-12 10:28:43,361 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderElection
2019-09-12 10:28:43,361 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,361 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 change Leader from null to 969f621b-625a-4660-bcba-147498526acd at term 1 for becomeLeader, leader elected after 5185ms
2019-09-12 10:28:43,361 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,361 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,362 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,362 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,362 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,362 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,362 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderState
2019-09-12 10:28:43,363 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850: Starting segment from index:0
2019-09-12 10:28:43,363 [969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 set configuration 0: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null at 0
2019-09-12 10:28:43,404 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850/current/log_inprogress_0
2019-09-12 10:28:43,421 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:43,440 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 changes to CANDIDATE, lastRpcTime:5126, electionTimeout:5126ms
2019-09-12 10:28:43,440 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown FollowerState
2019-09-12 10:28:43,440 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,440 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderElection
2019-09-12 10:28:43,457 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15: begin an election at term 1 for -1: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null
2019-09-12 10:28:43,457 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderElection
2019-09-12 10:28:43,458 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,458 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 change Leader from null to 349939a8-0e84-4617-9a16-3efaa8718099 at term 1 for becomeLeader, leader elected after 5148ms
2019-09-12 10:28:43,458 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,458 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,458 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,458 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,459 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,459 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,459 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 349939a8-0e84-4617-9a16-3efaa8718099: start LeaderState
2019-09-12 10:28:43,459 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6: Starting segment from index:0
2019-09-12 10:28:43,460 [349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 set configuration 0: [349939a8-0e84-4617-9a16-3efaa8718099:192.168.157.195:43393], old=null at 0
2019-09-12 10:28:43,522 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6/current/log_inprogress_0
2019-09-12 10:28:43,543 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 changes to CANDIDATE, lastRpcTime:5153, electionTimeout:5153ms
2019-09-12 10:28:43,543 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969f621b-625a-4660-bcba-147498526acd: shutdown FollowerState
2019-09-12 10:28:43,543 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,543 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderElection
2019-09-12 10:28:43,560 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16: begin an election at term 1 for -1: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null
2019-09-12 10:28:43,560 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderElection
2019-09-12 10:28:43,561 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,561 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 change Leader from null to 969f621b-625a-4660-bcba-147498526acd at term 1 for becomeLeader, leader elected after 5176ms
2019-09-12 10:28:43,561 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,561 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,561 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,561 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,562 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,562 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,562 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969f621b-625a-4660-bcba-147498526acd: start LeaderState
2019-09-12 10:28:43,562 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349: Starting segment from index:0
2019-09-12 10:28:43,563 [969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 set configuration 0: [969f621b-625a-4660-bcba-147498526acd:192.168.157.195:44966], old=null at 0
2019-09-12 10:28:43,596 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 changes to CANDIDATE, lastRpcTime:5096, electionTimeout:5079ms
2019-09-12 10:28:43,596 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 changes to CANDIDATE, lastRpcTime:5037, electionTimeout:5007ms
2019-09-12 10:28:43,596 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(106)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE changes to CANDIDATE, lastRpcTime:5151, electionTimeout:5128ms
2019-09-12 10:28:43,597 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown FollowerState
2019-09-12 10:28:43,597 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,596 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown FollowerState
2019-09-12 10:28:43,597 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderElection
2019-09-12 10:28:43,597 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown FollowerState
2019-09-12 10:28:43,597 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,597 [Thread-233] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:28:43,601 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderElection
2019-09-12 10:28:43,601 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderElection
2019-09-12 10:28:43,610 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349/current/log_inprogress_0
2019-09-12 10:28:43,611 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17: begin an election at term 1 for -1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null
2019-09-12 10:28:43,611 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderElection
2019-09-12 10:28:43,611 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,611 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 change Leader from null to bdedf58a-a481-4a9e-93e6-4446fa864847 at term 1 for becomeLeader, leader elected after 5054ms
2019-09-12 10:28:43,611 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,611 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19: begin an election at term 1 for -1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18: begin an election at term 1 for -1: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderElection
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderElection
2019-09-12 10:28:43,613 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderState
2019-09-12 10:28:43,612 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,613 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:28:43,613 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1: Starting segment from index:0
2019-09-12 10:28:43,613 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE change Leader from null to bdedf58a-a481-4a9e-93e6-4446fa864847 at term 1 for becomeLeader, leader elected after 5172ms
2019-09-12 10:28:43,613 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 change Leader from null to bdedf58a-a481-4a9e-93e6-4446fa864847 at term 1 for becomeLeader, leader elected after 5116ms
2019-09-12 10:28:43,613 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,614 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:28:43,614 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 set configuration 0: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null at 0
2019-09-12 10:28:43,614 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,614 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:28:43,650 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,651 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:28:43,652 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderState
2019-09-12 10:28:43,652 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdedf58a-a481-4a9e-93e6-4446fa864847: start LeaderState
2019-09-12 10:28:43,652 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce: Starting segment from index:0
2019-09-12 10:28:43,652 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38: Starting segment from index:0
2019-09-12 10:28:43,653 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE set configuration 0: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null at 0
2019-09-12 10:28:43,653 [bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 set configuration 0: [bdedf58a-a481-4a9e-93e6-4446fa864847:192.168.157.195:42442], old=null at 0
2019-09-12 10:28:43,689 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1/current/log_inprogress_0
2019-09-12 10:28:43,702 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38/current/log_inprogress_0
2019-09-12 10:28:43,702 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce/current/log_inprogress_0
2019-09-12 10:28:43,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,422 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,455 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779068103327763 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:44,456 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,489 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779068103327763 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:44,497 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=18, SUCCESS, logIndex=1, commits[969f621b-625a-4660-bcba-147498526acd:c1]
2019-09-12 10:28:44,562 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779068103327763 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:44,567 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-EB51C354D460->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=19, SUCCESS, logIndex=3, commits[969f621b-625a-4660-bcba-147498526acd:c4]
2019-09-12 10:28:44,588 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=fa9120f1-3182-421a-aeeb-74846de9fa00, bucket=630e8f37-0b9f-4d3b-a1ff-23550c894f04, key=d8e427be-35c6-47c9-b04d-1e65bb1e1cc4, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779068103327763
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:44,592 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:44,595 [IPC Server handler 8 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:44,595 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:44,596 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=fa9120f1-3182-421a-aeeb-74846de9fa00, bucket=630e8f37-0b9f-4d3b-a1ff-23550c894f04, key=d8e427be-35c6-47c9-b04d-1e65bb1e1cc4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:44,666 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:44,668 [IPC Server handler 9 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:44,668 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:44,669 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=fa9120f1-3182-421a-aeeb-74846de9fa00, bucket=630e8f37-0b9f-4d3b-a1ff-23550c894f04, key=d8e427be-35c6-47c9-b04d-1e65bb1e1cc4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:44,719 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779068103327763 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:44,743 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779068103327763 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:44,747 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b045a8c0-58dd-4ae2-a95f-c2c9c045a049, with jenkins1000 as owner.
2019-09-12 10:28:44,761 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, creationTime=1568284124748, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:44,763 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049} | ret=SUCCESS |  
2019-09-12 10:28:44,764 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b045a8c0-58dd-4ae2-a95f-c2c9c045a049/849101df-3f73-43c4-9c89-d2467e1aa681, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:44,773 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, bucket=849101df-3f73-43c4-9c89-d2467e1aa681, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284124765} | ret=SUCCESS |  
2019-09-12 10:28:44,775 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, bucket=849101df-3f73-43c4-9c89-d2467e1aa681} | ret=SUCCESS |  
2019-09-12 10:28:44,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, bucket=849101df-3f73-43c4-9c89-d2467e1aa681, key=null} | ret=SUCCESS |  
2019-09-12 10:28:44,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, bucket=849101df-3f73-43c4-9c89-d2467e1aa681, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-12 10:28:44,802 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, bucket=849101df-3f73-43c4-9c89-d2467e1aa681} | ret=SUCCESS |  
2019-09-12 10:28:44,803 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=b045a8c0-58dd-4ae2-a95f-c2c9c045a049, bucket=849101df-3f73-43c4-9c89-d2467e1aa681, key=null} | ret=SUCCESS |  
2019-09-12 10:28:44,805 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: bfc819d8-be90-4aa1-8b59-0db147c91c96, with jenkins1000 as owner.
2019-09-12 10:28:44,810 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, creationTime=1568284124806, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:44,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96} | ret=SUCCESS |  
2019-09-12 10:28:44,813 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: bfc819d8-be90-4aa1-8b59-0db147c91c96/66fdc6a0-d56f-4063-85ad-36ccba66a3ad, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:44,826 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284124814} | ret=SUCCESS |  
2019-09-12 10:28:44,828 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad} | ret=SUCCESS |  
2019-09-12 10:28:44,838 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,855 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,859 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:44,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068405645334} | ret=SUCCESS |  
2019-09-12 10:28:44,907 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068406759447 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:44,912 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068406759447 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:44,927 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068406759447 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:44,932 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068406759447 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:44,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:44,948 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068406759447 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:44,954 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068406759447 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:44,967 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068406759447 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:44,973 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068406759447 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:44,977 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:44,991 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068405645334} | ret=SUCCESS |  
2019-09-12 10:28:45,004 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068414492696 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,008 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068414492696 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:45,049 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068406759447
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068414492696
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:45,068 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,072 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:45,080 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068419538969} | ret=SUCCESS |  
2019-09-12 10:28:45,095 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068420718618 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,099 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068420718618 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:45,112 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068420718618 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,116 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068420718618 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:45,128 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068420718618 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,133 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068420718618 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:45,144 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068420718618 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,148 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068420718618 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:45,151 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:45,165 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068419538969} | ret=SUCCESS |  
2019-09-12 10:28:45,176 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068425895963 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,181 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068425895963 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:45,195 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068420718618
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068425895963
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:45,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:45,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,222 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068429041692} | ret=SUCCESS |  
2019-09-12 10:28:45,234 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068429631517 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,239 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068429631517 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:45,249 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068429631517 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,255 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068429631517 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:45,266 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068429631517 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,272 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068429631517 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:45,282 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068429631517 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,288 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068429631517 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:45,291 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:45,305 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068429041692} | ret=SUCCESS |  
2019-09-12 10:28:45,316 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068435071006 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:45,320 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068435071006 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:45,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, key=0a038b3e-5ba4-4816-abee-85803fb0489f, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068429631517
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068435071006
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:45,349 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=bfc819d8-be90-4aa1-8b59-0db147c91c96, bucket=66fdc6a0-d56f-4063-85ad-36ccba66a3ad, uploadID=08b842d6-2884-4324-bee3-408b3734cdef-102779068404858901, partNumberMarker=0, maxParts=3, key=0a038b3e-5ba4-4816-abee-85803fb0489f} | ret=SUCCESS |  
2019-09-12 10:28:45,355 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, with jenkins1000 as owner.
2019-09-12 10:28:45,369 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, creationTime=1568284125356, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:45,371 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c} | ret=SUCCESS |  
2019-09-12 10:28:45,372 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 239c78d7-2b1a-4c7e-be6b-d9c7ae30905c/5725af49-0952-4bca-9a08-d7bc2d60a7cf, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,393 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125373} | ret=SUCCESS |  
2019-09-12 10:28:45,394 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf} | ret=SUCCESS |  
2019-09-12 10:28:45,421 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,422 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,434 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,435 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,455 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,466 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,480 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,492 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,494 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf} | ret=SUCCESS |  
2019-09-12 10:28:45,558 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 239c78d7-2b1a-4c7e-be6b-d9c7ae30905c/5725af49-0952-4bca-9a08-d7bc2d60a7cf, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,572 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:remoteUser:r[ACCESS], group:remoteGroup:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125559} | ret=SUCCESS |  
2019-09-12 10:28:45,575 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=239c78d7-2b1a-4c7e-be6b-d9c7ae30905c, bucket=5725af49-0952-4bca-9a08-d7bc2d60a7cf, key=null} | ret=SUCCESS |  
2019-09-12 10:28:45,596 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {b4461894-fdf2-4e92-8111-1e0b8d83901f=s3Bucket} | ret=FAILURE | S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket b4461894-fdf2-4e92-8111-1e0b8d83901f not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:45,598 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.S3BucketDeleteRequest (S3BucketDeleteRequest.java:validateAndUpdateCache(175)) - S3Bucket Deletion failed for S3Bucket:b4461894-fdf2-4e92-8111-1e0b8d83901f
S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket b4461894-fdf2-4e92-8111-1e0b8d83901f not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:45,602 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: dc6af335-e4f3-4d20-8480-2ac668c99fc5, with jenkins1000 as owner.
2019-09-12 10:28:45,608 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=dc6af335-e4f3-4d20-8480-2ac668c99fc5, creationTime=1568284125603, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:45,610 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=dc6af335-e4f3-4d20-8480-2ac668c99fc5} | ret=SUCCESS |  
2019-09-12 10:28:45,611 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: dc6af335-e4f3-4d20-8480-2ac668c99fc5/708ae97b-370f-4d1a-9cb1-cd9695ff6c7b, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,625 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=dc6af335-e4f3-4d20-8480-2ac668c99fc5, bucket=708ae97b-370f-4d1a-9cb1-cd9695ff6c7b, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125612} | ret=SUCCESS |  
2019-09-12 10:28:45,627 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=dc6af335-e4f3-4d20-8480-2ac668c99fc5, bucket=708ae97b-370f-4d1a-9cb1-cd9695ff6c7b} | ret=SUCCESS |  
2019-09-12 10:28:45,629 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=dc6af335-e4f3-4d20-8480-2ac668c99fc5, bucket=708ae97b-370f-4d1a-9cb1-cd9695ff6c7b, uploadID=random, partNumberMarker=100, maxParts=2, key=0ae9342c-48af-4fe6-9d77-4335d3a89797} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No Such Multipart upload exists for this key.
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listParts(KeyManagerImpl.java:1294)
	at org.apache.hadoop.ozone.om.OzoneManager.listParts(OzoneManager.java:2846) 
2019-09-12 10:28:45,632 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ff751ac6-7bfb-412c-8caa-ecb7b8871c1e, with jenkins1000 as owner.
2019-09-12 10:28:45,634 [IPC Server handler 18 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-97_190 to index:190
2019-09-12 10:28:45,635 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_97-190
2019-09-12 10:28:45,647 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191
2019-09-12 10:28:45,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ff751ac6-7bfb-412c-8caa-ecb7b8871c1e, creationTime=1568284125633, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:45,650 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ff751ac6-7bfb-412c-8caa-ecb7b8871c1e} | ret=SUCCESS |  
2019-09-12 10:28:45,651 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ff751ac6-7bfb-412c-8caa-ecb7b8871c1e/ee54c48b-2323-4a9d-a66c-f2bfd7901429, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,663 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ff751ac6-7bfb-412c-8caa-ecb7b8871c1e, bucket=ee54c48b-2323-4a9d-a66c-f2bfd7901429, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125652} | ret=SUCCESS |  
2019-09-12 10:28:45,664 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ff751ac6-7bfb-412c-8caa-ecb7b8871c1e, bucket=ee54c48b-2323-4a9d-a66c-f2bfd7901429} | ret=SUCCESS |  
2019-09-12 10:28:45,668 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=ff751ac6-7bfb-412c-8caa-ecb7b8871c1e, bucket=ee54c48b-2323-4a9d-a66c-f2bfd7901429, key=9c5e9bfe-4020-4298-8008-9e05e9980372, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,673 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ff751ac6-7bfb-412c-8caa-ecb7b8871c1e, bucket=ee54c48b-2323-4a9d-a66c-f2bfd7901429, key=9c5e9bfe-4020-4298-8008-9e05e9980372, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,675 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,675 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,676 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,676 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,676 [IPC Server handler 13 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,676 [IPC Server handler 13 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,676 [IPC Server handler 13 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,676 [IPC Server handler 13 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,677 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,677 [IPC Server handler 6 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38663, call Call#250 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,679 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663. Trying to failover immediately.
2019-09-12 10:28:45,681 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,681 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,682 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,682 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,682 [IPC Server handler 15 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,682 [IPC Server handler 15 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,683 [IPC Server handler 15 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,683 [IPC Server handler 15 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,683 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,684 [IPC Server handler 4 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38663, call Call#250 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,685 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,687 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,687 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,687 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,687 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,687 [IPC Server handler 12 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,687 [IPC Server handler 12 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,688 [IPC Server handler 12 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,688 [IPC Server handler 12 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,688 [IPC Server handler 3 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 38663, call Call#250 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,690 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,691 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,691 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,692 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,692 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,692 [IPC Server handler 10 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,692 [IPC Server handler 10 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,693 [IPC Server handler 10 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,693 [IPC Server handler 10 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,693 [IPC Server handler 2 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 38663, call Call#250 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,695 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,696 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,696 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,696 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,697 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,697 [IPC Server handler 14 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,697 [IPC Server handler 14 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,697 [IPC Server handler 14 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,698 [IPC Server handler 14 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,698 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,698 [IPC Server handler 1 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 38663, call Call#250 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,699 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,701 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,701 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,701 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,701 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,701 [IPC Server handler 16 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,702 [IPC Server handler 16 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,702 [IPC Server handler 16 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,702 [IPC Server handler 16 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,702 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,703 [IPC Server handler 0 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 38663, call Call#250 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,704 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,706 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,706 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,706 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,706 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,707 [IPC Server handler 17 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,707 [IPC Server handler 17 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,707 [IPC Server handler 17 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,707 [IPC Server handler 17 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,707 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,708 [IPC Server handler 5 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38663, call Call#250 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,710 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,712 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,712 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,712 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,712 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,712 [IPC Server handler 18 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,713 [IPC Server handler 18 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,713 [IPC Server handler 18 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,713 [IPC Server handler 18 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,713 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,714 [IPC Server handler 12 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38663, call Call#250 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,716 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,717 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,718 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,718 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,718 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,718 [IPC Server handler 19 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,718 [IPC Server handler 19 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,719 [IPC Server handler 19 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,719 [IPC Server handler 19 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,719 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,720 [IPC Server handler 14 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 38663, call Call#250 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,721 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,723 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,723 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,723 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,723 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,723 [IPC Server handler 7 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,723 [IPC Server handler 7 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,724 [IPC Server handler 7 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,724 [IPC Server handler 7 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,724 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,724 [IPC Server handler 13 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 38663, call Call#250 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,726 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:28:45,727 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,728 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:45,728 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:45,728 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,728 [IPC Server handler 2 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:45,728 [IPC Server handler 2 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,729 [IPC Server handler 2 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:45,729 [IPC Server handler 2 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:45,729 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:45,729 [IPC Server handler 16 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38663, call Call#250 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:45,731 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:28:45,731 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testUploadPartOverrideWithRatis(TestOzoneRpcClientAbstract.java:1773)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:28:45,733 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-99557, with jenkins1000 as owner.
2019-09-12 10:28:45,780 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-99557, creationTime=1568284125734, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:45,782 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-94394, with jenkins1000 as owner.
2019-09-12 10:28:45,791 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-94394, creationTime=1568284125783, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:45,793 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-99557} | ret=SUCCESS |  
2019-09-12 10:28:45,794 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-94394} | ret=SUCCESS |  
2019-09-12 10:28:45,795 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-0-58520, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,809 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-0-58520, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125796} | ret=SUCCESS |  
2019-09-12 10:28:45,810 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-0-52909, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,820 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-0-52909, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125811} | ret=SUCCESS |  
2019-09-12 10:28:45,821 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-1-74103, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,834 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-1-74103, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125822} | ret=SUCCESS |  
2019-09-12 10:28:45,834 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-1-33759, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,848 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-1-33759, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125835} | ret=SUCCESS |  
2019-09-12 10:28:45,849 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-2-36624, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,860 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-2-36624, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125849} | ret=SUCCESS |  
2019-09-12 10:28:45,860 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-2-66602, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,873 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-2-66602, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125861} | ret=SUCCESS |  
2019-09-12 10:28:45,874 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-3-52849, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,886 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-3-52849, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125874} | ret=SUCCESS |  
2019-09-12 10:28:45,887 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-3-93981, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,900 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-3-93981, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125888} | ret=SUCCESS |  
2019-09-12 10:28:45,901 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-4-51863, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,914 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-4-51863, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125902} | ret=SUCCESS |  
2019-09-12 10:28:45,915 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-4-16945, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,918 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-4-16945, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125916} | ret=SUCCESS |  
2019-09-12 10:28:45,919 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-5-79256, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-5-79256, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125920} | ret=SUCCESS |  
2019-09-12 10:28:45,932 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-5-29085, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:45,940 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-5-29085, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125933} | ret=SUCCESS |  
2019-09-12 10:28:45,941 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-6-86561, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,952 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-6-86561, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125942} | ret=SUCCESS |  
2019-09-12 10:28:45,953 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-6-77968, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-6-77968, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125953} | ret=SUCCESS |  
2019-09-12 10:28:45,956 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-7-88155, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,959 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-7-88155, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125957} | ret=SUCCESS |  
2019-09-12 10:28:45,959 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-7-97273, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,971 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-7-97273, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125960} | ret=SUCCESS |  
2019-09-12 10:28:45,971 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-8-19630, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:45,982 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-8-19630, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125972} | ret=SUCCESS |  
2019-09-12 10:28:45,982 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-8-12330, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,005 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-8-12330, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284125983} | ret=SUCCESS |  
2019-09-12 10:28:46,006 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-a-9-61704, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,016 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-a-9-61704, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126007} | ret=SUCCESS |  
2019-09-12 10:28:46,017 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-a-9-36290, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,030 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-a-9-36290, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126018} | ret=SUCCESS |  
2019-09-12 10:28:46,030 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-0-17617, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,044 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-0-17617, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126031} | ret=SUCCESS |  
2019-09-12 10:28:46,045 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-0-26214, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,055 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-0-26214, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126046} | ret=SUCCESS |  
2019-09-12 10:28:46,056 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-1-77716, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,068 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-1-77716, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126056} | ret=SUCCESS |  
2019-09-12 10:28:46,069 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-1-41985, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,082 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-1-41985, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126070} | ret=SUCCESS |  
2019-09-12 10:28:46,082 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-2-81454, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,096 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-2-81454, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126083} | ret=SUCCESS |  
2019-09-12 10:28:46,097 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-2-97421, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,110 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-2-97421, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126098} | ret=SUCCESS |  
2019-09-12 10:28:46,111 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-3-37071, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,123 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-3-37071, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126111} | ret=SUCCESS |  
2019-09-12 10:28:46,124 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-3-58927, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,137 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-3-58927, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126125} | ret=SUCCESS |  
2019-09-12 10:28:46,138 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-4-10671, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,149 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-4-10671, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126139} | ret=SUCCESS |  
2019-09-12 10:28:46,150 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-4-33161, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,164 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-4-33161, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126151} | ret=SUCCESS |  
2019-09-12 10:28:46,164 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-5-08684, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,176 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-5-08684, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126165} | ret=SUCCESS |  
2019-09-12 10:28:46,176 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-5-51008, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,188 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-5-51008, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126177} | ret=SUCCESS |  
2019-09-12 10:28:46,189 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-6-27464, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,198 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-6-27464, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126189} | ret=SUCCESS |  
2019-09-12 10:28:46,198 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-6-06416, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,210 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-6-06416, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126199} | ret=SUCCESS |  
2019-09-12 10:28:46,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:46,211 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-7-59702, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,220 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-7-59702, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126212} | ret=SUCCESS |  
2019-09-12 10:28:46,221 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-7-04901, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,224 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-7-04901, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126222} | ret=SUCCESS |  
2019-09-12 10:28:46,225 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-8-06213, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,236 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-8-06213, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126225} | ret=SUCCESS |  
2019-09-12 10:28:46,237 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-8-40060, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,264 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-8-40060, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126238} | ret=SUCCESS |  
2019-09-12 10:28:46,265 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-99557/bucket-b-9-35162, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-99557, bucket=bucket-b-9-35162, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126267} | ret=SUCCESS |  
2019-09-12 10:28:46,276 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-94394/bucket-b-9-68357, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,292 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-94394, bucket=bucket-b-9-68357, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126277} | ret=SUCCESS |  
2019-09-12 10:28:46,301 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,304 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=bucket-b-9-35162, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,308 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,309 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=bucket-b-9-35162, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,311 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,312 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=bucket-a-9-61704, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,314 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,315 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=bucket-b-9-35162, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,319 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-99557, startKey=bucket-b-9-35162, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,320 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-94394, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-94394, startKey=bucket-a-9-36290, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:46,322 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ec6e1158-aad6-4a16-8421-0f94d465a268, with jenkins1000 as owner.
2019-09-12 10:28:46,335 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ec6e1158-aad6-4a16-8421-0f94d465a268, creationTime=1568284126323, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:46,336 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ec6e1158-aad6-4a16-8421-0f94d465a268} | ret=SUCCESS |  
2019-09-12 10:28:46,337 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ec6e1158-aad6-4a16-8421-0f94d465a268/e4604ca1-2203-4121-9256-9b57465a4a0d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,347 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ec6e1158-aad6-4a16-8421-0f94d465a268, bucket=e4604ca1-2203-4121-9256-9b57465a4a0d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126337} | ret=SUCCESS |  
2019-09-12 10:28:46,348 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ec6e1158-aad6-4a16-8421-0f94d465a268, bucket=e4604ca1-2203-4121-9256-9b57465a4a0d} | ret=SUCCESS |  
2019-09-12 10:28:46,361 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=ec6e1158-aad6-4a16-8421-0f94d465a268, bucket=e4604ca1-2203-4121-9256-9b57465a4a0d, isVersionEnabled=null, storageType=SSD} | ret=SUCCESS |  
2019-09-12 10:28:46,363 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ec6e1158-aad6-4a16-8421-0f94d465a268, bucket=e4604ca1-2203-4121-9256-9b57465a4a0d} | ret=SUCCESS |  
2019-09-12 10:28:46,364 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 72381a95-4697-4340-abe2-5a57bfd99e59, with jenkins1000 as owner.
2019-09-12 10:28:46,377 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=72381a95-4697-4340-abe2-5a57bfd99e59, creationTime=1568284126365, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:46,378 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=72381a95-4697-4340-abe2-5a57bfd99e59} | ret=SUCCESS |  
2019-09-12 10:28:46,379 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 72381a95-4697-4340-abe2-5a57bfd99e59/5806c97d-53c3-4400-8937-c20ccf8fd179, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126380} | ret=SUCCESS |  
2019-09-12 10:28:46,389 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179} | ret=SUCCESS |  
2019-09-12 10:28:46,392 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:46,407 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179, key=eb5e6fd0-ca9d-4eb0-986a-30e49d0b1200, dataSize=290, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068507226145
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,412 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068507226145 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,415 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068507226145 bcsId: 0,size=290]} | ret=SUCCESS |  
2019-09-12 10:28:46,430 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179, key=eb5e6fd0-ca9d-4eb0-986a-30e49d0b1200, dataSize=290, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068507226145
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 290
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,432 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:46,434 [IPC Server handler 9 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:46,434 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:46,435 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179, key=eb5e6fd0-ca9d-4eb0-986a-30e49d0b1200, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:46,444 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779068507226145 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,449 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779068507226145 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,452 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:46,453 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179, key=eb5e6fd0-ca9d-4eb0-986a-30e49d0b1200, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:46,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:46,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:46,458 [IPC Server handler 13 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:46,458 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:46,459 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=72381a95-4697-4340-abe2-5a57bfd99e59, bucket=5806c97d-53c3-4400-8937-c20ccf8fd179, key=eb5e6fd0-ca9d-4eb0-986a-30e49d0b1200, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:46,465 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: f1e4de40-ca94-475a-a69a-b250e07c4410, with jenkins1000 as owner.
2019-09-12 10:28:46,478 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, creationTime=1568284126466, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:46,479 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f1e4de40-ca94-475a-a69a-b250e07c4410} | ret=SUCCESS |  
2019-09-12 10:28:46,480 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: f1e4de40-ca94-475a-a69a-b250e07c4410/0a6e34a9-67a3-42a4-8c09-04123ad95f56, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,489 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126480} | ret=SUCCESS |  
2019-09-12 10:28:46,490 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56} | ret=SUCCESS |  
2019-09-12 10:28:46,493 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:46,509 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068513779747
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,515 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068513779747 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,519 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068513779747 bcsId: 0,size=2378]} | ret=SUCCESS |  
2019-09-12 10:28:46,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=2378, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068513779747
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2378
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,543 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:46,553 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF3eb95eaf-847d-4244-9d1a-1178a65ab271/KEYbaf145c0-126b-47bb-ad2f-76d3678a5ef6, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068517122085
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,557 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068517122085 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,561 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068517122085 bcsId: 0,size=2388]} | ret=SUCCESS |  
2019-09-12 10:28:46,578 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF3eb95eaf-847d-4244-9d1a-1178a65ab271/KEYbaf145c0-126b-47bb-ad2f-76d3678a5ef6, dataSize=2388, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068517122085
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2388
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,590 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/} | ret=SUCCESS |  
2019-09-12 10:28:46,606 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/} | ret=SUCCESS |  
2019-09-12 10:28:46,622 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/} | ret=SUCCESS |  
2019-09-12 10:28:46,661 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:46,663 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:46,665 [IPC Server handler 9 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-191_320 to index:320
2019-09-12 10:28:46,665 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_191-320
2019-09-12 10:28:46,679 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321
2019-09-12 10:28:46,692 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068524986407
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,698 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068524986407 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,702 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068524986407 bcsId: 0,size=2377]} | ret=SUCCESS |  
2019-09-12 10:28:46,717 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=2377, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068524986407
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2377
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,719 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/} | ret=SUCCESS |  
2019-09-12 10:28:46,721 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a} | ret=SUCCESS |  
2019-09-12 10:28:46,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:46,767 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:46,774 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068531802153
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,779 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068531802153 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:46,782 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068531802153 bcsId: 0,size=2387]} | ret=SUCCESS |  
2019-09-12 10:28:46,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a, dataSize=2387, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068531802153
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2387
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:46,798 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF3eb95eaf-847d-4244-9d1a-1178a65ab271/} | ret=SUCCESS |  
2019-09-12 10:28:46,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=f1e4de40-ca94-475a-a69a-b250e07c4410, bucket=0a6e34a9-67a3-42a4-8c09-04123ad95f56, key=PF52911eef-94b9-4168-b2cd-acad686587cd/KEYf013289d-77c1-4ca3-8394-82a6a6c41a1a} | ret=SUCCESS |  
2019-09-12 10:28:46,801 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b1625f00-6443-45c6-96ff-411b5b1b4656, with jenkins1000 as owner.
2019-09-12 10:28:46,814 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b1625f00-6443-45c6-96ff-411b5b1b4656, creationTime=1568284126802, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:46,815 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b1625f00-6443-45c6-96ff-411b5b1b4656} | ret=SUCCESS |  
2019-09-12 10:28:46,816 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b1625f00-6443-45c6-96ff-411b5b1b4656/dc374372-6408-4b21-a818-6b11dd2f21f7, with Versioning true and Storage Type set to SSD and Encryption set to false 
2019-09-12 10:28:46,829 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b1625f00-6443-45c6-96ff-411b5b1b4656, bucket=dc374372-6408-4b21-a818-6b11dd2f21f7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=true, storageType=SSD, creationTime=1568284126817} | ret=SUCCESS |  
2019-09-12 10:28:46,831 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b1625f00-6443-45c6-96ff-411b5b1b4656, bucket=dc374372-6408-4b21-a818-6b11dd2f21f7} | ret=SUCCESS |  
2019-09-12 10:28:46,832 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=b1625f00-6443-45c6-96ff-411b5b1b4656, bucket=dc374372-6408-4b21-a818-6b11dd2f21f7, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,833 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b3b052ae-c6b2-46d5-b820-64173cc1872a, with jenkins1000 as owner.
2019-09-12 10:28:46,841 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b3b052ae-c6b2-46d5-b820-64173cc1872a, creationTime=1568284126834, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:46,843 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b3b052ae-c6b2-46d5-b820-64173cc1872a} | ret=SUCCESS |  
2019-09-12 10:28:46,843 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b3b052ae-c6b2-46d5-b820-64173cc1872a/e7e8d739-c8f4-4b68-af1b-ffb372df39fc, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:46,856 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b3b052ae-c6b2-46d5-b820-64173cc1872a, bucket=e7e8d739-c8f4-4b68-af1b-ffb372df39fc, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284126844} | ret=SUCCESS |  
2019-09-12 10:28:46,857 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b3b052ae-c6b2-46d5-b820-64173cc1872a, bucket=e7e8d739-c8f4-4b68-af1b-ffb372df39fc} | ret=SUCCESS |  
2019-09-12 10:28:46,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b3b052ae-c6b2-46d5-b820-64173cc1872a, bucket=e7e8d739-c8f4-4b68-af1b-ffb372df39fc} | ret=SUCCESS |  
2019-09-12 10:28:46,873 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=b3b052ae-c6b2-46d5-b820-64173cc1872a, bucket=e7e8d739-c8f4-4b68-af1b-ffb372df39fc, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,874 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: cadcc47c-285a-4dcb-add7-705c22142ad8, with jenkins1000 as owner.
2019-09-12 10:28:46,883 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, creationTime=1568284126875, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:46,913 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,914 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,933 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:46,960 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,975 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,979 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,980 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:46,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=cadcc47c-285a-4dcb-add7-705c22142ad8, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:28:47,007 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ozone1=username, a9ffefe9-2610-496d-8634-60b13a510a1c=s3Bucket} | ret=SUCCESS |  
2019-09-12 10:28:47,010 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone1} | ret=SUCCESS |  
2019-09-12 10:28:47,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone1, bucket=a9ffefe9-2610-496d-8634-60b13a510a1c} | ret=SUCCESS |  
2019-09-12 10:28:47,034 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {a9ffefe9-2610-496d-8634-60b13a510a1c=s3Bucket} | ret=SUCCESS |  
2019-09-12 10:28:47,044 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {b1665c52-ac16-4933-826c-84c388f791b8=s3Bucket, 6e1f1f2b8cdde9c11717322d7e158a89=username} | ret=SUCCESS |  
2019-09-12 10:28:47,046 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s36e1f1f2b8cdde9c11717322d7e158a89} | ret=SUCCESS |  
2019-09-12 10:28:47,047 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s36e1f1f2b8cdde9c11717322d7e158a89, bucket=b1665c52-ac16-4933-826c-84c388f791b8} | ret=SUCCESS |  
2019-09-12 10:28:47,048 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 2babd76e-1efa-4cd1-866f-25b8bd22a2c4, with jenkins1000 as owner.
2019-09-12 10:28:47,061 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, creationTime=1568284127049, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:47,063 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4} | ret=SUCCESS |  
2019-09-12 10:28:47,063 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 2babd76e-1efa-4cd1-866f-25b8bd22a2c4/bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:47,076 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284127064} | ret=SUCCESS |  
2019-09-12 10:28:47,078 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a} | ret=SUCCESS |  
2019-09-12 10:28:47,088 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, key=8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:47,101 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, key=8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:47,103 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,116 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, key=8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068552904748} | ret=SUCCESS |  
2019-09-12 10:28:47,125 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068553822253 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,129 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068553822253 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:28:47,145 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, key=8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068553822253
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,166 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=2babd76e-1efa-4cd1-866f-25b8bd22a2c4, bucket=bab70a4c-3c5e-40f3-924a-8c4e7e2c227a, key=8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={3=random}} | ret=FAILURE | MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 2babd76e-1efa-4cd1-866f-25b8bd22a2c4bucket: bab70a4c-3c5e-40f3-924a-8c4e7e2c227akey: 8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:47,168 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3 in Volume/Bucket 2babd76e-1efa-4cd1-866f-25b8bd22a2c4/bab70a4c-3c5e-40f3-924a-8c4e7e2c227a
MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 2babd76e-1efa-4cd1-866f-25b8bd22a2c4bucket: bab70a4c-3c5e-40f3-924a-8c4e7e2c227akey: 8aaca7f9-3c86-4bed-91d2-5fdd88f3aab3
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:47,170 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c43d8047-2591-47e9-aee8-a990c0b68c38, with jenkins1000 as owner.
2019-09-12 10:28:47,183 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c43d8047-2591-47e9-aee8-a990c0b68c38, creationTime=1568284127171, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:47,184 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c43d8047-2591-47e9-aee8-a990c0b68c38} | ret=SUCCESS |  
2019-09-12 10:28:47,202 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=SET_QUOTA {volume=c43d8047-2591-47e9-aee8-a990c0b68c38, quota=100000000} | ret=SUCCESS |  
2019-09-12 10:28:47,208 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c43d8047-2591-47e9-aee8-a990c0b68c38} | ret=SUCCESS |  
2019-09-12 10:28:47,209 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 990a290c-ae0f-4c3e-8373-6c337e7665b4, with jenkins1000 as owner.
2019-09-12 10:28:47,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:47,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=990a290c-ae0f-4c3e-8373-6c337e7665b4, creationTime=1568284127210, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:47,213 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=990a290c-ae0f-4c3e-8373-6c337e7665b4} | ret=SUCCESS |  
2019-09-12 10:28:47,214 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 990a290c-ae0f-4c3e-8373-6c337e7665b4/2d4beb83-0f7e-4cfd-b7c7-381cd0d9068c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:47,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=990a290c-ae0f-4c3e-8373-6c337e7665b4, bucket=2d4beb83-0f7e-4cfd-b7c7-381cd0d9068c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284127215} | ret=SUCCESS |  
2019-09-12 10:28:47,226 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=990a290c-ae0f-4c3e-8373-6c337e7665b4, bucket=2d4beb83-0f7e-4cfd-b7c7-381cd0d9068c} | ret=SUCCESS |  
2019-09-12 10:28:47,238 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=990a290c-ae0f-4c3e-8373-6c337e7665b4, bucket=2d4beb83-0f7e-4cfd-b7c7-381cd0d9068c} | ret=SUCCESS |  
2019-09-12 10:28:47,239 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=990a290c-ae0f-4c3e-8373-6c337e7665b4, bucket=2d4beb83-0f7e-4cfd-b7c7-381cd0d9068c} | ret=FAILURE | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
	at org.apache.hadoop.ozone.om.BucketManagerImpl.getBucketInfo(BucketManagerImpl.java:229)
	at org.apache.hadoop.ozone.om.OzoneManager.getBucketInfo(OzoneManager.java:2147) 
2019-09-12 10:28:47,240 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-67809, with jenkins1000 as owner.
2019-09-12 10:28:47,301 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-67809, creationTime=1568284127241, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:47,303 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-72323, with jenkins1000 as owner.
2019-09-12 10:28:47,455 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:47,499 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-72323, creationTime=1568284127304, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:47,501 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-67809} | ret=SUCCESS |  
2019-09-12 10:28:47,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-72323} | ret=SUCCESS |  
2019-09-12 10:28:47,504 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-67809/buc-a-43404, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:47,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-67809, bucket=buc-a-43404, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284127505} | ret=SUCCESS |  
2019-09-12 10:28:47,512 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-67809/buc-b-56587, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:47,523 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-67809, bucket=buc-b-56587, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284127513} | ret=SUCCESS |  
2019-09-12 10:28:47,524 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-72323/buc-a-43404, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:47,530 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-72323, bucket=buc-a-43404, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284127525} | ret=SUCCESS |  
2019-09-12 10:28:47,531 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-72323/buc-b-56587, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:47,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-72323, bucket=buc-b-56587, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284127532} | ret=SUCCESS |  
2019-09-12 10:28:47,540 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-67809, bucket=buc-a-43404} | ret=SUCCESS |  
2019-09-12 10:28:47,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-67809, bucket=buc-b-56587} | ret=SUCCESS |  
2019-09-12 10:28:47,542 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-72323, bucket=buc-a-43404} | ret=SUCCESS |  
2019-09-12 10:28:47,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-72323, bucket=buc-b-56587} | ret=SUCCESS |  
2019-09-12 10:28:47,549 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,557 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-0-25382, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068583051310
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,563 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068583051310 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,567 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068583051310 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,575 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-0-25382, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068583051310
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,577 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,583 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-0-50651, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068584886320
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,588 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068584886320 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,591 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068584886320 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,601 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-0-50651, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068584886320
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,604 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,611 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-0-82665, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068586655794
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,616 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068586655794 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,619 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068586655794 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,627 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-0-82665, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068586655794
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,629 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,648 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-0-17116, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068588294196
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,652 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068588294196 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,655 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068588294196 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,671 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-0-17116, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068588294196
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,674 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,689 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-1-24847, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068591243318
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,694 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068591243318 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,698 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068591243318 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,712 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-1-24847, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068591243318
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,715 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,717 [IPC Server handler 16 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-321_422 to index:422
2019-09-12 10:28:47,718 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_321-422
2019-09-12 10:28:47,733 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423
2019-09-12 10:28:47,746 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-1-27350, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068593930296
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,752 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068593930296 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,755 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068593930296 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,771 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-1-27350, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068593930296
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,773 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-1-77661, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068597731386
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,792 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068597731386 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,795 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068597731386 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,811 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-1-77661, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068597731386
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,814 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,828 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-1-25301, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068600418364
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,833 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068600418364 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,836 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068600418364 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,850 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-1-25301, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068600418364
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,853 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-2-15115, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068602974270
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,869 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068602974270 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,872 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068602974270 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,887 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-2-15115, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068602974270
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,889 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,902 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-2-92279, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068605333568
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,906 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068605333568 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,909 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068605333568 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,924 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-2-92279, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068605333568
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,927 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-2-69865, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068607823938
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,935 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068607823938 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,938 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068607823938 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:47,952 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-2-69865, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068607823938
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,955 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:47,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-2-41688, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068609593412
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,978 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068609593412 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:47,981 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068609593412 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:47,996 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-2-41688, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068609593412
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:47,999 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,008 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-3-02636, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068612542534
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,013 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068612542534 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,016 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068612542534 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,031 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-3-02636, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068612542534
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,033 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,046 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-3-69949, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068614770760
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,050 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068614770760 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,053 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068614770760 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,067 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-3-69949, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068614770760
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,069 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,083 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-3-53802, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068617130058
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,087 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068617130058 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,090 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068617130058 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,105 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-3-53802, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068617130058
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,108 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,117 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-3-59947, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068619685964
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,122 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068619685964 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,125 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068619685964 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,139 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-3-59947, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068619685964
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,143 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,156 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-4-42646, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068621979726
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,163 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068621979726 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,166 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068621979726 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,180 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-4-42646, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068621979726
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,183 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-4-48307, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068624535632
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,201 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068624535632 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,204 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068624535632 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:48,214 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-4-48307, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068624535632
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,216 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,226 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-4-23350, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068626763858
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,231 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068626763858 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,234 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068626763858 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,249 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-4-23350, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068626763858
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,252 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,260 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-4-95209, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068629123156
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,265 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068629123156 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,268 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068629123156 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,282 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-4-95209, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068629123156
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,285 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,299 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-5-53037, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068631285846
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,303 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068631285846 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,307 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068631285846 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,323 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-5-53037, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068631285846
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,325 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,338 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-5-23044, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068633907288
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,345 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068633907288 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,349 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068633907288 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,366 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-5-23044, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068633907288
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,379 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-5-86503, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068636725338
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,383 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068636725338 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,387 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068636725338 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,390 [IPC Server handler 0 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-423_492 to index:492
2019-09-12 10:28:48,391 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_423-492
2019-09-12 10:28:48,403 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493
2019-09-12 10:28:48,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-5-86503, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068636725338
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,417 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-5-07016, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068639346780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,423 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068639346780 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,426 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068639346780 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,441 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-5-07016, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068639346780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,444 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,450 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-6-77029, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068641706078
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:48,454 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068641706078 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,458 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068641706078 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,471 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-6-77029, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068641706078
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,474 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,482 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-6-33767, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068643672160
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,487 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068643672160 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,491 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068643672160 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,505 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-6-33767, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068643672160
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,507 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-6-62524, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068645834850
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,526 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068645834850 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,529 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068645834850 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,543 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-6-62524, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068645834850
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,558 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-6-58709, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068648325220
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,563 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068648325220 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,565 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068648325220 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,579 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-6-58709, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068648325220
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,595 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-7-24507, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068650684518
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,599 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068650684518 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,602 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068650684518 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,616 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-7-24507, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068650684518
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,618 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,632 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-7-00572, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068653109352
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,638 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068653109352 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,643 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068653109352 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,658 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-7-00572, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068653109352
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,661 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,674 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-7-08632, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068655861866
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,680 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068655861866 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,683 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068655861866 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,696 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-7-08632, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068655861866
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,698 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,709 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-7-55976, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068658352236
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,715 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068658352236 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,718 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068658352236 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,731 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-7-55976, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068658352236
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,734 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-8-11505, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068660645998
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,744 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068660645998 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,747 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068660645998 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,760 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-8-11505, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068660645998
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,763 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-8-14559, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068662612080
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,782 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068662612080 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,788 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068662612080 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,803 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-8-14559, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068662612080
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,805 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,818 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-8-55171, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068665364594
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,823 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068665364594 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,827 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068665364594 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,841 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-8-55171, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068665364594
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,844 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,857 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-8-25119, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068667920500
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,861 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068667920500 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,865 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068667920500 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,879 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-8-25119, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068667920500
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,882 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,895 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-9-40327, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068670410870
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,900 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068670410870 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,904 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068670410870 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,919 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-a-9-40327, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068670410870
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,921 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,935 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-9-23450, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068672966776
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:48,939 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068672966776 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,942 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068672966776 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-a-9-23450, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068672966776
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,959 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:48,971 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-9-60353, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068675457146
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,976 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068675457146 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:48,978 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068675457146 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:48,995 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-a-9-60353, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068675457146
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:48,997 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,012 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-9-95125, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068677947516
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,017 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068677947516 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,019 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068677947516 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-a-9-95125, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068677947516
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,041 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,042 [IPC Server handler 6 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-493_562 to index:562
2019-09-12 10:28:49,043 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_493-562
2019-09-12 10:28:49,068 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563
2019-09-12 10:28:49,070 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-0-80933, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068680765566
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,077 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068680765566 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,082 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068680765566 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,097 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-0-80933, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068680765566
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,100 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,114 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-0-38301, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068684697728
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,122 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068684697728 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,125 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068684697728 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,140 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-0-38301, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068684697728
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,143 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,151 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-0-77511, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068687450242
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,157 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068687450242 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,160 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068687450242 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,174 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-0-77511, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068687450242
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,176 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,190 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-0-92794, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068689678468
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,195 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068689678468 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,197 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068689678468 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:49,211 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-0-92794, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068689678468
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,214 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,265 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-1-09559, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068692168838
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,272 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068692168838 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,276 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068692168838 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-1-09559, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068692168838
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,287 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,307 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-1-92020, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068696952968
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,314 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068696952968 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,317 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068696952968 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,332 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-1-92020, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068696952968
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,348 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-1-23419, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068700033162
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,355 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068700033162 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,357 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068700033162 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,375 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-1-23419, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068700033162
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,378 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-1-43411, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068702851212
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,395 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068702851212 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,398 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068702851212 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-1-43411, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068702851212
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,415 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-2-96287, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068705341582
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,436 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068705341582 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,439 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068705341582 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,453 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-2-96287, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068705341582
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:49,455 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,468 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-2-92132, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068707963024
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,474 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068707963024 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,477 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068707963024 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,492 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-2-92132, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068707963024
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,495 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-2-63534, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068710584466
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,510 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068710584466 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,513 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068710584466 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,527 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-2-63534, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068710584466
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-2-58454, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068712878228
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,551 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068712878228 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,554 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068712878228 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-2-58454, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068712878228
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,582 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-3-77741, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068715630742
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,587 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068715630742 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,590 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068715630742 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,593 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-3-77741, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068715630742
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,596 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,609 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-3-52111, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068717203608
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,613 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068717203608 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,616 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068717203608 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,621 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-3-52111, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068717203608
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,623 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,636 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-3-76456, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068718973082
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,640 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068718973082 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,642 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068718973082 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,656 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-3-76456, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068718973082
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,659 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,672 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-3-68099, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068721266844
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,676 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068721266844 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,679 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068721266844 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-3-68099, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068721266844
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,695 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,698 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-4-89030, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068723626142
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,703 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068723626142 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,706 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068723626142 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,718 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-4-89030, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068723626142
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,721 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,744 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-4-31279, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068725330080
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,748 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068725330080 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,750 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068725330080 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,752 [IPC Server handler 10 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-563_632 to index:632
2019-09-12 10:28:49,753 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_563-632
2019-09-12 10:28:49,769 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633
2019-09-12 10:28:49,771 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-4-31279, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068725330080
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,773 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,786 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-4-50841, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068728803490
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,792 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068728803490 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,796 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068728803490 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,810 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-4-50841, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068728803490
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,813 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,821 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-4-56520, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068731424932
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,828 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068731424932 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,831 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068731424932 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,845 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-4-56520, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068731424932
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,848 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,861 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-5-32325, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068733718694
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,867 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068733718694 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,870 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068733718694 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,883 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-5-32325, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068733718694
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,886 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,898 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-5-46993, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068736143528
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,904 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068736143528 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,906 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068736143528 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-5-46993, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068736143528
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,923 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-5-72833, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068738633898
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,939 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:49,942 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068738633898 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,945 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068738633898 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,959 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-5-72833, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068738633898
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,961 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:49,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-5-46595, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068741124268
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,978 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068741124268 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:49,981 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068741124268 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:49,995 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-5-46595, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068741124268
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:49,998 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,013 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-6-84131, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068743483566
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,017 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068743483566 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,020 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068743483566 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-6-84131, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068743483566
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,038 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,052 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-6-91355, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068746170544
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,056 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068746170544 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,058 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068746170544 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-6-91355, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068746170544
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,074 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,087 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-6-98570, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068748529842
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,091 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068748529842 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,094 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068748529842 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,108 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-6-98570, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068748529842
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,110 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,124 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-6-79212, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068750889140
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,128 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068750889140 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,131 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068750889140 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,145 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-6-79212, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068750889140
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,147 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,160 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-7-30810, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068753313974
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,167 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068753313974 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,170 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068753313974 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,185 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-7-30810, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068753313974
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,201 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-7-64348, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068755935416
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,205 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068755935416 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,207 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068755935416 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,220 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-7-64348, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068755935416
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,222 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,233 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-7-96014, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068758229178
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,237 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068758229178 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,240 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068758229178 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,251 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-7-96014, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068758229178
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,253 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,264 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-7-96377, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068760260796
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,268 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068760260796 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,270 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068760260796 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-7-96377, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068760260796
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,287 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,301 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-8-41080, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068762489022
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,305 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068762489022 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,308 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068762489022 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,322 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-8-41080, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068762489022
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,325 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,338 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-8-67420, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068764979392
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,343 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068764979392 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,346 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068764979392 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,358 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-8-67420, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068764979392
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,360 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,371 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-8-19225, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068767273154
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,376 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068767273154 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,379 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068767273154 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,395 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-8-19225, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068767273154
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,397 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,398 [IPC Server handler 16 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-633_702 to index:702
2019-09-12 10:28:50,399 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_633-702
2019-09-12 10:28:50,413 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703
2019-09-12 10:28:50,415 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-8-05751, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068769697988
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,420 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068769697988 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,423 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068769697988 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,441 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-8-05751, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068769697988
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,445 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,453 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-9-88343, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068772843718
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,455 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,459 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068772843718 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,463 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068772843718 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,477 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-a-43404, key=key-b-9-88343, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068772843718
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,480 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,492 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-9-43318, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068775137480
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,497 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068775137480 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,500 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068775137480 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,514 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-67809, bucket=buc-b-56587, key=key-b-9-43318, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068775137480
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,516 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,530 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-9-17831, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068777496778
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,534 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068777496778 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,536 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068777496778 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,550 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-a-43404, key=key-b-9-17831, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068777496778
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,565 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-9-92062, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068779856076
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,569 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068779856076 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,573 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068779856076 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:28:50,588 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-72323, bucket=buc-b-56587, key=key-b-9-92062, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068779856076
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,597 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-a-43404, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-a-43404, startKey=key-b-9-88343, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,606 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-b-56587, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,610 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-b-56587, startKey=key-b-9-43318, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,612 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-72323, bucket=buc-a-43404, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,616 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-72323, bucket=buc-a-43404, startKey=key-b-9-17831, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,619 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-72323, bucket=buc-b-56587, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,623 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-72323, bucket=buc-b-56587, startKey=key-b-9-92062, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,625 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-a-43404, startKey=, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-12 10:28:50,628 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-a-43404, startKey=key-a-9-40327, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-12 10:28:50,630 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-a-43404, startKey=, maxKeys=1000, keyPrefix=key-b-} | ret=SUCCESS |  
2019-09-12 10:28:50,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-67809, bucket=buc-b-56587, startKey=key-b-9-43318, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:28:50,634 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e0ff5fff-8c0e-41c4-9307-8500c3d51cd3, with jenkins1000 as owner.
2019-09-12 10:28:50,652 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e0ff5fff-8c0e-41c4-9307-8500c3d51cd3, creationTime=1568284130636, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:50,653 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e0ff5fff-8c0e-41c4-9307-8500c3d51cd3} | ret=SUCCESS |  
2019-09-12 10:28:50,654 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e0ff5fff-8c0e-41c4-9307-8500c3d51cd3/25319cb2-e99e-440f-a9ed-b10faef367ee, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:50,667 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e0ff5fff-8c0e-41c4-9307-8500c3d51cd3, bucket=25319cb2-e99e-440f-a9ed-b10faef367ee, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284130655} | ret=SUCCESS |  
2019-09-12 10:28:50,668 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e0ff5fff-8c0e-41c4-9307-8500c3d51cd3, bucket=25319cb2-e99e-440f-a9ed-b10faef367ee} | ret=SUCCESS |  
2019-09-12 10:28:50,669 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 689affa4-14b6-4b69-b2d7-faa8cde2d9c9, with jenkins1000 as owner.
2019-09-12 10:28:50,682 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, creationTime=1568284130670, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:50,683 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9} | ret=SUCCESS |  
2019-09-12 10:28:50,684 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 689affa4-14b6-4b69-b2d7-faa8cde2d9c9/fd46190c-4d2f-439e-bed4-dd79af1cf1b4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:50,696 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284130684} | ret=SUCCESS |  
2019-09-12 10:28:50,697 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4} | ret=SUCCESS |  
2019-09-12 10:28:50,710 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,723 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,726 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,738 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068790276303} | ret=SUCCESS |  
2019-09-12 10:28:50,743 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068791259344 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,746 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068791259344 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:28:50,760 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068791259344
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,773 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,776 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068793553105} | ret=SUCCESS |  
2019-09-12 10:28:50,800 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068794536146 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,812 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068794536146 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:28:50,841 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068794536146
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,856 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(212)) - MultipartUpload: /689affa4-14b6-4b69-b2d7-faa8cde2d9c9/fd46190c-4d2f-439e-bed4-dd79af1cf1b4/00e03183-d388-4e0c-9e40-58cfb03a7cf0Part number: 1size 4 is less than minimum part size 5242880
2019-09-12 10:28:50,856 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=689affa4-14b6-4b69-b2d7-faa8cde2d9c9, bucket=fd46190c-4d2f-439e-bed4-dd79af1cf1b4, key=00e03183-d388-4e0c-9e40-58cfb03a7cf0, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=/689affa4-14b6-4b69-b2d7-faa8cde2d9c9/fd46190c-4d2f-439e-bed4-dd79af1cf1b4/00e03183-d388-4e0c-9e40-58cfb03a7cf0102779068790276303, 2=/689affa4-14b6-4b69-b2d7-faa8cde2d9c9/fd46190c-4d2f-439e-bed4-dd79af1cf1b4/00e03183-d388-4e0c-9e40-58cfb03a7cf0102779068793553105}} | ret=FAILURE | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 689affa4-14b6-4b69-b2d7-faa8cde2d9c9bucket: fd46190c-4d2f-439e-bed4-dd79af1cf1b4key: 00e03183-d388-4e0c-9e40-58cfb03a7cf0
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:50,859 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 00e03183-d388-4e0c-9e40-58cfb03a7cf0 in Volume/Bucket 689affa4-14b6-4b69-b2d7-faa8cde2d9c9/fd46190c-4d2f-439e-bed4-dd79af1cf1b4
ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 689affa4-14b6-4b69-b2d7-faa8cde2d9c9bucket: fd46190c-4d2f-439e-bed4-dd79af1cf1b4key: 00e03183-d388-4e0c-9e40-58cfb03a7cf0
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:50,860 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 2c20f73c-86ae-46eb-9fe7-6f295bb36428, with jenkins1000 as owner.
2019-09-12 10:28:50,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, creationTime=1568284130861, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:50,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428} | ret=SUCCESS |  
2019-09-12 10:28:50,868 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 2c20f73c-86ae-46eb-9fe7-6f295bb36428/5b1a9a29-0559-4b6a-810c-bf127e80f788, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:50,879 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284130869} | ret=SUCCESS |  
2019-09-12 10:28:50,880 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788} | ret=SUCCESS |  
2019-09-12 10:28:50,884 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:50,890 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=28baa9c4-e2fd-4b0f-9aba-1a23438de34d, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102779068801614035
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "e16c15e4-8484-4070-a9b8-d38d0e46e828"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:50,939 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,979 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102779068801614035 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,980 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:50,991 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102779068801614035 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:50,998 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-CE990A2551C2->bdedf58a-a481-4a9e-93e6-4446fa864847: receive RaftClientReply:client-CE990A2551C2->bdedf58a-a481-4a9e-93e6-4446fa864847@group-D38D0E46E828, cid=20, SUCCESS, logIndex=1, commits[bdedf58a-a481-4a9e-93e6-4446fa864847:c1]
2019-09-12 10:28:51,063 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102779068801614035 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,075 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-CE990A2551C2->bdedf58a-a481-4a9e-93e6-4446fa864847: receive RaftClientReply:client-CE990A2551C2->bdedf58a-a481-4a9e-93e6-4446fa864847@group-D38D0E46E828, cid=21, SUCCESS, logIndex=3, commits[bdedf58a-a481-4a9e-93e6-4446fa864847:c4]
2019-09-12 10:28:51,090 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=28baa9c4-e2fd-4b0f-9aba-1a23438de34d, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102779068801614035
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "e16c15e4-8484-4070-a9b8-d38d0e46e828"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,092 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:28:51,094 [IPC Server handler 1 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,094 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,095 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=28baa9c4-e2fd-4b0f-9aba-1a23438de34d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,099 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:28:51,100 [IPC Server handler 4 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,100 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,100 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=28baa9c4-e2fd-4b0f-9aba-1a23438de34d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,111 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 3 locID: 102779068801614035 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,116 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 3 locID: 102779068801614035 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:28:51,118 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=28baa9c4-e2fd-4b0f-9aba-1a23438de34d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=3} | ret=SUCCESS |  
2019-09-12 10:28:51,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:51,138 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=51f90805-5dd2-471e-9bcb-d103b33194c3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779068817342677
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,148 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779068817342677 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,159 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779068817342677 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,162 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=22, SUCCESS, logIndex=5, commits[969f621b-625a-4660-bcba-147498526acd:c5]
2019-09-12 10:28:51,169 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779068817342677 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,171 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=23, SUCCESS, logIndex=7, commits[969f621b-625a-4660-bcba-147498526acd:c8]
2019-09-12 10:28:51,174 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=51f90805-5dd2-471e-9bcb-d103b33194c3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779068817342677
  }
  blockCommitSequenceId: 7
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,176 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:51,177 [IPC Server handler 8 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,178 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,178 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=51f90805-5dd2-471e-9bcb-d103b33194c3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,179 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:51,180 [IPC Server handler 5 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,181 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,181 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=51f90805-5dd2-471e-9bcb-d103b33194c3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,188 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779068817342677 bcsId: 7} | ret=SUCCESS |  
2019-09-12 10:28:51,191 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779068817342677 bcsId: 7} | ret=SUCCESS |  
2019-09-12 10:28:51,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:51,194 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=51f90805-5dd2-471e-9bcb-d103b33194c3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,194 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=2} | ret=SUCCESS |  
2019-09-12 10:28:51,196 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:51,207 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=340102ad-5743-4d06-9eb2-4f3e52909cbc, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102779068822061271
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "349939a8-0e84-4617-9a16-3efaa8718099"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 38045
    }
    ports {
      name: "RATIS"
      value: 43393
    }
    ports {
      name: "STANDALONE"
      value: 33880
    }
    networkName: "349939a8-0e84-4617-9a16-3efaa8718099"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "cb42bced-e0e3-4b06-8a26-f1321aaff4a4"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,251 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102779068822061271 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,252 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:51,265 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102779068822061271 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,269 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099: receive RaftClientReply:client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099@group-F1321AAFF4A4, cid=24, SUCCESS, logIndex=1, commits[349939a8-0e84-4617-9a16-3efaa8718099:c1]
2019-09-12 10:28:51,305 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102779068822061271 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,308 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099: receive RaftClientReply:client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099@group-F1321AAFF4A4, cid=25, SUCCESS, logIndex=3, commits[349939a8-0e84-4617-9a16-3efaa8718099:c4]
2019-09-12 10:28:51,322 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=340102ad-5743-4d06-9eb2-4f3e52909cbc, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102779068822061271
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "349939a8-0e84-4617-9a16-3efaa8718099"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 38045
    }
    ports {
      name: "RATIS"
      value: 43393
    }
    ports {
      name: "STANDALONE"
      value: 33880
    }
    networkName: "349939a8-0e84-4617-9a16-3efaa8718099"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "cb42bced-e0e3-4b06-8a26-f1321aaff4a4"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,325 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:28:51,326 [IPC Server handler 13 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,327 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=340102ad-5743-4d06-9eb2-4f3e52909cbc, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:28:51,329 [IPC Server handler 15 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,330 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=340102ad-5743-4d06-9eb2-4f3e52909cbc, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,339 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102779068822061271 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,342 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102779068822061271 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,344 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:28:51,344 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=340102ad-5743-4d06-9eb2-4f3e52909cbc, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,345 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-12 10:28:51,348 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:51,361 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=1faf010f-9436-4524-a0a5-79678e12ce47, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779068832022745
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,365 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779068832022745 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,377 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779068832022745 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,378 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779068832022745 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,378 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=26, SUCCESS, logIndex=9, commits[969f621b-625a-4660-bcba-147498526acd:c10]
2019-09-12 10:28:51,379 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=27, SUCCESS, logIndex=10, commits[969f621b-625a-4660-bcba-147498526acd:c11]
2019-09-12 10:28:51,393 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=1faf010f-9436-4524-a0a5-79678e12ce47, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779068832022745
  }
  blockCommitSequenceId: 10
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,395 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:51,396 [IPC Server handler 10 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,396 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,397 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=1faf010f-9436-4524-a0a5-79678e12ce47, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,399 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:51,400 [IPC Server handler 14 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,400 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,401 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=1faf010f-9436-4524-a0a5-79678e12ce47, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,404 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779068832022745 bcsId: 10} | ret=SUCCESS |  
2019-09-12 10:28:51,408 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779068832022745 bcsId: 10} | ret=SUCCESS |  
2019-09-12 10:28:51,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:51,412 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=1faf010f-9436-4524-a0a5-79678e12ce47, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,413 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=2} | ret=SUCCESS |  
2019-09-12 10:28:51,415 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:51,418 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=e6d55673-eb29-4645-a89e-c02b6764722e, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102779068836413659
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "15a42196-928e-4aff-9dca-50887c8f1a38"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,455 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:51,498 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102779068836413659 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:51,511 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102779068836413659 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,515 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-D3E6884B48F3->bdedf58a-a481-4a9e-93e6-4446fa864847: receive RaftClientReply:client-D3E6884B48F3->bdedf58a-a481-4a9e-93e6-4446fa864847@group-50887C8F1A38, cid=28, SUCCESS, logIndex=1, commits[bdedf58a-a481-4a9e-93e6-4446fa864847:c1]
2019-09-12 10:28:51,565 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 5 locID: 102779068836413659 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,568 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-D3E6884B48F3->bdedf58a-a481-4a9e-93e6-4446fa864847: receive RaftClientReply:client-D3E6884B48F3->bdedf58a-a481-4a9e-93e6-4446fa864847@group-50887C8F1A38, cid=29, SUCCESS, logIndex=3, commits[bdedf58a-a481-4a9e-93e6-4446fa864847:c4]
2019-09-12 10:28:51,575 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=e6d55673-eb29-4645-a89e-c02b6764722e, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102779068836413659
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "15a42196-928e-4aff-9dca-50887c8f1a38"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,577 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:28:51,579 [IPC Server handler 17 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,579 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,580 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=e6d55673-eb29-4645-a89e-c02b6764722e, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:28:51,583 [IPC Server handler 18 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,584 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=e6d55673-eb29-4645-a89e-c02b6764722e, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,592 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 5 locID: 102779068836413659 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,596 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 5 locID: 102779068836413659 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,598 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:28:51,599 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=e6d55673-eb29-4645-a89e-c02b6764722e, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,599 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=5} | ret=SUCCESS |  
2019-09-12 10:28:51,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:51,615 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=8818921d-a5bb-4308-821d-a6cec97fd6cc, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102779068848603357
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "33cdbc17-6036-4c6c-923f-5bc15abaaba1"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,691 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102779068848603357 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:51,704 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102779068848603357 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,709 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-850A3EF40929->bdedf58a-a481-4a9e-93e6-4446fa864847: receive RaftClientReply:client-850A3EF40929->bdedf58a-a481-4a9e-93e6-4446fa864847@group-5BC15ABAABA1, cid=30, SUCCESS, logIndex=1, commits[bdedf58a-a481-4a9e-93e6-4446fa864847:c1]
2019-09-12 10:28:51,755 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 6 locID: 102779068848603357 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,758 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-850A3EF40929->bdedf58a-a481-4a9e-93e6-4446fa864847: receive RaftClientReply:client-850A3EF40929->bdedf58a-a481-4a9e-93e6-4446fa864847@group-5BC15ABAABA1, cid=31, SUCCESS, logIndex=3, commits[bdedf58a-a481-4a9e-93e6-4446fa864847:c4]
2019-09-12 10:28:51,773 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=8818921d-a5bb-4308-821d-a6cec97fd6cc, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102779068848603357
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "33cdbc17-6036-4c6c-923f-5bc15abaaba1"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,775 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:28:51,776 [IPC Server handler 7 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,777 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=8818921d-a5bb-4308-821d-a6cec97fd6cc, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:28:51,780 [IPC Server handler 2 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:51,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:51,781 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=8818921d-a5bb-4308-821d-a6cec97fd6cc, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,788 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 6 locID: 102779068848603357 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,798 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 6 locID: 102779068848603357 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:51,799 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:28:51,800 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=8818921d-a5bb-4308-821d-a6cec97fd6cc, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:51,800 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=6} | ret=SUCCESS |  
2019-09-12 10:28:51,802 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:51,804 [IPC Server handler 8 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-703_774 to index:774
2019-09-12 10:28:51,804 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_703-774
2019-09-12 10:28:51,829 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775
2019-09-12 10:28:51,842 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=553d8f31-672e-4e8c-84cd-7148d26e7c2b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102779068861776095
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "998e4c04-750d-4fb5-9091-e7a6a1456dbd"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:51,907 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102779068861776095 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,908 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:51,909 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102779068861776095 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:51,914 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-844ED3A26B55->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-844ED3A26B55->969f621b-625a-4660-bcba-147498526acd@group-E7A6A1456DBD, cid=32, SUCCESS, logIndex=1, commits[969f621b-625a-4660-bcba-147498526acd:c2]
2019-09-12 10:28:51,993 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 7 locID: 102779068861776095 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:51,997 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-844ED3A26B55->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-844ED3A26B55->969f621b-625a-4660-bcba-147498526acd@group-E7A6A1456DBD, cid=33, SUCCESS, logIndex=3, commits[969f621b-625a-4660-bcba-147498526acd:c4]
2019-09-12 10:28:52,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=553d8f31-672e-4e8c-84cd-7148d26e7c2b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102779068861776095
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "998e4c04-750d-4fb5-9091-e7a6a1456dbd"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,013 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-12 10:28:52,014 [IPC Server handler 3 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,015 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=553d8f31-672e-4e8c-84cd-7148d26e7c2b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,017 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-12 10:28:52,018 [IPC Server handler 1 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,019 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,019 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=553d8f31-672e-4e8c-84cd-7148d26e7c2b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,028 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 7 locID: 102779068861776095 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:52,033 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 7 locID: 102779068861776095 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:52,035 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-12 10:28:52,035 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=553d8f31-672e-4e8c-84cd-7148d26e7c2b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,036 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=7} | ret=SUCCESS |  
2019-09-12 10:28:52,038 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,052 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=db5c96d6-b8f3-4c4b-9075-8b0f9e426876, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102779068877242593
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "349939a8-0e84-4617-9a16-3efaa8718099"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 38045
    }
    ports {
      name: "RATIS"
      value: 43393
    }
    ports {
      name: "STANDALONE"
      value: 33880
    }
    networkName: "349939a8-0e84-4617-9a16-3efaa8718099"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f287a6bd-6b22-404e-96eb-849e74f7b3cb"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,187 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102779068877242593 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,199 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102779068877242593 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,204 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-E03B78B58258->349939a8-0e84-4617-9a16-3efaa8718099: receive RaftClientReply:client-E03B78B58258->349939a8-0e84-4617-9a16-3efaa8718099@group-849E74F7B3CB, cid=34, SUCCESS, logIndex=1, commits[349939a8-0e84-4617-9a16-3efaa8718099:c1]
2019-09-12 10:28:52,298 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 8 locID: 102779068877242593 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:52,301 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-E03B78B58258->349939a8-0e84-4617-9a16-3efaa8718099: receive RaftClientReply:client-E03B78B58258->349939a8-0e84-4617-9a16-3efaa8718099@group-849E74F7B3CB, cid=35, SUCCESS, logIndex=3, commits[349939a8-0e84-4617-9a16-3efaa8718099:c4]
2019-09-12 10:28:52,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=db5c96d6-b8f3-4c4b-9075-8b0f9e426876, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102779068877242593
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "349939a8-0e84-4617-9a16-3efaa8718099"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 38045
    }
    ports {
      name: "RATIS"
      value: 43393
    }
    ports {
      name: "STANDALONE"
      value: 33880
    }
    networkName: "349939a8-0e84-4617-9a16-3efaa8718099"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f287a6bd-6b22-404e-96eb-849e74f7b3cb"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-12 10:28:52,331 [IPC Server handler 12 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,332 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=db5c96d6-b8f3-4c4b-9075-8b0f9e426876, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-12 10:28:52,335 [IPC Server handler 10 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,336 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=db5c96d6-b8f3-4c4b-9075-8b0f9e426876, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,345 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 8 locID: 102779068877242593 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:52,349 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 8 locID: 102779068877242593 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:52,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-12 10:28:52,351 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=db5c96d6-b8f3-4c4b-9075-8b0f9e426876, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,352 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=8} | ret=SUCCESS |  
2019-09-12 10:28:52,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,369 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=a39cd3ac-e089-4f9a-bc5f-d3c761c87da4, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102779068898017507
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "349939a8-0e84-4617-9a16-3efaa8718099"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 38045
    }
    ports {
      name: "RATIS"
      value: 43393
    }
    ports {
      name: "STANDALONE"
      value: 33880
    }
    networkName: "349939a8-0e84-4617-9a16-3efaa8718099"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "cb42bced-e0e3-4b06-8a26-f1321aaff4a4"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,375 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102779068898017507 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,386 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102779068898017507 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,387 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102779068898017507 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:52,388 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099: receive RaftClientReply:client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099@group-F1321AAFF4A4, cid=36, SUCCESS, logIndex=5, commits[349939a8-0e84-4617-9a16-3efaa8718099:c7]
2019-09-12 10:28:52,389 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099: receive RaftClientReply:client-5C459F021969->349939a8-0e84-4617-9a16-3efaa8718099@group-F1321AAFF4A4, cid=37, SUCCESS, logIndex=6, commits[349939a8-0e84-4617-9a16-3efaa8718099:c7]
2019-09-12 10:28:52,402 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=a39cd3ac-e089-4f9a-bc5f-d3c761c87da4, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102779068898017507
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "349939a8-0e84-4617-9a16-3efaa8718099"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 38045
    }
    ports {
      name: "RATIS"
      value: 43393
    }
    ports {
      name: "STANDALONE"
      value: 33880
    }
    networkName: "349939a8-0e84-4617-9a16-3efaa8718099"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "cb42bced-e0e3-4b06-8a26-f1321aaff4a4"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:28:52,406 [IPC Server handler 16 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=a39cd3ac-e089-4f9a-bc5f-d3c761c87da4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:28:52,409 [IPC Server handler 17 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,410 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,410 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=a39cd3ac-e089-4f9a-bc5f-d3c761c87da4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,413 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102779068898017507 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:28:52,417 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102779068898017507 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:28:52,419 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:28:52,419 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=a39cd3ac-e089-4f9a-bc5f-d3c761c87da4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,420 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-12 10:28:52,422 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,438 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=b7946f58-a7f1-453a-b3d0-f10763a07030, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102779068902408421
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "235368e5-9c0f-4999-ac47-6eeb257c2850"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,565 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102779068902408421 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,565 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,578 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102779068902408421 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,583 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-02215F8138BC->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-02215F8138BC->969f621b-625a-4660-bcba-147498526acd@group-6EEB257C2850, cid=38, SUCCESS, logIndex=1, commits[969f621b-625a-4660-bcba-147498526acd:c1]
2019-09-12 10:28:52,679 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 9 locID: 102779068902408421 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:52,683 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-02215F8138BC->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-02215F8138BC->969f621b-625a-4660-bcba-147498526acd@group-6EEB257C2850, cid=39, SUCCESS, logIndex=3, commits[969f621b-625a-4660-bcba-147498526acd:c4]
2019-09-12 10:28:52,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,698 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=b7946f58-a7f1-453a-b3d0-f10763a07030, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102779068902408421
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "235368e5-9c0f-4999-ac47-6eeb257c2850"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,700 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-12 10:28:52,701 [IPC Server handler 7 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,701 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=b7946f58-a7f1-453a-b3d0-f10763a07030, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,704 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-12 10:28:52,705 [IPC Server handler 2 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:52,705 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:52,706 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=b7946f58-a7f1-453a-b3d0-f10763a07030, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,712 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 9 locID: 102779068902408421 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:52,720 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 9 locID: 102779068902408421 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:52,721 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-12 10:28:52,722 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2c20f73c-86ae-46eb-9fe7-6f295bb36428, bucket=5b1a9a29-0559-4b6a-810c-bf127e80f788, key=b7946f58-a7f1-453a-b3d0-f10763a07030, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:52,723 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=9} | ret=SUCCESS |  
2019-09-12 10:28:52,736 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {b18a6746-1ccf-41f1-887c-7127848ef253=s3Bucket, ozone100=username} | ret=SUCCESS |  
2019-09-12 10:28:52,750 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ee426cf0-a093-4cc6-afd3-1350b9a7a591=s3Bucket, ozone100=username} | ret=SUCCESS |  
2019-09-12 10:28:52,757 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:52,769 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=ee426cf0-a093-4cc6-afd3-1350b9a7a591, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:52,770 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 7e3660a0-4199-4bf9-b8aa-4b06154dd22a, with jenkins1000 as owner.
2019-09-12 10:28:52,772 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, creationTime=1568284132770, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:52,774 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a} | ret=SUCCESS |  
2019-09-12 10:28:52,774 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 7e3660a0-4199-4bf9-b8aa-4b06154dd22a/c1ec8f8c-6b70-469b-9888-c85f00283677, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:52,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284132775} | ret=SUCCESS |  
2019-09-12 10:28:52,777 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677} | ret=SUCCESS |  
2019-09-12 10:28:52,781 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677, key=cf7cbcff-6752-49ed-b16e-135dadd1a989, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677, key=cf7cbcff-6752-49ed-b16e-135dadd1a989, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,786 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677, key=cf7cbcff-6752-49ed-b16e-135dadd1a989, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068926001384} | ret=SUCCESS |  
2019-09-12 10:28:52,793 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068926263529 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,796 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068926263529 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:28:52,803 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677, key=cf7cbcff-6752-49ed-b16e-135dadd1a989, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068926263529
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=7e3660a0-4199-4bf9-b8aa-4b06154dd22a, bucket=c1ec8f8c-6b70-469b-9888-c85f00283677, key=cf7cbcff-6752-49ed-b16e-135dadd1a989, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,814 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-12 10:28:52,817 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-12 10:28:52,819 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ff055f14-6f4b-403d-86e3-b54ebbf28341, with jenkins1000 as owner.
2019-09-12 10:28:52,822 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, creationTime=1568284132820, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:52,823 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341} | ret=SUCCESS |  
2019-09-12 10:28:52,824 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ff055f14-6f4b-403d-86e3-b54ebbf28341/24e6242e-e626-4225-9869-a8e08cce3ea6, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:52,826 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284132824} | ret=SUCCESS |  
2019-09-12 10:28:52,827 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6} | ret=SUCCESS |  
2019-09-12 10:28:52,831 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,838 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,840 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,842 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068929540331} | ret=SUCCESS |  
2019-09-12 10:28:52,855 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068929802476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,858 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068929802476 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:52,869 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068929802476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,873 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068929802476 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:52,880 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068929802476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,883 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068929802476 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:52,890 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068929802476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,898 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068929802476 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:52,900 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,903 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068929540331} | ret=SUCCESS |  
2019-09-12 10:28:52,911 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068933734637 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,914 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068933734637 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:52,918 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068929802476
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068933734637
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:52,927 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:52,929 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068935373038} | ret=SUCCESS |  
2019-09-12 10:28:52,941 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068935635183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,944 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068935635183 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:52,952 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068935635183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,954 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068935635183 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:52,962 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068935635183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,966 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068935635183 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:52,973 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068935635183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:52,977 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068935635183 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:52,979 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:52,997 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068935373038} | ret=SUCCESS |  
2019-09-12 10:28:53,007 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068938911984 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,010 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068938911984 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:53,025 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068935635183
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068938911984
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:53,044 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,046 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:53,059 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068942385393} | ret=SUCCESS |  
2019-09-12 10:28:53,069 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068943302898 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,073 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068943302898 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:53,081 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068943302898 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,083 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068943302898 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:53,091 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068943302898 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,093 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068943302898 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:53,100 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068943302898 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,102 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068943302898 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:53,105 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:53,118 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779068942385393} | ret=SUCCESS |  
2019-09-12 10:28:53,127 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068947169523 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,129 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068947169523 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:53,143 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, key=498c0732-0532-4e37-a4fb-bb048870c1a4, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068943302898
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068947169523
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:53,144 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, uploadID=38a51355-dec6-46ee-98fa-86fb6ffb8393-102779068929016042, partNumberMarker=0, maxParts=2, key=498c0732-0532-4e37-a4fb-bb048870c1a4} | ret=SUCCESS |  
2019-09-12 10:28:53,146 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=ff055f14-6f4b-403d-86e3-b54ebbf28341, bucket=24e6242e-e626-4225-9869-a8e08cce3ea6, uploadID=38a51355-dec6-46ee-98fa-86fb6ffb8393-102779068929016042, partNumberMarker=2, maxParts=2, key=498c0732-0532-4e37-a4fb-bb048870c1a4} | ret=SUCCESS |  
2019-09-12 10:28:53,147 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-66283, with jenkins1000 as owner.
2019-09-12 10:28:53,159 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-66283, creationTime=1568284133147, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,160 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-66283} | ret=SUCCESS |  
2019-09-12 10:28:53,161 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-66283, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:53,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-66283, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:28:53,162 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: fe2f65b4-237e-4828-b97d-35946878b4fb, with jenkins1000 as owner.
2019-09-12 10:28:53,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=fe2f65b4-237e-4828-b97d-35946878b4fb, creationTime=1568284133163, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=fe2f65b4-237e-4828-b97d-35946878b4fb} | ret=SUCCESS |  
2019-09-12 10:28:53,176 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: fe2f65b4-237e-4828-b97d-35946878b4fb/31054621-1ce2-44fb-8e4b-de28b41df17f, with Versioning false and Storage Type set to SSD and Encryption set to false 
2019-09-12 10:28:53,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,188 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=fe2f65b4-237e-4828-b97d-35946878b4fb, bucket=31054621-1ce2-44fb-8e4b-de28b41df17f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=SSD, creationTime=1568284133176} | ret=SUCCESS |  
2019-09-12 10:28:53,189 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=fe2f65b4-237e-4828-b97d-35946878b4fb, bucket=31054621-1ce2-44fb-8e4b-de28b41df17f} | ret=SUCCESS |  
2019-09-12 10:28:53,189 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c1cd0057-0205-4d31-876e-4c2efeb7be7c, with jenkins1000 as owner.
2019-09-12 10:28:53,280 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c1cd0057-0205-4d31-876e-4c2efeb7be7c, creationTime=1568284133190, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,290 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c1cd0057-0205-4d31-876e-4c2efeb7be7c} | ret=SUCCESS |  
2019-09-12 10:28:53,291 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c1cd0057-0205-4d31-876e-4c2efeb7be7c/78dbdb01-732a-4a63-8b95-d2a790d70afd, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,307 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c1cd0057-0205-4d31-876e-4c2efeb7be7c, bucket=78dbdb01-732a-4a63-8b95-d2a790d70afd, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS], user:test1:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133291} | ret=SUCCESS |  
2019-09-12 10:28:53,319 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=c1cd0057-0205-4d31-876e-4c2efeb7be7c, bucket=78dbdb01-732a-4a63-8b95-d2a790d70afd, key=null} | ret=SUCCESS |  
2019-09-12 10:28:53,321 [IPC Server handler 2 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-775_850 to index:850
2019-09-12 10:28:53,322 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_775-850
2019-09-12 10:28:53,355 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851
2019-09-12 10:28:53,357 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=c1cd0057-0205-4d31-876e-4c2efeb7be7c, bucket=78dbdb01-732a-4a63-8b95-d2a790d70afd, key=null} | ret=SUCCESS |  
2019-09-12 10:28:53,358 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c6a25041-749e-49d5-9ccb-c03c84577c8d, with jenkins1000 as owner.
2019-09-12 10:28:53,370 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, creationTime=1568284133359, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,372 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d} | ret=SUCCESS |  
2019-09-12 10:28:53,372 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c6a25041-749e-49d5-9ccb-c03c84577c8d/270ee64c-72e8-411f-b1cd-693bf818a632, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,384 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133373} | ret=SUCCESS |  
2019-09-12 10:28:53,385 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632} | ret=SUCCESS |  
2019-09-12 10:28:53,388 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:53,401 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632, key=de23358d-73f0-4ffb-815d-0d53ac1faa77, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068965650676
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:53,406 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779068965650676 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,409 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779068965650676 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:53,423 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632, key=de23358d-73f0-4ffb-815d-0d53ac1faa77, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779068965650676
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:53,425 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:53,426 [IPC Server handler 19 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:53,427 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:53,427 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632, key=de23358d-73f0-4ffb-815d-0d53ac1faa77, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:53,440 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632, key=de23358d-73f0-4ffb-815d-0d53ac1faa77, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,443 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=c6a25041-749e-49d5-9ccb-c03c84577c8d, bucket=270ee64c-72e8-411f-b1cd-693bf818a632, key=de23358d-73f0-4ffb-815d-0d53ac1faa77, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-12 10:28:53,446 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 518e83b4-b343-4e40-8850-bd4146abe652, with jenkins1000 as owner.
2019-09-12 10:28:53,459 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=518e83b4-b343-4e40-8850-bd4146abe652, creationTime=1568284133447, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,460 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=518e83b4-b343-4e40-8850-bd4146abe652} | ret=SUCCESS |  
2019-09-12 10:28:53,479 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_VOLUME {volume=518e83b4-b343-4e40-8850-bd4146abe652} | ret=SUCCESS |  
2019-09-12 10:28:53,481 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=518e83b4-b343-4e40-8850-bd4146abe652} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume 518e83b4-b343-4e40-8850-bd4146abe652 is not found
	at org.apache.hadoop.ozone.om.VolumeManagerImpl.getVolumeInfo(VolumeManagerImpl.java:326)
	at org.apache.hadoop.ozone.om.OzoneManager.getVolumeInfo(OzoneManager.java:1933) 
2019-09-12 10:28:53,487 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6e35c399-99c0-4975-a06e-35f713f6068c, with jenkins1000 as owner.
2019-09-12 10:28:53,498 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6e35c399-99c0-4975-a06e-35f713f6068c, creationTime=1568284133488, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,500 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6e35c399-99c0-4975-a06e-35f713f6068c} | ret=SUCCESS |  
2019-09-12 10:28:53,506 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 256b06a5-77e5-40ee-b8d6-f71381a9d373, with jenkins1000 as owner.
2019-09-12 10:28:53,514 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, creationTime=1568284133507, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,515 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373} | ret=SUCCESS |  
2019-09-12 10:28:53,516 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 256b06a5-77e5-40ee-b8d6-f71381a9d373/48c01ad9-1176-45e4-a8b8-d0bd849a7189, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,528 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, bucket=48c01ad9-1176-45e4-a8b8-d0bd849a7189, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133517} | ret=SUCCESS |  
2019-09-12 10:28:53,529 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, bucket=48c01ad9-1176-45e4-a8b8-d0bd849a7189} | ret=SUCCESS |  
2019-09-12 10:28:53,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:53,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, bucket=48c01ad9-1176-45e4-a8b8-d0bd849a7189, key=34cebe2e-2e5b-4ab8-833d-2bf672a91696, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 10
    localID: 102779068975087862
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "c280e1db-3360-42e4-9770-4e0965901142"
  }
}
]} | ret=SUCCESS |  
Sep 12, 2019 10:28:53 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=132, target=192.168.157.195:36227} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:175)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:423)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:372)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:285)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:167)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:222)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagDisable(TestOzoneRpcClientAbstract.java:905)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

2019-09-12 10:28:53,565 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,644 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 10 locID: 102779068975087862 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,645 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,657 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 10 locID: 102779068975087862 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:53,661 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4A79C999BD57->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-4A79C999BD57->969f621b-625a-4660-bcba-147498526acd@group-4E0965901142, cid=40, SUCCESS, logIndex=1, commits[969f621b-625a-4660-bcba-147498526acd:c2]
2019-09-12 10:28:53,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,719 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 10 locID: 102779068975087862 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:53,723 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-4A79C999BD57->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-4A79C999BD57->969f621b-625a-4660-bcba-147498526acd@group-4E0965901142, cid=41, SUCCESS, logIndex=3, commits[969f621b-625a-4660-bcba-147498526acd:c4]
2019-09-12 10:28:53,735 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, bucket=48c01ad9-1176-45e4-a8b8-d0bd849a7189, key=34cebe2e-2e5b-4ab8-833d-2bf672a91696, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 10
    localID: 102779068975087862
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "c280e1db-3360-42e4-9770-4e0965901142"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:53,737 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#10} | ret=SUCCESS |  
2019-09-12 10:28:53,738 [IPC Server handler 0 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:53,738 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:53,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, bucket=48c01ad9-1176-45e4-a8b8-d0bd849a7189, key=34cebe2e-2e5b-4ab8-833d-2bf672a91696, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:53,751 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#10} | ret=SUCCESS |  
2019-09-12 10:28:53,752 [IPC Server handler 3 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:53,753 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:53,753 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=256b06a5-77e5-40ee-b8d6-f71381a9d373, bucket=48c01ad9-1176-45e4-a8b8-d0bd849a7189, key=34cebe2e-2e5b-4ab8-833d-2bf672a91696, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:53,760 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 10 locID: 102779068975087862 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:53,763 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 10 locID: 102779068975087862 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:28:53,764 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "18abf9865e2a5842:18abf9865e2a5842:0:0"
containerID: 10
datanodeUuid: "969f621b-625a-4660-bcba-147498526acd"
readChunk {
  blockID {
    containerID: 10
    localID: 102779068975087862
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102779068975087862_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 969f621b-625a-4660-bcba-147498526acd
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagEnable(TestOzoneRpcClientAbstract.java:890)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:28:53,766 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "18abf9865e2a5842:18abf9865e2a5842:0:0"
containerID: 10
datanodeUuid: "969f621b-625a-4660-bcba-147498526acd"
readChunk {
  blockID {
    containerID: 10
    localID: 102779068975087862
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102779068975087862_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: c280e1db-3360-42e4-9770-4e0965901142, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-12 10:28:53,766 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b05cc83d-e7c8-4994-8a2d-ddcbaff22d68, with jenkins1000 as owner.
2019-09-12 10:28:53,779 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b05cc83d-e7c8-4994-8a2d-ddcbaff22d68, creationTime=1568284133767, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,781 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b05cc83d-e7c8-4994-8a2d-ddcbaff22d68} | ret=SUCCESS |  
2019-09-12 10:28:53,781 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b05cc83d-e7c8-4994-8a2d-ddcbaff22d68/59fa8de2-4d8e-4edd-9b62-93c9b020edd1, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,793 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b05cc83d-e7c8-4994-8a2d-ddcbaff22d68, bucket=59fa8de2-4d8e-4edd-9b62-93c9b020edd1, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133782} | ret=SUCCESS |  
2019-09-12 10:28:53,794 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b05cc83d-e7c8-4994-8a2d-ddcbaff22d68, bucket=59fa8de2-4d8e-4edd-9b62-93c9b020edd1} | ret=SUCCESS |  
2019-09-12 10:28:53,807 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b05cc83d-e7c8-4994-8a2d-ddcbaff22d68, bucket=59fa8de2-4d8e-4edd-9b62-93c9b020edd1, key=d784bda9-1331-4980-9e07-bac5deb2bc66, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,819 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=b05cc83d-e7c8-4994-8a2d-ddcbaff22d68, bucket=59fa8de2-4d8e-4edd-9b62-93c9b020edd1, key=d784bda9-1331-4980-9e07-bac5deb2bc66, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,820 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: aac88415-913f-405c-96bb-bf5b7cb0b6a0, with jenkins1000 as owner.
2019-09-12 10:28:53,832 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=aac88415-913f-405c-96bb-bf5b7cb0b6a0, creationTime=1568284133821, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,833 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=aac88415-913f-405c-96bb-bf5b7cb0b6a0} | ret=SUCCESS |  
2019-09-12 10:28:53,834 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: aac88415-913f-405c-96bb-bf5b7cb0b6a0/e3b43be1-85ca-411b-be6b-99444f7df78c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,846 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=aac88415-913f-405c-96bb-bf5b7cb0b6a0, bucket=e3b43be1-85ca-411b-be6b-99444f7df78c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133835} | ret=SUCCESS |  
2019-09-12 10:28:53,847 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=aac88415-913f-405c-96bb-bf5b7cb0b6a0, bucket=e3b43be1-85ca-411b-be6b-99444f7df78c} | ret=SUCCESS |  
2019-09-12 10:28:53,848 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 35bd96bc-3b66-4344-9ede-516480671e7c, with jenkins1000 as owner.
2019-09-12 10:28:53,861 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=35bd96bc-3b66-4344-9ede-516480671e7c, creationTime=1568284133849, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,862 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=35bd96bc-3b66-4344-9ede-516480671e7c} | ret=SUCCESS |  
2019-09-12 10:28:53,862 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 35bd96bc-3b66-4344-9ede-516480671e7c/d60bb6a8-9730-46a4-ae08-b83cc2468c74, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,874 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=35bd96bc-3b66-4344-9ede-516480671e7c, bucket=d60bb6a8-9730-46a4-ae08-b83cc2468c74, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133863} | ret=SUCCESS |  
2019-09-12 10:28:53,875 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=35bd96bc-3b66-4344-9ede-516480671e7c, bucket=d60bb6a8-9730-46a4-ae08-b83cc2468c74} | ret=SUCCESS |  
2019-09-12 10:28:53,888 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=35bd96bc-3b66-4344-9ede-516480671e7c, bucket=d60bb6a8-9730-46a4-ae08-b83cc2468c74, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-12 10:28:53,889 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=35bd96bc-3b66-4344-9ede-516480671e7c, bucket=d60bb6a8-9730-46a4-ae08-b83cc2468c74} | ret=SUCCESS |  
2019-09-12 10:28:53,890 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 51477fce-26cc-4273-928d-bb1bc6170565, with jenkins1000 as owner.
2019-09-12 10:28:53,902 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=51477fce-26cc-4273-928d-bb1bc6170565, creationTime=1568284133890, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,903 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=51477fce-26cc-4273-928d-bb1bc6170565} | ret=SUCCESS |  
2019-09-12 10:28:53,904 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 51477fce-26cc-4273-928d-bb1bc6170565/219bbe90-3801-479b-9043-b6e3074f3383, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,914 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=51477fce-26cc-4273-928d-bb1bc6170565, bucket=219bbe90-3801-479b-9043-b6e3074f3383, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133904} | ret=SUCCESS |  
2019-09-12 10:28:53,916 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=51477fce-26cc-4273-928d-bb1bc6170565, bucket=219bbe90-3801-479b-9043-b6e3074f3383} | ret=SUCCESS |  
2019-09-12 10:28:53,919 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=51477fce-26cc-4273-928d-bb1bc6170565, bucket=219bbe90-3801-479b-9043-b6e3074f3383, key=22c9f993-5369-4dbb-9554-448ec8c4da29, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: 51477fce-26cc-4273-928d-bb1bc6170565bucket: 219bbe90-3801-479b-9043-b6e3074f3383key: 22c9f993-5369-4dbb-9554-448ec8c4da29
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:53,922 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest (S3MultipartUploadAbortRequest.java:validateAndUpdateCache(167)) - Abort Multipart request is failed for KeyName 22c9f993-5369-4dbb-9554-448ec8c4da29 in VolumeName/Bucket 51477fce-26cc-4273-928d-bb1bc6170565/219bbe90-3801-479b-9043-b6e3074f3383
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: 51477fce-26cc-4273-928d-bb1bc6170565bucket: 219bbe90-3801-479b-9043-b6e3074f3383key: 22c9f993-5369-4dbb-9554-448ec8c4da29
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:53,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {4808f215-b074-4dff-b699-e4b314f9d555=s3Bucket, ozone=username} | ret=SUCCESS |  
2019-09-12 10:28:53,935 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone} | ret=SUCCESS |  
2019-09-12 10:28:53,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone, bucket=4808f215-b074-4dff-b699-e4b314f9d555} | ret=SUCCESS |  
2019-09-12 10:28:53,939 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 737f203e-6cf1-498f-afa2-1843760a3499, with jenkins1000 as owner.
2019-09-12 10:28:53,942 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=737f203e-6cf1-498f-afa2-1843760a3499, creationTime=1568284133940, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:53,943 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=737f203e-6cf1-498f-afa2-1843760a3499} | ret=SUCCESS |  
2019-09-12 10:28:53,943 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 737f203e-6cf1-498f-afa2-1843760a3499/2403e92f-2d90-414f-aa02-c000d275b328, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:53,946 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=737f203e-6cf1-498f-afa2-1843760a3499, bucket=2403e92f-2d90-414f-aa02-c000d275b328, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284133944} | ret=SUCCESS |  
2019-09-12 10:28:53,947 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=737f203e-6cf1-498f-afa2-1843760a3499, bucket=2403e92f-2d90-414f-aa02-c000d275b328} | ret=SUCCESS |  
2019-09-12 10:28:53,949 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=737f203e-6cf1-498f-afa2-1843760a3499, bucket=2403e92f-2d90-414f-aa02-c000d275b328, key=bfc737f9-d52a-4913-adbe-9090c91de439, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,963 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=737f203e-6cf1-498f-afa2-1843760a3499, bucket=2403e92f-2d90-414f-aa02-c000d275b328, key=bfc737f9-d52a-4913-adbe-9090c91de439, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:53,965 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,965 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:53,966 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,966 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,966 [IPC Server handler 6 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,966 [IPC Server handler 6 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,966 [IPC Server handler 6 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:53,966 [IPC Server handler 6 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:53,967 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:53,967 [IPC Server handler 2 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 38663, call Call#978 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,970 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663. Trying to failover immediately.
2019-09-12 10:28:53,972 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,972 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:53,972 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,973 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,973 [IPC Server handler 8 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,973 [IPC Server handler 8 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,973 [IPC Server handler 8 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:53,974 [IPC Server handler 8 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:53,974 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:53,974 [IPC Server handler 1 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 38663, call Call#978 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,977 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:28:53,978 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,979 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:53,979 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,979 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,979 [IPC Server handler 5 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,979 [IPC Server handler 5 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,980 [IPC Server handler 5 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:53,980 [IPC Server handler 5 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:53,980 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:53,981 [IPC Server handler 0 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 38663, call Call#978 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,983 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:28:53,984 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,984 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:53,985 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,985 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,985 [IPC Server handler 11 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,985 [IPC Server handler 11 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,986 [IPC Server handler 11 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:53,986 [IPC Server handler 11 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:53,986 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:53,987 [IPC Server handler 12 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38663, call Call#978 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,989 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:28:53,991 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,991 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:53,991 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,992 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,992 [IPC Server handler 9 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,992 [IPC Server handler 9 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,993 [IPC Server handler 9 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:53,993 [IPC Server handler 9 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:53,993 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:53,994 [IPC Server handler 5 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38663, call Call#978 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,996 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:28:53,997 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,997 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:53,998 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:53,998 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,998 [IPC Server handler 13 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:53,998 [IPC Server handler 13 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:53,999 [IPC Server handler 13 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:53,999 [IPC Server handler 13 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:53,999 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,000 [IPC Server handler 14 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 38663, call Call#978 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,006 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,008 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,008 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,008 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,009 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,009 [IPC Server handler 15 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,009 [IPC Server handler 15 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,014 [IPC Server handler 15 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,014 [IPC Server handler 15 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,014 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,015 [IPC Server handler 13 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 38663, call Call#978 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,019 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,021 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,021 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,021 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,021 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,022 [IPC Server handler 12 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,022 [IPC Server handler 12 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,022 [IPC Server handler 12 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,023 [IPC Server handler 12 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,023 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,023 [IPC Server handler 16 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38663, call Call#978 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,024 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,025 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,025 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,026 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,026 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,026 [IPC Server handler 10 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,026 [IPC Server handler 10 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,027 [IPC Server handler 10 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,027 [IPC Server handler 10 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,027 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,027 [IPC Server handler 15 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 38663, call Call#978 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,028 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,029 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,030 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,030 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,030 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,030 [IPC Server handler 14 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,031 [IPC Server handler 14 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,031 [IPC Server handler 14 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,031 [IPC Server handler 14 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,031 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,032 [IPC Server handler 17 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 38663, call Call#978 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,033 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,034 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,034 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,034 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,035 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,035 [IPC Server handler 16 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,035 [IPC Server handler 16 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,036 [IPC Server handler 16 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,036 [IPC Server handler 16 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,036 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,037 [IPC Server handler 19 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 38663, call Call#978 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,037 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:28:54,038 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUploadOverride(TestOzoneRpcClientAbstract.java:1848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:28:54,041 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 2f5d4248-de4e-4b0f-8711-e38fe5bad32b, with jenkins1000 as owner.
2019-09-12 10:28:54,076 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b, creationTime=1568284134041, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,078 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b} | ret=SUCCESS |  
2019-09-12 10:28:54,078 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 2f5d4248-de4e-4b0f-8711-e38fe5bad32b/58607cc3-3345-4222-bdec-d051c43a3250, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,091 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b, bucket=58607cc3-3345-4222-bdec-d051c43a3250, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134079} | ret=SUCCESS |  
2019-09-12 10:28:54,092 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b, bucket=58607cc3-3345-4222-bdec-d051c43a3250} | ret=SUCCESS |  
2019-09-12 10:28:54,094 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,107 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b, bucket=58607cc3-3345-4222-bdec-d051c43a3250, key=99c59d78-5a37-4063-a011-c68ccd7853e5, dataSize=4194304, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069011984635
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,111 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069011984635 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,114 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069011984635 bcsId: 0,size=1264]} | ret=SUCCESS |  
2019-09-12 10:28:54,129 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b, bucket=58607cc3-3345-4222-bdec-d051c43a3250, key=99c59d78-5a37-4063-a011-c68ccd7853e5, dataSize=1264, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069011984635
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1264
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,131 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=2f5d4248-de4e-4b0f-8711-e38fe5bad32b, bucket=58607cc3-3345-4222-bdec-d051c43a3250, key=99c59d78-5a37-4063-a011-c68ccd7853e5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,132 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: be7d362c-cfa7-45e0-9bb9-66facdfb57c3, with jenkins1000 as owner.
2019-09-12 10:28:54,140 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=be7d362c-cfa7-45e0-9bb9-66facdfb57c3, creationTime=1568284134133, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,141 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=be7d362c-cfa7-45e0-9bb9-66facdfb57c3} | ret=SUCCESS |  
2019-09-12 10:28:54,141 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: be7d362c-cfa7-45e0-9bb9-66facdfb57c3/da5966bc-ad24-4217-912e-448e5e0be241, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,153 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=be7d362c-cfa7-45e0-9bb9-66facdfb57c3, bucket=da5966bc-ad24-4217-912e-448e5e0be241, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134142} | ret=SUCCESS |  
2019-09-12 10:28:54,154 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=be7d362c-cfa7-45e0-9bb9-66facdfb57c3, bucket=da5966bc-ad24-4217-912e-448e5e0be241} | ret=SUCCESS |  
2019-09-12 10:28:54,167 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=be7d362c-cfa7-45e0-9bb9-66facdfb57c3, bucket=da5966bc-ad24-4217-912e-448e5e0be241, key=70ce112b-bbdb-4b30-b02e-c9086064f820, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:54,180 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=be7d362c-cfa7-45e0-9bb9-66facdfb57c3, bucket=da5966bc-ad24-4217-912e-448e5e0be241, key=70ce112b-bbdb-4b30-b02e-c9086064f820, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=9ed5a2ac-32ec-4d9b-bd43-fa1eb61106f4}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: be7d362c-cfa7-45e0-9bb9-66facdfb57c3bucket: da5966bc-ad24-4217-912e-448e5e0be241key: 70ce112b-bbdb-4b30-b02e-c9086064f820
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:54,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 70ce112b-bbdb-4b30-b02e-c9086064f820 in Volume/Bucket be7d362c-cfa7-45e0-9bb9-66facdfb57c3/da5966bc-ad24-4217-912e-448e5e0be241
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: be7d362c-cfa7-45e0-9bb9-66facdfb57c3bucket: da5966bc-ad24-4217-912e-448e5e0be241key: 70ce112b-bbdb-4b30-b02e-c9086064f820
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:54,184 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 600a31a7-bbe7-4b81-ac09-bb42272d59aa, with jenkins1000 as owner.
2019-09-12 10:28:54,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:54,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=600a31a7-bbe7-4b81-ac09-bb42272d59aa, creationTime=1568284134185, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,198 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=600a31a7-bbe7-4b81-ac09-bb42272d59aa} | ret=SUCCESS |  
2019-09-12 10:28:54,198 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 600a31a7-bbe7-4b81-ac09-bb42272d59aa/ac40c1bd-abfc-4b00-9feb-366f5b56a168, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,210 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=600a31a7-bbe7-4b81-ac09-bb42272d59aa, bucket=ac40c1bd-abfc-4b00-9feb-366f5b56a168, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134199} | ret=SUCCESS |  
2019-09-12 10:28:54,211 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=600a31a7-bbe7-4b81-ac09-bb42272d59aa, bucket=ac40c1bd-abfc-4b00-9feb-366f5b56a168} | ret=SUCCESS |  
2019-09-12 10:28:54,225 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRequest (OMKeyRequest.java:prepareCreateKeyResponse(331)) - ALLOCATE_KEY failed for Key: abef5b26-8b90-4625-9543-481ef7ad0d48 in volume/bucket:600a31a7-bbe7-4b81-ac09-bb42272d59aa/ac40c1bd-abfc-4b00-9feb-366f5b56a168
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422)
	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:179)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:54,225 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=600a31a7-bbe7-4b81-ac09-bb42272d59aa, bucket=ac40c1bd-abfc-4b00-9feb-366f5b56a168, key=abef5b26-8b90-4625-9543-481ef7ad0d48, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422) 
2019-09-12 10:28:54,226 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 9d195c1f-a457-49d9-b0c1-92e8b47f3a2d, with jenkins1000 as owner.
2019-09-12 10:28:54,229 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=9d195c1f-a457-49d9-b0c1-92e8b47f3a2d, creationTime=1568284134227, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,230 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=9d195c1f-a457-49d9-b0c1-92e8b47f3a2d} | ret=SUCCESS |  
2019-09-12 10:28:54,231 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 9d195c1f-a457-49d9-b0c1-92e8b47f3a2d/c9b8d2cc-f949-451d-9c8b-5b22ca3650bd, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,241 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=9d195c1f-a457-49d9-b0c1-92e8b47f3a2d, bucket=c9b8d2cc-f949-451d-9c8b-5b22ca3650bd, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134231} | ret=SUCCESS |  
2019-09-12 10:28:54,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=9d195c1f-a457-49d9-b0c1-92e8b47f3a2d, bucket=c9b8d2cc-f949-451d-9c8b-5b22ca3650bd} | ret=SUCCESS |  
2019-09-12 10:28:54,244 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,244 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,245 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,245 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,245 [IPC Server handler 18 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,245 [IPC Server handler 18 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,246 [IPC Server handler 18 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,246 [IPC Server handler 18 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,246 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,247 [IPC Server handler 10 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38663, call Call#1014 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,247 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663. Trying to failover immediately.
2019-09-12 10:28:54,249 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,249 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,249 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,249 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,250 [IPC Server handler 19 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,250 [IPC Server handler 19 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,251 [IPC Server handler 19 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,251 [IPC Server handler 19 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,251 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,251 [IPC Server handler 8 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38663, call Call#1014 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,252 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,253 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,254 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,254 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,254 [IPC Server handler 7 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,254 [IPC Server handler 7 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,254 [IPC Server handler 7 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,255 [IPC Server handler 7 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,255 [IPC Server handler 7 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,255 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,256 [IPC Server handler 11 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38663, call Call#1014 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,256 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,259 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,259 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,260 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,260 [IPC Server handler 2 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,260 [IPC Server handler 2 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,260 [IPC Server handler 2 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,261 [IPC Server handler 2 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,261 [IPC Server handler 2 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,261 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,262 [IPC Server handler 9 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38663, call Call#1014 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,262 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,263 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,264 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,264 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,264 [IPC Server handler 0 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,264 [IPC Server handler 0 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,265 [IPC Server handler 0 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,265 [IPC Server handler 0 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,265 [IPC Server handler 0 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,265 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,266 [IPC Server handler 7 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38663, call Call#1014 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,266 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,267 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,268 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,268 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,268 [IPC Server handler 3 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,268 [IPC Server handler 3 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,269 [IPC Server handler 3 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,269 [IPC Server handler 3 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,269 [IPC Server handler 3 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,269 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,270 [IPC Server handler 6 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38663, call Call#1014 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,270 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,271 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,272 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,272 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,272 [IPC Server handler 1 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,272 [IPC Server handler 1 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,272 [IPC Server handler 1 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,273 [IPC Server handler 1 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,273 [IPC Server handler 1 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,273 [IPC Server handler 3 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 38663, call Call#1014 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,274 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,275 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,275 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,275 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,276 [IPC Server handler 4 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,276 [IPC Server handler 4 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,276 [IPC Server handler 4 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,276 [IPC Server handler 4 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,277 [IPC Server handler 4 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,277 [IPC Server handler 4 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38663, call Call#1014 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,278 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,279 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,279 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,279 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,279 [IPC Server handler 6 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,279 [IPC Server handler 6 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,279 [IPC Server handler 6 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,280 [IPC Server handler 6 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,280 [IPC Server handler 6 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,280 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,280 [IPC Server handler 2 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 38663, call Call#1014 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,281 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,282 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,282 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,282 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,282 [IPC Server handler 8 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,282 [IPC Server handler 8 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,282 [IPC Server handler 8 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,283 [IPC Server handler 8 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,283 [IPC Server handler 8 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,283 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,284 [IPC Server handler 1 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 38663, call Call#1014 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,284 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,285 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,285 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,286 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,286 [IPC Server handler 5 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,286 [IPC Server handler 5 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,286 [IPC Server handler 5 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,287 [IPC Server handler 5 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,287 [IPC Server handler 5 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,287 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,288 [IPC Server handler 0 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 38663, call Call#1014 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,288 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:28:54,289 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-47684, with jenkins1000 as owner.
2019-09-12 10:28:54,300 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-47684, creationTime=1568284134290, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,301 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-47684} | ret=SUCCESS |  
2019-09-12 10:28:54,302 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-47684/buc-41971, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-47684, bucket=buc-41971, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134303} | ret=SUCCESS |  
2019-09-12 10:28:54,323 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-47684, bucket=buc-41971} | ret=SUCCESS |  
2019-09-12 10:28:54,324 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-47684, bucket=buc-41971, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-12 10:28:54,324 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-47684, bucket=buc-41971, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-12 10:28:54,325 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 3d2a3fd1-ed32-4c89-8fa7-7a7df9ee0893, with jenkins1000 as owner.
2019-09-12 10:28:54,331 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=3d2a3fd1-ed32-4c89-8fa7-7a7df9ee0893, creationTime=1568284134326, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,332 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3d2a3fd1-ed32-4c89-8fa7-7a7df9ee0893} | ret=SUCCESS |  
2019-09-12 10:28:54,333 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 3d2a3fd1-ed32-4c89-8fa7-7a7df9ee0893/1413c14b-e3bf-45a5-b2e8-c2bec5d828d2, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,345 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=3d2a3fd1-ed32-4c89-8fa7-7a7df9ee0893, bucket=1413c14b-e3bf-45a5-b2e8-c2bec5d828d2, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134333} | ret=SUCCESS |  
2019-09-12 10:28:54,346 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=3d2a3fd1-ed32-4c89-8fa7-7a7df9ee0893, bucket=1413c14b-e3bf-45a5-b2e8-c2bec5d828d2} | ret=SUCCESS |  
2019-09-12 10:28:54,348 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,348 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,348 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,348 [IPC Server handler 11 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,349 [IPC Server handler 11 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,349 [IPC Server handler 11 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,349 [IPC Server handler 11 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,349 [IPC Server handler 11 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,350 [IPC Server handler 8 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38663, call Call#1036 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,351 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663. Trying to failover immediately.
2019-09-12 10:28:54,352 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,352 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,352 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,353 [IPC Server handler 9 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,353 [IPC Server handler 9 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,353 [IPC Server handler 9 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,354 [IPC Server handler 9 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,354 [IPC Server handler 9 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,354 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,355 [IPC Server handler 11 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38663, call Call#1036 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,355 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,356 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,356 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,356 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,356 [IPC Server handler 13 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,357 [IPC Server handler 13 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,357 [IPC Server handler 13 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,357 [IPC Server handler 13 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,357 [IPC Server handler 13 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,357 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,357 [IPC Server handler 9 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38663, call Call#1036 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,358 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,359 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,359 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,359 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,360 [IPC Server handler 15 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,360 [IPC Server handler 15 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,360 [IPC Server handler 15 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,360 [IPC Server handler 15 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,361 [IPC Server handler 15 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,361 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,361 [IPC Server handler 7 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38663, call Call#1036 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,362 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,363 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,363 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,363 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,363 [IPC Server handler 12 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,363 [IPC Server handler 12 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,364 [IPC Server handler 12 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,364 [IPC Server handler 12 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,364 [IPC Server handler 12 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,365 [IPC Server handler 6 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38663, call Call#1036 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,365 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,366 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,366 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,367 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,367 [IPC Server handler 10 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,367 [IPC Server handler 10 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,367 [IPC Server handler 10 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,368 [IPC Server handler 10 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,368 [IPC Server handler 10 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,368 [IPC Server handler 3 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 38663, call Call#1036 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,369 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,370 [IPC Server handler 14 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,371 [IPC Server handler 4 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38663, call Call#1036 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,371 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,373 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,373 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,373 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,373 [IPC Server handler 16 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,373 [IPC Server handler 16 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,374 [IPC Server handler 16 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,374 [IPC Server handler 16 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,374 [IPC Server handler 16 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,374 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,375 [IPC Server handler 2 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 38663, call Call#1036 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,375 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,376 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,376 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,377 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,377 [IPC Server handler 17 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,377 [IPC Server handler 17 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,377 [IPC Server handler 17 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,377 [IPC Server handler 17 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,378 [IPC Server handler 17 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,378 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,378 [IPC Server handler 1 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 38663, call Call#1036 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,379 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,380 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,380 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,380 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,381 [IPC Server handler 18 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,381 [IPC Server handler 18 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,381 [IPC Server handler 18 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,381 [IPC Server handler 18 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,382 [IPC Server handler 18 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,382 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,382 [IPC Server handler 0 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 38663, call Call#1036 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,383 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38663 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:28:54,384 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,384 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:28:54,384 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:28:54,384 [IPC Server handler 19 on 33084] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,385 [IPC Server handler 19 on 33084] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:28:54,385 [IPC Server handler 19 on 33084] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:28:54,385 [IPC Server handler 19 on 33084] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:28:54,386 [IPC Server handler 19 on 33084] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:28:54,386 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:28:54,386 [IPC Server handler 12 on 38663] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38663, call Call#1036 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:55288
java.lang.NullPointerException
2019-09-12 10:28:54,387 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:28:54,388 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, with jenkins1000 as owner.
2019-09-12 10:28:54,400 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, creationTime=1568284134388, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,401 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2} | ret=SUCCESS |  
2019-09-12 10:28:54,402 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 68c48823-0e1c-4db7-9d67-9b1d4b0b42f2/30e6fedb-64ac-4057-be53-fa3fe1e5df12, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,414 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134403} | ret=SUCCESS |  
2019-09-12 10:28:54,415 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12} | ret=SUCCESS |  
2019-09-12 10:28:54,417 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,430 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=5492dc6b-8b2c-4446-b9a6-14ade6c305c9, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069033152767
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,433 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069033152767 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,435 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069033152767 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,448 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=5492dc6b-8b2c-4446-b9a6-14ade6c305c9, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069033152767
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,450 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,451 [IPC Server handler 2 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,452 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,452 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=5492dc6b-8b2c-4446-b9a6-14ade6c305c9, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,455 [IPC Server handler 0 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,455 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,455 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=5492dc6b-8b2c-4446-b9a6-14ade6c305c9, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,458 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069033152767 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,464 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069033152767 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,465 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,466 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=5492dc6b-8b2c-4446-b9a6-14ade6c305c9, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,466 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,468 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,481 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=dad20955-8ff7-47b6-a613-c7a8edcd3020, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069036495105
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,485 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069036495105 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,487 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069036495105 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,492 [Thread-141] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-851_955 to index:955
2019-09-12 10:28:54,493 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_851-955
2019-09-12 10:28:54,493 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=dad20955-8ff7-47b6-a613-c7a8edcd3020, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069036495105
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,495 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,496 [IPC Server handler 1 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,497 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=dad20955-8ff7-47b6-a613-c7a8edcd3020, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,498 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,499 [IPC Server handler 4 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,500 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=dad20955-8ff7-47b6-a613-c7a8edcd3020, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,502 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069036495105 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,506 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_956
2019-09-12 10:28:54,507 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069036495105 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,509 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,509 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=dad20955-8ff7-47b6-a613-c7a8edcd3020, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,510 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,511 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=fab674d6-ee91-4fcd-a6d4-c54e4940a19a, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069039313155
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,527 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069039313155 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,529 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069039313155 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,542 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=fab674d6-ee91-4fcd-a6d4-c54e4940a19a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069039313155
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,544 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,546 [IPC Server handler 8 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,546 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=fab674d6-ee91-4fcd-a6d4-c54e4940a19a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,548 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,549 [IPC Server handler 5 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,549 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,550 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=fab674d6-ee91-4fcd-a6d4-c54e4940a19a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,553 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069039313155 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,558 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069039313155 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,560 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,561 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=fab674d6-ee91-4fcd-a6d4-c54e4940a19a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,561 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,563 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,584 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=0b7384de-4009-44bb-accb-0a4c44ef6459, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069042721029
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,588 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069042721029 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,591 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069042721029 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,604 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=0b7384de-4009-44bb-accb-0a4c44ef6459, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069042721029
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,606 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,607 [IPC Server handler 9 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,607 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=0b7384de-4009-44bb-accb-0a4c44ef6459, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,610 [IPC Server handler 13 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,611 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,611 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=0b7384de-4009-44bb-accb-0a4c44ef6459, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,614 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069042721029 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,616 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069042721029 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,620 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,620 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=0b7384de-4009-44bb-accb-0a4c44ef6459, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,621 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,622 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,635 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e7c1eab8-4731-4fb6-b4bb-176bb4d79eee, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069046587655
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,640 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069046587655 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,642 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069046587655 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,646 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=969f621b-625a-4660-bcba-147498526acd, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:54,656 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e7c1eab8-4731-4fb6-b4bb-176bb4d79eee, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069046587655
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,657 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,658 [IPC Server handler 12 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,659 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,659 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e7c1eab8-4731-4fb6-b4bb-176bb4d79eee, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,661 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,662 [IPC Server handler 10 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,662 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,663 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e7c1eab8-4731-4fb6-b4bb-176bb4d79eee, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,665 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069046587655 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,673 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069046587655 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,675 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,675 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e7c1eab8-4731-4fb6-b4bb-176bb4d79eee, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,676 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,678 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=748df713-279b-4cdf-bd89-d55485dd6f95, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069050257673
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:54,694 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069050257673 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,697 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069050257673 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,710 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=748df713-279b-4cdf-bd89-d55485dd6f95, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069050257673
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,712 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,713 [IPC Server handler 16 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,713 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,714 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=748df713-279b-4cdf-bd89-d55485dd6f95, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,715 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,716 [IPC Server handler 17 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,716 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,717 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=748df713-279b-4cdf-bd89-d55485dd6f95, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,719 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069050257673 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,721 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069050257673 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,722 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,723 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=748df713-279b-4cdf-bd89-d55485dd6f95, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,723 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,725 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,737 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e71f76d8-33a9-4301-9c0e-e4a9311d7381, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069053337867
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,740 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069053337867 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,742 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069053337867 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,756 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e71f76d8-33a9-4301-9c0e-e4a9311d7381, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069053337867
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,758 [IPC Server handler 19 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,759 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e71f76d8-33a9-4301-9c0e-e4a9311d7381, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,761 [IPC Server handler 7 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,761 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,762 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e71f76d8-33a9-4301-9c0e-e4a9311d7381, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,764 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069053337867 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,766 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069053337867 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,767 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,768 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=e71f76d8-33a9-4301-9c0e-e4a9311d7381, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,768 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,783 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=50082799-2549-4992-b2aa-dfff9859fe46, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069056286989
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,786 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069056286989 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,788 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069056286989 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,802 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=50082799-2549-4992-b2aa-dfff9859fe46, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069056286989
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,803 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,804 [IPC Server handler 0 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,805 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,805 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=50082799-2549-4992-b2aa-dfff9859fe46, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,807 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,808 [IPC Server handler 3 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,808 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=50082799-2549-4992-b2aa-dfff9859fe46, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,811 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069056286989 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,813 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069056286989 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,814 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,815 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=50082799-2549-4992-b2aa-dfff9859fe46, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,815 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,817 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,826 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=9b4cdab1-b0a1-41e4-954f-b0b5ba15dec1, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069059367183
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,829 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069059367183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,831 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069059367183 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,845 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=9b4cdab1-b0a1-41e4-954f-b0b5ba15dec1, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069059367183
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,846 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,847 [IPC Server handler 4 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,847 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,848 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=9b4cdab1-b0a1-41e4-954f-b0b5ba15dec1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,849 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,850 [IPC Server handler 6 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,851 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,851 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=9b4cdab1-b0a1-41e4-954f-b0b5ba15dec1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,853 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069059367183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,856 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069059367183 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,857 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,858 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=9b4cdab1-b0a1-41e4-954f-b0b5ba15dec1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,858 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,859 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=44119b07-50be-4ffb-9c56-9251bf024918, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069062119697
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,875 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069062119697 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,878 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069062119697 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,891 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=44119b07-50be-4ffb-9c56-9251bf024918, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069062119697
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,892 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,893 [IPC Server handler 5 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,893 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=44119b07-50be-4ffb-9c56-9251bf024918, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,895 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,896 [IPC Server handler 11 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,896 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,897 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=44119b07-50be-4ffb-9c56-9251bf024918, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,899 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779069062119697 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,902 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779069062119697 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,903 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:28:54,903 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=68c48823-0e1c-4db7-9d67-9b1d4b0b42f2, bucket=30e6fedb-64ac-4057-be53-fa3fe1e5df12, key=44119b07-50be-4ffb-9c56-9251bf024918, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,904 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:28:54,904 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: fcd2a750-d8b6-4017-99be-d388efe49f5e, with jenkins1000 as owner.
2019-09-12 10:28:54,917 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, creationTime=1568284134905, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:54,918 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e} | ret=SUCCESS |  
2019-09-12 10:28:54,919 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: fcd2a750-d8b6-4017-99be-d388efe49f5e/053bc0c2-f3a1-49ae-afe4-684c6b863a78, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:54,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, bucket=053bc0c2-f3a1-49ae-afe4-684c6b863a78, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284134919} | ret=SUCCESS |  
2019-09-12 10:28:54,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, bucket=053bc0c2-f3a1-49ae-afe4-684c6b863a78} | ret=SUCCESS |  
2019-09-12 10:28:54,934 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:54,946 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, bucket=053bc0c2-f3a1-49ae-afe4-684c6b863a78, key=6c1fcf7b-3012-40c1-88aa-1254e8199910, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779069067034899
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,952 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779069067034899 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,964 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779069067034899 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:54,964 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779069067034899 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:54,965 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=42, SUCCESS, logIndex=12, commits[969f621b-625a-4660-bcba-147498526acd:c13]
2019-09-12 10:28:54,966 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd: receive RaftClientReply:client-FD48EE8A5033->969f621b-625a-4660-bcba-147498526acd@group-51CC9BFFB349, cid=43, SUCCESS, logIndex=13, commits[969f621b-625a-4660-bcba-147498526acd:c14]
2019-09-12 10:28:54,979 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, bucket=053bc0c2-f3a1-49ae-afe4-684c6b863a78, key=6c1fcf7b-3012-40c1-88aa-1254e8199910, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779069067034899
  }
  blockCommitSequenceId: 13
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "969f621b-625a-4660-bcba-147498526acd"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 39804
    }
    ports {
      name: "RATIS"
      value: 44966
    }
    ports {
      name: "STANDALONE"
      value: 36227
    }
    networkName: "969f621b-625a-4660-bcba-147498526acd"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "568e3496-d263-48bf-a1e2-51cc9bffb349"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:54,981 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:54,982 [IPC Server handler 13 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,982 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,983 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, bucket=053bc0c2-f3a1-49ae-afe4-684c6b863a78, key=6c1fcf7b-3012-40c1-88aa-1254e8199910, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,986 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:28:54,987 [IPC Server handler 15 on 33084] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:28:54,988 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:28:54,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=fcd2a750-d8b6-4017-99be-d388efe49f5e, bucket=053bc0c2-f3a1-49ae-afe4-684c6b863a78, key=6c1fcf7b-3012-40c1-88aa-1254e8199910, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:28:54,991 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779069067034899 bcsId: 13} | ret=SUCCESS |  
2019-09-12 10:28:54,993 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779069067034899 bcsId: 13} | ret=SUCCESS |  
2019-09-12 10:28:54,994 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "9aac955f38cc7f68:9aac955f38cc7f68:0:0"
containerID: 2
datanodeUuid: "969f621b-625a-4660-bcba-147498526acd"
readChunk {
  blockID {
    containerID: 2
    localID: 102779069067034899
    blockCommitSequenceId: 13
  }
  chunkData {
    chunkName: "102779069067034899_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 969f621b-625a-4660-bcba-147498526acd
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithCorruptedData(TestOzoneRpcClientAbstract.java:1108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:28:54,996 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "9aac955f38cc7f68:9aac955f38cc7f68:0:0"
containerID: 2
datanodeUuid: "969f621b-625a-4660-bcba-147498526acd"
readChunk {
  blockID {
    containerID: 2
    localID: 102779069067034899
    blockCommitSequenceId: 13
  }
  chunkData {
    chunkName: "102779069067034899_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: 568e3496-d263-48bf-a1e2-51cc9bffb349, Nodes: 969f621b-625a-4660-bcba-147498526acd{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-12 10:28:54,997 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: f833a45f-0087-46d3-abaa-0ff08f976364, with jenkins1000 as owner.
2019-09-12 10:28:55,009 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=f833a45f-0087-46d3-abaa-0ff08f976364, creationTime=1568284134998, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f833a45f-0087-46d3-abaa-0ff08f976364} | ret=SUCCESS |  
2019-09-12 10:28:55,011 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: f833a45f-0087-46d3-abaa-0ff08f976364/f50f8a0e-4201-4d59-8c0a-e285b7cf3dc0, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,024 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=f833a45f-0087-46d3-abaa-0ff08f976364, bucket=f50f8a0e-4201-4d59-8c0a-e285b7cf3dc0, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135012} | ret=SUCCESS |  
2019-09-12 10:28:55,025 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=f833a45f-0087-46d3-abaa-0ff08f976364, bucket=f50f8a0e-4201-4d59-8c0a-e285b7cf3dc0} | ret=SUCCESS |  
2019-09-12 10:28:55,026 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=f833a45f-0087-46d3-abaa-0ff08f976364, bucket=f50f8a0e-4201-4d59-8c0a-e285b7cf3dc0, key=null} | ret=SUCCESS |  
2019-09-12 10:28:55,026 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 9ff437aa-d28b-470a-8d4e-01576bf6d8d5, with jenkins1000 as owner.
2019-09-12 10:28:55,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, creationTime=1568284135027, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,039 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5} | ret=SUCCESS |  
2019-09-12 10:28:55,039 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 9ff437aa-d28b-470a-8d4e-01576bf6d8d5/6160d38e-ffff-4017-a6cd-c3db5176dba0, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,054 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135043} | ret=SUCCESS |  
2019-09-12 10:28:55,055 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0} | ret=SUCCESS |  
2019-09-12 10:28:55,077 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0, key=c7a693bb-25f9-4271-9beb-9713df5c7bc4, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,083 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0, key=c7a693bb-25f9-4271-9beb-9713df5c7bc4, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,085 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:55,097 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0, key=c7a693bb-25f9-4271-9beb-9713df5c7bc4, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779069076472086} | ret=SUCCESS |  
2019-09-12 10:28:55,100 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069076930839 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,104 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069076930839 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:28:55,118 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0, key=c7a693bb-25f9-4271-9beb-9713df5c7bc4, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069076930839
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:55,132 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=9ff437aa-d28b-470a-8d4e-01576bf6d8d5, bucket=6160d38e-ffff-4017-a6cd-c3db5176dba0, key=c7a693bb-25f9-4271-9beb-9713df5c7bc4, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=1803d9a5-ba2e-423d-abfb-375a8ba0128c}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 9ff437aa-d28b-470a-8d4e-01576bf6d8d5bucket: 6160d38e-ffff-4017-a6cd-c3db5176dba0key: c7a693bb-25f9-4271-9beb-9713df5c7bc4
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:202)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:28:55,133 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: c7a693bb-25f9-4271-9beb-9713df5c7bc4 in Volume/Bucket 9ff437aa-d28b-470a-8d4e-01576bf6d8d5/6160d38e-ffff-4017-a6cd-c3db5176dba0
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 9ff437aa-d28b-470a-8d4e-01576bf6d8d5bucket: 6160d38e-ffff-4017-a6cd-c3db5176dba0key: c7a693bb-25f9-4271-9beb-9713df5c7bc4
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:202)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:28:55,135 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 8010f851-9b9e-4303-8318-b4e175ac1b5b, with jenkins1000 as owner.
2019-09-12 10:28:55,141 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=8010f851-9b9e-4303-8318-b4e175ac1b5b, creationTime=1568284135136, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,142 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=8010f851-9b9e-4303-8318-b4e175ac1b5b} | ret=SUCCESS |  
2019-09-12 10:28:55,143 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 672b158c-a987-4ad0-8a01-57b3e3130f25, with jenkins1000 as owner.
2019-09-12 10:28:55,155 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=672b158c-a987-4ad0-8a01-57b3e3130f25, creationTime=1568284135143, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,155 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=672b158c-a987-4ad0-8a01-57b3e3130f25} | ret=SUCCESS |  
2019-09-12 10:28:55,156 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 672b158c-a987-4ad0-8a01-57b3e3130f25/94384737-f717-4a27-ae3e-5ca4e0f5543f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,168 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=672b158c-a987-4ad0-8a01-57b3e3130f25, bucket=94384737-f717-4a27-ae3e-5ca4e0f5543f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135157} | ret=SUCCESS |  
2019-09-12 10:28:55,169 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=672b158c-a987-4ad0-8a01-57b3e3130f25, bucket=94384737-f717-4a27-ae3e-5ca4e0f5543f} | ret=SUCCESS |  
2019-09-12 10:28:55,170 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b6d402a9-e8c8-4af3-aa68-749adf2f1de8, with jenkins1000 as owner.
2019-09-12 10:28:55,183 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, creationTime=1568284135171, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,184 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8} | ret=SUCCESS |  
2019-09-12 10:28:55,184 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b6d402a9-e8c8-4af3-aa68-749adf2f1de8/a0de0496-f94f-45c3-a786-7565ce50d16e, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=349939a8-0e84-4617-9a16-3efaa8718099, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135185} | ret=SUCCESS |  
2019-09-12 10:28:55,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e} | ret=SUCCESS |  
2019-09-12 10:28:55,208 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, key=dbef9687-162d-465d-9ee8-1987f8e70c89, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, key=dbef9687-162d-465d-9ee8-1987f8e70c89, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,227 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:55,239 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, key=dbef9687-162d-465d-9ee8-1987f8e70c89, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779069085319449} | ret=SUCCESS |  
2019-09-12 10:28:55,248 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069086236954 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,251 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069086236954 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:55,264 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069086236954 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,266 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069086236954 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:28:55,274 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069086236954 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,276 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069086236954 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:28:55,284 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069086236954 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,286 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069086236954 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:28:55,289 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:55,301 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, key=dbef9687-162d-465d-9ee8-1987f8e70c89, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779069085319449} | ret=SUCCESS |  
2019-09-12 10:28:55,311 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069090300187 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,314 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069090300187 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:28:55,316 [IPC Server handler 5 on 38663] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-956_1032 to index:1032
2019-09-12 10:28:55,317 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_956 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_956-1032
2019-09-12 10:28:55,329 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_1033
2019-09-12 10:28:55,332 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, key=dbef9687-162d-465d-9ee8-1987f8e70c89, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069086236954
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069090300187
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:55,334 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=b6d402a9-e8c8-4af3-aa68-749adf2f1de8, bucket=a0de0496-f94f-45c3-a786-7565ce50d16e, uploadID=d3980019-f4c1-4e18-b6b2-09e8a17912d9-102779069084270872, partNumberMarker=100, maxParts=2, key=dbef9687-162d-465d-9ee8-1987f8e70c89} | ret=SUCCESS |  
2019-09-12 10:28:55,334 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 417fe13e-2123-4d3b-a09a-07e261c0e50a, with jenkins1000 as owner.
2019-09-12 10:28:55,365 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=417fe13e-2123-4d3b-a09a-07e261c0e50a, creationTime=1568284135335, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,366 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=417fe13e-2123-4d3b-a09a-07e261c0e50a} | ret=SUCCESS |  
2019-09-12 10:28:55,367 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 417fe13e-2123-4d3b-a09a-07e261c0e50a/0631cd47-44aa-415b-9f00-a35aa3c7c9d5, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,390 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=417fe13e-2123-4d3b-a09a-07e261c0e50a, bucket=0631cd47-44aa-415b-9f00-a35aa3c7c9d5, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135368} | ret=SUCCESS |  
2019-09-12 10:28:55,391 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=417fe13e-2123-4d3b-a09a-07e261c0e50a, bucket=0631cd47-44aa-415b-9f00-a35aa3c7c9d5} | ret=SUCCESS |  
2019-09-12 10:28:55,392 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: fba8dd97-6d09-4a61-9bb0-544c98484ee8, with jenkins1000 as owner.
2019-09-12 10:28:55,404 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, creationTime=1568284135393, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8} | ret=SUCCESS |  
2019-09-12 10:28:55,406 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: fba8dd97-6d09-4a61-9bb0-544c98484ee8/58a6ef48-49a8-486b-80d6-ca8ff45ca557, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,418 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, bucket=58a6ef48-49a8-486b-80d6-ca8ff45ca557, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135407} | ret=SUCCESS |  
2019-09-12 10:28:55,419 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, bucket=58a6ef48-49a8-486b-80d6-ca8ff45ca557} | ret=SUCCESS |  
2019-09-12 10:28:55,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, bucket=58a6ef48-49a8-486b-80d6-ca8ff45ca557, key=3fb15126-becc-4472-8b93-ab00072cda91, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, bucket=58a6ef48-49a8-486b-80d6-ca8ff45ca557, key=3fb15126-becc-4472-8b93-ab00072cda91, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=cfd49e03-3682-4409-a0c3-4ec0743be209, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:28:55,459 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, bucket=58a6ef48-49a8-486b-80d6-ca8ff45ca557, key=3fb15126-becc-4472-8b93-ab00072cda91, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779069099737373} | ret=SUCCESS |  
2019-09-12 10:28:55,463 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779069100654878 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:28:55,466 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779069100654878 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:28:55,479 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=fba8dd97-6d09-4a61-9bb0-544c98484ee8, bucket=58a6ef48-49a8-486b-80d6-ca8ff45ca557, key=3fb15126-becc-4472-8b93-ab00072cda91, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779069100654878
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    ipAddress: "192.168.157.195"
    hostName: "pr-hdds-1569-xtfnx-3545843844"
    ports {
      name: "REST"
      value: 45925
    }
    ports {
      name: "RATIS"
      value: 42442
    }
    ports {
      name: "STANDALONE"
      value: 43304
    }
    networkName: "bdedf58a-a481-4a9e-93e6-4446fa864847"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "b7bad135-f2a1-48f5-99de-8146aaeeff1b"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:28:55,480 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c8b01ad9-d117-45e1-aa88-49fa98a27bce, with jenkins1000 as owner.
2019-09-12 10:28:55,493 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c8b01ad9-d117-45e1-aa88-49fa98a27bce, creationTime=1568284135481, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:28:55,495 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c8b01ad9-d117-45e1-aa88-49fa98a27bce} | ret=SUCCESS |  
2019-09-12 10:28:55,495 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c8b01ad9-d117-45e1-aa88-49fa98a27bce/b172b4bc-6e24-4348-9440-ea61b24818b2, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:28:55,508 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c8b01ad9-d117-45e1-aa88-49fa98a27bce, bucket=b172b4bc-6e24-4348-9440-ea61b24818b2, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568284135496} | ret=SUCCESS |  
2019-09-12 10:28:55,509 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c8b01ad9-d117-45e1-aa88-49fa98a27bce, bucket=b172b4bc-6e24-4348-9440-ea61b24818b2} | ret=SUCCESS |  
2019-09-12 10:28:55,521 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=c8b01ad9-d117-45e1-aa88-49fa98a27bce, bucket=b172b4bc-6e24-4348-9440-ea61b24818b2, key=5b5581de-4a11-40ef-936c-61bf9481882a, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,533 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=c8b01ad9-d117-45e1-aa88-49fa98a27bce, bucket=b172b4bc-6e24-4348-9440-ea61b24818b2, key=5b5581de-4a11-40ef-936c-61bf9481882a, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:28:55,540 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-09-12 10:28:55,541 | INFO  | SCMAudit | user=null | ip=null | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-12 10:28:55,541 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-09-12 10:28:55,541 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-09-12 10:28:55,541 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38663
2019-09-12 10:28:55,549 [IPC Server listener on 38663] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38663
2019-09-12 10:28:55,552 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:28:55,556 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cfd49e03-3682-4409-a0c3-4ec0743be209: close
2019-09-12 10:28:55,560 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - cfd49e03-3682-4409-a0c3-4ec0743be209: shutdown group-C5BA1605619E
2019-09-12 10:28:55,560 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=cfd49e03-3682-4409-a0c3-4ec0743be209
2019-09-12 10:28:55,560 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cfd49e03-3682-4409-a0c3-4ec0743be209: shutdown LeaderState
2019-09-12 10:28:55,561 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cfd49e03-3682-4409-a0c3-4ec0743be209-PendingRequests: sendNotLeaderResponses
2019-09-12 10:28:55,565 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E: set stopIndex = 1058
2019-09-12 10:28:55,566 [StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-12 10:28:55,571 [StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1057
2019-09-12 10:28:55,571 [StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E: Took a snapshot at index 1057
2019-09-12 10:28:55,573 [StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E: snapshotIndex: updateIncreasingly -1 -> 1057
2019-09-12 10:28:55,577 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - cfd49e03-3682-4409-a0c3-4ec0743be209:group-C5BA1605619E closes. The last applied log index is 1058
2019-09-12 10:28:55,578 [cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:28:55,580 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cfd49e03-3682-4409-a0c3-4ec0743be209-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e close()
2019-09-12 10:28:55,582 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - cfd49e03-3682-4409-a0c3-4ec0743be209: shutdown server with port 9872 now
2019-09-12 10:28:55,585 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - cfd49e03-3682-4409-a0c3-4ec0743be209: shutdown server with port 9872 successfully
2019-09-12 10:28:55,585 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-12 10:28:55,585 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-12 10:28:55,587 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-12 10:28:55,590 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1debc91c{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-12 10:28:55,595 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:28:55,595 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-12 10:28:55,595 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:28:55,599 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-09-12 10:28:55,599 [main] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-12 10:28:55,599 [ForkJoinPool.commonPool-worker-1] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-12 10:28:55,603 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@747f6c5a
2019-09-12 10:28:55,603 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-12 10:28:55,644 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-12 10:28:55,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:56,187 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-12 10:28:56,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:57,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:58,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:28:59,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:29:00,606 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-12 10:29:00,606 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-12 10:29:00,606 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 969f621b-625a-4660-bcba-147498526acd: close
2019-09-12 10:29:00,607 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 969f621b-625a-4660-bcba-147498526acd: shutdown group-1F01F129F436
2019-09-12 10:29:00,607 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 349939a8-0e84-4617-9a16-3efaa8718099: close
2019-09-12 10:29:00,607 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1F01F129F436,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:29:00,608 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown group-F1321AAFF4A4
2019-09-12 10:29:00,608 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderState
2019-09-12 10:29:00,608 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F1321AAFF4A4,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:29:00,609 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969f621b-625a-4660-bcba-147498526acd-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,609 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderState
2019-09-12 10:29:00,610 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436: set stopIndex = 0
2019-09-12 10:29:00,610 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 349939a8-0e84-4617-9a16-3efaa8718099-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,612 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 969f621b-625a-4660-bcba-147498526acd:group-1F01F129F436 closes. The last applied log index is 0
2019-09-12 10:29:00,616 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4: set stopIndex = 7
2019-09-12 10:29:00,617 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,617 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-F1321AAFF4A4: Taking a snapshot at:(t:1, i:7) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4/sm/snapshot.1_7
2019-09-12 10:29:00,619 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/2a28ef1f-5de8-4be3-ae76-1f01f129f436 close()
2019-09-12 10:29:00,621 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 969f621b-625a-4660-bcba-147498526acd: shutdown group-4E0965901142
2019-09-12 10:29:00,622 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E0965901142,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:29:00,622 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderState
2019-09-12 10:29:00,622 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969f621b-625a-4660-bcba-147498526acd-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,628 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142: set stopIndex = 4
2019-09-12 10:29:00,628 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-4E0965901142: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142/sm/snapshot.1_4
2019-09-12 10:29:00,656 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-F1321AAFF4A4: Finished taking a snapshot at:(t:1, i:7) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4/sm/snapshot.1_7 time:39
2019-09-12 10:29:00,656 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-4E0965901142: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142/sm/snapshot.1_4 time:27
2019-09-12 10:29:00,656 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4: Took a snapshot at index 7
2019-09-12 10:29:00,656 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142: Took a snapshot at index 4
2019-09-12 10:29:00,656 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-12 10:29:00,656 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-4E0965901142: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:00,657 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-F1321AAFF4A4 closes. The last applied log index is 7
2019-09-12 10:29:00,657 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 969f621b-625a-4660-bcba-147498526acd:group-4E0965901142 closes. The last applied log index is 4
2019-09-12 10:29:00,657 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,658 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,659 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/cb42bced-e0e3-4b06-8a26-f1321aaff4a4 close()
2019-09-12 10:29:00,661 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c280e1db-3360-42e4-9770-4e0965901142 close()
2019-09-12 10:29:00,663 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown group-C014B0813831
2019-09-12 10:29:00,666 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 969f621b-625a-4660-bcba-147498526acd: shutdown group-C524CC0FC1F5
2019-09-12 10:29:00,666 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C014B0813831,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:29:00,666 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C524CC0FC1F5,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:29:00,667 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderState
2019-09-12 10:29:00,667 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderState
2019-09-12 10:29:00,667 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 349939a8-0e84-4617-9a16-3efaa8718099-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,668 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969f621b-625a-4660-bcba-147498526acd-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,668 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831: set stopIndex = 0
2019-09-12 10:29:00,668 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5: set stopIndex = 0
2019-09-12 10:29:00,669 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-C014B0813831 closes. The last applied log index is 0
2019-09-12 10:29:00,669 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 969f621b-625a-4660-bcba-147498526acd:group-C524CC0FC1F5 closes. The last applied log index is 0
2019-09-12 10:29:00,669 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,670 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,671 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/74d04d19-7649-4420-bcc3-c014b0813831 close()
2019-09-12 10:29:00,672 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/c2f45f95-9152-4ec4-b2c9-c524cc0fc1f5 close()
2019-09-12 10:29:00,675 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown group-26600E4E4539
2019-09-12 10:29:00,677 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 969f621b-625a-4660-bcba-147498526acd: shutdown group-6EEB257C2850
2019-09-12 10:29:00,677 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-26600E4E4539,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:29:00,677 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6EEB257C2850,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:29:00,678 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderState
2019-09-12 10:29:00,678 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderState
2019-09-12 10:29:00,678 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 349939a8-0e84-4617-9a16-3efaa8718099-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,679 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969f621b-625a-4660-bcba-147498526acd-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,679 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539: set stopIndex = 0
2019-09-12 10:29:00,684 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850: set stopIndex = 4
2019-09-12 10:29:00,685 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-6EEB257C2850: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850/sm/snapshot.1_4
2019-09-12 10:29:00,685 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-26600E4E4539 closes. The last applied log index is 0
2019-09-12 10:29:00,686 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,687 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/fe89e5bd-39a7-4ea9-9c0c-26600e4e4539 close()
2019-09-12 10:29:00,689 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown group-CFB584CB038C
2019-09-12 10:29:00,690 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFB584CB038C,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:29:00,690 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderState
2019-09-12 10:29:00,690 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 349939a8-0e84-4617-9a16-3efaa8718099-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,691 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C: set stopIndex = 0
2019-09-12 10:29:00,691 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-CFB584CB038C closes. The last applied log index is 0
2019-09-12 10:29:00,692 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,693 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f95f9786-fb71-46c3-a70a-cfb584cb038c close()
2019-09-12 10:29:00,695 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=bdedf58a-a481-4a9e-93e6-4446fa864847, command=[]} | ret=SUCCESS |  
2019-09-12 10:29:00,695 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown group-7206917E1AC6
2019-09-12 10:29:00,696 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7206917E1AC6,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:29:00,696 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderState
2019-09-12 10:29:00,697 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 349939a8-0e84-4617-9a16-3efaa8718099-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,697 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6: set stopIndex = 0
2019-09-12 10:29:00,698 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-7206917E1AC6 closes. The last applied log index is 0
2019-09-12 10:29:00,698 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,700 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/9b955dda-cf86-45ed-b931-7206917e1ac6 close()
2019-09-12 10:29:00,700 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-6EEB257C2850: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850/sm/snapshot.1_4 time:15
2019-09-12 10:29:00,702 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850: Took a snapshot at index 4
2019-09-12 10:29:00,702 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown group-849E74F7B3CB
2019-09-12 10:29:00,702 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:00,703 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-849E74F7B3CB,id=349939a8-0e84-4617-9a16-3efaa8718099
2019-09-12 10:29:00,703 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 969f621b-625a-4660-bcba-147498526acd:group-6EEB257C2850 closes. The last applied log index is 4
2019-09-12 10:29:00,704 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown LeaderState
2019-09-12 10:29:00,704 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,704 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 349939a8-0e84-4617-9a16-3efaa8718099-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,706 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/235368e5-9c0f-4999-ac47-6eeb257c2850 close()
2019-09-12 10:29:00,715 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB: set stopIndex = 4
2019-09-12 10:29:00,715 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-849E74F7B3CB: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb/sm/snapshot.1_4
2019-09-12 10:29:00,719 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 969f621b-625a-4660-bcba-147498526acd: shutdown group-51CC9BFFB349
2019-09-12 10:29:00,720 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-51CC9BFFB349,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:29:00,721 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderState
2019-09-12 10:29:00,721 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969f621b-625a-4660-bcba-147498526acd-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,721 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349: set stopIndex = 14
2019-09-12 10:29:00,721 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-51CC9BFFB349: Taking a snapshot at:(t:1, i:14) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349/sm/snapshot.1_14
2019-09-12 10:29:00,733 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-51CC9BFFB349: Finished taking a snapshot at:(t:1, i:14) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349/sm/snapshot.1_14 time:12
2019-09-12 10:29:00,733 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-849E74F7B3CB: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb/sm/snapshot.1_4 time:18
2019-09-12 10:29:00,734 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349: Took a snapshot at index 14
2019-09-12 10:29:00,734 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB: Took a snapshot at index 4
2019-09-12 10:29:00,734 [StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:00,734 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349: snapshotIndex: updateIncreasingly -1 -> 14
2019-09-12 10:29:00,734 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 349939a8-0e84-4617-9a16-3efaa8718099:group-849E74F7B3CB closes. The last applied log index is 4
2019-09-12 10:29:00,734 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 969f621b-625a-4660-bcba-147498526acd:group-51CC9BFFB349 closes. The last applied log index is 14
2019-09-12 10:29:00,735 [349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,735 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,735 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 349939a8-0e84-4617-9a16-3efaa8718099-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/ratis/f287a6bd-6b22-404e-96eb-849e74f7b3cb close()
2019-09-12 10:29:00,736 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/568e3496-d263-48bf-a1e2-51cc9bffb349 close()
2019-09-12 10:29:00,737 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown server with port 43393 now
2019-09-12 10:29:00,738 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 969f621b-625a-4660-bcba-147498526acd: shutdown group-E7A6A1456DBD
2019-09-12 10:29:00,739 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 349939a8-0e84-4617-9a16-3efaa8718099: shutdown server with port 43393 successfully
2019-09-12 10:29:00,739 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E7A6A1456DBD,id=969f621b-625a-4660-bcba-147498526acd
2019-09-12 10:29:00,739 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969f621b-625a-4660-bcba-147498526acd: shutdown LeaderState
2019-09-12 10:29:00,740 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969f621b-625a-4660-bcba-147498526acd-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:00,741 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD: set stopIndex = 4
2019-09-12 10:29:00,741 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-E7A6A1456DBD: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd/sm/snapshot.1_4
2019-09-12 10:29:00,745 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-12 10:29:00,748 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-12 10:29:00,761 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-E7A6A1456DBD: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd/sm/snapshot.1_4 time:21
2019-09-12 10:29:00,761 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD: Took a snapshot at index 4
2019-09-12 10:29:00,761 [StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:00,761 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 969f621b-625a-4660-bcba-147498526acd:group-E7A6A1456DBD closes. The last applied log index is 4
2019-09-12 10:29:00,762 [969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:00,762 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969f621b-625a-4660-bcba-147498526acd-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/ratis/998e4c04-750d-4fb5-9091-e7a6a1456dbd close()
2019-09-12 10:29:00,763 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 969f621b-625a-4660-bcba-147498526acd: shutdown server with port 44966 now
2019-09-12 10:29:00,764 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 969f621b-625a-4660-bcba-147498526acd: shutdown server with port 44966 successfully
2019-09-12 10:29:00,768 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-12 10:29:00,769 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-12 10:29:00,770 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-12 10:29:00,772 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73f6e07{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-12 10:29:00,773 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c9d90fc{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:29:00,773 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@353e6389{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-12 10:29:00,776 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4be490da{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:29:00,777 [main] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-12 10:29:00,778 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@79add732
2019-09-12 10:29:00,794 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-12 10:29:00,797 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a87026{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-12 10:29:00,798 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:29:00,799 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-12 10:29:00,800 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:29:01,691 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-12 10:29:05,779 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-12 10:29:05,780 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - bdedf58a-a481-4a9e-93e6-4446fa864847: close
2019-09-12 10:29:05,781 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown group-5BC15ABAABA1
2019-09-12 10:29:05,782 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown group-1AEBB147EF01
2019-09-12 10:29:05,782 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BC15ABAABA1,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:29:05,782 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1AEBB147EF01,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:29:05,782 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderState
2019-09-12 10:29:05,783 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderState
2019-09-12 10:29:05,783 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bdedf58a-a481-4a9e-93e6-4446fa864847-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:05,783 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bdedf58a-a481-4a9e-93e6-4446fa864847-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:05,785 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1: set stopIndex = 4
2019-09-12 10:29:05,785 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01: set stopIndex = 0
2019-09-12 10:29:05,785 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-5BC15ABAABA1: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1/sm/snapshot.1_4
2019-09-12 10:29:05,786 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-1AEBB147EF01 closes. The last applied log index is 0
2019-09-12 10:29:05,786 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:05,786 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/3378cb60-8523-4838-a4d7-1aebb147ef01 close()
2019-09-12 10:29:05,788 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown group-E6C7178570C6
2019-09-12 10:29:05,788 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E6C7178570C6,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:29:05,788 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderState
2019-09-12 10:29:05,788 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bdedf58a-a481-4a9e-93e6-4446fa864847-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:05,789 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6: set stopIndex = 0
2019-09-12 10:29:05,789 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-E6C7178570C6 closes. The last applied log index is 0
2019-09-12 10:29:05,789 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:05,790 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/55a88f07-3f34-4613-8002-e6c7178570c6 close()
2019-09-12 10:29:05,791 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown group-8C6BC10213CE
2019-09-12 10:29:05,791 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C6BC10213CE,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:29:05,791 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderState
2019-09-12 10:29:05,791 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bdedf58a-a481-4a9e-93e6-4446fa864847-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:05,792 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE: set stopIndex = 0
2019-09-12 10:29:05,793 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-8C6BC10213CE closes. The last applied log index is 0
2019-09-12 10:29:05,793 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:05,793 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/2a08fba6-2ea0-4046-9d8c-8c6bc10213ce close()
2019-09-12 10:29:05,811 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-5BC15ABAABA1: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1/sm/snapshot.1_4 time:27
2019-09-12 10:29:05,811 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1: Took a snapshot at index 4
2019-09-12 10:29:05,812 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:05,812 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-5BC15ABAABA1 closes. The last applied log index is 4
2019-09-12 10:29:05,813 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:05,813 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/33cdbc17-6036-4c6c-923f-5bc15abaaba1 close()
2019-09-12 10:29:05,815 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown group-50887C8F1A38
2019-09-12 10:29:05,815 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-50887C8F1A38,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:29:05,815 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderState
2019-09-12 10:29:05,816 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bdedf58a-a481-4a9e-93e6-4446fa864847-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:05,816 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38: set stopIndex = 4
2019-09-12 10:29:05,816 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-50887C8F1A38: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38/sm/snapshot.1_4
2019-09-12 10:29:05,841 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-50887C8F1A38: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38/sm/snapshot.1_4 time:25
2019-09-12 10:29:05,842 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38: Took a snapshot at index 4
2019-09-12 10:29:05,842 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:05,842 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-50887C8F1A38 closes. The last applied log index is 4
2019-09-12 10:29:05,843 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:05,843 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/15a42196-928e-4aff-9dca-50887c8f1a38 close()
2019-09-12 10:29:05,845 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown group-D38D0E46E828
2019-09-12 10:29:05,845 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D38D0E46E828,id=bdedf58a-a481-4a9e-93e6-4446fa864847
2019-09-12 10:29:05,845 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown LeaderState
2019-09-12 10:29:05,846 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bdedf58a-a481-4a9e-93e6-4446fa864847-PendingRequests: sendNotLeaderResponses
2019-09-12 10:29:05,846 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828: set stopIndex = 4
2019-09-12 10:29:05,846 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-D38D0E46E828: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828/sm/snapshot.1_4
2019-09-12 10:29:05,868 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-D38D0E46E828: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828/sm/snapshot.1_4 time:22
2019-09-12 10:29:05,868 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828: Took a snapshot at index 4
2019-09-12 10:29:05,868 [StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:29:05,869 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bdedf58a-a481-4a9e-93e6-4446fa864847:group-D38D0E46E828 closes. The last applied log index is 4
2019-09-12 10:29:05,869 [bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:29:05,870 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bdedf58a-a481-4a9e-93e6-4446fa864847-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/ratis/e16c15e4-8484-4070-a9b8-d38d0e46e828 close()
2019-09-12 10:29:05,871 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown server with port 42442 now
2019-09-12 10:29:05,872 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - bdedf58a-a481-4a9e-93e6-4446fa864847: shutdown server with port 42442 successfully
2019-09-12 10:29:05,876 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-12 10:29:05,879 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-aeaef3a6-d46c-4184-8e50-ff21924cc5ed/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-12 10:29:05,900 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-12 10:29:05,901 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c18942{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-12 10:29:05,902 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@743c3520{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:29:05,903 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71d55b7e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-12 10:29:05,904 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52ba685a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:29:05,905 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-09-12 10:29:05,906 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(797)) - Stopping Replication Manager Service.
2019-09-12 10:29:05,906 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(192)) - Stopping Replication Monitor Thread.
2019-09-12 10:29:05,906 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Lease Manager of the command watchers
2019-09-12 10:29:05,906 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping datanode service RPC server
2019-09-12 10:29:05,907 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-12 10:29:05,907 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46331
2019-09-12 10:29:05,909 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:29:05,909 [IPC Server listener on 46331] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46331
2019-09-12 10:29:06,006 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-12 10:29:06,006 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(819)) - Stopping block service RPC server
2019-09-12 10:29:06,007 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-09-12 10:29:06,007 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33084
2019-09-12 10:29:06,009 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-12 10:29:06,009 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-12 10:29:06,009 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:29:06,009 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36871
2019-09-12 10:29:06,009 [IPC Server listener on 33084] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33084
2019-09-12 10:29:06,011 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping Storage Container Manager HTTP server.
2019-09-12 10:29:06,011 [IPC Server listener on 36871] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36871
2019-09-12 10:29:06,011 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:29:06,012 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43c67247{/,null,UNAVAILABLE}{/scm}
2019-09-12 10:29:06,013 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:29:06,013 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-12 10:29:06,013 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:29:06,014 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Block Manager Service.
2019-09-12 10:29:06,015 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-12 10:29:06,015 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-12 10:29:06,016 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(866)) - Stopping SCM Event Queue.
2019-09-12 10:29:06,021 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping XceiverClientMetrics metrics system...
2019-09-12 10:29:06,029 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - XceiverClientMetrics metrics system stopped.

<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="97.944" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.24.v20180605/jetty-server-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.24.v20180605/jetty-http-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.24.v20180605/jetty-io-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.24.v20180605/jetty-webapp-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.24.v20180605/jetty-xml-9.3.24.v20180605.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.5/jackson-databind-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.5/jackson-annotations-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.5/jackson-core-2.9.5.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.24.v20180605/jetty-util-ajax-9.3.24.v20180605.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0-2337318-SNAPSHOT/ratis-server-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0-2337318-SNAPSHOT/ratis-proto-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0-2337318-SNAPSHOT/ratis-common-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0-2337318-SNAPSHOT/ratis-client-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0-2337318-SNAPSHOT/ratis-metrics-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0-2337318-SNAPSHOT/ratis-netty-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0-2337318-SNAPSHOT/ratis-grpc-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.33.1/jaeger-client-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.33.1/jaeger-thrift-0.33.1.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.11.0/libthrift-0.11.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.33.1/jaeger-core-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.33.1/jaeger-tracerresolver-0.33.1.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-objectstore-service/0.5.0-SNAPSHOT/hadoop-ozone-objectstore-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7204017459067493829.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-09-12T10-13-21_360-jvmRun1 surefire3452157796007604705tmp surefire_1093723543892433161337tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.24.v20180605/jetty-server-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.24.v20180605/jetty-http-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.24.v20180605/jetty-io-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.24.v20180605/jetty-webapp-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.24.v20180605/jetty-xml-9.3.24.v20180605.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.5/jackson-databind-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.5/jackson-annotations-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.5/jackson-core-2.9.5.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.24.v20180605/jetty-util-ajax-9.3.24.v20180605.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0-2337318-SNAPSHOT/ratis-server-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0-2337318-SNAPSHOT/ratis-proto-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0-2337318-SNAPSHOT/ratis-common-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0-2337318-SNAPSHOT/ratis-client-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0-2337318-SNAPSHOT/ratis-metrics-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0-2337318-SNAPSHOT/ratis-netty-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0-2337318-SNAPSHOT/ratis-grpc-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.33.1/jaeger-client-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.33.1/jaeger-thrift-0.33.1.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.11.0/libthrift-0.11.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.33.1/jaeger-core-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.33.1/jaeger-tracerresolver-0.33.1.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-objectstore-service/0.5.0-SNAPSHOT/hadoop-ozone-objectstore-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7204017459067493829.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpdateDeepDirectoryStructureNoChange" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="13.979">
    <error message="DistCp failure: Job job_local1401702154_0001 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1401702154_0001 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureNoChange(AbstractContractDistCpTest.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:45:51,139 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:51,247 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:51,251 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:51,270 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @885ms
2019-09-12 11:45:51,374 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-12 11:45:51,374 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-12 11:45:51,375 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-12 11:45:51,375 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-12 11:45:51,375 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-12 11:45:51,375 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-12 11:45:51,387 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 11:45:51,388 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 11:45:51,389 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 11:45:51,597 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6b81ce95
2019-09-12 11:45:51,599 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-12 11:45:51,671 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 11:45:51,672 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 11:45:51,675 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-12 11:45:51,804 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-12 11:45:51,821 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:51,919 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-12 11:45:51,923 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:52,038 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-12 11:45:52,887 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:45:52,923 [Socket Reader #1 for port 41133] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41133
2019-09-12 11:45:52,956 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:45:52,959 [Socket Reader #1 for port 42152] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42152
2019-09-12 11:45:52,970 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:45:52,972 [Socket Reader #1 for port 44185] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44185
2019-09-12 11:45:53,007 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-12 11:45:53,150 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:53,165 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:53,175 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:53,177 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-12 11:45:53,177 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:53,177 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:53,202 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:44185
2019-09-12 11:45:53,251 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-12 11:45:53,263 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-12 11:45:53,263 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-12 11:45:53,545 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:44185
2019-09-12 11:45:53,546 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:45:53,546 [IPC Server listener on 44185] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44185: starting
2019-09-12 11:45:53,549 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42152
2019-09-12 11:45:53,549 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:42152
2019-09-12 11:45:53,550 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:45:53,550 [IPC Server listener on 42152] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42152: starting
2019-09-12 11:45:53,553 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41133
2019-09-12 11:45:53,553 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:41133
2019-09-12 11:45:53,553 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:45:53,554 [IPC Server listener on 41133] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41133: starting
2019-09-12 11:45:53,558 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41312
2019-09-12 11:45:53,560 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:53,593 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65b3a85a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:53,594 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53d1b9b3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:53,660 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@733037{/,file:///tmp/jetty-0.0.0.0-41312-scm-_-any-1820057184190054461.dir/webapp/,AVAILABLE}{/scm}
2019-09-12 11:45:53,664 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50b8ae8d{HTTP/1.1,[http/1.1]}{0.0.0.0:41312}
2019-09-12 11:45:53,665 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3279ms
2019-09-12 11:45:53,666 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:41312
2019-09-12 11:45:53,675 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7577b641] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:45:53,680 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:53,801 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:53,802 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:53,803 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-12 11:45:53,803 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 6fb9eb3f-512c-461e-9b37-636f90f75aa6
2019-09-12 11:45:53,804 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-12 11:45:54,110 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-12 11:45:54,580 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:45:54,590 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-12 11:45:54,590 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-12 11:45:54,590 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-12 11:45:54,591 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-12 11:45:54,591 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-12 11:45:54,591 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-12 11:45:54,591 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-12 11:45:54,592 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-12 11:45:54,592 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-12 11:45:54,592 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-12 11:45:54,592 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-12 11:45:54,593 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-12 11:45:54,593 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-12 11:45:54,593 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-12 11:45:54,593 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-12 11:45:54,594 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-12 11:45:54,594 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-12 11:45:54,594 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-12 11:45:54,594 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-12 11:45:54,595 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-12 11:45:54,595 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-12 11:45:54,595 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-12 11:45:54,595 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 11:45:54,596 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 11:45:54,596 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 11:45:55,307 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:45:55,309 [Socket Reader #1 for port 39252] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39252
2019-09-12 11:45:55,341 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:39252
2019-09-12 11:45:55,341 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-12 11:45:55,343 [IPC Server listener on 39252] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39252: starting
2019-09-12 11:45:55,343 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:45:55,350 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-12 11:45:55,355 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:55,357 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:55,361 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:55,363 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-12 11:45:55,363 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:55,363 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:55,367 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37370
2019-09-12 11:45:55,367 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:55,370 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@749ab7b4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:55,371 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bf94401{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:55,449 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54562ea6{/,file:///tmp/jetty-0.0.0.0-37370-ozoneManager-_-any-114457572813511442.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-12 11:45:55,450 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a35993f{HTTP/1.1,[http/1.1]}{0.0.0.0:37370}
2019-09-12 11:45:55,451 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5066ms
2019-09-12 11:45:55,454 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:37370
2019-09-12 11:45:55,622 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:45:55,706 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 11:45:55,742 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:45:55,744 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/containers/hdds to VolumeSet
2019-09-12 11:45:55,747 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-12 11:45:55,767 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-12 11:45:55,898 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:45:55,976 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:45:55,983 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:45:55,984 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:45:55,986 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:45:55,987 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:45:55,987 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:45:56,188 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:45:56,262 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:45:56,286 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:45:56,288 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:56,289 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:56,291 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:56,292 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:45:56,292 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:56,293 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:56,293 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 32820
2019-09-12 11:45:56,294 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:56,296 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb66650{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:56,296 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a869a16{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:56,325 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6d5c2745{/,file:///tmp/jetty-0.0.0.0-32820-hddsDatanode-_-any-7562927927252445166.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:45:56,326 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44b29496{HTTP/1.1,[http/1.1]}{0.0.0.0:32820}
2019-09-12 11:45:56,326 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5941ms
2019-09-12 11:45:56,329 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:32820
2019-09-12 11:45:57,405 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:35625 |  
2019-09-12 11:45:57,407 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@2eda2062
2019-09-12 11:45:57,408 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:45:57,411 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 11:45:57,415 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@30bcc757] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:45:57,421 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:45:57,421 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/containers/hdds to VolumeSet
2019-09-12 11:45:57,421 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@126f8f24
2019-09-12 11:45:57,422 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@126f8f24
2019-09-12 11:45:57,447 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:45:57,448 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:45:57,448 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:45:57,448 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:45:57,448 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:45:57,449 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:45:57,449 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:45:57,449 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:45:57,450 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:45:57,451 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:45:57,455 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:57,456 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:57,458 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:57,459 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:45:57,459 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:57,459 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:57,460 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34011
2019-09-12 11:45:57,460 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:57,463 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57fdb8a4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:57,464 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2db15f70{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:57,493 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44b940a2{/,file:///tmp/jetty-0.0.0.0-34011-hddsDatanode-_-any-5551465982159502088.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:45:57,493 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@34c53688{HTTP/1.1,[http/1.1]}{0.0.0.0:34011}
2019-09-12 11:45:57,494 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7109ms
2019-09-12 11:45:57,496 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34011
2019-09-12 11:45:57,549 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/meta/datanode.id
2019-09-12 11:45:57,666 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:45369 |  
2019-09-12 11:45:57,666 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@284bdeed
2019-09-12 11:45:57,667 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:45:57,670 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6aace554] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:45:57,671 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 11:45:57,676 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/meta/datanode.id
2019-09-12 11:45:57,684 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:45:57,685 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/containers/hdds to VolumeSet
2019-09-12 11:45:57,685 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-12 11:45:57,686 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-12 11:45:57,714 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:45:57,714 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:45:57,715 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:45:57,715 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:45:57,715 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:45:57,715 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:45:57,716 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:45:57,716 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:45:57,717 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:45:57,719 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:45:57,721 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:57,721 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:57,723 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:57,724 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:45:57,724 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:57,725 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:57,725 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40075
2019-09-12 11:45:57,726 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:57,728 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a0c5be{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:57,728 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14efa279{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:57,756 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24fba488{/,file:///tmp/jetty-0.0.0.0-40075-hddsDatanode-_-any-4949912424932363014.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:45:57,758 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73a6cc79{HTTP/1.1,[http/1.1]}{0.0.0.0:40075}
2019-09-12 11:45:57,758 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7373ms
2019-09-12 11:45:57,761 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40075
2019-09-12 11:45:57,934 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:42698 |  
2019-09-12 11:45:57,934 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3bbf1c0d
2019-09-12 11:45:57,934 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:45:57,938 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 11:45:57,938 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@465383ef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:45:57,941 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/meta/datanode.id
2019-09-12 11:45:57,947 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:45:57,947 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/containers/hdds to VolumeSet
2019-09-12 11:45:57,947 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@143fefaf
2019-09-12 11:45:57,948 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@143fefaf
2019-09-12 11:45:57,972 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:45:57,972 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:45:57,972 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:45:57,973 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:45:57,973 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:45:57,973 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:45:57,974 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:45:57,975 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:45:57,975 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:45:57,977 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:45:57,980 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:57,981 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:57,984 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:57,986 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:45:57,986 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:57,986 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:57,987 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33295
2019-09-12 11:45:57,987 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:57,991 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58d4238e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:57,992 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36478bce{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:58,038 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@78b03788{/,file:///tmp/jetty-0.0.0.0-33295-hddsDatanode-_-any-4612532405399302454.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:45:58,039 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f5dfe69{HTTP/1.1,[http/1.1]}{0.0.0.0:33295}
2019-09-12 11:45:58,040 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7654ms
2019-09-12 11:45:58,041 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33295
2019-09-12 11:45:58,188 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:35716 |  
2019-09-12 11:45:58,188 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@700b9e6b
2019-09-12 11:45:58,188 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:45:58,191 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40db17d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:45:58,191 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-xtfnx-3545843844 ip:192.168.157.195
2019-09-12 11:45:58,194 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/meta/datanode.id
2019-09-12 11:45:58,200 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:45:58,201 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/containers/hdds to VolumeSet
2019-09-12 11:45:58,201 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7eaa2bc6
2019-09-12 11:45:58,201 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7eaa2bc6
2019-09-12 11:45:58,224 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:45:58,224 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:45:58,224 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:45:58,224 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:45:58,225 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:45:58,225 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:45:58,225 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:45:58,225 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:45:58,226 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:45:58,227 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:45:58,230 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:45:58,231 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:45:58,234 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:45:58,236 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:45:58,236 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:45:58,236 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:45:58,238 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34310
2019-09-12 11:45:58,238 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:45:58,241 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cf01c2e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:45:58,242 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1eb9bf60{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:45:58,281 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68bd8ca7{/,file:///tmp/jetty-0.0.0.0-34310-hddsDatanode-_-any-161030095996679979.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:45:58,282 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6744707b{HTTP/1.1,[http/1.1]}{0.0.0.0:34310}
2019-09-12 11:45:58,283 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7898ms
2019-09-12 11:45:58,284 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34310
2019-09-12 11:45:58,538 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:36330 |  
2019-09-12 11:45:58,538 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@5d66ae3a
2019-09-12 11:45:58,541 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-12 11:45:58,542 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46d98db9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:45:58,545 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/meta/datanode.id
2019-09-12 11:45:59,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:45:59,475 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:45:59,477 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:45:59,477 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis b702d902-25f1-483f-8834-460c179f9559 at port 0
2019-09-12 11:45:59,503 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b702d902-25f1-483f-8834-460c179f9559: start RPC server
2019-09-12 11:45:59,541 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-12 11:45:59,655 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - b702d902-25f1-483f-8834-460c179f9559: GrpcService started, listening on 0.0.0.0/0.0.0.0:43533
2019-09-12 11:45:59,656 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis b702d902-25f1-483f-8834-460c179f9559 is started using port 43533
2019-09-12 11:45:59,658 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc b702d902-25f1-483f-8834-460c179f9559 is started using port 42655
2019-09-12 11:45:59,672 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:45:59,686 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:45:59,687 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:45:59,687 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at port 0
2019-09-12 11:45:59,694 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start RPC server
2019-09-12 11:45:59,696 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: GrpcService started, listening on 0.0.0.0/0.0.0.0:41687
2019-09-12 11:45:59,697 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 is started using port 41687
2019-09-12 11:45:59,698 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 is started using port 37965
2019-09-12 11:45:59,940 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:45:59,955 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:45:59,957 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:45:59,957 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 17737a86-5417-40d5-bd10-6caac07f8585 at port 0
2019-09-12 11:45:59,964 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 17737a86-5417-40d5-bd10-6caac07f8585: start RPC server
2019-09-12 11:45:59,967 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 17737a86-5417-40d5-bd10-6caac07f8585: GrpcService started, listening on 0.0.0.0/0.0.0.0:36978
2019-09-12 11:45:59,967 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 17737a86-5417-40d5-bd10-6caac07f8585 is started using port 36978
2019-09-12 11:45:59,970 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 17737a86-5417-40d5-bd10-6caac07f8585 is started using port 43109
2019-09-12 11:46:00,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:46:00,210 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:46:00,213 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:46:00,213 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 261c0364-c1a8-4b3d-89b8-311b79ab6415 at port 0
2019-09-12 11:46:00,223 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start RPC server
2019-09-12 11:46:00,227 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: GrpcService started, listening on 0.0.0.0/0.0.0.0:45680
2019-09-12 11:46:00,228 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 261c0364-c1a8-4b3d-89b8-311b79ab6415 is started using port 45680
2019-09-12 11:46:00,231 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 261c0364-c1a8-4b3d-89b8-311b79ab6415 is started using port 40562
2019-09-12 11:46:00,542 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-12 11:46:00,544 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:46:00,559 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:46:00,566 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:46:00,567 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at port 0
2019-09-12 11:46:00,578 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start RPC server
2019-09-12 11:46:00,583 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: GrpcService started, listening on 0.0.0.0/0.0.0.0:37151
2019-09-12 11:46:00,583 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 is started using port 37151
2019-09-12 11:46:00,587 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 is started using port 37597
2019-09-12 11:46:01,456 [IPC Server handler 3 on 41133] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:01,456 [IPC Server handler 3 on 41133] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:46:01,461 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-12 11:46:01,461 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-12 11:46:01,461 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-12 11:46:01,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:46:01,543 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 5 DN Heartbeats.
2019-09-12 11:46:01,675 [IPC Server handler 1 on 41133] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:01,675 [IPC Server handler 1 on 41133] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:46:01,675 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:46:02,326 [IPC Server handler 3 on 41133] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:02,326 [IPC Server handler 5 on 41133] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:02,326 [IPC Server handler 3 on 41133] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:46:02,327 [IPC Server handler 5 on 41133] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:46:02,327 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:46:02,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:46:02,458 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b702d902-25f1-483f-8834-460c179f9559: addNew group-1A850029EF7F:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] returns group-1A850029EF7F:java.util.concurrent.CompletableFuture@36f034d9[Not completed]
2019-09-12 11:46:02,483 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - b702d902-25f1-483f-8834-460c179f9559: new RaftServerImpl for group-1A850029EF7F:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] with ContainerStateMachine:uninitialized
2019-09-12 11:46:02,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:02,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:02,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:02,489 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:02,491 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:02,503 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F ConfigurationManager, init=-1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:02,503 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:46:02,517 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f does not exist. Creating ...
2019-09-12 11:46:02,536 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:02,545 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-12 11:46:02,546 [IPC Server handler 4 on 41133] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:02,546 [IPC Server handler 4 on 41133] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:46:02,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=REGISTER {datanodeDetails=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:46:02,552 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f has been successfully formatted.
2019-09-12 11:46:02,554 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1A850029EF7F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:02,554 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:02,556 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:02,561 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:02,562 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:02,563 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,568 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:02,573 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f
2019-09-12 11:46:02,585 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:02,586 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:02,591 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,591 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:02,591 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:02,592 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:02,593 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:02,593 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:02,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:02,603 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:02,608 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:02,612 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:02,613 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:02,614 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:02,643 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - b702d902-25f1-483f-8834-460c179f9559: start group-1A850029EF7F
2019-09-12 11:46:02,645 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:02,647 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start FollowerState
2019-09-12 11:46:02,650 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1A850029EF7F,id=b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:02,729 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 491c39c3-7aa3-4d10-bb8f-1a850029ef7f, Nodes: b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:02,750 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b702d902-25f1-483f-8834-460c179f9559: addNew group-32C8BDFB17BB:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] returns group-32C8BDFB17BB:java.util.concurrent.CompletableFuture@4a9dd07f[Not completed]
2019-09-12 11:46:02,751 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - b702d902-25f1-483f-8834-460c179f9559: new RaftServerImpl for group-32C8BDFB17BB:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] with ContainerStateMachine:uninitialized
2019-09-12 11:46:02,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:02,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:02,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:02,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:02,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:02,752 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB ConfigurationManager, init=-1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:02,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:46:02,753 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb does not exist. Creating ...
2019-09-12 11:46:02,766 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:02,779 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb has been successfully formatted.
2019-09-12 11:46:02,780 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-32C8BDFB17BB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:02,780 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:02,780 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:02,781 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:02,781 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:02,781 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,781 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:02,781 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb
2019-09-12 11:46:02,782 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:02,782 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:02,782 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,782 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:02,783 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:02,783 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:02,783 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:02,783 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:02,783 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:02,784 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:02,784 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:02,785 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:02,785 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:02,785 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:02,785 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - b702d902-25f1-483f-8834-460c179f9559: start group-32C8BDFB17BB
2019-09-12 11:46:02,785 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:02,786 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start FollowerState
2019-09-12 11:46:02,786 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-32C8BDFB17BB,id=b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:02,802 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 565ac36a-b13c-4f43-8fe4-32c8bdfb17bb, Nodes: b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:02,819 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: addNew group-EFB98FE9C9C4:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] returns group-EFB98FE9C9C4:java.util.concurrent.CompletableFuture@3b2a3740[Not completed]
2019-09-12 11:46:02,860 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: new RaftServerImpl for group-EFB98FE9C9C4:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] with ContainerStateMachine:uninitialized
2019-09-12 11:46:02,861 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:02,861 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:02,861 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:02,862 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:02,862 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:02,862 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 ConfigurationManager, init=-1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:02,862 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:46:02,863 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4 does not exist. Creating ...
2019-09-12 11:46:02,877 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:02,890 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4 has been successfully formatted.
2019-09-12 11:46:02,892 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-EFB98FE9C9C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:02,893 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4
2019-09-12 11:46:02,894 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:02,894 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:02,895 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:02,896 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:02,896 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:02,896 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:02,896 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:02,897 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:02,897 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start group-EFB98FE9C9C4
2019-09-12 11:46:02,897 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:02,897 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start FollowerState
2019-09-12 11:46:02,898 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EFB98FE9C9C4,id=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:02,910 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 131aeea8-a2b9-4498-8719-efb98fe9c9c4, Nodes: 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:02,928 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: addNew group-AA80A99638C6:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] returns group-AA80A99638C6:java.util.concurrent.CompletableFuture@4df67578[Not completed]
2019-09-12 11:46:02,939 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: new RaftServerImpl for group-AA80A99638C6:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] with ContainerStateMachine:uninitialized
2019-09-12 11:46:02,939 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:02,940 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:02,940 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:02,940 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:02,940 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:02,940 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 ConfigurationManager, init=-1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:02,940 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:46:02,941 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6 does not exist. Creating ...
2019-09-12 11:46:02,954 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:02,966 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6 has been successfully formatted.
2019-09-12 11:46:02,967 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-AA80A99638C6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:02,967 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:02,967 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:02,967 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:02,967 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:02,967 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:02,968 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6
2019-09-12 11:46:02,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:02,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:02,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:02,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:02,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:02,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:02,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:02,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:02,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:02,970 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:02,970 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:02,970 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:02,970 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:02,970 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:02,971 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start group-AA80A99638C6
2019-09-12 11:46:02,971 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:02,971 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start FollowerState
2019-09-12 11:46:02,972 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AA80A99638C6,id=261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:02,982 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 61522dcd-8534-4a42-8068-aa80a99638c6, Nodes: 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,003 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: addNew group-A2B095ABEBC3:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] returns group-A2B095ABEBC3:java.util.concurrent.CompletableFuture@38306ab4[Not completed]
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: new RaftServerImpl for group-A2B095ABEBC3:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,005 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 ConfigurationManager, init=-1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,006 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:46:03,006 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3 does not exist. Creating ...
2019-09-12 11:46:03,018 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,031 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3 has been successfully formatted.
2019-09-12 11:46:03,032 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A2B095ABEBC3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,032 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,032 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,033 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,033 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,033 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,033 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,033 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3
2019-09-12 11:46:03,034 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,034 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,034 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,034 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,034 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,035 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,035 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,035 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,035 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,035 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,036 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,037 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start group-A2B095ABEBC3
2019-09-12 11:46:03,037 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,038 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start FollowerState
2019-09-12 11:46:03,038 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2B095ABEBC3,id=261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:03,054 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0aa8f310-eb34-4693-bc97-a2b095abebc3, Nodes: 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,075 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b702d902-25f1-483f-8834-460c179f9559: addNew group-9DDC0391D2B2:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] returns group-9DDC0391D2B2:java.util.concurrent.CompletableFuture@625480fe[Not completed]
2019-09-12 11:46:03,076 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - b702d902-25f1-483f-8834-460c179f9559: new RaftServerImpl for group-9DDC0391D2B2:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,076 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,076 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,077 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 ConfigurationManager, init=-1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:46:03,077 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2 does not exist. Creating ...
2019-09-12 11:46:03,090 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,103 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2 has been successfully formatted.
2019-09-12 11:46:03,103 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-9DDC0391D2B2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,105 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,105 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,105 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,105 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,105 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,106 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - b702d902-25f1-483f-8834-460c179f9559: start group-9DDC0391D2B2
2019-09-12 11:46:03,106 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,106 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start FollowerState
2019-09-12 11:46:03,107 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9DDC0391D2B2,id=b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:03,124 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 956eba62-8f34-490d-b713-9ddc0391d2b2, Nodes: b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,139 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b702d902-25f1-483f-8834-460c179f9559: addNew group-7C2FBA5D927B:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] returns group-7C2FBA5D927B:java.util.concurrent.CompletableFuture@189ab540[Not completed]
2019-09-12 11:46:03,140 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - b702d902-25f1-483f-8834-460c179f9559: new RaftServerImpl for group-7C2FBA5D927B:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,140 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B ConfigurationManager, init=-1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:46:03,141 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b does not exist. Creating ...
2019-09-12 11:46:03,154 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,166 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b has been successfully formatted.
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7C2FBA5D927B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,167 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,168 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,169 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,169 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,170 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - b702d902-25f1-483f-8834-460c179f9559: start group-7C2FBA5D927B
2019-09-12 11:46:03,170 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,170 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start FollowerState
2019-09-12 11:46:03,170 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7C2FBA5D927B,id=b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:03,189 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 87093451-cb38-4462-a5b9-7c2fba5d927b, Nodes: b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,203 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: addNew group-B40F59C1D1B0:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] returns group-B40F59C1D1B0:java.util.concurrent.CompletableFuture@79822b01[Not completed]
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: new RaftServerImpl for group-B40F59C1D1B0:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,205 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 ConfigurationManager, init=-1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,206 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:46:03,206 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0 does not exist. Creating ...
2019-09-12 11:46:03,218 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,231 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0 has been successfully formatted.
2019-09-12 11:46:03,231 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B40F59C1D1B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,231 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,232 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,232 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,232 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,232 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,232 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,232 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0
2019-09-12 11:46:03,233 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,233 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,233 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,233 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,233 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,234 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,234 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,234 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,234 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,234 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,235 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,235 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,235 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,236 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,236 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start group-B40F59C1D1B0
2019-09-12 11:46:03,236 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,236 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start FollowerState
2019-09-12 11:46:03,237 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B40F59C1D1B0,id=261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:03,248 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0, Nodes: 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,260 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b702d902-25f1-483f-8834-460c179f9559: addNew group-9C2D8D1DBCC8:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] returns group-9C2D8D1DBCC8:java.util.concurrent.CompletableFuture@374ab6fa[Not completed]
2019-09-12 11:46:03,261 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - b702d902-25f1-483f-8834-460c179f9559: new RaftServerImpl for group-9C2D8D1DBCC8:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,262 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 ConfigurationManager, init=-1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:46:03,262 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8 does not exist. Creating ...
2019-09-12 11:46:03,274 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,287 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8 has been successfully formatted.
2019-09-12 11:46:03,287 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-9C2D8D1DBCC8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,287 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,287 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,287 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,287 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,289 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,289 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,289 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,289 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,289 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,290 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,290 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,290 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,290 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - b702d902-25f1-483f-8834-460c179f9559: start group-9C2D8D1DBCC8
2019-09-12 11:46:03,290 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,290 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start FollowerState
2019-09-12 11:46:03,291 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9C2D8D1DBCC8,id=b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:03,298 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8, Nodes: b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,309 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 17737a86-5417-40d5-bd10-6caac07f8585: addNew group-18477BC7668C:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] returns group-18477BC7668C:java.util.concurrent.CompletableFuture@1b856e90[Not completed]
2019-09-12 11:46:03,311 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 17737a86-5417-40d5-bd10-6caac07f8585: new RaftServerImpl for group-18477BC7668C:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,311 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,311 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,311 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,311 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,312 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,312 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C ConfigurationManager, init=-1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,312 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:46:03,312 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c does not exist. Creating ...
2019-09-12 11:46:03,325 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,338 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c has been successfully formatted.
2019-09-12 11:46:03,339 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-18477BC7668C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,339 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,339 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,339 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,339 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,339 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,340 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,340 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c
2019-09-12 11:46:03,340 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,340 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,340 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,341 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,341 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,341 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,341 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,347 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,347 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,348 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,348 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,348 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,349 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,349 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,349 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 17737a86-5417-40d5-bd10-6caac07f8585: start group-18477BC7668C
2019-09-12 11:46:03,349 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,349 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start FollowerState
2019-09-12 11:46:03,350 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18477BC7668C,id=17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:03,358 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 18fd224b-01b8-4f6a-bf6c-18477bc7668c, Nodes: 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,375 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: addNew group-79FFC3E38AF9:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] returns group-79FFC3E38AF9:java.util.concurrent.CompletableFuture@6ae752d[Not completed]
2019-09-12 11:46:03,379 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: new RaftServerImpl for group-79FFC3E38AF9:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,379 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,379 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,379 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,379 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,380 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,380 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 ConfigurationManager, init=-1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,380 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:46:03,380 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9 does not exist. Creating ...
2019-09-12 11:46:03,393 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,407 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9 has been successfully formatted.
2019-09-12 11:46:03,407 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-79FFC3E38AF9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,409 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9
2019-09-12 11:46:03,409 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,409 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,409 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,409 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,410 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,410 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,410 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,410 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,410 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,411 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,411 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,411 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,412 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,412 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,412 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start group-79FFC3E38AF9
2019-09-12 11:46:03,412 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,412 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start FollowerState
2019-09-12 11:46:03,413 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-79FFC3E38AF9,id=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:03,422 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9, Nodes: 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,439 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b702d902-25f1-483f-8834-460c179f9559: addNew group-5DE989847E1A:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] returns group-5DE989847E1A:java.util.concurrent.CompletableFuture@18685321[Not completed]
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - b702d902-25f1-483f-8834-460c179f9559: new RaftServerImpl for group-5DE989847E1A:[b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A ConfigurationManager, init=-1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis] (custom)
2019-09-12 11:46:03,442 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a does not exist. Creating ...
2019-09-12 11:46:03,443 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:03,455 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,468 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a has been successfully formatted.
2019-09-12 11:46:03,468 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-5DE989847E1A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,470 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a
2019-09-12 11:46:03,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,472 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,473 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - b702d902-25f1-483f-8834-460c179f9559: start group-5DE989847E1A
2019-09-12 11:46:03,473 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,473 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start FollowerState
2019-09-12 11:46:03,473 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5DE989847E1A,id=b702d902-25f1-483f-8834-460c179f9559
2019-09-12 11:46:03,480 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: aedbcd97-01f4-4e85-9d95-5de989847e1a, Nodes: b702d902-25f1-483f-8834-460c179f9559{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,482 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,490 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: addNew group-EAB71CD28997:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] returns group-EAB71CD28997:java.util.concurrent.CompletableFuture@7ace5395[Not completed]
2019-09-12 11:46:03,492 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: new RaftServerImpl for group-EAB71CD28997:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,492 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,492 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,493 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,493 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,493 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,493 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 ConfigurationManager, init=-1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,493 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:46:03,494 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997 does not exist. Creating ...
2019-09-12 11:46:03,507 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,520 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997 has been successfully formatted.
2019-09-12 11:46:03,520 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-EAB71CD28997: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,520 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,520 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,521 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,521 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,521 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,521 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,521 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,522 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,523 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,523 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,523 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,523 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,524 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,524 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,524 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,525 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start group-EAB71CD28997
2019-09-12 11:46:03,525 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,525 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start FollowerState
2019-09-12 11:46:03,525 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EAB71CD28997,id=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:03,532 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a9db4387-f32d-425a-9dc4-eab71cd28997, Nodes: 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,534 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,544 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 17737a86-5417-40d5-bd10-6caac07f8585: addNew group-1CD6213CC7AD:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] returns group-1CD6213CC7AD:java.util.concurrent.CompletableFuture@6d13919d[Not completed]
2019-09-12 11:46:03,545 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-12 11:46:03,546 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 17737a86-5417-40d5-bd10-6caac07f8585: new RaftServerImpl for group-1CD6213CC7AD:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,546 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,546 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,546 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,547 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,547 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,547 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD ConfigurationManager, init=-1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,547 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:46:03,547 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad does not exist. Creating ...
2019-09-12 11:46:03,560 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,573 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad has been successfully formatted.
2019-09-12 11:46:03,573 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1CD6213CC7AD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,574 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,574 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,574 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,574 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,574 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,574 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,575 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad
2019-09-12 11:46:03,575 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,575 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,575 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,575 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,577 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,578 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 17737a86-5417-40d5-bd10-6caac07f8585: start group-1CD6213CC7AD
2019-09-12 11:46:03,578 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,578 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start FollowerState
2019-09-12 11:46:03,578 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CD6213CC7AD,id=17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:03,589 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 572eb5a5-11e5-4477-a75b-1cd6213cc7ad, Nodes: 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,590 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,602 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: addNew group-77760AFAF5A4:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] returns group-77760AFAF5A4:java.util.concurrent.CompletableFuture@8da83cb[Not completed]
2019-09-12 11:46:03,604 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: new RaftServerImpl for group-77760AFAF5A4:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,604 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,604 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,605 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,605 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,605 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,605 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 ConfigurationManager, init=-1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,605 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:46:03,606 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4 does not exist. Creating ...
2019-09-12 11:46:03,614 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,627 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4 has been successfully formatted.
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-77760AFAF5A4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,628 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,629 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,630 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,630 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,630 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,630 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,631 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,631 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,631 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,631 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,632 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start group-77760AFAF5A4
2019-09-12 11:46:03,632 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,632 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start FollowerState
2019-09-12 11:46:03,632 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-77760AFAF5A4,id=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:03,639 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: cf0cc841-ccbd-4095-9608-77760afaf5a4, Nodes: 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,641 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,651 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 17737a86-5417-40d5-bd10-6caac07f8585: addNew group-DBE769A4F88E:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] returns group-DBE769A4F88E:java.util.concurrent.CompletableFuture@52dedecb[Not completed]
2019-09-12 11:46:03,653 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 17737a86-5417-40d5-bd10-6caac07f8585: new RaftServerImpl for group-DBE769A4F88E:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,654 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,654 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,654 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,654 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,654 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,654 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E ConfigurationManager, init=-1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,655 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:46:03,655 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e does not exist. Creating ...
2019-09-12 11:46:03,668 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,675 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:03,681 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e has been successfully formatted.
2019-09-12 11:46:03,682 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DBE769A4F88E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,682 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,682 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,682 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,682 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,682 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,683 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,683 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e
2019-09-12 11:46:03,683 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,683 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,683 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,683 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,684 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,684 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,684 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,684 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,684 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,684 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,685 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,685 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,685 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,686 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,686 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 17737a86-5417-40d5-bd10-6caac07f8585: start group-DBE769A4F88E
2019-09-12 11:46:03,686 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,686 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start FollowerState
2019-09-12 11:46:03,687 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBE769A4F88E,id=17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:03,692 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d575a456-8a38-4cc0-bacc-dbe769a4f88e, Nodes: 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,694 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,704 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: addNew group-5D52E4889E03:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] returns group-5D52E4889E03:java.util.concurrent.CompletableFuture@547fdb72[Not completed]
2019-09-12 11:46:03,706 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: new RaftServerImpl for group-5D52E4889E03:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,706 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,706 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,706 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,706 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,706 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,707 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 ConfigurationManager, init=-1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,707 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:46:03,707 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03 does not exist. Creating ...
2019-09-12 11:46:03,720 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,730 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:46:03,732 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03 has been successfully formatted.
2019-09-12 11:46:03,733 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-5D52E4889E03: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,733 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,733 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,733 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,733 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,733 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,735 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,736 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,736 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start group-5D52E4889E03
2019-09-12 11:46:03,736 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,736 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start FollowerState
2019-09-12 11:46:03,736 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5D52E4889E03,id=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:03,742 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4ebf219e-776f-4191-a665-5d52e4889e03, Nodes: 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,744 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,753 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 17737a86-5417-40d5-bd10-6caac07f8585: addNew group-8FB40B5BA673:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] returns group-8FB40B5BA673:java.util.concurrent.CompletableFuture@480deceb[Not completed]
2019-09-12 11:46:03,755 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 17737a86-5417-40d5-bd10-6caac07f8585: new RaftServerImpl for group-8FB40B5BA673:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,755 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,755 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,755 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,755 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,756 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,756 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 ConfigurationManager, init=-1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,756 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:46:03,756 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673 does not exist. Creating ...
2019-09-12 11:46:03,769 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,782 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673 has been successfully formatted.
2019-09-12 11:46:03,783 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8FB40B5BA673: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,783 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,783 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,783 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,783 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,783 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,784 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,784 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673
2019-09-12 11:46:03,784 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,784 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,784 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,784 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,785 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,785 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,785 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,785 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,785 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,785 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,786 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,786 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,786 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,786 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,787 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 17737a86-5417-40d5-bd10-6caac07f8585: start group-8FB40B5BA673
2019-09-12 11:46:03,787 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,787 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start FollowerState
2019-09-12 11:46:03,787 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8FB40B5BA673,id=17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:03,793 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a2632748-963e-4068-876e-8fb40b5ba673, Nodes: 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,796 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,805 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: addNew group-9C3B7727AF2C:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] returns group-9C3B7727AF2C:java.util.concurrent.CompletableFuture@2f2d6d89[Not completed]
2019-09-12 11:46:03,807 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: new RaftServerImpl for group-9C3B7727AF2C:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,807 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,807 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,807 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,808 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,808 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,808 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C ConfigurationManager, init=-1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,808 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:46:03,808 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c does not exist. Creating ...
2019-09-12 11:46:03,821 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,834 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c has been successfully formatted.
2019-09-12 11:46:03,835 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-9C3B7727AF2C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,835 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,835 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,835 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,835 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,836 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,837 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,837 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,837 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,837 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,837 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,837 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,838 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,839 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,839 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start group-9C3B7727AF2C
2019-09-12 11:46:03,839 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,839 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start FollowerState
2019-09-12 11:46:03,840 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9C3B7727AF2C,id=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:03,851 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 87274a5a-eabd-484d-a6a2-9c3b7727af2c, Nodes: 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,853 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,876 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: addNew group-E146A15113ED:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] returns group-E146A15113ED:java.util.concurrent.CompletableFuture@6efe38dc[Not completed]
2019-09-12 11:46:03,878 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: new RaftServerImpl for group-E146A15113ED:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,879 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,879 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,879 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,879 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,879 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,879 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED ConfigurationManager, init=-1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,880 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:46:03,880 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed does not exist. Creating ...
2019-09-12 11:46:03,893 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:03,938 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed has been successfully formatted.
2019-09-12 11:46:03,939 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-E146A15113ED: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:03,939 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:03,939 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:03,939 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:03,939 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:03,939 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,940 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:03,942 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed
2019-09-12 11:46:03,942 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:03,942 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:03,943 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:03,943 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:03,943 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:03,943 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:03,943 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:03,944 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:03,944 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:03,944 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:03,945 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:03,945 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:03,945 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:03,945 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:03,946 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start group-E146A15113ED
2019-09-12 11:46:03,946 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:03,946 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start FollowerState
2019-09-12 11:46:03,952 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E146A15113ED,id=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:03,964 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: eb506660-89b4-4486-8c96-e146a15113ed, Nodes: 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:03,968 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:03,986 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: addNew group-17AD65B68911:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] returns group-17AD65B68911:java.util.concurrent.CompletableFuture@33d1ce73[Not completed]
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: new RaftServerImpl for group-17AD65B68911:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] with ContainerStateMachine:uninitialized
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:03,988 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 ConfigurationManager, init=-1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:03,989 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:46:03,989 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911 does not exist. Creating ...
2019-09-12 11:46:04,002 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,001 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin33622, owner=user87238, volume=volume34480, creationTime=1568288763996, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:46:04,015 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911 has been successfully formatted.
2019-09-12 11:46:04,015 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-17AD65B68911: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,015 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,015 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,016 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,017 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,018 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,018 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,018 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,018 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start group-17AD65B68911
2019-09-12 11:46:04,018 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,018 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start FollowerState
2019-09-12 11:46:04,019 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-17AD65B68911,id=261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:04,028 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: abe19cac-4c41-49c7-b73a-17ad65b68911, Nodes: 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,029 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,030 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume34480, bucket=bucket73514, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:46:04,037 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: addNew group-7FCDC4344207:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] returns group-7FCDC4344207:java.util.concurrent.CompletableFuture@7aee3d56[Not completed]
2019-09-12 11:46:04,038 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: new RaftServerImpl for group-7FCDC4344207:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 ConfigurationManager, init=-1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,039 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:46:04,040 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207 does not exist. Creating ...
2019-09-12 11:46:04,052 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,065 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207 has been successfully formatted.
2019-09-12 11:46:04,065 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7FCDC4344207: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,066 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207
2019-09-12 11:46:04,067 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,067 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,067 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,067 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,067 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,067 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,068 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,068 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,068 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,068 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,068 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,069 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,069 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,069 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,069 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start group-7FCDC4344207
2019-09-12 11:46:04,070 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,070 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start FollowerState
2019-09-12 11:46:04,070 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7FCDC4344207,id=261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:04,076 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ac31828e-b2f3-485b-a6d1-7fcdc4344207, Nodes: 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,077 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,085 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 17737a86-5417-40d5-bd10-6caac07f8585: addNew group-4277701997DB:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] returns group-4277701997DB:java.util.concurrent.CompletableFuture@15d6aa9e[Not completed]
2019-09-12 11:46:04,087 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 17737a86-5417-40d5-bd10-6caac07f8585: new RaftServerImpl for group-4277701997DB:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,088 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,088 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,088 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,088 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,089 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,089 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB ConfigurationManager, init=-1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,089 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:46:04,090 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db does not exist. Creating ...
2019-09-12 11:46:04,102 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,115 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db has been successfully formatted.
2019-09-12 11:46:04,115 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-4277701997DB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,116 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,116 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,116 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,116 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,116 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,117 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,118 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,118 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,118 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,118 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,118 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,118 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,119 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,119 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,119 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,119 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 17737a86-5417-40d5-bd10-6caac07f8585: start group-4277701997DB
2019-09-12 11:46:04,119 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,120 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start FollowerState
2019-09-12 11:46:04,120 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4277701997DB,id=17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:04,126 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0321fbbf-be02-4dee-9337-4277701997db, Nodes: 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,128 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,136 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: addNew group-A986DD9D2720:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] returns group-A986DD9D2720:java.util.concurrent.CompletableFuture@35b4e94a[Not completed]
2019-09-12 11:46:04,137 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: new RaftServerImpl for group-A986DD9D2720:[6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,137 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 ConfigurationManager, init=-1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis] (custom)
2019-09-12 11:46:04,138 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720 does not exist. Creating ...
2019-09-12 11:46:04,151 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,171 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720 has been successfully formatted.
2019-09-12 11:46:04,171 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A986DD9D2720: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,172 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,173 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start group-A986DD9D2720
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,174 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start FollowerState
2019-09-12 11:46:04,175 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A986DD9D2720,id=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363
2019-09-12 11:46:04,179 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e001c55e-75a5-4fb2-957d-a986dd9d2720, Nodes: 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,181 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,181 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,188 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: addNew group-FF51D3FF553B:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] returns group-FF51D3FF553B:java.util.concurrent.CompletableFuture@77e0e239[Not completed]
2019-09-12 11:46:04,189 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: new RaftServerImpl for group-FF51D3FF553B:[261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,189 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,189 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,190 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,190 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,190 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,190 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B ConfigurationManager, init=-1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,190 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis] (custom)
2019-09-12 11:46:04,191 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b does not exist. Creating ...
2019-09-12 11:46:04,203 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b has been successfully formatted.
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-FF51D3FF553B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,217 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,218 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,219 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start group-FF51D3FF553B
2019-09-12 11:46:04,220 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,220 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start FollowerState
2019-09-12 11:46:04,220 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF51D3FF553B,id=261c0364-c1a8-4b3d-89b8-311b79ab6415
2019-09-12 11:46:04,224 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 39c7aaee-e216-4bfc-882a-ff51d3ff553b, Nodes: 261c0364-c1a8-4b3d-89b8-311b79ab6415{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,226 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,226 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,226 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,234 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: addNew group-69A588A2B697:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] returns group-69A588A2B697:java.util.concurrent.CompletableFuture@e86f77[Not completed]
2019-09-12 11:46:04,236 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: new RaftServerImpl for group-69A588A2B697:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 ConfigurationManager, init=-1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,237 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:46:04,238 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697 does not exist. Creating ...
2019-09-12 11:46:04,245 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume34480} | ret=SUCCESS |  
2019-09-12 11:46:04,252 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume34480, bucket=bucket73514} | ret=SUCCESS |  
2019-09-12 11:46:04,259 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,272 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697 has been successfully formatted.
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-69A588A2B697: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,273 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,275 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,275 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,275 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,275 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,275 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,276 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start group-69A588A2B697
2019-09-12 11:46:04,276 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,276 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start FollowerState
2019-09-12 11:46:04,276 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-69A588A2B697,id=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:04,281 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 67b478a9-bb1d-4f95-8fe8-69a588a2b697, Nodes: 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,282 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,282 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,283 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,286 [Thread-256] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket73514.volume34480 implemented by OzoneFileSystem{URI=o3fs://bucket73514.volume34480, workingDir=o3fs://bucket73514.volume34480/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-12 11:46:04,289 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 17737a86-5417-40d5-bd10-6caac07f8585: addNew group-4B65869F9488:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] returns group-4B65869F9488:java.util.concurrent.CompletableFuture@366d66a9[Not completed]
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 17737a86-5417-40d5-bd10-6caac07f8585: new RaftServerImpl for group-4B65869F9488:[17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 ConfigurationManager, init=-1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,291 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis] (custom)
2019-09-12 11:46:04,292 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488 does not exist. Creating ...
2019-09-12 11:46:04,304 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,317 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488 has been successfully formatted.
2019-09-12 11:46:04,317 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-4B65869F9488: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,319 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,319 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,319 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,319 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,319 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,319 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,320 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,320 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,320 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,321 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 17737a86-5417-40d5-bd10-6caac07f8585: start group-4B65869F9488
2019-09-12 11:46:04,321 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,321 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start FollowerState
2019-09-12 11:46:04,328 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B65869F9488,id=17737a86-5417-40d5-bd10-6caac07f8585
2019-09-12 11:46:04,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:04,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:04,332 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0b42dbb5-d926-4a12-bda3-4b65869f9488, Nodes: 17737a86-5417-40d5-bd10-6caac07f8585{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,334 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,334 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,334 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,334 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,342 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: addNew group-DD3C16C34EDC:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] returns group-DD3C16C34EDC:java.util.concurrent.CompletableFuture@465cfc3b[Not completed]
2019-09-12 11:46:04,343 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: new RaftServerImpl for group-DD3C16C34EDC:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,343 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,343 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,343 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,343 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,343 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,344 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC ConfigurationManager, init=-1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,344 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:46:04,344 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc does not exist. Creating ...
2019-09-12 11:46:04,352 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:04,357 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,370 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc has been successfully formatted.
2019-09-12 11:46:04,370 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DD3C16C34EDC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,370 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,370 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,370 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,370 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,371 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,372 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,372 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,372 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,372 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,372 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,373 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,375 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,378 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,378 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,379 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start group-DD3C16C34EDC
2019-09-12 11:46:04,379 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,379 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start FollowerState
2019-09-12 11:46:04,379 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD3C16C34EDC,id=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:04,389 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0409b8e-f413-426b-aac4-dd3c16c34edc, Nodes: 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,395 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:04,400 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: addNew group-95BDBF0CCA42:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] returns group-95BDBF0CCA42:java.util.concurrent.CompletableFuture@38bdc42a[Not completed]
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: new RaftServerImpl for group-95BDBF0CCA42:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,401 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 ConfigurationManager, init=-1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,402 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:46:04,402 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42 does not exist. Creating ...
2019-09-12 11:46:04,402 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:04,415 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:04,416 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:04,417 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,424 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume34480, bucket=bucket73514, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42 has been successfully formatted.
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-95BDBF0CCA42: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,431 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,432 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,432 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,432 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,432 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,432 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,432 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,433 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:04,433 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,433 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start group-95BDBF0CCA42
2019-09-12 11:46:04,433 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,434 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start FollowerState
2019-09-12 11:46:04,435 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-95BDBF0CCA42,id=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:04,435 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume34480, bucket=bucket73514, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-12 11:46:04,440 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:04,443 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a0facd19-358b-4147-be7a-95bdbf0cca42, Nodes: 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,444 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,445 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,445 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,445 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,450 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:04,452 [Thread-256] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-12 11:46:04,455 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: addNew group-6ADEE2299693:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] returns group-6ADEE2299693:java.util.concurrent.CompletableFuture@798cf4f2[Not completed]
2019-09-12 11:46:04,456 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: new RaftServerImpl for group-6ADEE2299693:[6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151] with ContainerStateMachine:uninitialized
2019-09-12 11:46:04,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:46:04,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:46:04,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:46:04,457 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:46:04,457 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:46:04,457 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 ConfigurationManager, init=-1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null, confs=<EMPTY_MAP>
2019-09-12 11:46:04,457 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis] (custom)
2019-09-12 11:46:04,457 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693 does not exist. Creating ...
2019-09-12 11:46:04,468 [Thread-207] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-12 11:46:04,470 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693/in_use.lock acquired by nodename 3972@pr-hdds-1569-xtfnx-3545843844
2019-09-12 11:46:04,482 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-12 11:46:04,493 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693 has been successfully formatted.
2019-09-12 11:46:04,494 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6ADEE2299693: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:46:04,494 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:46:04,494 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:46:04,495 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:46:04,499 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:46:04,500 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:46:04,501 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:46:04,501 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:46:04,501 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:46:04,501 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start group-6ADEE2299693
2019-09-12 11:46:04,501 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:46:04,501 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start FollowerState
2019-09-12 11:46:04,502 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6ADEE2299693,id=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7
2019-09-12 11:46:04,511 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ff3563c8-8519-4b4e-a33f-6adee2299693, Nodes: 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7{ip: 192.168.157.195, host: pr-hdds-1569-xtfnx-3545843844, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:46:04,513 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,517 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,520 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,520 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,520 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,521 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,522 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,522 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,522 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,522 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,523 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,523 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,523 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,523 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,523 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,524 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,524 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,524 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:04,524 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,524 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:04,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:04,669 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:04,675 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:04,728 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:04,808 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:04,955 [Thread-256] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-12 11:46:04,955 [Thread-256] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:46:04,958 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-12 11:46:04,958 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-12 11:46:05,002 [Thread-256] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:46:05,019 [Thread-256] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:46:05,025 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:05,063 [Thread-256] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:46:05,175 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:8
2019-09-12 11:46:05,324 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:05,324 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:05,343 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1401702154_0001
2019-09-12 11:46:05,344 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:46:05,416 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:05,548 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:05,554 [Thread-256] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:46:05,555 [Thread-256] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1401702154_0001
2019-09-12 11:46:05,557 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1401702154_0001
2019-09-12 11:46:05,563 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:46:05,578 [Thread-369] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:05,578 [Thread-369] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:05,582 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:46:05,660 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:46:05,663 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:05,674 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:05,699 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:05,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:05,732 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:05,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:1447+1124
2019-09-12 11:46:05,747 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:05,748 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:05,782 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:05,785 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-12 11:46:05,802 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:05,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:05,848 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:05,848 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:05,848 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:05,848 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:05,849 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:05,849 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:05,849 [IPC Server handler 0 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:05,850 [IPC Server handler 0 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:05,852 [IPC Server handler 0 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:05,852 [IPC Server handler 0 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:05,853 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:05,859 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:05,861 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:05,863 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:05,864 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:06,321 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:06,321 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:06,415 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:06,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:06,565 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1401702154_0001 running in uber mode : false
2019-09-12 11:46:06,568 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-12 11:46:06,673 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:07,321 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:07,321 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:07,415 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:07,545 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:07,673 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:07,831 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(106)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F changes to CANDIDATE, lastRpcTime:5184, electionTimeout:5183ms
2019-09-12 11:46:07,831 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b702d902-25f1-483f-8834-460c179f9559: shutdown FollowerState
2019-09-12 11:46:07,831 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:07,835 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderElection
2019-09-12 11:46:07,846 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(106)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB changes to CANDIDATE, lastRpcTime:5060, electionTimeout:5060ms
2019-09-12 11:46:07,848 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b702d902-25f1-483f-8834-460c179f9559: shutdown FollowerState
2019-09-12 11:46:07,848 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:07,848 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderElection
2019-09-12 11:46:07,875 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2: begin an election at term 1 for -1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null
2019-09-12 11:46:07,875 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1: begin an election at term 1 for -1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null
2019-09-12 11:46:07,879 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b702d902-25f1-483f-8834-460c179f9559: shutdown LeaderElection
2019-09-12 11:46:07,879 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b702d902-25f1-483f-8834-460c179f9559: shutdown LeaderElection
2019-09-12 11:46:07,880 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:07,880 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:07,880 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB change Leader from null to b702d902-25f1-483f-8834-460c179f9559 at term 1 for becomeLeader, leader elected after 5100ms
2019-09-12 11:46:07,881 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F change Leader from null to b702d902-25f1-483f-8834-460c179f9559 at term 1 for becomeLeader, leader elected after 5326ms
2019-09-12 11:46:07,892 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:07,892 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:07,892 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:07,892 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:07,896 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:07,896 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:07,900 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:07,900 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:07,901 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:07,901 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:07,902 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:07,902 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:07,921 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderState
2019-09-12 11:46:07,921 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderState
2019-09-12 11:46:07,950 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb: Starting segment from index:0
2019-09-12 11:46:07,950 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f: Starting segment from index:0
2019-09-12 11:46:07,961 [b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - b702d902-25f1-483f-8834-460c179f9559:group-1A850029EF7F set configuration 0: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null at 0
2019-09-12 11:46:07,961 [b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - b702d902-25f1-483f-8834-460c179f9559:group-32C8BDFB17BB set configuration 0: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null at 0
2019-09-12 11:46:08,070 [Thread-221] INFO  impl.FollowerState (FollowerState.java:run(106)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 changes to CANDIDATE, lastRpcTime:5032, electionTimeout:5032ms
2019-09-12 11:46:08,070 [Thread-221] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown FollowerState
2019-09-12 11:46:08,070 [Thread-221] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,071 [Thread-221] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderElection
2019-09-12 11:46:08,087 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 changes to CANDIDATE, lastRpcTime:5190, electionTimeout:5189ms
2019-09-12 11:46:08,087 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown FollowerState
2019-09-12 11:46:08,088 [Thread-215] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,088 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderElection
2019-09-12 11:46:08,090 [Thread-218] INFO  impl.FollowerState (FollowerState.java:run(106)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 changes to CANDIDATE, lastRpcTime:5118, electionTimeout:5117ms
2019-09-12 11:46:08,090 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown FollowerState
2019-09-12 11:46:08,090 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3: begin an election at term 1 for -1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null
2019-09-12 11:46:08,093 [Thread-218] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,093 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown LeaderElection
2019-09-12 11:46:08,093 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderElection
2019-09-12 11:46:08,093 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,093 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 change Leader from null to 261c0364-c1a8-4b3d-89b8-311b79ab6415 at term 1 for becomeLeader, leader elected after 5061ms
2019-09-12 11:46:08,096 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,098 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,098 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,098 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,099 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,099 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,099 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderState
2019-09-12 11:46:08,099 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3: Starting segment from index:0
2019-09-12 11:46:08,100 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-A2B095ABEBC3 set configuration 0: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null at 0
2019-09-12 11:46:08,117 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4: begin an election at term 1 for -1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null
2019-09-12 11:46:08,117 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5: begin an election at term 1 for -1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null
2019-09-12 11:46:08,117 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown LeaderElection
2019-09-12 11:46:08,117 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown LeaderElection
2019-09-12 11:46:08,118 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,118 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,118 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 change Leader from null to 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at term 1 for becomeLeader, leader elected after 5225ms
2019-09-12 11:46:08,118 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 change Leader from null to 261c0364-c1a8-4b3d-89b8-311b79ab6415 at term 1 for becomeLeader, leader elected after 5151ms
2019-09-12 11:46:08,120 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,120 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,120 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,120 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,120 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,120 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,120 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,121 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,121 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,121 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,121 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,121 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,121 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderState
2019-09-12 11:46:08,122 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderState
2019-09-12 11:46:08,122 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4: Starting segment from index:0
2019-09-12 11:46:08,122 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6: Starting segment from index:0
2019-09-12 11:46:08,122 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-EFB98FE9C9C4 set configuration 0: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null at 0
2019-09-12 11:46:08,124 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-AA80A99638C6 set configuration 0: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null at 0
2019-09-12 11:46:08,177 [b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/565ac36a-b13c-4f43-8fe4-32c8bdfb17bb/current/log_inprogress_0
2019-09-12 11:46:08,177 [261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/0aa8f310-eb34-4693-bc97-a2b095abebc3/current/log_inprogress_0
2019-09-12 11:46:08,177 [261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/61522dcd-8534-4a42-8068-aa80a99638c6/current/log_inprogress_0
2019-09-12 11:46:08,177 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/131aeea8-a2b9-4498-8719-efb98fe9c9c4/current/log_inprogress_0
2019-09-12 11:46:08,177 [b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/491c39c3-7aa3-4d10-bb8f-1a850029ef7f/current/log_inprogress_0
2019-09-12 11:46:08,212 [Thread-224] INFO  impl.FollowerState (FollowerState.java:run(106)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 changes to CANDIDATE, lastRpcTime:5105, electionTimeout:5105ms
2019-09-12 11:46:08,214 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b702d902-25f1-483f-8834-460c179f9559: shutdown FollowerState
2019-09-12 11:46:08,214 [Thread-224] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,214 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderElection
2019-09-12 11:46:08,231 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6: begin an election at term 1 for -1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null
2019-09-12 11:46:08,233 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b702d902-25f1-483f-8834-460c179f9559: shutdown LeaderElection
2019-09-12 11:46:08,233 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,233 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 change Leader from null to b702d902-25f1-483f-8834-460c179f9559 at term 1 for becomeLeader, leader elected after 5130ms
2019-09-12 11:46:08,233 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,233 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,234 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,234 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,234 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,234 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,235 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderState
2019-09-12 11:46:08,235 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2: Starting segment from index:0
2019-09-12 11:46:08,236 [b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - b702d902-25f1-483f-8834-460c179f9559:group-9DDC0391D2B2 set configuration 0: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null at 0
2019-09-12 11:46:08,288 [b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/956eba62-8f34-490d-b713-9ddc0391d2b2/current/log_inprogress_0
2019-09-12 11:46:08,318 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(106)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 changes to CANDIDATE, lastRpcTime:5027, electionTimeout:5027ms
2019-09-12 11:46:08,319 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b702d902-25f1-483f-8834-460c179f9559: shutdown FollowerState
2019-09-12 11:46:08,319 [Thread-233] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,319 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderElection
2019-09-12 11:46:08,327 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:08,327 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:08,332 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 changes to CANDIDATE, lastRpcTime:5095, electionTimeout:5095ms
2019-09-12 11:46:08,333 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown FollowerState
2019-09-12 11:46:08,333 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,334 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderElection
2019-09-12 11:46:08,338 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7: begin an election at term 1 for -1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null
2019-09-12 11:46:08,338 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b702d902-25f1-483f-8834-460c179f9559: shutdown LeaderElection
2019-09-12 11:46:08,338 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,338 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 change Leader from null to b702d902-25f1-483f-8834-460c179f9559 at term 1 for becomeLeader, leader elected after 5051ms
2019-09-12 11:46:08,338 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,339 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,339 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,339 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,339 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,339 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,340 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderState
2019-09-12 11:46:08,340 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8: Starting segment from index:0
2019-09-12 11:46:08,340 [b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - b702d902-25f1-483f-8834-460c179f9559:group-9C2D8D1DBCC8 set configuration 0: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null at 0
2019-09-12 11:46:08,381 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B changes to CANDIDATE, lastRpcTime:5210, electionTimeout:5184ms
2019-09-12 11:46:08,381 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b702d902-25f1-483f-8834-460c179f9559: shutdown FollowerState
2019-09-12 11:46:08,381 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,381 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8: begin an election at term 1 for -1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null
2019-09-12 11:46:08,381 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderElection
2019-09-12 11:46:08,381 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown LeaderElection
2019-09-12 11:46:08,381 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,382 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 change Leader from null to 261c0364-c1a8-4b3d-89b8-311b79ab6415 at term 1 for becomeLeader, leader elected after 5150ms
2019-09-12 11:46:08,383 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C changes to CANDIDATE, lastRpcTime:5033, electionTimeout:5033ms
2019-09-12 11:46:08,386 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,386 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown FollowerState
2019-09-12 11:46:08,387 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,387 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,387 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,387 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderElection
2019-09-12 11:46:08,387 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,389 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,392 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,392 [b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/5d97e177-b198-4c8a-9bc0-9c2d8d1dbcc8/current/log_inprogress_0
2019-09-12 11:46:08,392 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9: begin an election at term 1 for -1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null
2019-09-12 11:46:08,392 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderState
2019-09-12 11:46:08,394 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b702d902-25f1-483f-8834-460c179f9559: shutdown LeaderElection
2019-09-12 11:46:08,394 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,394 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0: Starting segment from index:0
2019-09-12 11:46:08,394 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B change Leader from null to b702d902-25f1-483f-8834-460c179f9559 at term 1 for becomeLeader, leader elected after 5227ms
2019-09-12 11:46:08,395 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,395 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,395 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-B40F59C1D1B0 set configuration 0: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null at 0
2019-09-12 11:46:08,395 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,430 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:08,430 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10: begin an election at term 1 for -1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null
2019-09-12 11:46:08,430 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,431 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,431 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown LeaderElection
2019-09-12 11:46:08,431 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,431 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,432 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C change Leader from null to 17737a86-5417-40d5-bd10-6caac07f8585 at term 1 for becomeLeader, leader elected after 5092ms
2019-09-12 11:46:08,432 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderState
2019-09-12 11:46:08,434 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:08,434 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,434 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b: Starting segment from index:0
2019-09-12 11:46:08,435 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,435 [b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - b702d902-25f1-483f-8834-460c179f9559:group-7C2FBA5D927B set configuration 0: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null at 0
2019-09-12 11:46:08,435 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,474 [261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/a6ef8ab0-a1c3-4491-9035-b40f59c1d1b0/current/log_inprogress_0
2019-09-12 11:46:08,474 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 changes to CANDIDATE, lastRpcTime:5061, electionTimeout:5050ms
2019-09-12 11:46:08,475 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,475 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown FollowerState
2019-09-12 11:46:08,482 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,482 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,482 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,483 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderElection
2019-09-12 11:46:08,483 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderState
2019-09-12 11:46:08,488 [b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/87093451-cb38-4462-a5b9-7c2fba5d927b/current/log_inprogress_0
2019-09-12 11:46:08,490 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c: Starting segment from index:0
2019-09-12 11:46:08,490 [17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-18477BC7668C set configuration 0: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null at 0
2019-09-12 11:46:08,525 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11: begin an election at term 1 for -1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null
2019-09-12 11:46:08,526 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown LeaderElection
2019-09-12 11:46:08,526 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,526 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:08,526 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 change Leader from null to 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at term 1 for becomeLeader, leader elected after 5118ms
2019-09-12 11:46:08,526 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:08,528 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,528 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:08,529 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:08,528 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,529 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:08,529 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,529 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:08,529 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,530 [IPC Server handler 1 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:08,530 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,530 [IPC Server handler 1 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:08,530 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,531 [IPC Server handler 1 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:08,531 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderState
2019-09-12 11:46:08,531 [IPC Server handler 1 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:08,531 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9: Starting segment from index:0
2019-09-12 11:46:08,532 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:08,533 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-79FFC3E38AF9 set configuration 0: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null at 0
2019-09-12 11:46:08,565 [17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/18fd224b-01b8-4f6a-bf6c-18477bc7668c/current/log_inprogress_0
2019-09-12 11:46:08,566 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/e1e82dd9-0140-4d7d-9c9e-79ffc3e38af9/current/log_inprogress_0
2019-09-12 11:46:08,566 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:08,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:08,569 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:08,571 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:08,571 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:08,590 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(106)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A changes to CANDIDATE, lastRpcTime:5116, electionTimeout:5116ms
2019-09-12 11:46:08,590 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b702d902-25f1-483f-8834-460c179f9559: shutdown FollowerState
2019-09-12 11:46:08,591 [Thread-242] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,591 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderElection
2019-09-12 11:46:08,599 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12: begin an election at term 1 for -1: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null
2019-09-12 11:46:08,600 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b702d902-25f1-483f-8834-460c179f9559: shutdown LeaderElection
2019-09-12 11:46:08,600 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,600 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A change Leader from null to b702d902-25f1-483f-8834-460c179f9559 at term 1 for becomeLeader, leader elected after 5131ms
2019-09-12 11:46:08,600 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,601 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,601 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,601 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,601 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,601 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,602 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b702d902-25f1-483f-8834-460c179f9559: start LeaderState
2019-09-12 11:46:08,602 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a: Starting segment from index:0
2019-09-12 11:46:08,603 [b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - b702d902-25f1-483f-8834-460c179f9559:group-5DE989847E1A set configuration 0: [b702d902-25f1-483f-8834-460c179f9559:192.168.157.195:43533], old=null at 0
2019-09-12 11:46:08,639 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(106)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD changes to CANDIDATE, lastRpcTime:5061, electionTimeout:5061ms
2019-09-12 11:46:08,639 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown FollowerState
2019-09-12 11:46:08,640 [Thread-248] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,640 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderElection
2019-09-12 11:46:08,647 [b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b702d902-25f1-483f-8834-460c179f9559-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-0/data/ratis/aedbcd97-01f4-4e85-9d95-5de989847e1a/current/log_inprogress_0
2019-09-12 11:46:08,652 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13: begin an election at term 1 for -1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null
2019-09-12 11:46:08,652 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown LeaderElection
2019-09-12 11:46:08,652 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,652 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD change Leader from null to 17737a86-5417-40d5-bd10-6caac07f8585 at term 1 for becomeLeader, leader elected after 5078ms
2019-09-12 11:46:08,652 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,653 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,653 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,653 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,653 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,653 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,653 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderState
2019-09-12 11:46:08,654 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad: Starting segment from index:0
2019-09-12 11:46:08,654 [17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-1CD6213CC7AD set configuration 0: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null at 0
2019-09-12 11:46:08,684 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:08,694 [17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/572eb5a5-11e5-4477-a75b-1cd6213cc7ad/current/log_inprogress_0
2019-09-12 11:46:08,723 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 changes to CANDIDATE, lastRpcTime:5198, electionTimeout:5198ms
2019-09-12 11:46:08,723 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown FollowerState
2019-09-12 11:46:08,724 [Thread-245] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,724 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderElection
2019-09-12 11:46:08,742 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14: begin an election at term 1 for -1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null
2019-09-12 11:46:08,742 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown LeaderElection
2019-09-12 11:46:08,742 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,742 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 change Leader from null to 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at term 1 for becomeLeader, leader elected after 5221ms
2019-09-12 11:46:08,742 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,742 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,743 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,743 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,743 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,743 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,743 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderState
2019-09-12 11:46:08,744 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997: Starting segment from index:0
2019-09-12 11:46:08,744 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-EAB71CD28997 set configuration 0: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null at 0
2019-09-12 11:46:08,791 [Thread-251] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 changes to CANDIDATE, lastRpcTime:5159, electionTimeout:5159ms
2019-09-12 11:46:08,792 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown FollowerState
2019-09-12 11:46:08,792 [Thread-251] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,792 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderElection
2019-09-12 11:46:08,808 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a9db4387-f32d-425a-9dc4-eab71cd28997/current/log_inprogress_0
2019-09-12 11:46:08,810 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15: begin an election at term 1 for -1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null
2019-09-12 11:46:08,810 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown LeaderElection
2019-09-12 11:46:08,810 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,810 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 change Leader from null to 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at term 1 for becomeLeader, leader elected after 5182ms
2019-09-12 11:46:08,811 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,811 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,811 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,811 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,812 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,812 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,812 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderState
2019-09-12 11:46:08,812 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4: Starting segment from index:0
2019-09-12 11:46:08,813 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-77760AFAF5A4 set configuration 0: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null at 0
2019-09-12 11:46:08,859 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(106)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 changes to CANDIDATE, lastRpcTime:5071, electionTimeout:5071ms
2019-09-12 11:46:08,859 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown FollowerState
2019-09-12 11:46:08,859 [Thread-262] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,859 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderElection
2019-09-12 11:46:08,864 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(106)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E changes to CANDIDATE, lastRpcTime:5178, electionTimeout:5175ms
2019-09-12 11:46:08,864 [Thread-254] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown FollowerState
2019-09-12 11:46:08,865 [Thread-254] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,865 [Thread-254] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderElection
2019-09-12 11:46:08,870 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/cf0cc841-ccbd-4095-9608-77760afaf5a4/current/log_inprogress_0
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16: begin an election at term 1 for -1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17: begin an election at term 1 for -1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown LeaderElection
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown LeaderElection
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,877 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 change Leader from null to 17737a86-5417-40d5-bd10-6caac07f8585 at term 1 for becomeLeader, leader elected after 5094ms
2019-09-12 11:46:08,878 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E change Leader from null to 17737a86-5417-40d5-bd10-6caac07f8585 at term 1 for becomeLeader, leader elected after 5195ms
2019-09-12 11:46:08,878 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,878 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,878 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,878 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,879 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,879 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,879 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,879 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,879 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,880 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,880 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,880 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,880 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderState
2019-09-12 11:46:08,881 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderState
2019-09-12 11:46:08,881 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673: Starting segment from index:0
2019-09-12 11:46:08,881 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e: Starting segment from index:0
2019-09-12 11:46:08,882 [17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-8FB40B5BA673 set configuration 0: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null at 0
2019-09-12 11:46:08,925 [17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-DBE769A4F88E set configuration 0: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null at 0
2019-09-12 11:46:08,932 [Thread-258] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 changes to CANDIDATE, lastRpcTime:5195, electionTimeout:5195ms
2019-09-12 11:46:08,932 [Thread-258] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown FollowerState
2019-09-12 11:46:08,932 [Thread-258] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,932 [Thread-258] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderElection
2019-09-12 11:46:08,938 [17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/a2632748-963e-4068-876e-8fb40b5ba673/current/log_inprogress_0
2019-09-12 11:46:08,938 [17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/d575a456-8a38-4cc0-bacc-dbe769a4f88e/current/log_inprogress_0
2019-09-12 11:46:08,957 [Thread-265] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C changes to CANDIDATE, lastRpcTime:5117, electionTimeout:5117ms
2019-09-12 11:46:08,957 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown FollowerState
2019-09-12 11:46:08,957 [Thread-265] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:08,957 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderElection
2019-09-12 11:46:08,965 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18: begin an election at term 1 for -1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null
2019-09-12 11:46:08,965 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown LeaderElection
2019-09-12 11:46:08,965 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:08,965 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 change Leader from null to 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at term 1 for becomeLeader, leader elected after 5232ms
2019-09-12 11:46:08,966 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:08,966 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:08,966 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:08,966 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:08,966 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:08,967 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:08,967 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderState
2019-09-12 11:46:08,967 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03: Starting segment from index:0
2019-09-12 11:46:08,968 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-5D52E4889E03 set configuration 0: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null at 0
2019-09-12 11:46:09,010 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19: begin an election at term 1 for -1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null
2019-09-12 11:46:09,010 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown LeaderElection
2019-09-12 11:46:09,010 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,011 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C change Leader from null to 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at term 1 for becomeLeader, leader elected after 5175ms
2019-09-12 11:46:09,011 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,011 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,011 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,011 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,011 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,012 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,012 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderState
2019-09-12 11:46:09,012 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c: Starting segment from index:0
2019-09-12 11:46:09,013 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-9C3B7727AF2C set configuration 0: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null at 0
2019-09-12 11:46:09,057 [Thread-271] INFO  impl.FollowerState (FollowerState.java:run(106)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 changes to CANDIDATE, lastRpcTime:5038, electionTimeout:5007ms
2019-09-12 11:46:09,057 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/4ebf219e-776f-4191-a665-5d52e4889e03/current/log_inprogress_0
2019-09-12 11:46:09,057 [Thread-271] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown FollowerState
2019-09-12 11:46:09,058 [Thread-271] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,058 [Thread-271] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderElection
2019-09-12 11:46:09,081 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/87274a5a-eabd-484d-a6a2-9c3b7727af2c/current/log_inprogress_0
2019-09-12 11:46:09,083 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20: begin an election at term 1 for -1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null
2019-09-12 11:46:09,083 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown LeaderElection
2019-09-12 11:46:09,083 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,083 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 change Leader from null to 261c0364-c1a8-4b3d-89b8-311b79ab6415 at term 1 for becomeLeader, leader elected after 5068ms
2019-09-12 11:46:09,084 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,084 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,084 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,084 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,084 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,084 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,085 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderState
2019-09-12 11:46:09,085 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911: Starting segment from index:0
2019-09-12 11:46:09,086 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-17AD65B68911 set configuration 0: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null at 0
2019-09-12 11:46:09,135 [Thread-268] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED changes to CANDIDATE, lastRpcTime:5188, electionTimeout:5188ms
2019-09-12 11:46:09,135 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown FollowerState
2019-09-12 11:46:09,135 [Thread-268] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,135 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderElection
2019-09-12 11:46:09,149 [261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/abe19cac-4c41-49c7-b73a-17ad65b68911/current/log_inprogress_0
2019-09-12 11:46:09,151 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21: begin an election at term 1 for -1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null
2019-09-12 11:46:09,151 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown LeaderElection
2019-09-12 11:46:09,151 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,151 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED change Leader from null to 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at term 1 for becomeLeader, leader elected after 5212ms
2019-09-12 11:46:09,152 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,152 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,152 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,152 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,152 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,153 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,153 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderState
2019-09-12 11:46:09,153 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed: Starting segment from index:0
2019-09-12 11:46:09,154 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-E146A15113ED set configuration 0: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null at 0
2019-09-12 11:46:09,197 [Thread-274] INFO  impl.FollowerState (FollowerState.java:run(106)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 changes to CANDIDATE, lastRpcTime:5127, electionTimeout:5118ms
2019-09-12 11:46:09,197 [Thread-274] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown FollowerState
2019-09-12 11:46:09,197 [Thread-274] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,198 [Thread-274] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderElection
2019-09-12 11:46:09,222 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/eb506660-89b4-4486-8c96-e146a15113ed/current/log_inprogress_0
2019-09-12 11:46:09,222 [Thread-285] INFO  impl.FollowerState (FollowerState.java:run(106)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B changes to CANDIDATE, lastRpcTime:5002, electionTimeout:5002ms
2019-09-12 11:46:09,222 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22: begin an election at term 1 for -1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null
2019-09-12 11:46:09,222 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown FollowerState
2019-09-12 11:46:09,222 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown LeaderElection
2019-09-12 11:46:09,223 [Thread-285] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,223 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,223 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderElection
2019-09-12 11:46:09,223 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 change Leader from null to 261c0364-c1a8-4b3d-89b8-311b79ab6415 at term 1 for becomeLeader, leader elected after 5157ms
2019-09-12 11:46:09,223 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,225 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,225 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,226 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,226 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,226 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,226 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderState
2019-09-12 11:46:09,227 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207: Starting segment from index:0
2019-09-12 11:46:09,227 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-7FCDC4344207 set configuration 0: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null at 0
2019-09-12 11:46:09,269 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23: begin an election at term 1 for -1: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null
2019-09-12 11:46:09,269 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: shutdown LeaderElection
2019-09-12 11:46:09,269 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,270 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B change Leader from null to 261c0364-c1a8-4b3d-89b8-311b79ab6415 at term 1 for becomeLeader, leader elected after 5052ms
2019-09-12 11:46:09,270 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,270 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,270 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,270 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,271 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,271 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,271 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415: start LeaderState
2019-09-12 11:46:09,272 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b: Starting segment from index:0
2019-09-12 11:46:09,272 [261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415:group-FF51D3FF553B set configuration 0: [261c0364-c1a8-4b3d-89b8-311b79ab6415:192.168.157.195:45680], old=null at 0
2019-09-12 11:46:09,315 [261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/ac31828e-b2f3-485b-a6d1-7fcdc4344207/current/log_inprogress_0
2019-09-12 11:46:09,315 [Thread-278] INFO  impl.FollowerState (FollowerState.java:run(106)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB changes to CANDIDATE, lastRpcTime:5195, electionTimeout:5175ms
2019-09-12 11:46:09,315 [Thread-288] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 changes to CANDIDATE, lastRpcTime:5039, electionTimeout:5006ms
2019-09-12 11:46:09,316 [Thread-278] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown FollowerState
2019-09-12 11:46:09,316 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown FollowerState
2019-09-12 11:46:09,316 [Thread-278] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,316 [Thread-288] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,317 [Thread-278] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderElection
2019-09-12 11:46:09,317 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderElection
2019-09-12 11:46:09,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:09,327 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:09,330 [261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 261c0364-c1a8-4b3d-89b8-311b79ab6415-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-3/data/ratis/39c7aaee-e216-4bfc-882a-ff51d3ff553b/current/log_inprogress_0
2019-09-12 11:46:09,330 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25: begin an election at term 1 for -1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null
2019-09-12 11:46:09,330 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24: begin an election at term 1 for -1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null
2019-09-12 11:46:09,330 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown LeaderElection
2019-09-12 11:46:09,330 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown LeaderElection
2019-09-12 11:46:09,330 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,330 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,331 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 change Leader from null to 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at term 1 for becomeLeader, leader elected after 5057ms
2019-09-12 11:46:09,331 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB change Leader from null to 17737a86-5417-40d5-bd10-6caac07f8585 at term 1 for becomeLeader, leader elected after 5215ms
2019-09-12 11:46:09,331 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,331 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,331 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,331 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,331 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,332 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,332 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,332 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,332 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,332 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,332 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,333 [Thread-292] INFO  impl.FollowerState (FollowerState.java:run(106)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 changes to CANDIDATE, lastRpcTime:5011, electionTimeout:5004ms
2019-09-12 11:46:09,332 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,333 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderState
2019-09-12 11:46:09,333 [Thread-292] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown FollowerState
2019-09-12 11:46:09,333 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697: Starting segment from index:0
2019-09-12 11:46:09,333 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderState
2019-09-12 11:46:09,333 [Thread-292] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,334 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db: Starting segment from index:0
2019-09-12 11:46:09,334 [Thread-292] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderElection
2019-09-12 11:46:09,334 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-69A588A2B697 set configuration 0: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null at 0
2019-09-12 11:46:09,334 [17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4277701997DB set configuration 0: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null at 0
2019-09-12 11:46:09,377 [Thread-281] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 changes to CANDIDATE, lastRpcTime:5202, electionTimeout:5164ms
2019-09-12 11:46:09,382 [Thread-281] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown FollowerState
2019-09-12 11:46:09,382 [Thread-281] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,382 [Thread-281] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderElection
2019-09-12 11:46:09,390 [17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0321fbbf-be02-4dee-9337-4277701997db/current/log_inprogress_0
2019-09-12 11:46:09,390 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/67b478a9-bb1d-4f95-8fe8-69a588a2b697/current/log_inprogress_0
2019-09-12 11:46:09,390 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26: begin an election at term 1 for -1: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null
2019-09-12 11:46:09,390 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27: begin an election at term 1 for -1: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null
2019-09-12 11:46:09,391 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 17737a86-5417-40d5-bd10-6caac07f8585: shutdown LeaderElection
2019-09-12 11:46:09,391 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: shutdown LeaderElection
2019-09-12 11:46:09,391 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,391 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,391 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 change Leader from null to 17737a86-5417-40d5-bd10-6caac07f8585 at term 1 for becomeLeader, leader elected after 5074ms
2019-09-12 11:46:09,392 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 change Leader from null to 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363 at term 1 for becomeLeader, leader elected after 5219ms
2019-09-12 11:46:09,392 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,392 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,392 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,392 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,392 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,393 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,393 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,393 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,393 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,393 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,393 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,394 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,394 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 17737a86-5417-40d5-bd10-6caac07f8585: start LeaderState
2019-09-12 11:46:09,394 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363: start LeaderState
2019-09-12 11:46:09,394 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488: Starting segment from index:0
2019-09-12 11:46:09,394 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720: Starting segment from index:0
2019-09-12 11:46:09,395 [17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 17737a86-5417-40d5-bd10-6caac07f8585:group-4B65869F9488 set configuration 0: [17737a86-5417-40d5-bd10-6caac07f8585:192.168.157.195:36978], old=null at 0
2019-09-12 11:46:09,431 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:group-A986DD9D2720 set configuration 0: [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363:192.168.157.195:41687], old=null at 0
2019-09-12 11:46:09,464 [17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 17737a86-5417-40d5-bd10-6caac07f8585-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-2/data/ratis/0b42dbb5-d926-4a12-bda3-4b65869f9488/current/log_inprogress_0
2019-09-12 11:46:09,465 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:09,476 [6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6462bdcf-7de1-4e9a-9a3d-ebe3c9246363-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-1/data/ratis/e001c55e-75a5-4fb2-957d-a986dd9d2720/current/log_inprogress_0
2019-09-12 11:46:09,498 [Thread-297] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC changes to CANDIDATE, lastRpcTime:5119, electionTimeout:5119ms
2019-09-12 11:46:09,499 [Thread-297] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown FollowerState
2019-09-12 11:46:09,499 [Thread-297] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,499 [Thread-297] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderElection
2019-09-12 11:46:09,514 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28: begin an election at term 1 for -1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown LeaderElection
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC change Leader from null to 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at term 1 for becomeLeader, leader elected after 5144ms
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,515 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,516 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,516 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,516 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderState
2019-09-12 11:46:09,516 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc: Starting segment from index:0
2019-09-12 11:46:09,517 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-DD3C16C34EDC set configuration 0: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null at 0
2019-09-12 11:46:09,556 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/b0409b8e-f413-426b-aac4-dd3c16c34edc/current/log_inprogress_0
2019-09-12 11:46:09,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:09,615 [Thread-301] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 changes to CANDIDATE, lastRpcTime:5181, electionTimeout:5180ms
2019-09-12 11:46:09,615 [Thread-301] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown FollowerState
2019-09-12 11:46:09,616 [Thread-301] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,616 [Thread-301] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderElection
2019-09-12 11:46:09,632 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29: begin an election at term 1 for -1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null
2019-09-12 11:46:09,632 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown LeaderElection
2019-09-12 11:46:09,632 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,633 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 change Leader from null to 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at term 1 for becomeLeader, leader elected after 5202ms
2019-09-12 11:46:09,633 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,633 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,633 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,633 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,634 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,634 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,634 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderState
2019-09-12 11:46:09,634 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42: Starting segment from index:0
2019-09-12 11:46:09,635 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-95BDBF0CCA42 set configuration 0: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null at 0
2019-09-12 11:46:09,669 [Thread-308] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 changes to CANDIDATE, lastRpcTime:5167, electionTimeout:5142ms
2019-09-12 11:46:09,669 [Thread-308] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown FollowerState
2019-09-12 11:46:09,669 [Thread-308] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:46:09,670 [Thread-308] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderElection
2019-09-12 11:46:09,682 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/a0facd19-358b-4147-be7a-95bdbf0cca42/current/log_inprogress_0
2019-09-12 11:46:09,682 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30: begin an election at term 1 for -1: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null
2019-09-12 11:46:09,682 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: shutdown LeaderElection
2019-09-12 11:46:09,682 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:46:09,683 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 change Leader from null to 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7 at term 1 for becomeLeader, leader elected after 5188ms
2019-09-12 11:46:09,683 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:46:09,683 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:46:09,683 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:46:09,683 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:46:09,683 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:46:09,684 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:46:09,684 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:09,684 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7: start LeaderState
2019-09-12 11:46:09,684 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693: Starting segment from index:0
2019-09-12 11:46:09,685 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:group-6ADEE2299693 set configuration 0: [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7:192.168.157.195:37151], old=null at 0
2019-09-12 11:46:09,740 [6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-077e8a1b-782c-4d23-a80b-4988f3cb8787/datanode-4/data/ratis/ff3563c8-8519-4b4e-a33f-6adee2299693/current/log_inprogress_0
2019-09-12 11:46:10,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:10,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:10,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:10,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:10,685 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:10,915 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:10,923 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:10,923 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:10,923 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:10,923 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:10,924 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:10,924 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:10,924 [IPC Server handler 1 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:10,924 [IPC Server handler 1 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:10,925 [IPC Server handler 1 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:10,925 [IPC Server handler 1 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:10,925 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:10,926 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:10,930 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:10,931 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000000_0
2019-09-12 11:46:10,931 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:10,932 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:10,939 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000001_0
2019-09-12 11:46:10,945 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:10,946 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:10,946 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:10,948 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:0+327
2019-09-12 11:46:10,949 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:10,949 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:10,975 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:10,978 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-12 11:46:10,988 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:10,996 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:11,003 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:11,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1401702154_0001_m_000001_0 is done. And is in the process of committing
2019-09-12 11:46:11,018 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:11,018 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1401702154_0001_m_000001_0 is allowed to commit now
2019-09-12 11:46:11,020 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1401702154_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/_logs
2019-09-12 11:46:11,022 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-12 11:46:11,022 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1401702154_0001_m_000001_0' done.
2019-09-12 11:46:11,025 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1401702154_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=208364
		FILE: Number of bytes written=826432
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:11,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1401702154_0001_m_000001_0
2019-09-12 11:46:11,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:11,031 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:11,031 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:11,032 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:11,033 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:327+293
2019-09-12 11:46:11,034 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:11,034 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:11,057 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:11,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-12 11:46:11,067 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:11,084 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:11,090 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:11,090 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:11,091 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:11,091 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:11,091 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:11,091 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:11,091 [IPC Server handler 11 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:11,092 [IPC Server handler 11 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:11,092 [IPC Server handler 11 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:11,092 [IPC Server handler 11 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:11,092 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:11,093 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:11,099 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:11,101 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:11,101 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:11,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:11,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:11,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:11,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:11,574 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:46:11,685 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:12,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:12,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:12,434 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:12,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:12,685 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:13,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:13,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:13,385 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:13,391 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:13,391 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:13,392 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:13,392 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:13,392 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:13,392 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:13,393 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:13,393 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:13,393 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:13,393 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:13,394 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:13,395 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:13,398 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:13,402 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:13,402 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:13,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:13,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:13,685 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:14,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:14,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:14,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:14,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:14,686 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:15,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:15,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:15,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:15,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:15,686 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:16,327 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:16,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:16,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:16,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:16,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:16,583 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:16,584 [IPC Server handler 0 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:16,585 [IPC Server handler 0 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:16,585 [IPC Server handler 0 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:16,585 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:16,586 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:16,589 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:16,593 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1401702154_0001_m_000002_0
2019-09-12 11:46:16,593 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:16,594 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:16,595 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000003_0
2019-09-12 11:46:16,604 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,604 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,605 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:16,608 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:620+281
2019-09-12 11:46:16,610 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,610 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:46:16,642 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:16,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,650 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,650 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1401702154_0001_m_000003_0 is done. And is in the process of committing
2019-09-12 11:46:16,651 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,651 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1401702154_0001_m_000003_0 is allowed to commit now
2019-09-12 11:46:16,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1401702154_0001_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/_logs
2019-09-12 11:46:16,653 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:46:16,654 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1401702154_0001_m_000003_0' done.
2019-09-12 11:46:16,654 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1401702154_0001_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=217212
		FILE: Number of bytes written=826448
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=18
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:16,654 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1401702154_0001_m_000003_0
2019-09-12 11:46:16,654 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000004_0
2019-09-12 11:46:16,655 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,656 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:16,657 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:1166+281
2019-09-12 11:46:16,658 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,658 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,676 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,677 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:46:16,684 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:16,687 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:16,689 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,690 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,690 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1401702154_0001_m_000004_0 is done. And is in the process of committing
2019-09-12 11:46:16,691 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,691 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1401702154_0001_m_000004_0 is allowed to commit now
2019-09-12 11:46:16,692 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1401702154_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/_logs
2019-09-12 11:46:16,693 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:46:16,693 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1401702154_0001_m_000004_0' done.
2019-09-12 11:46:16,693 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1401702154_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=221124
		FILE: Number of bytes written=826456
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=20
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:16,694 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1401702154_0001_m_000004_0
2019-09-12 11:46:16,694 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000005_0
2019-09-12 11:46:16,694 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,694 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,695 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:16,696 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:901+265
2019-09-12 11:46:16,696 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,696 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,712 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,713 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-12 11:46:16,719 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1401702154_0001_m_000005_0 is done. And is in the process of committing
2019-09-12 11:46:16,724 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,724 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1401702154_0001_m_000005_0 is allowed to commit now
2019-09-12 11:46:16,725 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1401702154_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/_logs
2019-09-12 11:46:16,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-12 11:46:16,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1401702154_0001_m_000005_0' done.
2019-09-12 11:46:16,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1401702154_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=225036
		FILE: Number of bytes written=826464
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=22
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:16,727 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1401702154_0001_m_000005_0
2019-09-12 11:46:16,727 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000006_0
2019-09-12 11:46:16,727 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,727 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:16,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:2571+265
2019-09-12 11:46:16,729 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,729 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,745 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,746 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-12 11:46:16,753 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume34480 bucket: bucket73514 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:16,756 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1401702154_0001_m_000006_0 is done. And is in the process of committing
2019-09-12 11:46:16,758 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,758 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1401702154_0001_m_000006_0 is allowed to commit now
2019-09-12 11:46:16,759 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1401702154_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/_logs
2019-09-12 11:46:16,760 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-12 11:46:16,760 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1401702154_0001_m_000006_0' done.
2019-09-12 11:46:16,761 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1401702154_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=228948
		FILE: Number of bytes written=826472
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=24
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:16,761 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1401702154_0001_m_000006_0
2019-09-12 11:46:16,761 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1401702154_0001_m_000007_0
2019-09-12 11:46:16,762 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,762 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,762 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:16,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/fileList.seq:2836+265
2019-09-12 11:46:16,764 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:16,764 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:16,780 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,781 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-12 11:46:16,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,790 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,791 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,792 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1401702154_0001_m_000007_0 is done. And is in the process of committing
2019-09-12 11:46:16,792 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:16,793 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1401702154_0001_m_000007_0 is allowed to commit now
2019-09-12 11:46:16,794 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1401702154_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550/_logs
2019-09-12 11:46:16,794 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-12 11:46:16,795 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1401702154_0001_m_000007_0' done.
2019-09-12 11:46:16,795 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1401702154_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=232348
		FILE: Number of bytes written=826480
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=26
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=155
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:16,795 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1401702154_0001_m_000007_0
2019-09-12 11:46:16,795 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:46:16,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,819 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,828 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,830 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:16,831 [Thread-369] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000288545671/.staging/_distcp95691550
2019-09-12 11:46:16,833 [Thread-369] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1401702154_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73514.volume34480/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:17,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:17,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:17,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:17,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:17,579 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1401702154_0001 failed with state FAILED due to: NA
2019-09-12 11:46:17,644 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=1333032
		FILE: Number of bytes written=4958752
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=121
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=72
	Map-Reduce Framework
		Map input records=6
		Map output records=0
		Input split bytes=930
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=12350128128
	File Input Format Counters 
		Bytes Read=18942
	File Output Format Counters 
		Bytes Written=48
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-12 11:46:17,647 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,651 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume34480, bucket=bucket73514, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,654 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume34480, bucket=bucket73514, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:46:17,656 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,658 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,660 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,661 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,663 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,664 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume34480, bucket=bucket73514, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,666 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume34480, bucket=bucket73514, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
    <system-err><![CDATA[Sep 12, 2019 11:45:56 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:45:57 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:45:57 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:45:58 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:45:58 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:46:03 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
]]></system-err>
  </testcase>
  <testcase name="testTrackDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="26.807">
    <error message="DistCp failure: Job job_local1174252886_0002 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1174252886_0002 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testTrackDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:46:17,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:17,712 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-12 11:46:17,723 [Thread-477] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:46:17,726 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin35012, owner=user76283, volume=volume54865, creationTime=1568288777725, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:46:17,728 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume54865, bucket=bucket47017, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:46:17,785 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume54865} | ret=SUCCESS |  
2019-09-12 11:46:17,786 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume54865, bucket=bucket47017} | ret=SUCCESS |  
2019-09-12 11:46:17,787 [Thread-477] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket47017.volume54865 implemented by OzoneFileSystem{URI=o3fs://bucket47017.volume54865, workingDir=o3fs://bucket47017.volume54865/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 33 read ops, 0 large read ops, 14 write ops}
2019-09-12 11:46:17,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,806 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,808 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,810 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume54865, bucket=bucket47017, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:17,811 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,813 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume54865, bucket=bucket47017, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:17,814 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:17,817 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:17,818 [Thread-477] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-12 11:46:17,944 [Thread-477] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:17,976 [Thread-477] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:17,994 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:18,095 [Thread-477] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-12 11:46:18,097 [Thread-477] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:46:18,110 [Thread-477] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:46:18,128 [Thread-477] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:46:18,129 [Thread-477] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:18,144 [Thread-477] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:46:18,224 [Thread-477] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-12 11:46:18,273 [Thread-477] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1174252886_0002
2019-09-12 11:46:18,273 [Thread-477] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:46:18,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:18,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:18,393 [Thread-477] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:46:18,393 [Thread-477] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1174252886_0002
2019-09-12 11:46:18,396 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1174252886_0002
2019-09-12 11:46:18,396 [Thread-540] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:46:18,396 [Thread-540] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:18,397 [Thread-540] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:18,397 [Thread-540] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:46:18,422 [Thread-540] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:46:18,422 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:18,424 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:18,424 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:18,424 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:18,425 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:1146+584
2019-09-12 11:46:18,426 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:18,426 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:18,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:18,451 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:18,452 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-12 11:46:18,459 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:18,460 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:18,464 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:18,464 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:18,464 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:18,464 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:18,464 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:18,465 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:18,465 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:18,465 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:18,465 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:18,465 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:18,466 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:18,466 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:18,468 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:18,475 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:18,475 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:18,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:18,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:19,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:19,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:19,397 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1174252886_0002 running in uber mode : false
2019-09-12 11:46:19,397 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-12 11:46:19,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:19,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:19,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:20,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:20,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:20,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:20,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:20,687 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:20,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:20,733 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:20,733 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:20,733 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:20,734 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:20,734 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:20,734 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:20,734 [IPC Server handler 1 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:20,735 [IPC Server handler 1 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:20,735 [IPC Server handler 1 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:20,735 [IPC Server handler 1 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:20,736 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:20,737 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:20,743 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:20,744 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:20,745 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:21,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:21,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:21,434 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:21,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:21,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:22,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:22,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:22,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:22,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:22,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:23,043 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:46:23,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:23,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:23,434 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:23,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:23,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:24,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:24,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:24,435 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:24,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:24,689 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:25,269 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:25,275 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,276 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,276 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,276 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,276 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,276 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:25,277 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:25,277 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:25,277 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:25,277 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:25,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:25,278 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:25,295 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:25,296 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000000_0
2019-09-12 11:46:25,296 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:25,297 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:25,298 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000001_0
2019-09-12 11:46:25,299 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:25,299 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:25,300 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:25,301 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:0+326
2019-09-12 11:46:25,302 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:25,302 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:25,325 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:25,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:46:25,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:25,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:25,334 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:25,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:25,340 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:25,341 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1174252886_0002_m_000001_0 is done. And is in the process of committing
2019-09-12 11:46:25,342 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:25,342 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1174252886_0002_m_000001_0 is allowed to commit now
2019-09-12 11:46:25,344 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1174252886_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/_logs
2019-09-12 11:46:25,344 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:46:25,345 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1174252886_0002_m_000001_0' done.
2019-09-12 11:46:25,345 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1174252886_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=441317
		FILE: Number of bytes written=1653237
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=44
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=21
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:25,345 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1174252886_0002_m_000001_0
2019-09-12 11:46:25,346 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:25,347 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:25,347 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:25,347 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:25,348 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:1994+292
2019-09-12 11:46:25,349 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:25,349 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:25,372 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:25,373 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-12 11:46:25,380 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:25,381 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:25,385 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,386 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,386 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,386 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,386 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:25,386 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:25,387 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:25,387 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:25,387 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:25,387 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:25,388 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:25,388 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:25,391 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:25,392 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:25,392 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:25,401 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:46:25,435 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:25,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:25,689 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:26,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:26,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:26,435 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:26,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:26,689 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:27,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:27,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:27,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:27,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:27,689 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:27,917 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:27,922 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:27,923 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:27,923 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:27,923 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:27,923 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:27,923 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:27,923 [IPC Server handler 11 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:27,924 [IPC Server handler 11 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:27,924 [IPC Server handler 11 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:27,924 [IPC Server handler 11 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:27,924 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:27,925 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:27,928 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:27,929 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:27,929 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:28,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:28,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:28,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:28,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:28,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:29,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:29,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:29,435 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:29,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:29,690 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:30,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:30,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:30,443 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-12 11:46:30,446 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:30,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:30,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:31,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:31,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:31,405 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-12 11:46:31,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:31,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:31,690 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:32,207 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:32,214 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,214 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,215 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,215 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,215 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,215 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:32,215 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:32,216 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:32,216 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:32,216 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:32,217 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:32,218 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:32,224 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:32,225 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000002_0
2019-09-12 11:46:32,225 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:32,226 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:32,227 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000003_0
2019-09-12 11:46:32,229 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:32,230 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:32,230 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:32,231 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:866+280
2019-09-12 11:46:32,232 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:32,232 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:32,257 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:32,258 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:46:32,268 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:32,272 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:32,273 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:32,274 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1174252886_0002_m_000003_0 is done. And is in the process of committing
2019-09-12 11:46:32,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:32,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1174252886_0002_m_000003_0 is allowed to commit now
2019-09-12 11:46:32,277 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1174252886_0002_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/_logs
2019-09-12 11:46:32,277 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:46:32,278 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1174252886_0002_m_000003_0' done.
2019-09-12 11:46:32,278 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1174252886_0002_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=450811
		FILE: Number of bytes written=1653253
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=51
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=27
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:32,278 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1174252886_0002_m_000003_0
2019-09-12 11:46:32,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000004_0
2019-09-12 11:46:32,280 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:32,280 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:32,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:32,281 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:2286+280
2019-09-12 11:46:32,282 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:32,282 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:32,305 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:32,306 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:46:32,315 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:32,319 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:32,321 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:32,321 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1174252886_0002_m_000004_0 is done. And is in the process of committing
2019-09-12 11:46:32,322 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:32,322 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1174252886_0002_m_000004_0 is allowed to commit now
2019-09-12 11:46:32,324 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1174252886_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/_logs
2019-09-12 11:46:32,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:46:32,325 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1174252886_0002_m_000004_0' done.
2019-09-12 11:46:32,325 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1174252886_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=455046
		FILE: Number of bytes written=1653261
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=53
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=27
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:32,325 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1174252886_0002_m_000004_0
2019-09-12 11:46:32,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:32,326 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:32,327 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:32,327 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:32,329 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:590+276
2019-09-12 11:46:32,329 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:32,329 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:32,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:32,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:32,352 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:32,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-09-12 11:46:32,367 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:32,368 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:32,372 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,373 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,373 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,373 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,373 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:32,373 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:32,374 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:32,374 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:32,374 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:32,374 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:32,375 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:32,376 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:32,378 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:32,379 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:32,380 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:32,405 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:46:32,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:32,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:32,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:33,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:33,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:33,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:33,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:33,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:34,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:34,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:34,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:34,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:34,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:35,247 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:35,253 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:35,253 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:35,254 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:35,254 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:35,254 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:35,254 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:35,254 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:35,254 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:35,255 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:35,255 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:35,255 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:35,256 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:35,259 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:35,259 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:35,259 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:35,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:35,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:35,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:35,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:35,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:36,330 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:36,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:36,437 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:36,446 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-12 11:46:36,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:36,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:37,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:37,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:37,366 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-12 11:46:37,408 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-12 11:46:37,437 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:37,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:37,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:38,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:38,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:38,437 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:38,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:38,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:39,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:39,051 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,052 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,052 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,052 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,053 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,053 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:39,053 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:39,053 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:39,054 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:39,054 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:39,054 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:39,056 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:39,064 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:39,065 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000005_0
2019-09-12 11:46:39,065 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:39,066 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:39,067 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000006_0
2019-09-12 11:46:39,069 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,069 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,070 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:39,072 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:326+264
2019-09-12 11:46:39,072 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,073 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,096 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,097 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:46:39,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,109 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,110 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:39,111 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1174252886_0002_m_000006_0 is done. And is in the process of committing
2019-09-12 11:46:39,111 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:39,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1174252886_0002_m_000006_0 is allowed to commit now
2019-09-12 11:46:39,116 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1174252886_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/_logs
2019-09-12 11:46:39,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:46:39,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1174252886_0002_m_000006_0' done.
2019-09-12 11:46:39,118 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1174252886_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=463516
		FILE: Number of bytes written=1653277
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=60
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:39,118 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1174252886_0002_m_000006_0
2019-09-12 11:46:39,118 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000007_0
2019-09-12 11:46:39,120 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,120 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,120 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:39,122 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:1730+264
2019-09-12 11:46:39,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,146 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,149 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:46:39,159 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,163 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:39,164 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1174252886_0002_m_000007_0 is done. And is in the process of committing
2019-09-12 11:46:39,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:39,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1174252886_0002_m_000007_0 is allowed to commit now
2019-09-12 11:46:39,166 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1174252886_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/_logs
2019-09-12 11:46:39,167 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:46:39,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1174252886_0002_m_000007_0' done.
2019-09-12 11:46:39,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1174252886_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=467239
		FILE: Number of bytes written=1653285
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=62
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:39,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1174252886_0002_m_000007_0
2019-09-12 11:46:39,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000008_0
2019-09-12 11:46:39,169 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,169 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,170 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:39,171 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:2826+264
2019-09-12 11:46:39,172 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,172 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,195 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:46:39,203 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:39,207 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,207 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:39,208 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1174252886_0002_m_000008_0 is done. And is in the process of committing
2019-09-12 11:46:39,208 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:46:39,208 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1174252886_0002_m_000008_0 is allowed to commit now
2019-09-12 11:46:39,209 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1174252886_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/_logs
2019-09-12 11:46:39,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:46:39,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1174252886_0002_m_000008_0' done.
2019-09-12 11:46:39,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1174252886_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=470962
		FILE: Number of bytes written=1653293
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=64
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:46:39,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1174252886_0002_m_000008_0
2019-09-12 11:46:39,211 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:39,211 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,211 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,212 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:39,212 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876/fileList.seq:2566+260
2019-09-12 11:46:39,213 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:39,213 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:39,229 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:39,230 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-12 11:46:39,237 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:39,238 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:39,242 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,242 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,243 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,243 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,243 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:39,243 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:39,243 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:39,243 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:39,244 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:39,244 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:39,244 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:39,245 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:39,247 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:39,248 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:39,248 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:39,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:39,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:39,410 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:46:39,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:39,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:39,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:40,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:40,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:40,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:40,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:40,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:41,201 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:41,207 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:41,207 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:41,207 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:41,208 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:41,208 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:41,208 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:41,208 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:41,208 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:41,209 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:41,209 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:41,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:41,211 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:41,227 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:41,228 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:41,228 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:41,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:41,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:41,437 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:41,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:41,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:42,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:42,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:42,437 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:42,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:42,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:43,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:43,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:43,367 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-12 11:46:43,412 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 75% reduce 0%
2019-09-12 11:46:43,438 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:43,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:43,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:43,983 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:43,990 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:43,990 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:43,991 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:43,991 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:43,991 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:43,992 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:43,992 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:43,992 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:43,993 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:43,993 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:43,993 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:43,994 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:43,997 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume54865 bucket: bucket47017 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:43,998 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1174252886_0002_m_000009_0
2019-09-12 11:46:43,999 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:43,999 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:44,001 [Thread-540] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:46:44,010 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,012 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,016 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,018 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,019 [Thread-540] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000714154342/.staging/_distcp2146119876
2019-09-12 11:46:44,021 [Thread-540] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1174252886_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket47017.volume54865/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:44,340 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-12 11:46:44,341 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:44,341 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:44,413 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 85% reduce 0%
2019-09-12 11:46:44,414 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1174252886_0002 failed with state FAILED due to: NA
2019-09-12 11:46:44,457 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:44,459 [Thread-477] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=4157542
		FILE: Number of bytes written=14879477
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=532
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=281
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Input split bytes=1413
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=18525192192
	File Input Format Counters 
		Bytes Read=28314
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-12 11:46:44,464 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,466 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,468 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume54865, bucket=bucket47017, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,471 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume54865, bucket=bucket47017, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:46:44,474 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,476 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,478 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,480 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,481 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,483 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume54865, bucket=bucket47017, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,484 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume54865, bucket=bucket47017, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="largeFilesToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="11.836">
    <error message="DistCp failure: Job job_local564417730_0003 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local564417730_0003 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:534)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFilesToRemote(AbstractContractDistCpTest.java:452)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:46:44,516 [Thread-588] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:46:44,519 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin63742, owner=user97118, volume=volume06750, creationTime=1568288804519, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:46:44,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume06750, bucket=bucket13221, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:46:44,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:44,582 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume06750} | ret=SUCCESS |  
2019-09-12 11:46:44,584 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume06750, bucket=bucket13221} | ret=SUCCESS |  
2019-09-12 11:46:44,585 [Thread-588] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket13221.volume06750 implemented by OzoneFileSystem{URI=o3fs://bucket13221.volume06750, workingDir=o3fs://bucket13221.volume06750/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 76 read ops, 0 large read ops, 40 write ops}
2019-09-12 11:46:44,586 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume06750, bucket=bucket13221, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,600 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,605 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume06750, bucket=bucket13221, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:44,607 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,609 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume06750, bucket=bucket13221, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:44,610 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:44,613 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:44,613 [Thread-588] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-12 11:46:44,623 [Thread-588] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-12 11:46:44,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:44,792 [Thread-588] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:44,811 [Thread-588] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:44,826 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:44,874 [Thread-588] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-12 11:46:44,875 [Thread-588] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:46:44,887 [Thread-588] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-12 11:46:44,903 [Thread-588] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-12 11:46:44,904 [Thread-588] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:44,916 [Thread-588] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:46:44,982 [Thread-588] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-12 11:46:45,036 [Thread-588] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local564417730_0003
2019-09-12 11:46:45,036 [Thread-588] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:46:45,301 [Thread-588] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:46:45,304 [Thread-588] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local564417730_0003
2019-09-12 11:46:45,304 [Thread-635] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:46:45,304 [Thread-588] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local564417730_0003
2019-09-12 11:46:45,304 [Thread-635] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:45,304 [Thread-635] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:45,305 [Thread-635] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:46:45,326 [Thread-635] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:46:45,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:45,327 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:45,327 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:45,328 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:45,330 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001902674564/.staging/_distcp-1196960257/fileList.seq:0+780
2019-09-12 11:46:45,332 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:45,333 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:45,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:45,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:45,362 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:45,363 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
2019-09-12 11:46:45,372 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:45,375 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:45,376 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
2019-09-12 11:46:45,385 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:45,386 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:45,392 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:45,393 [IPC Server handler 7 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:45,394 [IPC Server handler 7 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:45,394 [IPC Server handler 7 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:45,394 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:45,395 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:45,397 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:45,398 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:45,399 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:45,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:45,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:45,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:46,305 [Thread-588] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local564417730_0003 running in uber mode : false
2019-09-12 11:46:46,305 [Thread-588] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-12 11:46:46,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:46,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:46,440 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:46,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:46,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:47,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:47,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:47,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:47,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:47,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:47,951 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:47,955 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:47,955 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:47,956 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:47,956 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:47,956 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:47,956 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:47,957 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:47,957 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:47,957 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:47,957 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:47,958 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:47,958 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:47,960 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:47,961 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:47,961 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:48,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:48,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:48,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:48,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:48,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:49,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:49,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:49,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:49,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:49,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:50,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:50,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:50,341 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-12 11:46:50,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:50,549 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:50,555 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,555 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,555 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,556 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,556 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,556 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:50,556 [IPC Server handler 8 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:50,556 [IPC Server handler 8 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:50,557 [IPC Server handler 8 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:50,557 [IPC Server handler 8 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:50,557 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:50,558 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:50,561 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:50,562 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000000_0
2019-09-12 11:46:50,563 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:50,563 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:50,564 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:50,565 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:50,565 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:50,565 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:50,566 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001902674564/.staging/_distcp-1196960257/fileList.seq:780+238
2019-09-12 11:46:50,567 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:50,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:50,567 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:50,589 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:50,590 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
2019-09-12 11:46:50,597 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:50,597 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:50,601 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,601 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,601 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,601 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,602 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:50,602 [IPC Server handler 1 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:50,602 [IPC Server handler 1 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:50,602 [IPC Server handler 1 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:50,603 [IPC Server handler 1 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:50,603 [IPC Server handler 1 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:50,603 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:50,604 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:50,605 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:50,606 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:50,606 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:50,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:51,258 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-12 11:46:51,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:51,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:51,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:51,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:51,651 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:51,655 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:51,656 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:51,656 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:51,656 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:51,656 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:51,657 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:51,657 [IPC Server handler 11 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:51,657 [IPC Server handler 11 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:51,658 [IPC Server handler 11 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:51,658 [IPC Server handler 11 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:51,658 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:51,659 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:51,661 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:51,662 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:51,662 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:51,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:52,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:52,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:52,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:52,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:52,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:53,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:53,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:53,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:53,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:53,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:54,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:54,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:54,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:54,569 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:54,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:55,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:55,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:55,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:55,570 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:55,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:56,267 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:56,273 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,273 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,273 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,273 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,273 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,274 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:56,274 [IPC Server handler 7 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:56,274 [IPC Server handler 7 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:56,274 [IPC Server handler 7 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:56,274 [IPC Server handler 7 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:56,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:56,275 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:56,277 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket13221 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:56,277 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local564417730_0003_m_000001_0
2019-09-12 11:46:56,278 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:56,278 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:56,279 [Thread-635] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:46:56,283 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,287 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,288 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,289 [Thread-635] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001902674564/.staging/_distcp-1196960257
2019-09-12 11:46:56,292 [Thread-635] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local564417730_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket13221.volume06750/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:46:56,310 [Thread-588] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local564417730_0003 failed with state FAILED due to: NA
2019-09-12 11:46:56,311 [Thread-588] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 0
2019-09-12 11:46:56,312 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,313 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,314 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket13221, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,316 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume06750, bucket=bucket13221, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:46:56,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume06750, bucket=bucket13221, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,318 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,320 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume06750, bucket=bucket13221, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,320 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume06750, bucket=bucket13221, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testLargeFilesFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.126">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:528)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testLargeFilesFromRemote(AbstractContractDistCpTest.java:464)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:46:56,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:56,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:56,343 [Thread-653] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:46:56,345 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin15302, owner=user90022, volume=volume61710, creationTime=1568288816345, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:46:56,346 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume61710, bucket=bucket05667, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:46:56,396 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume61710} | ret=SUCCESS |  
2019-09-12 11:46:56,398 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume61710, bucket=bucket05667} | ret=SUCCESS |  
2019-09-12 11:46:56,398 [Thread-653] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket05667.volume61710 implemented by OzoneFileSystem{URI=o3fs://bucket05667.volume61710, workingDir=o3fs://bucket05667.volume61710/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 98 read ops, 0 large read ops, 54 write ops}
2019-09-12 11:46:56,400 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume61710, bucket=bucket05667, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,414 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,415 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,416 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume61710, bucket=bucket05667, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:56,418 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,419 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume61710, bucket=bucket05667, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:56,420 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume61710 bucket: bucket05667 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:56,422 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,423 [Thread-653] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-12 11:46:56,424 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,425 [Thread-653] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-12 11:46:56,435 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,435 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,435 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:56,436 [IPC Server handler 8 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:56,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:56,437 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:56,438 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume61710, bucket=bucket05667, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,440 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume61710, bucket=bucket05667, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:56,442 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume61710, bucket=bucket05667, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,443 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume61710, bucket=bucket05667, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:46:56,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume61710, bucket=bucket05667, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,446 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,447 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume61710, bucket=bucket05667, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,448 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume61710, bucket=bucket05667, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testUpdateDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="16.62">
    <error message="DistCp failure: Job job_local78706719_0004 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local78706719_0004 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:46:56,476 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin62935, owner=user87105, volume=volume05020, creationTime=1568288816475, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:46:56,477 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume05020, bucket=bucket73271, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:46:56,528 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume05020} | ret=SUCCESS |  
2019-09-12 11:46:56,529 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume05020, bucket=bucket73271} | ret=SUCCESS |  
2019-09-12 11:46:56,530 [Thread-657] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket73271.volume05020 implemented by OzoneFileSystem{URI=o3fs://bucket73271.volume05020, workingDir=o3fs://bucket73271.volume05020/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 104 read ops, 0 large read ops, 57 write ops}
2019-09-12 11:46:56,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,543 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,545 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,546 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume05020, bucket=bucket73271, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:56,548 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,549 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume05020, bucket=bucket73271, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:46:56,550 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:56,552 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:46:56,553 [Thread-657] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-12 11:46:56,569 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:56,650 [Thread-657] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:56,661 [Thread-657] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:56,672 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:56,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:56,742 [Thread-657] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-12 11:46:56,742 [Thread-657] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:46:56,752 [Thread-657] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:46:56,762 [Thread-657] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:46:56,763 [Thread-657] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:46:56,773 [Thread-657] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:46:56,833 [Thread-657] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-12 11:46:56,870 [Thread-657] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local78706719_0004
2019-09-12 11:46:56,870 [Thread-657] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:46:56,964 [Thread-657] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:46:56,967 [Thread-657] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local78706719_0004
2019-09-12 11:46:56,967 [Thread-719] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:46:56,967 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local78706719_0004
2019-09-12 11:46:56,967 [Thread-719] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:56,967 [Thread-719] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:56,968 [Thread-719] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:46:56,992 [Thread-719] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:46:56,992 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000000_0
2019-09-12 11:46:56,993 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:56,993 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:56,993 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:46:56,994 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:2234+586
2019-09-12 11:46:56,995 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:46:56,995 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:46:57,020 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:57,021 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-12 11:46:57,028 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:57,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
2019-09-12 11:46:57,032 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:57,033 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:57,034 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:57,034 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:57,034 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:57,034 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:57,036 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:57,041 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
2019-09-12 11:46:57,042 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:57,345 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-12 11:46:57,348 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:57,348 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:57,460 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:57,569 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:57,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:57,967 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local78706719_0004 running in uber mode : false
2019-09-12 11:46:57,968 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-12 11:46:58,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:58,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:58,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:58,570 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:58,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:59,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:59,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:59,383 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
2019-09-12 11:46:59,388 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:59,389 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:59,389 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:59,389 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:59,389 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:46:59,390 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:59,390 [IPC Server handler 8 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:46:59,390 [IPC Server handler 8 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:46:59,390 [IPC Server handler 8 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:46:59,390 [IPC Server handler 8 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:46:59,391 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:46:59,391 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:46:59,393 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:46:59,394 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
2019-09-12 11:46:59,394 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:46:59,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:59,571 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:46:59,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:00,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:00,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:00,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:00,570 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:00,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:01,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:01,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:01,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:01,570 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:01,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:02,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:02,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:02,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:02,578 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-12 11:47:02,579 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:02,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:03,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:03,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:03,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:03,571 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:03,625 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
2019-09-12 11:47:03,630 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,631 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,631 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,631 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,631 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,631 [IPC Server handler 11 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:03,632 [IPC Server handler 11 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:03,632 [IPC Server handler 11 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:03,632 [IPC Server handler 11 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:03,632 [IPC Server handler 11 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:03,633 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:03,633 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:03,635 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:03,636 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000000_0
2019-09-12 11:47:03,636 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:03,637 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:47:03,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:03,646 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:03,646 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:03,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:03,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:1431+538
2019-09-12 11:47:03,648 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:03,648 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:03,670 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:03,670 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-12 11:47:03,678 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:03,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:03,682 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,682 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,683 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,683 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,683 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:03,683 [IPC Server handler 18 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:03,683 [IPC Server handler 18 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:03,683 [IPC Server handler 18 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:03,684 [IPC Server handler 18 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:03,684 [IPC Server handler 18 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:03,684 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:03,685 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:03,687 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:03,687 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:03,687 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:03,695 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:04,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:04,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:04,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:04,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:04,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:05,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:05,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:05,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:05,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:05,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:05,935 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:05,942 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:05,942 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:05,942 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:05,942 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:05,943 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:05,943 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:05,943 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:05,943 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:05,944 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:05,944 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:05,944 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:05,945 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:05,947 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:05,948 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:05,948 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:06,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:06,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:06,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:06,571 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:06,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:07,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:07,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:07,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:07,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:07,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:08,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:08,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:08,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:08,573 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:08,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:08,877 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:08,881 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,881 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,881 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,881 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,881 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,881 [IPC Server handler 14 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:08,882 [IPC Server handler 14 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:08,882 [IPC Server handler 14 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:08,882 [IPC Server handler 14 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:08,882 [IPC Server handler 14 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:08,882 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:08,883 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:08,886 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:08,886 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000001_0
2019-09-12 11:47:08,886 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:08,887 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:47:08,887 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000002_0
2019-09-12 11:47:08,888 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:08,889 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:08,889 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:08,890 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:0+327
2019-09-12 11:47:08,891 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:08,891 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:08,918 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:08,919 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:47:08,926 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:08,929 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:08,930 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:08,930 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local78706719_0004_m_000002_0 is done. And is in the process of committing
2019-09-12 11:47:08,931 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:08,931 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local78706719_0004_m_000002_0 is allowed to commit now
2019-09-12 11:47:08,932 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local78706719_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/_logs
2019-09-12 11:47:08,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:47:08,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local78706719_0004_m_000002_0' done.
2019-09-12 11:47:08,934 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local78706719_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=880020
		FILE: Number of bytes written=12799580
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=120
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2005925888
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:47:08,934 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local78706719_0004_m_000002_0
2019-09-12 11:47:08,934 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:08,935 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:08,935 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:08,935 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:08,936 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:873+293
2019-09-12 11:47:08,936 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:08,937 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:08,953 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:08,953 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-12 11:47:08,959 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:08,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:08,962 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,962 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,963 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,963 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,963 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:08,963 [IPC Server handler 7 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:08,963 [IPC Server handler 7 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:08,964 [IPC Server handler 7 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:08,964 [IPC Server handler 7 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:08,964 [IPC Server handler 7 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:08,964 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:08,965 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:08,967 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:08,967 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:08,967 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:08,973 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:47:09,014 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:47:09,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:09,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:09,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:09,573 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:09,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:09,974 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 17% reduce 0%
2019-09-12 11:47:10,033 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:10,037 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:10,037 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:10,037 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:10,037 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:10,038 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:10,038 [IPC Server handler 8 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:10,038 [IPC Server handler 8 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:10,039 [IPC Server handler 8 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:10,039 [IPC Server handler 8 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:10,039 [IPC Server handler 8 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:10,039 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:10,040 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:10,042 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:10,043 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:10,043 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:10,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:10,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:10,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:10,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:10,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:11,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:11,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:11,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:11,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:11,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:12,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=17737a86-5417-40d5-bd10-6caac07f8585, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:12,341 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=261c0364-c1a8-4b3d-89b8-311b79ab6415, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:12,388 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:12,393 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:12,393 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:12,393 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:12,393 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:12,394 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:12,394 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:12,394 [IPC Server handler 15 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:12,394 [IPC Server handler 15 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:12,394 [IPC Server handler 15 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:12,395 [IPC Server handler 15 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:12,395 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:12,396 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:12,398 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:12,398 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local78706719_0004_m_000003_0
2019-09-12 11:47:12,399 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:47:12,399 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:47:12,400 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000004_0
2019-09-12 11:47:12,401 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,401 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,401 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:12,402 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:592+281
2019-09-12 11:47:12,403 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,403 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,420 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,421 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:47:12,430 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:12,433 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,434 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,434 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local78706719_0004_m_000004_0 is done. And is in the process of committing
2019-09-12 11:47:12,435 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,435 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local78706719_0004_m_000004_0 is allowed to commit now
2019-09-12 11:47:12,437 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local78706719_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/_logs
2019-09-12 11:47:12,437 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:47:12,437 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local78706719_0004_m_000004_0' done.
2019-09-12 11:47:12,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local78706719_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=888684
		FILE: Number of bytes written=12799596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=127
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2005925888
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:47:12,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local78706719_0004_m_000004_0
2019-09-12 11:47:12,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000005_0
2019-09-12 11:47:12,439 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,439 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,440 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:12,441 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:2820+281
2019-09-12 11:47:12,441 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,441 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=b702d902-25f1-483f-8834-460c179f9559, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:12,458 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,459 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:47:12,465 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:12,468 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,468 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,469 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local78706719_0004_m_000005_0 is done. And is in the process of committing
2019-09-12 11:47:12,469 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,470 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local78706719_0004_m_000005_0 is allowed to commit now
2019-09-12 11:47:12,471 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local78706719_0004_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/_logs
2019-09-12 11:47:12,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:47:12,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local78706719_0004_m_000005_0' done.
2019-09-12 11:47:12,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local78706719_0004_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=892760
		FILE: Number of bytes written=12799604
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=129
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2005925888
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:47:12,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local78706719_0004_m_000005_0
2019-09-12 11:47:12,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000006_0
2019-09-12 11:47:12,473 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,473 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,474 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:12,474 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:327+265
2019-09-12 11:47:12,475 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,475 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,493 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:47:12,502 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,504 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,504 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local78706719_0004_m_000006_0 is done. And is in the process of committing
2019-09-12 11:47:12,505 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,505 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local78706719_0004_m_000006_0 is allowed to commit now
2019-09-12 11:47:12,506 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local78706719_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/_logs
2019-09-12 11:47:12,506 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:47:12,506 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local78706719_0004_m_000006_0' done.
2019-09-12 11:47:12,507 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local78706719_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=896836
		FILE: Number of bytes written=12799612
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=131
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2005925888
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:47:12,507 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local78706719_0004_m_000006_0
2019-09-12 11:47:12,507 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000007_0
2019-09-12 11:47:12,508 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,508 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,508 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:12,509 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:1166+265
2019-09-12 11:47:12,509 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,509 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,525 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:47:12,532 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,534 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local78706719_0004_m_000007_0 is done. And is in the process of committing
2019-09-12 11:47:12,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local78706719_0004_m_000007_0 is allowed to commit now
2019-09-12 11:47:12,536 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local78706719_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/_logs
2019-09-12 11:47:12,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:47:12,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local78706719_0004_m_000007_0' done.
2019-09-12 11:47:12,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local78706719_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=900400
		FILE: Number of bytes written=12799620
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=133
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2005925888
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:47:12,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local78706719_0004_m_000007_0
2019-09-12 11:47:12,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local78706719_0004_m_000008_0
2019-09-12 11:47:12,538 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,538 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,538 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:47:12,539 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/fileList.seq:1969+265
2019-09-12 11:47:12,539 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:47:12,539 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:47:12,557 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,558 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:47:12,566 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume05020 bucket: bucket73271 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:12,568 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,569 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,570 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local78706719_0004_m_000008_0 is done. And is in the process of committing
2019-09-12 11:47:12,570 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:47:12,571 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local78706719_0004_m_000008_0 is allowed to commit now
2019-09-12 11:47:12,572 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local78706719_0004_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676/_logs
2019-09-12 11:47:12,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6ddfd42a-9a66-4e8f-a2a3-a92fd134b7c7, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:12,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:47:12,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local78706719_0004_m_000008_0' done.
2019-09-12 11:47:12,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local78706719_0004_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=903964
		FILE: Number of bytes written=12799628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=135
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=156
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2005925888
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:47:12,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local78706719_0004_m_000008_0
2019-09-12 11:47:12,573 [Thread-719] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:47:12,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,578 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,580 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,582 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:12,582 [Thread-719] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000312303270/.staging/_distcp442611676
2019-09-12 11:47:12,584 [Thread-719] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local78706719_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket73271.volume05020/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:47:12,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=SEND_HEARTBEAT {datanodeUUID=6462bdcf-7de1-4e9a-9a3d-ebe3c9246363, command=[]} | ret=SUCCESS |  
2019-09-12 11:47:12,976 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:47:12,976 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local78706719_0004 failed with state FAILED due to: NA
2019-09-12 11:47:13,052 [Thread-657] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=6247272
		FILE: Number of bytes written=89597228
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=898
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=522
	Map-Reduce Framework
		Map input records=7
		Map output records=0
		Input split bytes=1092
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=14041481216
	File Input Format Counters 
		Bytes Read=22099
	File Output Format Counters 
		Bytes Written=56
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-12 11:47:13,055 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,057 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,058 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume05020, bucket=bucket73271, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,059 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume05020, bucket=bucket73271, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:47:13,061 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,062 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,063 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,064 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,065 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,066 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume05020, bucket=bucket73271, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,066 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume05020, bucket=bucket73271, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testDeepDirectoryStructureFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.111">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:488)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testDeepDirectoryStructureFromRemote(AbstractContractDistCpTest.java:458)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:47:13,086 [Thread-768] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:47:13,088 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin20372, owner=user27556, volume=volume09839, creationTime=1568288833088, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:47:13,090 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume09839, bucket=bucket25154, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:47:13,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume09839} | ret=SUCCESS |  
2019-09-12 11:47:13,136 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume09839, bucket=bucket25154} | ret=SUCCESS |  
2019-09-12 11:47:13,137 [Thread-768] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket25154.volume09839 implemented by OzoneFileSystem{URI=o3fs://bucket25154.volume09839, workingDir=o3fs://bucket25154.volume09839/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 142 read ops, 0 large read ops, 77 write ops}
2019-09-12 11:47:13,138 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume09839, bucket=bucket25154, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,150 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,151 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,153 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,156 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume09839, bucket=bucket25154, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:47:13,157 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,158 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume09839, bucket=bucket25154, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:47:13,159 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume09839 bucket: bucket25154 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:47:13,161 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,161 [Thread-768] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-12 11:47:13,163 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,165 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:13,168 [IPC Server handler 15 on 42152] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:47:13,169 [IPC Server handler 15 on 42152] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:47:13,169 [IPC Server handler 15 on 42152] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:47:13,169 [IPC Server handler 15 on 42152] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:47:13,169 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.195 | op=ALLOCATE_BLOCK {owner=6fb9eb3f-512c-461e-9b37-636f90f75aa6, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:47:13,169 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:47:13,171 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume09839, bucket=bucket25154, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,171 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume09839, bucket=bucket25154, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,172 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume09839, bucket=bucket25154, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,173 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume09839, bucket=bucket25154, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:47:13,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume09839, bucket=bucket25154, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,176 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,177 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,178 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume09839, bucket=bucket25154, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:47:13,179 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume09839, bucket=bucket25154, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
</testsuite>
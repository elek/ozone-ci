<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="99.523" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.24.v20180605/jetty-server-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.24.v20180605/jetty-http-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.24.v20180605/jetty-io-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.24.v20180605/jetty-webapp-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.24.v20180605/jetty-xml-9.3.24.v20180605.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.5/jackson-databind-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.5/jackson-annotations-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.5/jackson-core-2.9.5.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.24.v20180605/jetty-util-ajax-9.3.24.v20180605.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0-2337318-SNAPSHOT/ratis-server-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0-2337318-SNAPSHOT/ratis-proto-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0-2337318-SNAPSHOT/ratis-common-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0-2337318-SNAPSHOT/ratis-client-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0-2337318-SNAPSHOT/ratis-metrics-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0-2337318-SNAPSHOT/ratis-netty-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0-2337318-SNAPSHOT/ratis-grpc-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.33.1/jaeger-client-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.33.1/jaeger-thrift-0.33.1.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.11.0/libthrift-0.11.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.33.1/jaeger-core-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.33.1/jaeger-tracerresolver-0.33.1.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-objectstore-service/0.5.0-SNAPSHOT/hadoop-ozone-objectstore-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7827568948903961583.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-09-19T11-05-02_939-jvmRun1 surefire3342326458283873291tmp surefire_1095696536184436983025tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.24.v20180605/jetty-server-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.24.v20180605/jetty-http-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.24.v20180605/jetty-io-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.24.v20180605/jetty-webapp-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.24.v20180605/jetty-xml-9.3.24.v20180605.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.5/jackson-databind-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.5/jackson-annotations-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.5/jackson-core-2.9.5.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.24.v20180605/jetty-util-ajax-9.3.24.v20180605.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0-2337318-SNAPSHOT/ratis-server-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0-2337318-SNAPSHOT/ratis-proto-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0-2337318-SNAPSHOT/ratis-common-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0-2337318-SNAPSHOT/ratis-client-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0-2337318-SNAPSHOT/ratis-metrics-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0-2337318-SNAPSHOT/ratis-netty-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0-2337318-SNAPSHOT/ratis-grpc-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.33.1/jaeger-client-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.33.1/jaeger-thrift-0.33.1.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.11.0/libthrift-0.11.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.33.1/jaeger-core-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.33.1/jaeger-tracerresolver-0.33.1.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-objectstore-service/0.5.0-SNAPSHOT/hadoop-ozone-objectstore-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7827568948903961583.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpdateDeepDirectoryStructureNoChange" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="23.349">
    <error message="DistCp failure: Job job_local81299712_0001 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local81299712_0001 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureNoChange(AbstractContractDistCpTest.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-19 16:50:29,949 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:30,048 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:30,052 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:30,068 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @859ms
2019-09-19 16:50:30,169 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-19 16:50:30,169 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-19 16:50:30,169 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-19 16:50:30,170 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-19 16:50:30,170 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-19 16:50:30,170 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-19 16:50:30,180 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 16:50:30,180 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 16:50:30,181 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 16:50:30,410 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6b81ce95
2019-09-19 16:50:30,413 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-19 16:50:30,494 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 16:50:30,496 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 16:50:30,498 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-19 16:50:30,636 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-19 16:50:30,653 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:30,750 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-19 16:50:30,753 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:30,929 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-19 16:50:31,753 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 16:50:31,791 [Socket Reader #1 for port 41576] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41576
2019-09-19 16:50:31,820 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 16:50:31,821 [Socket Reader #1 for port 45504] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45504
2019-09-19 16:50:31,829 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 16:50:31,830 [Socket Reader #1 for port 42851] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42851
2019-09-19 16:50:31,852 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-19 16:50:32,014 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:32,029 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:32,039 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:32,042 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-19 16:50:32,042 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:32,042 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:32,067 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42851
2019-09-19 16:50:32,118 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-19 16:50:32,131 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-19 16:50:32,132 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-19 16:50:32,380 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:42851
2019-09-19 16:50:32,381 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 16:50:32,381 [IPC Server listener on 42851] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42851: starting
2019-09-19 16:50:32,384 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45504
2019-09-19 16:50:32,384 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:45504
2019-09-19 16:50:32,385 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 16:50:32,385 [IPC Server listener on 45504] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45504: starting
2019-09-19 16:50:32,388 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41576
2019-09-19 16:50:32,388 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:41576
2019-09-19 16:50:32,388 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 16:50:32,389 [IPC Server listener on 41576] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41576: starting
2019-09-19 16:50:32,393 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46507
2019-09-19 16:50:32,394 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:32,430 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65b3a85a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:32,430 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53d1b9b3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:32,499 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@733037{/,file:///tmp/jetty-0.0.0.0-46507-scm-_-any-5263375911182207553.dir/webapp/,AVAILABLE}{/scm}
2019-09-19 16:50:32,504 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50b8ae8d{HTTP/1.1,[http/1.1]}{0.0.0.0:46507}
2019-09-19 16:50:32,504 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3295ms
2019-09-19 16:50:32,506 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:46507
2019-09-19 16:50:32,514 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7577b641] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 16:50:32,520 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:32,646 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:32,647 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:32,648 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-19 16:50:32,648 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3
2019-09-19 16:50:32,649 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-19 16:50:32,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 16:50:33,451 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 16:50:33,461 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-19 16:50:33,461 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-19 16:50:33,461 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-19 16:50:33,462 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-19 16:50:33,462 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-19 16:50:33,462 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-19 16:50:33,462 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-19 16:50:33,463 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-19 16:50:33,463 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-19 16:50:33,463 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-19 16:50:33,463 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-19 16:50:33,463 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-19 16:50:33,464 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-19 16:50:33,464 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-19 16:50:33,464 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-19 16:50:33,464 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-19 16:50:33,465 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-19 16:50:33,465 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-19 16:50:33,465 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-19 16:50:33,465 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-19 16:50:33,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-19 16:50:33,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-19 16:50:33,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 16:50:33,466 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 16:50:33,467 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 16:50:34,063 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 16:50:34,066 [Socket Reader #1 for port 40516] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40516
2019-09-19 16:50:34,118 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40516
2019-09-19 16:50:34,118 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-19 16:50:34,120 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 16:50:34,122 [IPC Server listener on 40516] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40516: starting
2019-09-19 16:50:34,129 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-19 16:50:34,134 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:34,135 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:34,139 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:34,141 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-19 16:50:34,142 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:34,142 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:34,146 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38972
2019-09-19 16:50:34,147 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:34,151 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@749ab7b4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:34,152 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bf94401{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:34,216 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54562ea6{/,file:///tmp/jetty-0.0.0.0-38972-ozoneManager-_-any-4606980472034727277.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-19 16:50:34,218 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a35993f{HTTP/1.1,[http/1.1]}{0.0.0.0:38972}
2019-09-19 16:50:34,219 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5009ms
2019-09-19 16:50:34,220 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:38972
2019-09-19 16:50:34,414 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 16:50:34,522 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-swxfz-3172132826 ip:192.168.157.226
2019-09-19 16:50:34,560 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 16:50:34,562 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/containers/hdds to VolumeSet
2019-09-19 16:50:34,565 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-19 16:50:34,591 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-19 16:50:34,747 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 16:50:34,831 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 16:50:34,839 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 16:50:34,841 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 16:50:34,843 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:34,844 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 16:50:34,846 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 16:50:35,065 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:35,135 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 16:50:35,158 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 16:50:35,162 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:35,162 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:35,166 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:35,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 16:50:35,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:35,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:35,169 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43545
2019-09-19 16:50:35,169 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:35,172 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb66650{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:35,173 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a869a16{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:35,211 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6d5c2745{/,file:///tmp/jetty-0.0.0.0-43545-hddsDatanode-_-any-6261271967004248966.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 16:50:35,211 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44b29496{HTTP/1.1,[http/1.1]}{0.0.0.0:43545}
2019-09-19 16:50:35,212 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6003ms
2019-09-19 16:50:35,215 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43545
2019-09-19 16:50:36,326 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:38706 |  
2019-09-19 16:50:36,327 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@2eda2062
2019-09-19 16:50:36,329 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 16:50:36,332 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-swxfz-3172132826 ip:192.168.157.226
2019-09-19 16:50:36,336 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ca0025c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 16:50:36,342 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 16:50:36,342 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/containers/hdds to VolumeSet
2019-09-19 16:50:36,342 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@126f8f24
2019-09-19 16:50:36,343 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@126f8f24
2019-09-19 16:50:36,367 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 16:50:36,367 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 16:50:36,367 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 16:50:36,368 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 16:50:36,368 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:36,368 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 16:50:36,368 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 16:50:36,369 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:36,369 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 16:50:36,371 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 16:50:36,374 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:36,375 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:36,379 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:36,380 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 16:50:36,380 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:36,380 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:36,381 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39981
2019-09-19 16:50:36,381 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:36,384 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57fdb8a4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:36,385 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2db15f70{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:36,419 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44b940a2{/,file:///tmp/jetty-0.0.0.0-39981-hddsDatanode-_-any-4857792401959072843.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 16:50:36,420 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@34c53688{HTTP/1.1,[http/1.1]}{0.0.0.0:39981}
2019-09-19 16:50:36,420 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7211ms
2019-09-19 16:50:36,421 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39981
2019-09-19 16:50:36,458 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/meta/datanode.id
2019-09-19 16:50:36,585 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:42332 |  
2019-09-19 16:50:36,585 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@284bdeed
2019-09-19 16:50:36,585 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 16:50:36,588 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-swxfz-3172132826 ip:192.168.157.226
2019-09-19 16:50:36,588 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@459e79ff] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 16:50:36,594 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/meta/datanode.id
2019-09-19 16:50:36,597 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 16:50:36,598 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/containers/hdds to VolumeSet
2019-09-19 16:50:36,598 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-19 16:50:36,599 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-19 16:50:36,631 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 16:50:36,631 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 16:50:36,632 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 16:50:36,632 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 16:50:36,632 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:36,633 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 16:50:36,633 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 16:50:36,633 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:36,635 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 16:50:36,636 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 16:50:36,639 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:36,640 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:36,643 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:36,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 16:50:36,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:36,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:36,646 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38725
2019-09-19 16:50:36,647 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:36,650 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a0c5be{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:36,651 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14efa279{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:36,694 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24fba488{/,file:///tmp/jetty-0.0.0.0-38725-hddsDatanode-_-any-6591110996710823327.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 16:50:36,695 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73a6cc79{HTTP/1.1,[http/1.1]}{0.0.0.0:38725}
2019-09-19 16:50:36,697 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7488ms
2019-09-19 16:50:36,698 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38725
2019-09-19 16:50:36,863 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:37084 |  
2019-09-19 16:50:36,864 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3bbf1c0d
2019-09-19 16:50:36,864 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 16:50:36,867 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-swxfz-3172132826 ip:192.168.157.226
2019-09-19 16:50:36,867 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61de19ab] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 16:50:36,870 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/meta/datanode.id
2019-09-19 16:50:36,875 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 16:50:36,875 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/containers/hdds to VolumeSet
2019-09-19 16:50:36,876 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@143fefaf
2019-09-19 16:50:36,876 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@143fefaf
2019-09-19 16:50:36,897 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 16:50:36,898 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 16:50:36,898 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 16:50:36,898 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 16:50:36,898 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:36,899 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 16:50:36,899 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 16:50:36,899 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:36,900 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 16:50:36,901 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 16:50:36,903 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:36,903 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:36,905 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:36,906 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 16:50:36,906 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:36,906 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:36,907 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37207
2019-09-19 16:50:36,907 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:36,911 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58d4238e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:36,911 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36478bce{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:36,939 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@78b03788{/,file:///tmp/jetty-0.0.0.0-37207-hddsDatanode-_-any-5461012364067616435.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 16:50:36,940 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f5dfe69{HTTP/1.1,[http/1.1]}{0.0.0.0:37207}
2019-09-19 16:50:36,941 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7732ms
2019-09-19 16:50:36,941 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37207
2019-09-19 16:50:37,104 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:36957 |  
2019-09-19 16:50:37,104 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@700b9e6b
2019-09-19 16:50:37,104 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 16:50:37,107 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-swxfz-3172132826 ip:192.168.157.226
2019-09-19 16:50:37,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@299e1def] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 16:50:37,110 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/meta/datanode.id
2019-09-19 16:50:37,116 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 16:50:37,116 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/containers/hdds to VolumeSet
2019-09-19 16:50:37,117 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@751d7425
2019-09-19 16:50:37,117 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@751d7425
2019-09-19 16:50:37,140 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 16:50:37,140 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 16:50:37,140 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 16:50:37,140 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 16:50:37,141 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:37,141 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 16:50:37,141 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 16:50:37,142 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:37,142 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 16:50:37,143 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 16:50:37,145 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 16:50:37,145 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 16:50:37,147 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 16:50:37,148 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 16:50:37,148 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 16:50:37,148 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 16:50:37,149 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34940
2019-09-19 16:50:37,149 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 16:50:37,202 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b46392c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 16:50:37,204 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f15f52a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 16:50:37,246 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68e5c7ae{/,file:///tmp/jetty-0.0.0.0-34940-hddsDatanode-_-any-2535413405222678598.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 16:50:37,246 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@68bd8ca7{HTTP/1.1,[http/1.1]}{0.0.0.0:34940}
2019-09-19 16:50:37,247 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8038ms
2019-09-19 16:50:37,248 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34940
2019-09-19 16:50:37,424 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:36837 |  
2019-09-19 16:50:37,424 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@30159886
2019-09-19 16:50:37,427 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-19 16:50:37,428 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70125dfb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 16:50:37,431 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/meta/datanode.id
2019-09-19 16:50:38,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 16:50:38,410 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 16:50:38,412 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 16:50:38,412 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 6fd479a2-5728-477d-9065-d2b622b80b85 at port 0
2019-09-19 16:50:38,427 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-19 16:50:38,436 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start RPC server
2019-09-19 16:50:38,581 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 6fd479a2-5728-477d-9065-d2b622b80b85: GrpcService started, listening on 0.0.0.0/0.0.0.0:33726
2019-09-19 16:50:38,583 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 6fd479a2-5728-477d-9065-d2b622b80b85 is started using port 33726
2019-09-19 16:50:38,586 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 6fd479a2-5728-477d-9065-d2b622b80b85 is started using port 42222
2019-09-19 16:50:38,591 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 16:50:38,617 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 16:50:38,620 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 16:50:38,620 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 5a3ee61b-140e-4199-b942-69cb3515ef3d at port 0
2019-09-19 16:50:38,630 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start RPC server
2019-09-19 16:50:38,635 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: GrpcService started, listening on 0.0.0.0/0.0.0.0:34145
2019-09-19 16:50:38,635 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 5a3ee61b-140e-4199-b942-69cb3515ef3d is started using port 34145
2019-09-19 16:50:38,638 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 5a3ee61b-140e-4199-b942-69cb3515ef3d is started using port 41632
2019-09-19 16:50:38,870 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 16:50:38,897 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 16:50:38,899 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 16:50:38,900 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 18ae6263-d76c-4059-8eaf-4f5e3148b226 at port 0
2019-09-19 16:50:38,909 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start RPC server
2019-09-19 16:50:38,913 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: GrpcService started, listening on 0.0.0.0/0.0.0.0:41809
2019-09-19 16:50:38,913 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 18ae6263-d76c-4059-8eaf-4f5e3148b226 is started using port 41809
2019-09-19 16:50:38,916 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 18ae6263-d76c-4059-8eaf-4f5e3148b226 is started using port 43495
2019-09-19 16:50:39,111 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 16:50:39,138 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 16:50:39,141 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 16:50:39,141 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis e437f173-6a54-4062-88a9-cae9a5018cc4 at port 0
2019-09-19 16:50:39,152 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start RPC server
2019-09-19 16:50:39,156 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - e437f173-6a54-4062-88a9-cae9a5018cc4: GrpcService started, listening on 0.0.0.0/0.0.0.0:36244
2019-09-19 16:50:39,156 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis e437f173-6a54-4062-88a9-cae9a5018cc4 is started using port 36244
2019-09-19 16:50:39,159 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc e437f173-6a54-4062-88a9-cae9a5018cc4 is started using port 41199
2019-09-19 16:50:39,428 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-19 16:50:39,431 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 16:50:39,458 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 16:50:39,465 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 16:50:39,465 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis f763b2c0-c12b-45c9-b18c-74b12c137ba3 at port 0
2019-09-19 16:50:39,475 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start RPC server
2019-09-19 16:50:39,480 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: GrpcService started, listening on 0.0.0.0/0.0.0.0:34759
2019-09-19 16:50:39,480 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis f763b2c0-c12b-45c9-b18c-74b12c137ba3 is started using port 34759
2019-09-19 16:50:39,484 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc f763b2c0-c12b-45c9-b18c-74b12c137ba3 is started using port 41256
2019-09-19 16:50:40,386 [IPC Server handler 4 on 41576] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:40,386 [IPC Server handler 4 on 41576] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}
2019-09-19 16:50:40,393 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-19 16:50:40,393 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-19 16:50:40,393 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-19 16:50:40,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=REGISTER {datanodeDetails=6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 16:50:40,431 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 5 DN Heartbeats.
2019-09-19 16:50:40,593 [IPC Server handler 2 on 41576] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:40,593 [IPC Server handler 2 on 41576] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}
2019-09-19 16:50:40,594 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=REGISTER {datanodeDetails=5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 16:50:41,334 [IPC Server handler 3 on 41576] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:41,334 [IPC Server handler 5 on 41576] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:41,334 [IPC Server handler 3 on 41576] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}
2019-09-19 16:50:41,334 [IPC Server handler 5 on 41576] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}
2019-09-19 16:50:41,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=REGISTER {datanodeDetails=e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 16:50:41,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=REGISTER {datanodeDetails=18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 16:50:41,431 [IPC Server handler 0 on 41576] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:41,431 [IPC Server handler 0 on 41576] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}
2019-09-19 16:50:41,431 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=REGISTER {datanodeDetails=f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 16:50:41,432 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-19 16:50:41,457 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6fd479a2-5728-477d-9065-d2b622b80b85: addNew group-366F76CB3580:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] returns group-366F76CB3580:java.util.concurrent.CompletableFuture@32dc707a[Not completed]
2019-09-19 16:50:41,481 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6fd479a2-5728-477d-9065-d2b622b80b85: new RaftServerImpl for group-366F76CB3580:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] with ContainerStateMachine:uninitialized
2019-09-19 16:50:41,484 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:41,485 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:41,485 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:41,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:41,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:41,497 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 ConfigurationManager, init=-1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:41,498 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:41,507 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580 does not exist. Creating ...
2019-09-19 16:50:41,525 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:41,531 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580 has been successfully formatted.
2019-09-19 16:50:41,533 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-366F76CB3580: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:41,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:41,536 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:41,542 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:41,542 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:41,544 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:41,549 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:41,555 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580
2019-09-19 16:50:41,569 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:41,569 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:41,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:41,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:41,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:41,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:41,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:41,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:41,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:41,588 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:41,592 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:41,596 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:41,597 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:41,598 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:41,620 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start group-366F76CB3580
2019-09-19 16:50:41,621 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:41,622 [Thread-208] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 16:50:41,624 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start FollowerState
2019-09-19 16:50:41,626 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-366F76CB3580,id=6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:41,702 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d4f8b453-7151-46a2-91df-366f76cb3580, Nodes: 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:41,728 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: addNew group-C6DC1A38C79C:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] returns group-C6DC1A38C79C:java.util.concurrent.CompletableFuture@42cca0a6[Not completed]
2019-09-19 16:50:41,779 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: new RaftServerImpl for group-C6DC1A38C79C:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] with ContainerStateMachine:uninitialized
2019-09-19 16:50:41,780 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:41,780 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:41,781 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:41,781 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:41,781 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:41,781 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C ConfigurationManager, init=-1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:41,781 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:41,782 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c does not exist. Creating ...
2019-09-19 16:50:41,795 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:41,817 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c has been successfully formatted.
2019-09-19 16:50:41,819 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C6DC1A38C79C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:41,820 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:41,821 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:41,821 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:41,821 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:41,821 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:41,821 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:41,822 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c
2019-09-19 16:50:41,823 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:41,823 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:41,823 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:41,823 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:41,824 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:41,824 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:41,824 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:41,824 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:41,824 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:41,825 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:41,825 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:41,826 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:41,826 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:41,826 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:41,826 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start group-C6DC1A38C79C
2019-09-19 16:50:41,826 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:41,827 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start FollowerState
2019-09-19 16:50:41,828 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C6DC1A38C79C,id=5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:41,847 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 12982e67-1abd-429e-ad48-c6dc1a38c79c, Nodes: 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:41,867 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6fd479a2-5728-477d-9065-d2b622b80b85: addNew group-FFF24DCD1F36:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] returns group-FFF24DCD1F36:java.util.concurrent.CompletableFuture@1e9252d0[Not completed]
2019-09-19 16:50:41,877 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6fd479a2-5728-477d-9065-d2b622b80b85: new RaftServerImpl for group-FFF24DCD1F36:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] with ContainerStateMachine:uninitialized
2019-09-19 16:50:41,877 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:41,878 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:41,878 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:41,878 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:41,878 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:41,878 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 ConfigurationManager, init=-1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:41,878 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:41,879 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36 does not exist. Creating ...
2019-09-19 16:50:41,892 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:41,905 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36 has been successfully formatted.
2019-09-19 16:50:41,905 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-FFF24DCD1F36: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:41,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:41,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:41,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:41,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:41,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:41,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:41,907 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36
2019-09-19 16:50:41,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:41,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:41,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:41,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:41,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:41,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:41,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:41,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:41,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:41,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:41,909 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:41,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:41,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:41,910 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:41,910 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start group-FFF24DCD1F36
2019-09-19 16:50:41,910 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:41,910 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start FollowerState
2019-09-19 16:50:41,911 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFF24DCD1F36,id=6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:41,924 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 80634a0e-ae57-4848-8516-fff24dcd1f36, Nodes: 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:41,960 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: addNew group-27C651FA0180:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] returns group-27C651FA0180:java.util.concurrent.CompletableFuture@3d8a97dd[Not completed]
2019-09-19 16:50:41,962 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: new RaftServerImpl for group-27C651FA0180:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] with ContainerStateMachine:uninitialized
2019-09-19 16:50:41,962 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:41,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:41,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:41,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:41,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:41,963 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 ConfigurationManager, init=-1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:41,964 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:41,964 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180 does not exist. Creating ...
2019-09-19 16:50:41,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin53720, owner=user47639, volume=volume60973, creationTime=1568911841967, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 16:50:41,985 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:41,999 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180 has been successfully formatted.
2019-09-19 16:50:42,000 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-27C651FA0180: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,000 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,000 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,000 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,000 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,001 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,001 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,001 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180
2019-09-19 16:50:42,001 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,001 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,002 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,002 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,002 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,002 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,002 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,003 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,003 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,008 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,009 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,009 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,009 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,011 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,011 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start group-27C651FA0180
2019-09-19 16:50:42,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume60973, bucket=bucket48852, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 16:50:42,011 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,011 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start FollowerState
2019-09-19 16:50:42,013 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-27C651FA0180,id=18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:42,025 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: af0c61aa-ba58-488f-9e79-27c651fa0180, Nodes: 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,053 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: addNew group-D8CA64E41541:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] returns group-D8CA64E41541:java.util.concurrent.CompletableFuture@257f8a36[Not completed]
2019-09-19 16:50:42,054 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: new RaftServerImpl for group-D8CA64E41541:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,055 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,055 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,055 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,055 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,055 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,055 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 ConfigurationManager, init=-1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,056 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:42,056 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541 does not exist. Creating ...
2019-09-19 16:50:42,069 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,093 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541 has been successfully formatted.
2019-09-19 16:50:42,093 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D8CA64E41541: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,093 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,093 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,094 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,095 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,095 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,095 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,095 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,095 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,095 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,096 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,096 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,096 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,096 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,097 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,097 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,097 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start group-D8CA64E41541
2019-09-19 16:50:42,097 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,097 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start FollowerState
2019-09-19 16:50:42,098 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D8CA64E41541,id=5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:42,113 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5fe0751b-5e20-4dcf-9a75-d8ca64e41541, Nodes: 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,135 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: addNew group-34CB2F4BD411:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] returns group-34CB2F4BD411:java.util.concurrent.CompletableFuture@da2e354[Not completed]
2019-09-19 16:50:42,137 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: new RaftServerImpl for group-34CB2F4BD411:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,137 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,137 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,137 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,138 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,138 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,138 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 ConfigurationManager, init=-1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,138 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:42,138 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411 does not exist. Creating ...
2019-09-19 16:50:42,164 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,176 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411 has been successfully formatted.
2019-09-19 16:50:42,177 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-34CB2F4BD411: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,177 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,177 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,177 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,177 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,177 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,178 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,179 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,179 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,179 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,179 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,179 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,179 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,180 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,180 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,180 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start group-34CB2F4BD411
2019-09-19 16:50:42,180 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,180 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start FollowerState
2019-09-19 16:50:42,181 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-34CB2F4BD411,id=18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:42,198 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 251cc331-869b-4e2a-bf1a-34cb2f4bd411, Nodes: 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,218 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e437f173-6a54-4062-88a9-cae9a5018cc4: addNew group-5363C6BE4C4C:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] returns group-5363C6BE4C4C:java.util.concurrent.CompletableFuture@6e82ca8f[Not completed]
2019-09-19 16:50:42,220 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e437f173-6a54-4062-88a9-cae9a5018cc4: new RaftServerImpl for group-5363C6BE4C4C:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,221 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,221 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,221 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,221 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,221 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,221 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C ConfigurationManager, init=-1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,222 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:42,222 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c does not exist. Creating ...
2019-09-19 16:50:42,236 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,249 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c has been successfully formatted.
2019-09-19 16:50:42,249 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-5363C6BE4C4C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,250 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,250 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,250 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,250 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,250 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,250 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,251 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c
2019-09-19 16:50:42,251 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,251 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,251 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,251 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,252 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,252 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,252 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,252 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,252 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,253 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,253 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,255 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,255 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,255 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,255 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start group-5363C6BE4C4C
2019-09-19 16:50:42,256 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,256 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start FollowerState
2019-09-19 16:50:42,261 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5363C6BE4C4C,id=e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:42,284 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1fcd285c-2d6a-4538-be1f-5363c6be4c4c, Nodes: e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,299 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6fd479a2-5728-477d-9065-d2b622b80b85: addNew group-39F997D43FF2:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] returns group-39F997D43FF2:java.util.concurrent.CompletableFuture@59109a51[Not completed]
2019-09-19 16:50:42,301 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6fd479a2-5728-477d-9065-d2b622b80b85: new RaftServerImpl for group-39F997D43FF2:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,301 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,301 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,301 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,302 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,302 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,302 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 ConfigurationManager, init=-1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,302 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:42,302 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2 does not exist. Creating ...
2019-09-19 16:50:42,315 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,327 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2 has been successfully formatted.
2019-09-19 16:50:42,328 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-39F997D43FF2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,328 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,330 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,331 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,331 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,331 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,331 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start group-39F997D43FF2
2019-09-19 16:50:42,331 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,332 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start FollowerState
2019-09-19 16:50:42,334 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-39F997D43FF2,id=6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:42,341 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume60973} | ret=SUCCESS |  
2019-09-19 16:50:42,345 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 52c59cc7-af56-43c7-b36d-39f997d43ff2, Nodes: 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,363 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume60973, bucket=bucket48852} | ret=SUCCESS |  
2019-09-19 16:50:42,368 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6fd479a2-5728-477d-9065-d2b622b80b85: addNew group-A9CBAD69C1AE:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] returns group-A9CBAD69C1AE:java.util.concurrent.CompletableFuture@6d96e7ff[Not completed]
2019-09-19 16:50:42,369 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6fd479a2-5728-477d-9065-d2b622b80b85: new RaftServerImpl for group-A9CBAD69C1AE:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,370 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,370 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,370 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,370 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,370 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,371 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE ConfigurationManager, init=-1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,371 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:42,371 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae does not exist. Creating ...
2019-09-19 16:50:42,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:42,383 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,388 [Thread-208] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket48852.volume60973 implemented by OzoneFileSystem{URI=o3fs://bucket48852.volume60973, workingDir=o3fs://bucket48852.volume60973/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-19 16:50:42,398 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae has been successfully formatted.
2019-09-19 16:50:42,398 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A9CBAD69C1AE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,400 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,400 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae
2019-09-19 16:50:42,400 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,400 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,400 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,402 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,403 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,403 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,403 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start group-A9CBAD69C1AE
2019-09-19 16:50:42,403 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,404 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start FollowerState
2019-09-19 16:50:42,404 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9CBAD69C1AE,id=6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:42,427 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 60341465-0897-4ad3-9650-a9cbad69c1ae, Nodes: 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,444 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e437f173-6a54-4062-88a9-cae9a5018cc4: addNew group-8C4F7D23B342:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] returns group-8C4F7D23B342:java.util.concurrent.CompletableFuture@45be873e[Not completed]
2019-09-19 16:50:42,446 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e437f173-6a54-4062-88a9-cae9a5018cc4: new RaftServerImpl for group-8C4F7D23B342:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,446 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,446 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,446 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,446 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,447 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,447 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 ConfigurationManager, init=-1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,447 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:42,447 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342 does not exist. Creating ...
2019-09-19 16:50:42,458 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:42,460 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,475 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342 has been successfully formatted.
2019-09-19 16:50:42,477 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8C4F7D23B342: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,477 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,477 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,477 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,477 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,478 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,478 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,478 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342
2019-09-19 16:50:42,478 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,478 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,479 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,479 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,479 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,479 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,479 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,479 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,480 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,480 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,480 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,481 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,487 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,489 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,489 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start group-8C4F7D23B342
2019-09-19 16:50:42,489 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,489 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start FollowerState
2019-09-19 16:50:42,490 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C4F7D23B342,id=e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:42,512 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d751dc99-2dc4-4e2b-861c-8c4f7d23b342, Nodes: e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:42,533 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: addNew group-EBB665818962:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] returns group-EBB665818962:java.util.concurrent.CompletableFuture@4eaf313e[Not completed]
2019-09-19 16:50:42,539 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: new RaftServerImpl for group-EBB665818962:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,539 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,539 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,539 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,540 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,540 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,540 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 ConfigurationManager, init=-1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,540 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:42,541 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962 does not exist. Creating ...
2019-09-19 16:50:42,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:42,555 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:42,567 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962 has been successfully formatted.
2019-09-19 16:50:42,568 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-EBB665818962: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,568 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,568 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,568 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,568 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,568 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,569 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,569 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962
2019-09-19 16:50:42,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume60973, bucket=bucket48852, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-19 16:50:42,569 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,569 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,569 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,570 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,570 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,570 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,570 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,570 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,570 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,571 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,571 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,571 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,571 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,572 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,572 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start group-EBB665818962
2019-09-19 16:50:42,572 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,572 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start FollowerState
2019-09-19 16:50:42,573 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EBB665818962,id=5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:42,583 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a779824c-372d-4b11-913e-ebb665818962, Nodes: 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,585 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:42,589 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume60973, bucket=bucket48852, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-19 16:50:42,596 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:42,596 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:42,602 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: addNew group-A5C6C8EC658D:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] returns group-A5C6C8EC658D:java.util.concurrent.CompletableFuture@6d895dd0[Not completed]
2019-09-19 16:50:42,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:42,604 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: new RaftServerImpl for group-A5C6C8EC658D:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,604 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,604 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,604 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,604 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,604 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,605 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D ConfigurationManager, init=-1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,605 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:42,605 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d does not exist. Creating ...
2019-09-19 16:50:42,606 [Thread-208] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-19 16:50:42,618 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,640 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d has been successfully formatted.
2019-09-19 16:50:42,640 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A5C6C8EC658D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,640 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,640 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,641 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,641 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,641 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,641 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,641 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d
2019-09-19 16:50:42,642 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,642 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,642 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,642 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,642 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,642 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,643 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,643 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,643 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,643 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,646 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,648 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,648 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,648 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,649 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start group-A5C6C8EC658D
2019-09-19 16:50:42,649 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,649 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start FollowerState
2019-09-19 16:50:42,650 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A5C6C8EC658D,id=18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:42,665 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3efcb5aa-e904-4726-bfd0-a5c6c8ec658d, Nodes: 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,679 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: addNew group-319FCD2B7150:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] returns group-319FCD2B7150:java.util.concurrent.CompletableFuture@2a9e7f57[Not completed]
2019-09-19 16:50:42,680 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: new RaftServerImpl for group-319FCD2B7150:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,680 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,680 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,680 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,681 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,681 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,681 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 ConfigurationManager, init=-1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,681 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:42,681 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150 does not exist. Creating ...
2019-09-19 16:50:42,694 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,707 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150 has been successfully formatted.
2019-09-19 16:50:42,707 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-319FCD2B7150: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,707 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,707 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,707 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,707 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,708 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,709 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,712 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,712 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,712 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,712 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,713 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,713 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start group-319FCD2B7150
2019-09-19 16:50:42,713 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,713 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start FollowerState
2019-09-19 16:50:42,714 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-319FCD2B7150,id=5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:42,726 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0e2beae4-fee4-4348-afa5-319fcd2b7150, Nodes: 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,749 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e437f173-6a54-4062-88a9-cae9a5018cc4: addNew group-4457C9B016D7:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] returns group-4457C9B016D7:java.util.concurrent.CompletableFuture@2c708827[Not completed]
2019-09-19 16:50:42,751 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e437f173-6a54-4062-88a9-cae9a5018cc4: new RaftServerImpl for group-4457C9B016D7:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,751 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,751 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,751 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,751 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,752 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,752 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 ConfigurationManager, init=-1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,755 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:42,755 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7 does not exist. Creating ...
2019-09-19 16:50:42,780 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,795 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7 has been successfully formatted.
2019-09-19 16:50:42,796 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-4457C9B016D7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,796 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,796 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,796 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,796 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,796 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,797 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,797 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7
2019-09-19 16:50:42,797 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,797 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,797 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,797 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,798 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,798 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,798 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,798 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,798 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,798 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,799 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,799 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,799 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,800 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,800 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start group-4457C9B016D7
2019-09-19 16:50:42,800 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,800 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start FollowerState
2019-09-19 16:50:42,801 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4457C9B016D7,id=e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:42,810 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 734a19d6-aadc-4fbc-b681-4457c9b016d7, Nodes: e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,825 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: addNew group-4E0F1CE772A7:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] returns group-4E0F1CE772A7:java.util.concurrent.CompletableFuture@14fb235b[Not completed]
2019-09-19 16:50:42,827 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: new RaftServerImpl for group-4E0F1CE772A7:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,827 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,827 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,827 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,828 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,828 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,828 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 ConfigurationManager, init=-1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,828 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:42,828 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7 does not exist. Creating ...
2019-09-19 16:50:42,840 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,853 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7 has been successfully formatted.
2019-09-19 16:50:42,854 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-4E0F1CE772A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,854 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,854 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,854 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,854 [Thread-208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:50:42,854 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,855 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,856 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,856 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,856 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,856 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,856 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,856 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,857 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,857 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,857 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,857 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start group-4E0F1CE772A7
2019-09-19 16:50:42,857 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,858 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start FollowerState
2019-09-19 16:50:42,858 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E0F1CE772A7,id=18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:42,864 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9a39c600-2d16-465d-a799-4e0f1ce772a7, Nodes: 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,889 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: addNew group-802DD26E27A1:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] returns group-802DD26E27A1:java.util.concurrent.CompletableFuture@29ac36b[Not completed]
2019-09-19 16:50:42,891 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: new RaftServerImpl for group-802DD26E27A1:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,891 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,891 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,891 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,891 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,892 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,892 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 ConfigurationManager, init=-1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,892 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:42,903 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1 does not exist. Creating ...
2019-09-19 16:50:42,911 [Thread-208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:50:42,924 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:42,948 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1 has been successfully formatted.
2019-09-19 16:50:42,949 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-802DD26E27A1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:42,949 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:42,950 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:42,950 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:42,950 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:42,950 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,951 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:42,951 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1
2019-09-19 16:50:42,951 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:42,951 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:42,951 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:42,951 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:42,952 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:42,952 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:42,952 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:42,952 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:42,953 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:42,953 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:42,953 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:42,954 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:42,954 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:42,954 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:42,955 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start group-802DD26E27A1
2019-09-19 16:50:42,955 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:42,955 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start FollowerState
2019-09-19 16:50:42,955 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-802DD26E27A1,id=5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:42,962 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 77957b02-543c-4a43-8875-802dd26e27a1, Nodes: 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:42,972 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6fd479a2-5728-477d-9065-d2b622b80b85: addNew group-469CCD9AF2CD:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] returns group-469CCD9AF2CD:java.util.concurrent.CompletableFuture@66f532de[Not completed]
2019-09-19 16:50:42,974 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6fd479a2-5728-477d-9065-d2b622b80b85: new RaftServerImpl for group-469CCD9AF2CD:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] with ContainerStateMachine:uninitialized
2019-09-19 16:50:42,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:42,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:42,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:42,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:42,975 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:42,975 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD ConfigurationManager, init=-1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:42,975 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:42,975 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd does not exist. Creating ...
2019-09-19 16:50:42,990 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,002 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd has been successfully formatted.
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-469CCD9AF2CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,005 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,007 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,007 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,007 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,007 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,008 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,008 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start group-469CCD9AF2CD
2019-09-19 16:50:43,008 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,010 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start FollowerState
2019-09-19 16:50:43,008 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:43,010 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-469CCD9AF2CD,id=6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:43,016 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9cabc86e-e946-4c16-9d9b-469ccd9af2cd, Nodes: 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,030 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6fd479a2-5728-477d-9065-d2b622b80b85: addNew group-BB2E2BCB1639:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] returns group-BB2E2BCB1639:java.util.concurrent.CompletableFuture@4bee3812[Not completed]
2019-09-19 16:50:43,031 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6fd479a2-5728-477d-9065-d2b622b80b85: new RaftServerImpl for group-BB2E2BCB1639:[6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,032 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,032 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 ConfigurationManager, init=-1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,032 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis] (custom)
2019-09-19 16:50:43,032 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639 does not exist. Creating ...
2019-09-19 16:50:43,046 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,067 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639 has been successfully formatted.
2019-09-19 16:50:43,068 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-BB2E2BCB1639: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,069 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639
2019-09-19 16:50:43,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,074 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,075 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,075 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start group-BB2E2BCB1639
2019-09-19 16:50:43,075 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,075 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start FollowerState
2019-09-19 16:50:43,076 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BB2E2BCB1639,id=6fd479a2-5728-477d-9065-d2b622b80b85
2019-09-19 16:50:43,088 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: de27293f-759e-45e9-a4ba-bb2e2bcb1639, Nodes: 6fd479a2-5728-477d-9065-d2b622b80b85{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,089 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,104 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e437f173-6a54-4062-88a9-cae9a5018cc4: addNew group-CD4340813117:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] returns group-CD4340813117:java.util.concurrent.CompletableFuture@788ee0b2[Not completed]
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e437f173-6a54-4062-88a9-cae9a5018cc4: new RaftServerImpl for group-CD4340813117:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 ConfigurationManager, init=-1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:43,107 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117 does not exist. Creating ...
2019-09-19 16:50:43,121 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,135 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117 has been successfully formatted.
2019-09-19 16:50:43,135 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-CD4340813117: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117
2019-09-19 16:50:43,136 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,138 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,139 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start group-CD4340813117
2019-09-19 16:50:43,139 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,139 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start FollowerState
2019-09-19 16:50:43,140 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD4340813117,id=e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:43,147 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a2d7f562-8598-41d2-a5b7-cd4340813117, Nodes: e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,154 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,176 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e437f173-6a54-4062-88a9-cae9a5018cc4: addNew group-C9199B074752:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] returns group-C9199B074752:java.util.concurrent.CompletableFuture@46f44da[Not completed]
2019-09-19 16:50:43,177 [Thread-208] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-19 16:50:43,177 [Thread-208] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e437f173-6a54-4062-88a9-cae9a5018cc4: new RaftServerImpl for group-C9199B074752:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 ConfigurationManager, init=-1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,178 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:43,179 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752 does not exist. Creating ...
2019-09-19 16:50:43,179 [Thread-208] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-19 16:50:43,180 [Thread-208] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-19 16:50:43,191 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,204 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752 has been successfully formatted.
2019-09-19 16:50:43,204 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C9199B074752: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,204 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,204 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,207 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,208 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,209 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,209 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,209 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,209 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,209 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start group-C9199B074752
2019-09-19 16:50:43,210 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,210 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start FollowerState
2019-09-19 16:50:43,216 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C9199B074752,id=e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:43,228 [Thread-208] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 16:50:43,233 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1cd0eb5b-066d-4b8c-ad72-c9199b074752, Nodes: e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,234 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,243 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: addNew group-8B443A60BB5D:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] returns group-8B443A60BB5D:java.util.concurrent.CompletableFuture@2ed63472[Not completed]
2019-09-19 16:50:43,244 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: new RaftServerImpl for group-8B443A60BB5D:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D ConfigurationManager, init=-1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,245 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:43,246 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d does not exist. Creating ...
2019-09-19 16:50:43,248 [Thread-208] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 16:50:43,254 [Thread-208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:50:43,259 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,273 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d has been successfully formatted.
2019-09-19 16:50:43,273 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8B443A60BB5D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,274 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,275 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,276 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,276 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,276 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,276 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,276 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start group-8B443A60BB5D
2019-09-19 16:50:43,276 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,277 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start FollowerState
2019-09-19 16:50:43,277 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8B443A60BB5D,id=18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:43,283 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e2b5a851-5642-4dc3-a2f5-8b443a60bb5d, Nodes: 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,285 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,294 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e437f173-6a54-4062-88a9-cae9a5018cc4: addNew group-76E3D31CEAC8:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] returns group-76E3D31CEAC8:java.util.concurrent.CompletableFuture@30571e38[Not completed]
2019-09-19 16:50:43,296 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e437f173-6a54-4062-88a9-cae9a5018cc4: new RaftServerImpl for group-76E3D31CEAC8:[e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,296 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,296 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,296 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,296 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,296 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,297 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 ConfigurationManager, init=-1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,297 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis] (custom)
2019-09-19 16:50:43,297 [Thread-208] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 16:50:43,297 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8 does not exist. Creating ...
2019-09-19 16:50:43,313 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,316 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:43,316 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:43,327 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8 has been successfully formatted.
2019-09-19 16:50:43,328 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-76E3D31CEAC8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,328 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,328 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,328 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,328 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,329 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,329 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,329 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8
2019-09-19 16:50:43,329 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,329 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,329 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,330 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,331 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,331 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,331 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,332 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,332 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start group-76E3D31CEAC8
2019-09-19 16:50:43,332 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,332 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start FollowerState
2019-09-19 16:50:43,333 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-76E3D31CEAC8,id=e437f173-6a54-4062-88a9-cae9a5018cc4
2019-09-19 16:50:43,338 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d31c33c3-9393-45ac-82f7-76e3d31ceac8, Nodes: e437f173-6a54-4062-88a9-cae9a5018cc4{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,342 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,342 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:43,342 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,352 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: addNew group-A69C18C43FE9:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] returns group-A69C18C43FE9:java.util.concurrent.CompletableFuture@18844c08[Not completed]
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: new RaftServerImpl for group-A69C18C43FE9:[18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,353 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 ConfigurationManager, init=-1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,354 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis] (custom)
2019-09-19 16:50:43,354 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9 does not exist. Creating ...
2019-09-19 16:50:43,366 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,379 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9 has been successfully formatted.
2019-09-19 16:50:43,379 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A69C18C43FE9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,379 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,379 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,379 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,380 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,381 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,381 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,381 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,381 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,381 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,381 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,382 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,382 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,382 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,382 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start group-A69C18C43FE9
2019-09-19 16:50:43,382 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,382 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start FollowerState
2019-09-19 16:50:43,383 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A69C18C43FE9,id=18ae6263-d76c-4059-8eaf-4f5e3148b226
2019-09-19 16:50:43,388 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 331db2a9-b357-4f4d-9507-a69c18c43fe9, Nodes: 18ae6263-d76c-4059-8eaf-4f5e3148b226{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,390 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,394 [Thread-208] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-19 16:50:43,395 [Thread-207] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-19 16:50:43,397 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-19 16:50:43,400 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: addNew group-919626DA8EC4:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] returns group-919626DA8EC4:java.util.concurrent.CompletableFuture@58579251[Not completed]
2019-09-19 16:50:43,401 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: new RaftServerImpl for group-919626DA8EC4:[5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,402 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,402 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,402 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,402 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,402 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,402 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 ConfigurationManager, init=-1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,403 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis] (custom)
2019-09-19 16:50:43,403 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4 does not exist. Creating ...
2019-09-19 16:50:43,416 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,430 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4 has been successfully formatted.
2019-09-19 16:50:43,430 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-919626DA8EC4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,430 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,430 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,430 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:43,430 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,431 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4
2019-09-19 16:50:43,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,433 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,433 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,433 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,434 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,434 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,434 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,434 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start group-919626DA8EC4
2019-09-19 16:50:43,434 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,434 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start FollowerState
2019-09-19 16:50:43,435 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-919626DA8EC4,id=5a3ee61b-140e-4199-b942-69cb3515ef3d
2019-09-19 16:50:43,439 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: aeeeff5b-79f8-4c14-8732-919626da8ec4, Nodes: 5a3ee61b-140e-4199-b942-69cb3515ef3d{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,453 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: addNew group-0A7960E0436F:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] returns group-0A7960E0436F:java.util.concurrent.CompletableFuture@e1eb83a[Not completed]
2019-09-19 16:50:43,456 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: new RaftServerImpl for group-0A7960E0436F:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,456 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,457 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,457 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F ConfigurationManager, init=-1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,457 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:43,458 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f does not exist. Creating ...
2019-09-19 16:50:43,496 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,507 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f has been successfully formatted.
2019-09-19 16:50:43,507 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0A7960E0436F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,507 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,508 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,508 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,508 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,508 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,508 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,509 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f
2019-09-19 16:50:43,509 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,509 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,509 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,509 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,510 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,510 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,510 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,510 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,510 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,511 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,511 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,511 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,512 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,512 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,512 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start group-0A7960E0436F
2019-09-19 16:50:43,512 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,512 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start FollowerState
2019-09-19 16:50:43,513 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A7960E0436F,id=f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:43,518 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9f1069f3-bc9c-405f-abcd-0a7960e0436f, Nodes: f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,520 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,521 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,532 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: addNew group-39EC1FCAB3C4:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] returns group-39EC1FCAB3C4:java.util.concurrent.CompletableFuture@5df060eb[Not completed]
2019-09-19 16:50:43,533 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: new RaftServerImpl for group-39EC1FCAB3C4:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,534 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,534 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,534 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,534 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 ConfigurationManager, init=-1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,534 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:43,535 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4 does not exist. Creating ...
2019-09-19 16:50:43,548 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,561 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4 has been successfully formatted.
2019-09-19 16:50:43,561 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-39EC1FCAB3C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,561 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,561 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,561 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,562 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4
2019-09-19 16:50:43,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,564 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,564 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,564 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,564 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,565 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,565 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,565 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start group-39EC1FCAB3C4
2019-09-19 16:50:43,565 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,565 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start FollowerState
2019-09-19 16:50:43,566 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-39EC1FCAB3C4,id=f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:43,571 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3896a833-2bd9-498d-a968-39ec1fcab3c4, Nodes: f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,573 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,573 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,574 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,574 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,575 [Thread-208] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local81299712_0001
2019-09-19 16:50:43,577 [Thread-208] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 16:50:43,584 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: addNew group-865F19210AED:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] returns group-865F19210AED:java.util.concurrent.CompletableFuture@5ce31bec[Not completed]
2019-09-19 16:50:43,585 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: new RaftServerImpl for group-865F19210AED:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,585 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,585 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,586 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,586 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,586 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,586 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED ConfigurationManager, init=-1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,586 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:43,586 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed does not exist. Creating ...
2019-09-19 16:50:43,594 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:43,600 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,613 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed has been successfully formatted.
2019-09-19 16:50:43,614 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-865F19210AED: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,614 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,614 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,614 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,614 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,614 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,615 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,615 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed
2019-09-19 16:50:43,615 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,615 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,615 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,615 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,616 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,616 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,616 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,616 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,616 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,616 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,617 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,617 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,617 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,617 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,618 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start group-865F19210AED
2019-09-19 16:50:43,618 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,618 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start FollowerState
2019-09-19 16:50:43,618 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-865F19210AED,id=f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:43,623 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7276e335-0113-4af7-b0b7-865f19210aed, Nodes: f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,625 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,625 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,625 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,625 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,634 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: addNew group-2CE0B52551B3:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] returns group-2CE0B52551B3:java.util.concurrent.CompletableFuture@13d1ba58[Not completed]
2019-09-19 16:50:43,636 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: new RaftServerImpl for group-2CE0B52551B3:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,636 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,636 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,636 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,636 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,637 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,637 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 ConfigurationManager, init=-1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,637 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:43,637 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3 does not exist. Creating ...
2019-09-19 16:50:43,650 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,663 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3 has been successfully formatted.
2019-09-19 16:50:43,663 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-2CE0B52551B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,663 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,664 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,664 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,664 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,664 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,664 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,664 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,665 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,666 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,666 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,666 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,666 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,667 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,667 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,667 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,667 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start group-2CE0B52551B3
2019-09-19 16:50:43,668 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,668 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start FollowerState
2019-09-19 16:50:43,668 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2CE0B52551B3,id=f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:43,673 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2adceafd-2af5-46c0-97f2-2ce0b52551b3, Nodes: f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,675 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,675 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,675 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,675 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,685 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: addNew group-010DBAC00C20:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] returns group-010DBAC00C20:java.util.concurrent.CompletableFuture@4d366352[Not completed]
2019-09-19 16:50:43,687 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: new RaftServerImpl for group-010DBAC00C20:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,687 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,688 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,688 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,688 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,688 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,688 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 ConfigurationManager, init=-1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,688 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:43,689 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20 does not exist. Creating ...
2019-09-19 16:50:43,702 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,719 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20 has been successfully formatted.
2019-09-19 16:50:43,719 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-010DBAC00C20: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,720 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,720 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,720 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,720 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,720 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,720 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,721 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20
2019-09-19 16:50:43,721 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,721 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,721 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,721 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,721 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,722 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,722 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,722 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,722 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,722 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,723 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,723 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,723 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,723 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,724 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start group-010DBAC00C20
2019-09-19 16:50:43,724 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,724 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start FollowerState
2019-09-19 16:50:43,725 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-010DBAC00C20,id=f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:43,730 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c7ea30dd-e1fe-44f7-a383-010dbac00c20, Nodes: f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,732 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,732 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,732 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,732 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,742 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: addNew group-D35F78DF511A:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] returns group-D35F78DF511A:java.util.concurrent.CompletableFuture@5d3c4e5a[Not completed]
2019-09-19 16:50:43,744 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: new RaftServerImpl for group-D35F78DF511A:[f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759] with ContainerStateMachine:uninitialized
2019-09-19 16:50:43,744 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 16:50:43,744 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 16:50:43,744 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 16:50:43,744 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 16:50:43,744 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 16:50:43,745 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A ConfigurationManager, init=-1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null, confs=<EMPTY_MAP>
2019-09-19 16:50:43,745 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis] (custom)
2019-09-19 16:50:43,745 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a does not exist. Creating ...
2019-09-19 16:50:43,766 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a/in_use.lock acquired by nodename 8981@pr-hdds-1569-swxfz-3172132826
2019-09-19 16:50:43,780 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a has been successfully formatted.
2019-09-19 16:50:43,781 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D35F78DF511A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 16:50:43,781 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 16:50:43,781 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 16:50:43,782 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 16:50:43,782 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 16:50:43,782 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,782 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 16:50:43,783 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a
2019-09-19 16:50:43,783 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 16:50:43,783 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 16:50:43,784 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 16:50:43,784 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 16:50:43,784 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 16:50:43,784 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 16:50:43,785 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 16:50:43,785 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 16:50:43,785 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 16:50:43,785 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 16:50:43,786 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a: flushIndex: setUnconditionally 0 -> -1
2019-09-19 16:50:43,786 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 16:50:43,787 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 16:50:43,787 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 16:50:43,787 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start group-D35F78DF511A
2019-09-19 16:50:43,788 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 16:50:43,788 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start FollowerState
2019-09-19 16:50:43,789 [Thread-208] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 16:50:43,789 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D35F78DF511A,id=f763b2c0-c12b-45c9-b18c-74b12c137ba3
2019-09-19 16:50:43,791 [Thread-208] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local81299712_0001
2019-09-19 16:50:43,793 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local81299712_0001
2019-09-19 16:50:43,803 [Thread-357] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 16:50:43,804 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f0a0c40f-fa8f-41a4-93af-d35f78df511a, Nodes: f763b2c0-c12b-45c9-b18c-74b12c137ba3{ip: 192.168.157.226, host: pr-hdds-1569-swxfz-3172132826, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 16:50:43,804 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,804 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,805 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,805 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,805 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,806 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,808 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,808 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,808 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,809 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,809 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,809 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,809 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,810 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,810 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,812 [Thread-357] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:43,812 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,812 [Thread-357] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:43,813 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,814 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,816 [Thread-357] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 16:50:43,816 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,816 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,816 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,817 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,817 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,817 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,818 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,820 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:43,821 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,821 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:43,880 [Thread-357] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 16:50:43,882 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:43,929 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:43,930 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:43,956 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:50:43,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:2254+847
2019-09-19 16:50:43,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:43,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:44,013 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:44,017 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
2019-09-19 16:50:44,026 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:44,035 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:44,072 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:44,073 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:44,073 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:44,073 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:44,073 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:44,074 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:44,074 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:44,075 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:44,077 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:44,077 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:44,077 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:44,083 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:44,089 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:44,090 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:44,091 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:44,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:44,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:44,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:44,429 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:44,592 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:44,804 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local81299712_0001 running in uber mode : false
2019-09-19 16:50:44,807 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 16:50:45,314 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:45,317 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:45,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:45,429 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:45,591 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:46,314 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:46,317 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:46,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:46,429 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:46,592 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:46,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:46,651 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:46,651 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:46,651 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:46,652 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:46,652 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:46,652 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:46,652 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:46,652 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:46,653 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:46,653 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:46,654 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:46,654 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:46,657 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:46,661 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:46,661 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:46,721 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5096ms
2019-09-19 16:50:46,721 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown FollowerState
2019-09-19 16:50:46,721 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:46,725 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderElection
2019-09-19 16:50:46,757 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1: begin an election at term 1 for -1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null
2019-09-19 16:50:46,760 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown LeaderElection
2019-09-19 16:50:46,761 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:46,761 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 change Leader from null to 6fd479a2-5728-477d-9065-d2b622b80b85 at term 1 for becomeLeader, leader elected after 5227ms
2019-09-19 16:50:46,771 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:46,771 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:46,775 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:46,778 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:46,779 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:46,780 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:46,791 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderState
2019-09-19 16:50:46,819 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580: Starting segment from index:0
2019-09-19 16:50:46,833 [6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-366F76CB3580 set configuration 0: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null at 0
2019-09-19 16:50:46,950 [Thread-214] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C changes to CANDIDATE, lastRpcTime:5123, electionTimeout:5122ms
2019-09-19 16:50:46,952 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown FollowerState
2019-09-19 16:50:46,952 [Thread-214] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:46,952 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderElection
2019-09-19 16:50:46,983 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2: begin an election at term 1 for -1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null
2019-09-19 16:50:46,985 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown LeaderElection
2019-09-19 16:50:46,985 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:46,985 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C change Leader from null to 5a3ee61b-140e-4199-b942-69cb3515ef3d at term 1 for becomeLeader, leader elected after 5164ms
2019-09-19 16:50:46,987 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:46,987 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:46,987 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:46,988 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:46,988 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:46,988 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:46,988 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderState
2019-09-19 16:50:46,989 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c: Starting segment from index:0
2019-09-19 16:50:46,989 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-C6DC1A38C79C set configuration 0: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null at 0
2019-09-19 16:50:47,046 [6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/d4f8b453-7151-46a2-91df-366f76cb3580/current/log_inprogress_0
2019-09-19 16:50:47,046 [5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/12982e67-1abd-429e-ad48-c6dc1a38c79c/current/log_inprogress_0
2019-09-19 16:50:47,065 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 changes to CANDIDATE, lastRpcTime:5154, electionTimeout:5154ms
2019-09-19 16:50:47,068 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown FollowerState
2019-09-19 16:50:47,068 [Thread-217] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,068 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderElection
2019-09-19 16:50:47,086 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3: begin an election at term 1 for -1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null
2019-09-19 16:50:47,087 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown LeaderElection
2019-09-19 16:50:47,087 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,087 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 change Leader from null to 6fd479a2-5728-477d-9065-d2b622b80b85 at term 1 for becomeLeader, leader elected after 5181ms
2019-09-19 16:50:47,088 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,088 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,088 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,088 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,088 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,088 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,089 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderState
2019-09-19 16:50:47,089 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36: Starting segment from index:0
2019-09-19 16:50:47,089 [6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-FFF24DCD1F36 set configuration 0: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null at 0
2019-09-19 16:50:47,123 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 changes to CANDIDATE, lastRpcTime:5111, electionTimeout:5078ms
2019-09-19 16:50:47,123 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown FollowerState
2019-09-19 16:50:47,123 [Thread-220] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,123 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderElection
2019-09-19 16:50:47,135 [6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/80634a0e-ae57-4848-8516-fff24dcd1f36/current/log_inprogress_0
2019-09-19 16:50:47,135 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4: begin an election at term 1 for -1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null
2019-09-19 16:50:47,136 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown LeaderElection
2019-09-19 16:50:47,136 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,136 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 change Leader from null to 18ae6263-d76c-4059-8eaf-4f5e3148b226 at term 1 for becomeLeader, leader elected after 5136ms
2019-09-19 16:50:47,138 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,138 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,138 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,138 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,139 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,139 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,139 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderState
2019-09-19 16:50:47,139 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180: Starting segment from index:0
2019-09-19 16:50:47,140 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-27C651FA0180 set configuration 0: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null at 0
2019-09-19 16:50:47,192 [18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/af0c61aa-ba58-488f-9e79-27c651fa0180/current/log_inprogress_0
2019-09-19 16:50:47,204 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 changes to CANDIDATE, lastRpcTime:5106, electionTimeout:5106ms
2019-09-19 16:50:47,204 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown FollowerState
2019-09-19 16:50:47,204 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,205 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderElection
2019-09-19 16:50:47,225 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5: begin an election at term 1 for -1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null
2019-09-19 16:50:47,227 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown LeaderElection
2019-09-19 16:50:47,227 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,227 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 change Leader from null to 5a3ee61b-140e-4199-b942-69cb3515ef3d at term 1 for becomeLeader, leader elected after 5133ms
2019-09-19 16:50:47,228 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,228 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,228 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,228 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,228 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,229 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,229 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderState
2019-09-19 16:50:47,230 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541: Starting segment from index:0
2019-09-19 16:50:47,230 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-D8CA64E41541 set configuration 0: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null at 0
2019-09-19 16:50:47,278 [5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/5fe0751b-5e20-4dcf-9a75-d8ca64e41541/current/log_inprogress_0
2019-09-19 16:50:47,314 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:47,317 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:47,336 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 changes to CANDIDATE, lastRpcTime:5155, electionTimeout:5155ms
2019-09-19 16:50:47,336 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown FollowerState
2019-09-19 16:50:47,336 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,337 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderElection
2019-09-19 16:50:47,343 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:47,367 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6: begin an election at term 1 for -1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null
2019-09-19 16:50:47,369 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown LeaderElection
2019-09-19 16:50:47,369 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,369 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 change Leader from null to 18ae6263-d76c-4059-8eaf-4f5e3148b226 at term 1 for becomeLeader, leader elected after 5192ms
2019-09-19 16:50:47,369 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,369 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,370 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,370 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,370 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,370 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,371 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderState
2019-09-19 16:50:47,371 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411: Starting segment from index:0
2019-09-19 16:50:47,372 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-34CB2F4BD411 set configuration 0: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null at 0
2019-09-19 16:50:47,422 [Thread-234] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 changes to CANDIDATE, lastRpcTime:5090, electionTimeout:5088ms
2019-09-19 16:50:47,422 [Thread-234] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown FollowerState
2019-09-19 16:50:47,422 [Thread-234] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,422 [Thread-234] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderElection
2019-09-19 16:50:47,429 [18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/251cc331-869b-4e2a-bf1a-34cb2f4bd411/current/log_inprogress_0
2019-09-19 16:50:47,430 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:47,432 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7: begin an election at term 1 for -1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null
2019-09-19 16:50:47,432 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown LeaderElection
2019-09-19 16:50:47,432 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,432 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 change Leader from null to 6fd479a2-5728-477d-9065-d2b622b80b85 at term 1 for becomeLeader, leader elected after 5104ms
2019-09-19 16:50:47,432 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,432 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,433 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,433 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,433 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,433 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,433 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderState
2019-09-19 16:50:47,434 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2: Starting segment from index:0
2019-09-19 16:50:47,434 [6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-39F997D43FF2 set configuration 0: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null at 0
2019-09-19 16:50:47,477 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C changes to CANDIDATE, lastRpcTime:5221, electionTimeout:5196ms
2019-09-19 16:50:47,479 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown FollowerState
2019-09-19 16:50:47,479 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,479 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderElection
2019-09-19 16:50:47,490 [6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/52c59cc7-af56-43c7-b36d-39f997d43ff2/current/log_inprogress_0
2019-09-19 16:50:47,490 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8: begin an election at term 1 for -1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null
2019-09-19 16:50:47,490 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown LeaderElection
2019-09-19 16:50:47,491 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,491 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C change Leader from null to e437f173-6a54-4062-88a9-cae9a5018cc4 at term 1 for becomeLeader, leader elected after 5241ms
2019-09-19 16:50:47,492 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,492 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,493 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,493 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,493 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,493 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,494 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderState
2019-09-19 16:50:47,494 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c: Starting segment from index:0
2019-09-19 16:50:47,495 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-5363C6BE4C4C set configuration 0: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null at 0
2019-09-19 16:50:47,534 [Thread-243] INFO  impl.FollowerState (FollowerState.java:run(106)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 changes to CANDIDATE, lastRpcTime:5044, electionTimeout:5042ms
2019-09-19 16:50:47,535 [Thread-243] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown FollowerState
2019-09-19 16:50:47,535 [Thread-243] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,535 [Thread-243] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderElection
2019-09-19 16:50:47,548 [e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1fcd285c-2d6a-4538-be1f-5363c6be4c4c/current/log_inprogress_0
2019-09-19 16:50:47,548 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9: begin an election at term 1 for -1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null
2019-09-19 16:50:47,548 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown LeaderElection
2019-09-19 16:50:47,549 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,549 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 change Leader from null to e437f173-6a54-4062-88a9-cae9a5018cc4 at term 1 for becomeLeader, leader elected after 5071ms
2019-09-19 16:50:47,549 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,549 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,549 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,549 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,550 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,550 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,550 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderState
2019-09-19 16:50:47,550 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342: Starting segment from index:0
2019-09-19 16:50:47,551 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-8C4F7D23B342 set configuration 0: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null at 0
2019-09-19 16:50:47,590 [Thread-238] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE changes to CANDIDATE, lastRpcTime:5186, electionTimeout:5165ms
2019-09-19 16:50:47,599 [e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d751dc99-2dc4-4e2b-861c-8c4f7d23b342/current/log_inprogress_0
2019-09-19 16:50:47,599 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown FollowerState
2019-09-19 16:50:47,599 [Thread-238] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,599 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderElection
2019-09-19 16:50:47,605 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:47,612 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10: begin an election at term 1 for -1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null
2019-09-19 16:50:47,612 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown LeaderElection
2019-09-19 16:50:47,612 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,612 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE change Leader from null to 6fd479a2-5728-477d-9065-d2b622b80b85 at term 1 for becomeLeader, leader elected after 5213ms
2019-09-19 16:50:47,613 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,613 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,613 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,613 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,613 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,614 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,614 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderState
2019-09-19 16:50:47,614 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae: Starting segment from index:0
2019-09-19 16:50:47,615 [6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-A9CBAD69C1AE set configuration 0: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null at 0
2019-09-19 16:50:47,682 [6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/60341465-0897-4ad3-9650-a9cbad69c1ae/current/log_inprogress_0
2019-09-19 16:50:47,747 [Thread-247] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 changes to CANDIDATE, lastRpcTime:5174, electionTimeout:5174ms
2019-09-19 16:50:47,747 [Thread-247] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown FollowerState
2019-09-19 16:50:47,747 [Thread-247] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,747 [Thread-247] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderElection
2019-09-19 16:50:47,764 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D changes to CANDIDATE, lastRpcTime:5114, electionTimeout:5114ms
2019-09-19 16:50:47,764 [Thread-254] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown FollowerState
2019-09-19 16:50:47,764 [Thread-254] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,764 [Thread-254] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderElection
2019-09-19 16:50:47,771 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11: begin an election at term 1 for -1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null
2019-09-19 16:50:47,771 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown LeaderElection
2019-09-19 16:50:47,771 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,772 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 change Leader from null to 5a3ee61b-140e-4199-b942-69cb3515ef3d at term 1 for becomeLeader, leader elected after 5203ms
2019-09-19 16:50:47,772 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,772 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,773 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,773 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,773 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,773 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,774 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderState
2019-09-19 16:50:47,774 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962: Starting segment from index:0
2019-09-19 16:50:47,775 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-EBB665818962 set configuration 0: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null at 0
2019-09-19 16:50:47,811 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 changes to CANDIDATE, lastRpcTime:5098, electionTimeout:5091ms
2019-09-19 16:50:47,812 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12: begin an election at term 1 for -1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null
2019-09-19 16:50:47,812 [Thread-261] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown FollowerState
2019-09-19 16:50:47,812 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown LeaderElection
2019-09-19 16:50:47,812 [Thread-261] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,812 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,812 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D change Leader from null to 18ae6263-d76c-4059-8eaf-4f5e3148b226 at term 1 for becomeLeader, leader elected after 5172ms
2019-09-19 16:50:47,812 [Thread-261] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderElection
2019-09-19 16:50:47,813 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,813 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,818 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,818 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,818 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,819 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,819 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderState
2019-09-19 16:50:47,819 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d: Starting segment from index:0
2019-09-19 16:50:47,820 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A5C6C8EC658D set configuration 0: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null at 0
2019-09-19 16:50:47,852 [5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/a779824c-372d-4b11-913e-ebb665818962/current/log_inprogress_0
2019-09-19 16:50:47,852 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13: begin an election at term 1 for -1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null
2019-09-19 16:50:47,852 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown LeaderElection
2019-09-19 16:50:47,853 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,853 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 change Leader from null to 5a3ee61b-140e-4199-b942-69cb3515ef3d at term 1 for becomeLeader, leader elected after 5145ms
2019-09-19 16:50:47,853 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,853 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,854 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,854 [Thread-273] INFO  impl.FollowerState (FollowerState.java:run(106)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 changes to CANDIDATE, lastRpcTime:5053, electionTimeout:5038ms
2019-09-19 16:50:47,854 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,854 [Thread-273] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown FollowerState
2019-09-19 16:50:47,855 [Thread-273] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,855 [Thread-273] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderElection
2019-09-19 16:50:47,854 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,859 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,862 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderState
2019-09-19 16:50:47,863 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150: Starting segment from index:0
2019-09-19 16:50:47,863 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-319FCD2B7150 set configuration 0: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null at 0
2019-09-19 16:50:47,901 [18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/3efcb5aa-e904-4726-bfd0-a5c6c8ec658d/current/log_inprogress_0
2019-09-19 16:50:47,901 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14: begin an election at term 1 for -1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null
2019-09-19 16:50:47,901 [Thread-276] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 changes to CANDIDATE, lastRpcTime:5043, electionTimeout:5025ms
2019-09-19 16:50:47,901 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown LeaderElection
2019-09-19 16:50:47,901 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown FollowerState
2019-09-19 16:50:47,902 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,902 [Thread-276] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:47,902 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 change Leader from null to e437f173-6a54-4062-88a9-cae9a5018cc4 at term 1 for becomeLeader, leader elected after 5105ms
2019-09-19 16:50:47,902 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderElection
2019-09-19 16:50:47,902 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,904 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,907 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,907 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,907 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,908 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,908 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderState
2019-09-19 16:50:47,908 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7: Starting segment from index:0
2019-09-19 16:50:47,909 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-4457C9B016D7 set configuration 0: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null at 0
2019-09-19 16:50:47,948 [5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/0e2beae4-fee4-4348-afa5-319fcd2b7150/current/log_inprogress_0
2019-09-19 16:50:47,948 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15: begin an election at term 1 for -1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null
2019-09-19 16:50:47,948 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown LeaderElection
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 change Leader from null to 18ae6263-d76c-4059-8eaf-4f5e3148b226 at term 1 for becomeLeader, leader elected after 5094ms
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:47,949 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:47,950 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:47,950 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderState
2019-09-19 16:50:47,950 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7: Starting segment from index:0
2019-09-19 16:50:47,951 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-4E0F1CE772A7 set configuration 0: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null at 0
2019-09-19 16:50:47,987 [e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/734a19d6-aadc-4fbc-b681-4457c9b016d7/current/log_inprogress_0
2019-09-19 16:50:48,011 [18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/9a39c600-2d16-465d-a799-4e0f1ce772a7/current/log_inprogress_0
2019-09-19 16:50:48,085 [Thread-297] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 changes to CANDIDATE, lastRpcTime:5009, electionTimeout:5009ms
2019-09-19 16:50:48,085 [Thread-297] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown FollowerState
2019-09-19 16:50:48,085 [Thread-297] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,085 [Thread-297] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderElection
2019-09-19 16:50:48,105 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16: begin an election at term 1 for -1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null
2019-09-19 16:50:48,105 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown LeaderElection
2019-09-19 16:50:48,105 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,105 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 change Leader from null to 6fd479a2-5728-477d-9065-d2b622b80b85 at term 1 for becomeLeader, leader elected after 5037ms
2019-09-19 16:50:48,105 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,106 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,106 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,106 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,106 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,107 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,107 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderState
2019-09-19 16:50:48,107 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639: Starting segment from index:0
2019-09-19 16:50:48,108 [6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-BB2E2BCB1639 set configuration 0: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null at 0
2019-09-19 16:50:48,151 [Thread-286] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 changes to CANDIDATE, lastRpcTime:5195, electionTimeout:5183ms
2019-09-19 16:50:48,151 [Thread-289] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD changes to CANDIDATE, lastRpcTime:5141, electionTimeout:5107ms
2019-09-19 16:50:48,151 [Thread-286] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown FollowerState
2019-09-19 16:50:48,151 [Thread-289] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown FollowerState
2019-09-19 16:50:48,151 [Thread-286] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,151 [Thread-289] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,152 [Thread-286] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderElection
2019-09-19 16:50:48,152 [Thread-289] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderElection
2019-09-19 16:50:48,163 [6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/de27293f-759e-45e9-a4ba-bb2e2bcb1639/current/log_inprogress_0
2019-09-19 16:50:48,175 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17: begin an election at term 1 for -1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null
2019-09-19 16:50:48,175 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18: begin an election at term 1 for -1: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null
2019-09-19 16:50:48,176 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown LeaderElection
2019-09-19 16:50:48,176 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6fd479a2-5728-477d-9065-d2b622b80b85: shutdown LeaderElection
2019-09-19 16:50:48,176 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,176 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,176 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 change Leader from null to 5a3ee61b-140e-4199-b942-69cb3515ef3d at term 1 for becomeLeader, leader elected after 5226ms
2019-09-19 16:50:48,176 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD change Leader from null to 6fd479a2-5728-477d-9065-d2b622b80b85 at term 1 for becomeLeader, leader elected after 5173ms
2019-09-19 16:50:48,176 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,177 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,177 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,177 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,177 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,177 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,177 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,178 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,178 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,178 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,178 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,178 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,179 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderState
2019-09-19 16:50:48,179 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6fd479a2-5728-477d-9065-d2b622b80b85: start LeaderState
2019-09-19 16:50:48,179 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1: Starting segment from index:0
2019-09-19 16:50:48,179 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd: Starting segment from index:0
2019-09-19 16:50:48,180 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-802DD26E27A1 set configuration 0: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null at 0
2019-09-19 16:50:48,180 [6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6fd479a2-5728-477d-9065-d2b622b80b85:group-469CCD9AF2CD set configuration 0: [6fd479a2-5728-477d-9065-d2b622b80b85:192.168.157.226:33726], old=null at 0
2019-09-19 16:50:48,234 [5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/77957b02-543c-4a43-8875-802dd26e27a1/current/log_inprogress_0
2019-09-19 16:50:48,235 [6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6fd479a2-5728-477d-9065-d2b622b80b85-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-0/data/ratis/9cabc86e-e946-4c16-9d9b-469ccd9af2cd/current/log_inprogress_0
2019-09-19 16:50:48,283 [Thread-306] INFO  impl.FollowerState (FollowerState.java:run(106)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 changes to CANDIDATE, lastRpcTime:5143, electionTimeout:5143ms
2019-09-19 16:50:48,283 [Thread-306] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown FollowerState
2019-09-19 16:50:48,283 [Thread-306] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,283 [Thread-306] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderElection
2019-09-19 16:50:48,302 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19: begin an election at term 1 for -1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null
2019-09-19 16:50:48,302 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown LeaderElection
2019-09-19 16:50:48,303 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,303 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 change Leader from null to e437f173-6a54-4062-88a9-cae9a5018cc4 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-19 16:50:48,303 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,303 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,304 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,304 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,304 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,304 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,305 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderState
2019-09-19 16:50:48,305 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117: Starting segment from index:0
2019-09-19 16:50:48,306 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-CD4340813117 set configuration 0: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null at 0
2019-09-19 16:50:48,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:48,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:48,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:48,372 [e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/a2d7f562-8598-41d2-a5b7-cd4340813117/current/log_inprogress_0
2019-09-19 16:50:48,375 [Thread-313] INFO  impl.FollowerState (FollowerState.java:run(106)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 changes to CANDIDATE, lastRpcTime:5165, electionTimeout:5165ms
2019-09-19 16:50:48,375 [Thread-313] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown FollowerState
2019-09-19 16:50:48,375 [Thread-313] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,376 [Thread-313] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderElection
2019-09-19 16:50:48,401 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20: begin an election at term 1 for -1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null
2019-09-19 16:50:48,401 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown LeaderElection
2019-09-19 16:50:48,401 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,401 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 change Leader from null to e437f173-6a54-4062-88a9-cae9a5018cc4 at term 1 for becomeLeader, leader elected after 5196ms
2019-09-19 16:50:48,402 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,402 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,402 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,402 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,402 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,403 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,403 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderState
2019-09-19 16:50:48,403 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752: Starting segment from index:0
2019-09-19 16:50:48,404 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-C9199B074752 set configuration 0: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null at 0
2019-09-19 16:50:48,456 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:48,460 [Thread-321] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D changes to CANDIDATE, lastRpcTime:5183, electionTimeout:5183ms
2019-09-19 16:50:48,460 [Thread-321] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown FollowerState
2019-09-19 16:50:48,460 [Thread-321] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,461 [Thread-321] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderElection
2019-09-19 16:50:48,468 [Thread-339] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 changes to CANDIDATE, lastRpcTime:5085, electionTimeout:5085ms
2019-09-19 16:50:48,468 [Thread-339] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown FollowerState
2019-09-19 16:50:48,468 [Thread-339] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,468 [Thread-339] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderElection
2019-09-19 16:50:48,470 [e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/1cd0eb5b-066d-4b8c-ad72-c9199b074752/current/log_inprogress_0
2019-09-19 16:50:48,471 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21: begin an election at term 1 for -1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null
2019-09-19 16:50:48,471 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown LeaderElection
2019-09-19 16:50:48,471 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,471 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D change Leader from null to 18ae6263-d76c-4059-8eaf-4f5e3148b226 at term 1 for becomeLeader, leader elected after 5197ms
2019-09-19 16:50:48,471 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,472 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,472 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,472 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,472 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,473 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,473 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderState
2019-09-19 16:50:48,473 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d: Starting segment from index:0
2019-09-19 16:50:48,474 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-8B443A60BB5D set configuration 0: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null at 0
2019-09-19 16:50:48,515 [Thread-329] INFO  impl.FollowerState (FollowerState.java:run(106)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 changes to CANDIDATE, lastRpcTime:5182, electionTimeout:5165ms
2019-09-19 16:50:48,515 [Thread-349] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5046ms
2019-09-19 16:50:48,515 [Thread-329] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown FollowerState
2019-09-19 16:50:48,515 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22: begin an election at term 1 for -1: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null
2019-09-19 16:50:48,515 [Thread-329] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,515 [Thread-349] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown FollowerState
2019-09-19 16:50:48,516 [Thread-329] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderElection
2019-09-19 16:50:48,515 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: shutdown LeaderElection
2019-09-19 16:50:48,516 [Thread-349] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,516 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,516 [Thread-349] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderElection
2019-09-19 16:50:48,518 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 change Leader from null to 18ae6263-d76c-4059-8eaf-4f5e3148b226 at term 1 for becomeLeader, leader elected after 5138ms
2019-09-19 16:50:48,519 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,521 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,521 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,521 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,521 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,522 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,522 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226: start LeaderState
2019-09-19 16:50:48,522 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9: Starting segment from index:0
2019-09-19 16:50:48,523 [18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226:group-A69C18C43FE9 set configuration 0: [18ae6263-d76c-4059-8eaf-4f5e3148b226:192.168.157.226:41809], old=null at 0
2019-09-19 16:50:48,558 [18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/e2b5a851-5642-4dc3-a2f5-8b443a60bb5d/current/log_inprogress_0
2019-09-19 16:50:48,558 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23: begin an election at term 1 for -1: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null
2019-09-19 16:50:48,558 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24: begin an election at term 1 for -1: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null
2019-09-19 16:50:48,559 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e437f173-6a54-4062-88a9-cae9a5018cc4: shutdown LeaderElection
2019-09-19 16:50:48,559 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: shutdown LeaderElection
2019-09-19 16:50:48,559 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,559 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,559 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 change Leader from null to e437f173-6a54-4062-88a9-cae9a5018cc4 at term 1 for becomeLeader, leader elected after 5231ms
2019-09-19 16:50:48,559 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 change Leader from null to 5a3ee61b-140e-4199-b942-69cb3515ef3d at term 1 for becomeLeader, leader elected after 5129ms
2019-09-19 16:50:48,560 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,560 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,560 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,560 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,560 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,560 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,561 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,561 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,561 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,561 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,561 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,562 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,562 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e437f173-6a54-4062-88a9-cae9a5018cc4: start LeaderState
2019-09-19 16:50:48,562 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d: start LeaderState
2019-09-19 16:50:48,562 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8: Starting segment from index:0
2019-09-19 16:50:48,562 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4: Starting segment from index:0
2019-09-19 16:50:48,563 [e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e437f173-6a54-4062-88a9-cae9a5018cc4:group-76E3D31CEAC8 set configuration 0: [e437f173-6a54-4062-88a9-cae9a5018cc4:192.168.157.226:36244], old=null at 0
2019-09-19 16:50:48,606 [18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18ae6263-d76c-4059-8eaf-4f5e3148b226-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-2/data/ratis/331db2a9-b357-4f4d-9507-a69c18c43fe9/current/log_inprogress_0
2019-09-19 16:50:48,606 [5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d:group-919626DA8EC4 set configuration 0: [5a3ee61b-140e-4199-b942-69cb3515ef3d:192.168.157.226:34145], old=null at 0
2019-09-19 16:50:48,647 [e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e437f173-6a54-4062-88a9-cae9a5018cc4-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-3/data/ratis/d31c33c3-9393-45ac-82f7-76e3d31ceac8/current/log_inprogress_0
2019-09-19 16:50:48,648 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:48,660 [5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a3ee61b-140e-4199-b942-69cb3515ef3d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-1/data/ratis/aeeeff5b-79f8-4c14-8732-919626da8ec4/current/log_inprogress_0
2019-09-19 16:50:48,693 [Thread-352] INFO  impl.FollowerState (FollowerState.java:run(106)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F changes to CANDIDATE, lastRpcTime:5180, electionTimeout:5180ms
2019-09-19 16:50:48,693 [Thread-352] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown FollowerState
2019-09-19 16:50:48,694 [Thread-352] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,694 [Thread-352] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderElection
2019-09-19 16:50:48,710 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25: begin an election at term 1 for -1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null
2019-09-19 16:50:48,710 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown LeaderElection
2019-09-19 16:50:48,710 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,710 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F change Leader from null to f763b2c0-c12b-45c9-b18c-74b12c137ba3 at term 1 for becomeLeader, leader elected after 5203ms
2019-09-19 16:50:48,712 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,712 [Thread-355] INFO  impl.FollowerState (FollowerState.java:run(106)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 changes to CANDIDATE, lastRpcTime:5146, electionTimeout:5146ms
2019-09-19 16:50:48,713 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,713 [Thread-355] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown FollowerState
2019-09-19 16:50:48,713 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,713 [Thread-355] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,713 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,714 [Thread-355] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderElection
2019-09-19 16:50:48,714 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,714 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,716 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderState
2019-09-19 16:50:48,716 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f: Starting segment from index:0
2019-09-19 16:50:48,717 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-0A7960E0436F set configuration 0: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null at 0
2019-09-19 16:50:48,757 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26: begin an election at term 1 for -1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null
2019-09-19 16:50:48,758 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown LeaderElection
2019-09-19 16:50:48,758 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,758 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 change Leader from null to f763b2c0-c12b-45c9-b18c-74b12c137ba3 at term 1 for becomeLeader, leader elected after 5196ms
2019-09-19 16:50:48,758 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,759 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,759 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,759 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,759 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,760 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,760 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderState
2019-09-19 16:50:48,760 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4: Starting segment from index:0
2019-09-19 16:50:48,761 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-39EC1FCAB3C4 set configuration 0: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null at 0
2019-09-19 16:50:48,802 [f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/9f1069f3-bc9c-405f-abcd-0a7960e0436f/current/log_inprogress_0
2019-09-19 16:50:48,802 [Thread-360] INFO  impl.FollowerState (FollowerState.java:run(106)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED changes to CANDIDATE, lastRpcTime:5184, electionTimeout:5168ms
2019-09-19 16:50:48,802 [Thread-360] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown FollowerState
2019-09-19 16:50:48,803 [Thread-360] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,803 [Thread-360] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderElection
2019-09-19 16:50:48,805 [Thread-373] INFO  impl.FollowerState (FollowerState.java:run(106)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5079ms
2019-09-19 16:50:48,805 [Thread-373] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown FollowerState
2019-09-19 16:50:48,805 [Thread-373] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,806 [Thread-373] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderElection
2019-09-19 16:50:48,808 [Thread-365] INFO  impl.FollowerState (FollowerState.java:run(106)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 changes to CANDIDATE, lastRpcTime:5140, electionTimeout:5140ms
2019-09-19 16:50:48,809 [Thread-365] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown FollowerState
2019-09-19 16:50:48,809 [Thread-365] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,809 [Thread-365] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderElection
2019-09-19 16:50:48,816 [f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/3896a833-2bd9-498d-a968-39ec1fcab3c4/current/log_inprogress_0
2019-09-19 16:50:48,816 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27: begin an election at term 1 for -1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null
2019-09-19 16:50:48,816 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28: begin an election at term 1 for -1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null
2019-09-19 16:50:48,816 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29: begin an election at term 1 for -1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null
2019-09-19 16:50:48,817 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown LeaderElection
2019-09-19 16:50:48,817 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,817 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown LeaderElection
2019-09-19 16:50:48,817 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 change Leader from null to f763b2c0-c12b-45c9-b18c-74b12c137ba3 at term 1 for becomeLeader, leader elected after 5097ms
2019-09-19 16:50:48,817 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown LeaderElection
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED change Leader from null to f763b2c0-c12b-45c9-b18c-74b12c137ba3 at term 1 for becomeLeader, leader elected after 5204ms
2019-09-19 16:50:48,819 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,818 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 change Leader from null to f763b2c0-c12b-45c9-b18c-74b12c137ba3 at term 1 for becomeLeader, leader elected after 5154ms
2019-09-19 16:50:48,819 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,819 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,819 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,819 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,819 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderState
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20: Starting segment from index:0
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,820 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,821 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,821 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-010DBAC00C20 set configuration 0: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null at 0
2019-09-19 16:50:48,821 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,821 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderState
2019-09-19 16:50:48,864 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,864 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3: Starting segment from index:0
2019-09-19 16:50:48,864 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderState
2019-09-19 16:50:48,865 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed: Starting segment from index:0
2019-09-19 16:50:48,865 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-2CE0B52551B3 set configuration 0: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null at 0
2019-09-19 16:50:48,909 [f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/c7ea30dd-e1fe-44f7-a383-010dbac00c20/current/log_inprogress_0
2019-09-19 16:50:48,909 [Thread-376] INFO  impl.FollowerState (FollowerState.java:run(106)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A changes to CANDIDATE, lastRpcTime:5121, electionTimeout:5088ms
2019-09-19 16:50:48,910 [Thread-376] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown FollowerState
2019-09-19 16:50:48,909 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-865F19210AED set configuration 0: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null at 0
2019-09-19 16:50:48,910 [Thread-376] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 16:50:48,951 [f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/2adceafd-2af5-46c0-97f2-2ce0b52551b3/current/log_inprogress_0
2019-09-19 16:50:48,952 [Thread-376] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderElection
2019-09-19 16:50:48,952 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:48,961 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:48,962 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:48,962 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:48,962 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:48,962 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:48,963 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:48,963 [IPC Server handler 3 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:48,963 [IPC Server handler 3 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:48,964 [IPC Server handler 3 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:48,964 [IPC Server handler 3 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:48,964 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:48,966 [f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/7276e335-0113-4af7-b0b7-865f19210aed/current/log_inprogress_0
2019-09-19 16:50:48,966 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30: begin an election at term 1 for -1: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null
2019-09-19 16:50:48,967 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: shutdown LeaderElection
2019-09-19 16:50:48,967 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 16:50:48,967 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:48,967 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A change Leader from null to f763b2c0-c12b-45c9-b18c-74b12c137ba3 at term 1 for becomeLeader, leader elected after 5186ms
2019-09-19 16:50:48,968 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 16:50:48,968 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 16:50:48,968 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 16:50:48,969 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 16:50:48,969 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 16:50:48,969 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 16:50:48,969 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3: start LeaderState
2019-09-19 16:50:48,970 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a: Starting segment from index:0
2019-09-19 16:50:48,970 [f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3:group-D35F78DF511A set configuration 0: [f763b2c0-c12b-45c9-b18c-74b12c137ba3:192.168.157.226:34759], old=null at 0
2019-09-19 16:50:48,970 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:49,015 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000000_0
2019-09-19 16:50:49,015 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:49,016 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 --> o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:50:49,025 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000001_0
2019-09-19 16:50:49,028 [f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f763b2c0-c12b-45c9-b18c-74b12c137ba3-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-c17f71ef-ee47-4324-a3fc-f9e48ab63aea/datanode-4/data/ratis/f0a0c40f-fa8f-41a4-93af-d35f78df511a/current/log_inprogress_0
2019-09-19 16:50:49,029 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:49,030 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:49,031 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:50:49,032 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:0+327
2019-09-19 16:50:49,034 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:49,034 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:49,057 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:49,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-19 16:50:49,067 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:49,073 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:49,080 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:50:49,093 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local81299712_0001_m_000001_0 is done. And is in the process of committing
2019-09-19 16:50:49,095 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:50:49,095 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local81299712_0001_m_000001_0 is allowed to commit now
2019-09-19 16:50:49,098 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local81299712_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/_logs
2019-09-19 16:50:49,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-19 16:50:49,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local81299712_0001_m_000001_0' done.
2019-09-19 16:50:49,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local81299712_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=208735
		FILE: Number of bytes written=820575
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:50:49,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local81299712_0001_m_000001_0
2019-09-19 16:50:49,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:49,108 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:49,108 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:49,109 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:50:49,110 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:327+293
2019-09-19 16:50:49,110 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:49,111 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:49,131 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:49,132 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-19 16:50:49,140 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:49,141 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:49,144 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:49,144 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:49,145 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:49,145 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:49,145 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:49,145 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:49,145 [IPC Server handler 6 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:49,145 [IPC Server handler 6 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:49,146 [IPC Server handler 6 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:49,146 [IPC Server handler 6 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:49,146 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:49,146 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:49,148 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:49,155 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:49,156 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:49,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:49,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:49,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:49,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:49,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:49,814 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 16:50:50,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:50,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:50,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:50,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:50,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:50,855 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:50,861 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:50,862 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:50,862 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:50,862 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:50,862 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:50,863 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:50,863 [IPC Server handler 3 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:50,863 [IPC Server handler 3 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:50,864 [IPC Server handler 3 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:50,864 [IPC Server handler 3 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:50,864 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:50,865 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:50,869 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:50,870 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:50,870 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:51,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:51,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:51,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:51,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:51,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:52,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:52,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:52,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:52,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:52,606 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:53,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:53,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:53,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:53,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:53,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:54,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:54,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:54,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:54,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:54,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:55,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:55,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:55,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:55,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:55,491 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:55,497 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,498 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,498 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,498 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,498 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,499 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:55,499 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:55,499 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:55,500 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:55,500 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:55,500 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:55,501 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:55,507 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:55,510 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000002_0
2019-09-19 16:50:55,510 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:55,511 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:50:55,512 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000003_0
2019-09-19 16:50:55,525 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:55,525 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:55,526 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:50:55,529 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:620+281
2019-09-19 16:50:55,529 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:55,530 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:55,553 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:55,554 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 16:50:55,563 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:55,566 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:55,568 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:50:55,568 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local81299712_0001_m_000003_0 is done. And is in the process of committing
2019-09-19 16:50:55,569 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:50:55,569 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local81299712_0001_m_000003_0 is allowed to commit now
2019-09-19 16:50:55,571 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local81299712_0001_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/_logs
2019-09-19 16:50:55,571 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 16:50:55,571 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local81299712_0001_m_000003_0' done.
2019-09-19 16:50:55,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local81299712_0001_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=217947
		FILE: Number of bytes written=820591
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=18
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:50:55,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local81299712_0001_m_000003_0
2019-09-19 16:50:55,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000004_0
2019-09-19 16:50:55,574 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:55,574 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:55,574 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:50:55,575 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:1708+281
2019-09-19 16:50:55,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:55,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:55,596 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:55,597 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 16:50:55,604 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:55,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:55,611 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:55,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:50:55,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local81299712_0001_m_000004_0 is done. And is in the process of committing
2019-09-19 16:50:55,613 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:50:55,613 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local81299712_0001_m_000004_0 is allowed to commit now
2019-09-19 16:50:55,614 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local81299712_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/_logs
2019-09-19 16:50:55,615 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 16:50:55,615 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local81299712_0001_m_000004_0' done.
2019-09-19 16:50:55,616 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local81299712_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=222041
		FILE: Number of bytes written=820599
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=20
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:50:55,616 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local81299712_0001_m_000004_0
2019-09-19 16:50:55,616 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000005_0
2019-09-19 16:50:55,617 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:55,617 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:55,617 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:50:55,618 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:1166+277
2019-09-19 16:50:55,619 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:50:55,619 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:50:55,638 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:50:55,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
2019-09-19 16:50:55,647 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:55,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
2019-09-19 16:50:55,652 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,653 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,653 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,653 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,653 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:55,654 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:55,654 [IPC Server handler 3 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:55,654 [IPC Server handler 3 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:55,654 [IPC Server handler 3 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:55,655 [IPC Server handler 3 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:55,655 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:55,656 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:55,659 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:55,660 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
2019-09-19 16:50:55,660 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:55,948 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-19 16:50:56,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:56,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:56,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:56,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:56,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:56,819 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 37% reduce 0%
2019-09-19 16:50:57,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:57,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:57,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:57,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:57,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:58,322 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
2019-09-19 16:50:58,328 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:58,329 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:58,329 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:58,329 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:58,329 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:50:58,329 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:58,330 [IPC Server handler 2 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:50:58,330 [IPC Server handler 2 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:50:58,330 [IPC Server handler 2 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:50:58,331 [IPC Server handler 2 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:50:58,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:50:58,332 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:50:58,336 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:50:58,340 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
2019-09-19 16:50:58,340 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:50:58,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:58,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:58,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:58,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:58,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:59,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:59,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:59,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:59,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:50:59,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:00,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:00,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:00,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:00,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:00,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:01,133 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 16:51:01,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:01,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:01,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:01,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:01,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:01,823 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 48% reduce 0%
2019-09-19 16:51:02,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:02,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:02,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:02,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:02,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:03,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:03,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:03,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:03,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:03,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:04,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
2019-09-19 16:51:04,149 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:04,149 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:04,150 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:04,150 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:04,150 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:04,150 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:04,151 [IPC Server handler 2 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:04,151 [IPC Server handler 2 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:04,152 [IPC Server handler 2 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:04,152 [IPC Server handler 2 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:04,152 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:04,153 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:04,173 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:04,175 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local81299712_0001_m_000005_0
2019-09-19 16:51:04,176 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:04,176 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:04,177 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000006_0
2019-09-19 16:51:04,179 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:04,179 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:04,180 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:04,181 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:901+265
2019-09-19 16:51:04,182 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:04,182 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:04,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,207 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-19 16:51:04,216 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,218 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,220 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:04,220 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local81299712_0001_m_000006_0 is done. And is in the process of committing
2019-09-19 16:51:04,221 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:04,221 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local81299712_0001_m_000006_0 is allowed to commit now
2019-09-19 16:51:04,223 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local81299712_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/_logs
2019-09-19 16:51:04,224 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-19 16:51:04,225 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local81299712_0001_m_000006_0' done.
2019-09-19 16:51:04,225 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local81299712_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=230229
		FILE: Number of bytes written=820615
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=27
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:04,226 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local81299712_0001_m_000006_0
2019-09-19 16:51:04,226 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000007_0
2019-09-19 16:51:04,227 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:04,227 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:04,228 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:04,229 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:1443+265
2019-09-19 16:51:04,229 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:04,230 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:04,251 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,252 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-19 16:51:04,261 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume60973 bucket: bucket48852 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:04,273 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:04,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local81299712_0001_m_000007_0 is done. And is in the process of committing
2019-09-19 16:51:04,276 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:04,277 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local81299712_0001_m_000007_0 is allowed to commit now
2019-09-19 16:51:04,278 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local81299712_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/_logs
2019-09-19 16:51:04,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-19 16:51:04,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local81299712_0001_m_000007_0' done.
2019-09-19 16:51:04,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local81299712_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=233811
		FILE: Number of bytes written=820623
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=29
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:04,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local81299712_0001_m_000007_0
2019-09-19 16:51:04,281 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local81299712_0001_m_000008_0
2019-09-19 16:51:04,282 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:04,282 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:04,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:04,284 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/fileList.seq:1989+265
2019-09-19 16:51:04,284 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:04,285 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:04,306 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,307 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-19 16:51:04,315 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:04,319 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local81299712_0001_m_000008_0 is done. And is in the process of committing
2019-09-19 16:51:04,320 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:04,320 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local81299712_0001_m_000008_0 is allowed to commit now
2019-09-19 16:51:04,322 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local81299712_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942/_logs
2019-09-19 16:51:04,322 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-19 16:51:04,323 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local81299712_0001_m_000008_0' done.
2019-09-19 16:51:04,323 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local81299712_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=237393
		FILE: Number of bytes written=820631
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=31
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:04,323 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local81299712_0001_m_000008_0
2019-09-19 16:51:04,324 [Thread-357] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 16:51:04,340 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,347 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:04,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:04,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:04,355 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,358 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,359 [Thread-357] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001254034877/.staging/_distcp1443750942
2019-09-19 16:51:04,360 [Thread-357] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local81299712_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 --> o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 --> o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket48852.volume60973/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:04,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:04,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:04,825 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 16:51:04,826 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local81299712_0001 failed with state FAILED due to: NA
2019-09-19 16:51:04,898 [Thread-208] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=1802426
		FILE: Number of bytes written=6564848
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=183
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=122
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1264
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16466837504
	File Input Format Counters 
		Bytes Read=25256
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-19 16:51:04,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,904 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,906 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume60973, bucket=bucket48852, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,909 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume60973, bucket=bucket48852, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 16:51:04,913 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,915 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,917 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,919 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,921 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,923 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume60973, bucket=bucket48852, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:04,924 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume60973, bucket=bucket48852, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
    <system-err><![CDATA[Sep 19, 2019 4:50:35 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 19, 2019 4:50:36 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 19, 2019 4:50:36 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 19, 2019 4:50:36 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 19, 2019 4:50:37 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 19, 2019 4:50:41 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
]]></system-err>
  </testcase>
  <testcase name="testTrackDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="26.825">
    <error message="DistCp failure: Job job_local1005015064_0002 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1005015064_0002 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testTrackDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-19 16:51:04,978 [Thread-481] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 16:51:04,982 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin82516, owner=user12235, volume=volume18257, creationTime=1568911864981, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 16:51:04,984 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume18257, bucket=bucket48587, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 16:51:05,056 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume18257} | ret=SUCCESS |  
2019-09-19 16:51:05,058 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume18257, bucket=bucket48587} | ret=SUCCESS |  
2019-09-19 16:51:05,059 [Thread-481] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket48587.volume18257 implemented by OzoneFileSystem{URI=o3fs://bucket48587.volume18257, workingDir=o3fs://bucket48587.volume18257/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 38 read ops, 0 large read ops, 20 write ops}
2019-09-19 16:51:05,061 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:05,076 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:05,079 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:05,081 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:05,085 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume18257, bucket=bucket48587, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:05,087 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:05,089 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume18257, bucket=bucket48587, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:05,091 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:05,094 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:05,095 [Thread-481] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-19 16:51:05,198 [Thread-481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:05,227 [Thread-481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:05,243 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:05,328 [Thread-481] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-19 16:51:05,331 [Thread-481] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 16:51:05,345 [Thread-481] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 16:51:05,354 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:05,354 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:05,354 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:05,366 [Thread-481] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 16:51:05,368 [Thread-481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:05,382 [Thread-481] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 16:51:05,447 [Thread-481] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-19 16:51:05,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:05,506 [Thread-481] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1005015064_0002
2019-09-19 16:51:05,506 [Thread-481] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 16:51:05,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:05,639 [Thread-481] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 16:51:05,641 [Thread-481] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1005015064_0002
2019-09-19 16:51:05,641 [Thread-544] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 16:51:05,642 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1005015064_0002
2019-09-19 16:51:05,642 [Thread-544] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:05,642 [Thread-544] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:05,642 [Thread-544] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 16:51:05,671 [Thread-544] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 16:51:05,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:05,673 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:05,673 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:05,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:05,675 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:2506+584
2019-09-19 16:51:05,675 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:05,676 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:05,703 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:05,704 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-19 16:51:05,711 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:05,712 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:05,716 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:05,716 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:05,716 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:05,717 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:05,717 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:05,717 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:05,717 [IPC Server handler 6 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:05,717 [IPC Server handler 6 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:05,718 [IPC Server handler 6 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:05,718 [IPC Server handler 6 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:05,718 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:05,719 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:05,721 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:05,722 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:05,722 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:06,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:06,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:06,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:06,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:06,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:06,642 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1005015064_0002 running in uber mode : false
2019-09-19 16:51:06,643 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 16:51:07,135 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 16:51:07,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:07,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:07,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:07,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:07,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:07,623 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-19 16:51:08,226 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:08,232 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:08,232 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:08,233 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:08,233 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:08,233 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:08,233 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:08,234 [IPC Server handler 18 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:08,234 [IPC Server handler 18 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:08,235 [IPC Server handler 18 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:08,235 [IPC Server handler 18 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:08,235 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:08,236 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:08,243 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:08,244 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:08,244 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:08,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:08,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:08,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:08,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:08,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:09,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:09,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:09,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:09,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:09,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:10,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:10,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:10,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:10,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:10,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:11,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:11,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:11,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:11,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:11,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:12,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:12,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:12,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:12,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:12,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:13,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:13,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:13,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:13,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:13,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:13,625 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-19 16:51:13,847 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:13,852 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,852 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,852 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,853 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,853 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,853 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:13,853 [IPC Server handler 2 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:13,854 [IPC Server handler 2 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:13,854 [IPC Server handler 2 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:13,854 [IPC Server handler 2 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:13,855 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:13,856 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:13,861 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:13,862 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000000_0
2019-09-19 16:51:13,862 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:13,862 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:13,864 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000001_0
2019-09-19 16:51:13,865 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:13,865 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:13,866 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:13,867 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:0+326
2019-09-19 16:51:13,868 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:13,868 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:13,891 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:13,892 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 16:51:13,898 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:13,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:13,902 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:13,903 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1005015064_0002_m_000001_0 is done. And is in the process of committing
2019-09-19 16:51:13,903 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:13,903 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1005015064_0002_m_000001_0 is allowed to commit now
2019-09-19 16:51:13,904 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1005015064_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/_logs
2019-09-19 16:51:13,905 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 16:51:13,905 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1005015064_0002_m_000001_0' done.
2019-09-19 16:51:13,906 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1005015064_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=446362
		FILE: Number of bytes written=1647388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=49
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=27
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:13,906 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1005015064_0002_m_000001_0
2019-09-19 16:51:13,906 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:13,907 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:13,907 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:13,907 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:13,908 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:866+292
2019-09-19 16:51:13,909 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:13,909 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:13,925 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:13,925 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-19 16:51:13,932 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:13,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:13,936 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,936 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,936 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,936 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,936 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:13,937 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:13,937 [IPC Server handler 18 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:13,937 [IPC Server handler 18 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:13,937 [IPC Server handler 18 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:13,937 [IPC Server handler 18 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:13,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:13,938 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:13,940 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:13,941 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:13,941 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:14,354 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:14,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:14,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:14,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:14,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:14,647 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 16:51:15,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:15,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:15,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:15,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:15,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:16,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:16,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:16,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:16,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:16,482 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:16,487 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:16,487 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:16,487 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:16,487 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:16,488 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:16,488 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:16,488 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:16,488 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:16,489 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:16,489 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:16,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:16,490 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:16,496 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:16,497 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:16,497 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:16,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:17,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:17,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:17,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:17,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:17,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:17,689 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 16:51:18,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:18,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:18,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:18,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:18,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:18,650 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-19 16:51:19,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:19,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:19,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:19,450 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:19,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:20,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:20,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:20,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:20,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:20,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:20,992 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:20,998 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:20,998 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:20,999 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:20,999 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:20,999 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:20,999 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:20,999 [IPC Server handler 9 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:21,000 [IPC Server handler 9 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:21,000 [IPC Server handler 9 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:21,000 [IPC Server handler 9 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:21,001 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:21,002 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:21,014 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:21,015 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000002_0
2019-09-19 16:51:21,015 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:21,016 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:21,017 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000003_0
2019-09-19 16:51:21,018 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:21,018 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:21,019 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:21,020 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:586+280
2019-09-19 16:51:21,021 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:21,021 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:21,044 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:21,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 16:51:21,053 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:21,057 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:21,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:21,058 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1005015064_0002_m_000003_0 is done. And is in the process of committing
2019-09-19 16:51:21,059 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:21,059 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1005015064_0002_m_000003_0 is allowed to commit now
2019-09-19 16:51:21,061 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1005015064_0002_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/_logs
2019-09-19 16:51:21,061 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 16:51:21,061 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1005015064_0002_m_000003_0' done.
2019-09-19 16:51:21,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1005015064_0002_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=455856
		FILE: Number of bytes written=1647404
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=56
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:21,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1005015064_0002_m_000003_0
2019-09-19 16:51:21,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000004_0
2019-09-19 16:51:21,063 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:21,063 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:21,064 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:21,065 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:1158+280
2019-09-19 16:51:21,065 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:21,066 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:21,086 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:21,087 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 16:51:21,096 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:21,099 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:21,100 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:21,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1005015064_0002_m_000004_0 is done. And is in the process of committing
2019-09-19 16:51:21,102 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:21,102 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1005015064_0002_m_000004_0 is allowed to commit now
2019-09-19 16:51:21,104 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1005015064_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/_logs
2019-09-19 16:51:21,105 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 16:51:21,105 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1005015064_0002_m_000004_0' done.
2019-09-19 16:51:21,105 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1005015064_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=460091
		FILE: Number of bytes written=1647412
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=58
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:21,105 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1005015064_0002_m_000004_0
2019-09-19 16:51:21,106 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:21,107 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:21,107 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:21,107 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:21,108 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:1702+276
2019-09-19 16:51:21,109 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:21,109 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:21,132 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:21,133 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-09-19 16:51:21,141 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:21,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:21,146 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:21,146 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:21,146 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:21,146 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:21,146 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:21,147 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:21,147 [IPC Server handler 1 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:21,147 [IPC Server handler 1 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:21,147 [IPC Server handler 1 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:21,148 [IPC Server handler 1 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:21,148 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:21,149 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:21,153 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:21,153 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:21,153 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:21,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:21,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:21,357 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:21,450 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:21,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:21,652 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 16:51:22,355 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:22,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:22,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:22,450 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:22,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:23,341 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:23,347 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:23,348 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:23,348 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:23,348 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:23,348 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:23,349 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:23,349 [IPC Server handler 17 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:23,349 [IPC Server handler 17 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:23,362 [IPC Server handler 17 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:23,362 [IPC Server handler 17 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:23,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:23,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:23,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:23,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:23,364 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:23,367 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:23,368 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:23,368 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:23,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:23,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:23,692 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 16:51:24,366 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:24,366 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:24,366 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:24,452 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:24,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:24,654 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 35% reduce 0%
2019-09-19 16:51:25,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:25,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:25,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:25,453 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:25,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:25,868 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:25,881 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:25,881 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:25,881 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:25,881 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:25,882 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:25,882 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:25,882 [IPC Server handler 18 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:25,882 [IPC Server handler 18 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:25,883 [IPC Server handler 18 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:25,883 [IPC Server handler 18 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:25,883 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:25,884 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:25,886 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:25,887 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000005_0
2019-09-19 16:51:25,887 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:25,888 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:25,889 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000006_0
2019-09-19 16:51:25,891 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:25,891 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:25,892 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:25,894 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:1438+264
2019-09-19 16:51:25,894 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:25,894 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:25,918 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-19 16:51:25,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:25,922 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 16:51:25,929 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:25,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:25,932 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:25,932 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1005015064_0002_m_000006_0 is done. And is in the process of committing
2019-09-19 16:51:25,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:25,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1005015064_0002_m_000006_0 is allowed to commit now
2019-09-19 16:51:25,935 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1005015064_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/_logs
2019-09-19 16:51:25,935 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 16:51:25,936 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1005015064_0002_m_000006_0' done.
2019-09-19 16:51:25,936 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1005015064_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=468561
		FILE: Number of bytes written=1647428
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=65
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:25,936 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1005015064_0002_m_000006_0
2019-09-19 16:51:25,936 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000007_0
2019-09-19 16:51:25,937 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:25,937 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:25,938 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:25,939 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:1978+264
2019-09-19 16:51:25,939 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:25,939 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:25,958 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:25,959 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 16:51:25,965 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:25,968 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:25,969 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:25,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1005015064_0002_m_000007_0 is done. And is in the process of committing
2019-09-19 16:51:25,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:25,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1005015064_0002_m_000007_0 is allowed to commit now
2019-09-19 16:51:25,972 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1005015064_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/_logs
2019-09-19 16:51:25,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 16:51:25,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1005015064_0002_m_000007_0' done.
2019-09-19 16:51:25,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1005015064_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=472284
		FILE: Number of bytes written=1647436
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=67
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:25,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1005015064_0002_m_000007_0
2019-09-19 16:51:25,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000008_0
2019-09-19 16:51:25,974 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:25,974 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:25,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:25,975 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:2242+264
2019-09-19 16:51:25,976 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:25,976 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:25,991 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:25,992 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 16:51:25,999 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:26,001 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:26,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:26,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1005015064_0002_m_000008_0 is done. And is in the process of committing
2019-09-19 16:51:26,003 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:26,003 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1005015064_0002_m_000008_0 is allowed to commit now
2019-09-19 16:51:26,005 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1005015064_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/_logs
2019-09-19 16:51:26,008 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 16:51:26,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1005015064_0002_m_000008_0' done.
2019-09-19 16:51:26,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1005015064_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=476007
		FILE: Number of bytes written=1647444
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=69
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:26,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1005015064_0002_m_000008_0
2019-09-19 16:51:26,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:26,010 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:26,010 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:26,010 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:26,011 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987/fileList.seq:326+260
2019-09-19 16:51:26,011 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:26,012 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:26,027 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:26,028 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-19 16:51:26,035 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:26,036 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:26,039 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:26,040 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:26,040 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:26,040 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:26,040 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:26,040 [IPC Server handler 1 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:26,041 [IPC Server handler 1 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:26,041 [IPC Server handler 1 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:26,041 [IPC Server handler 1 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:26,041 [IPC Server handler 1 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:26,042 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:26,042 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:26,044 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:26,045 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:26,045 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:26,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:26,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:26,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:26,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:26,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:26,656 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 16:51:27,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:27,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:27,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:27,452 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:27,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:27,873 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:27,879 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:27,880 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:27,880 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:27,880 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:27,880 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:27,881 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:27,881 [IPC Server handler 18 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:27,881 [IPC Server handler 18 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:27,881 [IPC Server handler 18 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:27,882 [IPC Server handler 18 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:27,882 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:27,883 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:27,885 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:27,885 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:27,886 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:28,362 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:28,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:28,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:28,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:28,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:29,362 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:29,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:29,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:29,453 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:29,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:30,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:30,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:30,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:30,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:30,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:31,319 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:31,324 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:31,324 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:31,325 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:31,325 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:31,325 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:31,325 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:31,325 [IPC Server handler 17 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:31,326 [IPC Server handler 17 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:31,326 [IPC Server handler 17 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:31,326 [IPC Server handler 17 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:31,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:31,327 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:31,329 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume18257 bucket: bucket48587 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:31,330 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1005015064_0002_m_000009_0
2019-09-19 16:51:31,330 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:31,331 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:31,332 [Thread-544] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 16:51:31,340 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,342 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,345 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,347 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,348 [Thread-544] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001456227358/.staging/_distcp283754987
2019-09-19 16:51:31,350 [Thread-544] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1005015064_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket48587.volume18257/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:31,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:31,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:31,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:31,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:31,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:31,659 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1005015064_0002 failed with state FAILED due to: NA
2019-09-19 16:51:31,745 [Thread-481] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=3708902
		FILE: Number of bytes written=13179352
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=489
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=286
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1256
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16466837504
	File Input Format Counters 
		Bytes Read=25168
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-19 16:51:31,747 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,749 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,751 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume18257, bucket=bucket48587, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,753 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume18257, bucket=bucket48587, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 16:51:31,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,757 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,758 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,760 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,761 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,762 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume18257, bucket=bucket48587, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,763 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume18257, bucket=bucket48587, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="largeFilesToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="12.836">
    <error message="DistCp failure: Job job_local339080931_0003 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local339080931_0003 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:534)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFilesToRemote(AbstractContractDistCpTest.java:452)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-19 16:51:31,804 [Thread-592] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 16:51:31,810 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin15268, owner=user66325, volume=volume72586, creationTime=1568911891809, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 16:51:31,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume72586, bucket=bucket73824, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 16:51:31,884 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume72586} | ret=SUCCESS |  
2019-09-19 16:51:31,886 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume72586, bucket=bucket73824} | ret=SUCCESS |  
2019-09-19 16:51:31,887 [Thread-592] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket73824.volume72586 implemented by OzoneFileSystem{URI=o3fs://bucket73824.volume72586, workingDir=o3fs://bucket73824.volume72586/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 81 read ops, 0 large read ops, 46 write ops}
2019-09-19 16:51:31,890 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume72586, bucket=bucket73824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,904 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,905 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,907 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume72586, bucket=bucket73824, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:31,910 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,911 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume72586, bucket=bucket73824, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:31,913 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:31,915 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:31,916 [Thread-592] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-19 16:51:31,919 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-19 16:51:31,929 [Thread-592] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-19 16:51:32,077 [Thread-592] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:32,089 [Thread-592] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:32,103 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:32,151 [Thread-592] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-19 16:51:32,151 [Thread-592] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 16:51:32,164 [Thread-592] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-19 16:51:32,180 [Thread-592] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-19 16:51:32,181 [Thread-592] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:32,194 [Thread-592] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 16:51:32,255 [Thread-592] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-19 16:51:32,317 [Thread-592] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local339080931_0003
2019-09-19 16:51:32,317 [Thread-592] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 16:51:32,366 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:32,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:32,370 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:32,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:32,579 [Thread-592] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 16:51:32,581 [Thread-592] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local339080931_0003
2019-09-19 16:51:32,581 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 16:51:32,582 [Thread-592] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local339080931_0003
2019-09-19 16:51:32,582 [Thread-639] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:32,582 [Thread-639] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:32,583 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 16:51:32,606 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 16:51:32,606 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:32,608 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:32,608 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:32,608 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:32,611 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:32,611 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000590448756/.staging/_distcp2084277603/fileList.seq:0+780
2019-09-19 16:51:32,613 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:32,613 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:32,637 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:32,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
2019-09-19 16:51:32,647 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:32,650 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:32,651 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
2019-09-19 16:51:32,658 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:32,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:32,664 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:32,664 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:32,664 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:32,665 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:32,665 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:32,665 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:32,665 [IPC Server handler 6 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:32,666 [IPC Server handler 6 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:32,666 [IPC Server handler 6 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:32,666 [IPC Server handler 6 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:32,666 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:32,667 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:32,669 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:32,669 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:32,671 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:33,115 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-19 16:51:33,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:33,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:33,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:33,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:33,582 [Thread-592] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local339080931_0003 running in uber mode : false
2019-09-19 16:51:33,583 [Thread-592] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 16:51:33,611 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:34,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:34,121 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:34,121 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:34,121 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:34,121 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:34,121 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:34,122 [IPC Server handler 17 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:34,122 [IPC Server handler 17 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:34,122 [IPC Server handler 17 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:34,122 [IPC Server handler 17 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:34,122 [IPC Server handler 17 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:34,122 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:34,123 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:34,125 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:34,126 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:34,126 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:34,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:34,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:34,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:34,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:34,611 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:35,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:35,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:35,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:35,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:35,612 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:36,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:36,370 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:36,385 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:36,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:36,612 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:37,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:37,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:37,370 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:37,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:37,613 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:38,019 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-19 16:51:38,362 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:38,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:38,370 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:38,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:38,613 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:39,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:39,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:39,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:39,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:39,613 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:39,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:39,677 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,677 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,677 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,677 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,677 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,678 [IPC Server handler 2 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:39,678 [IPC Server handler 2 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:39,678 [IPC Server handler 2 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:39,678 [IPC Server handler 2 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:39,679 [IPC Server handler 2 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:39,679 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:39,680 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:39,682 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:39,683 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000000_0
2019-09-19 16:51:39,683 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:39,684 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:39,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:39,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:39,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:39,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:39,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000590448756/.staging/_distcp2084277603/fileList.seq:780+238
2019-09-19 16:51:39,688 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:39,688 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:39,709 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:39,710 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
2019-09-19 16:51:39,718 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:39,719 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:39,723 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,723 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,723 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,724 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,724 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:39,724 [IPC Server handler 18 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:39,724 [IPC Server handler 18 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:39,724 [IPC Server handler 18 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:39,725 [IPC Server handler 18 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:39,725 [IPC Server handler 18 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:39,725 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:39,726 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:39,728 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:39,728 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:39,728 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:40,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:40,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:40,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:40,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:40,615 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:40,930 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:40,935 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:40,936 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:40,936 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:40,936 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:40,936 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:40,937 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:40,937 [IPC Server handler 9 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:40,937 [IPC Server handler 9 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:40,937 [IPC Server handler 9 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:40,938 [IPC Server handler 9 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:40,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:40,939 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:40,942 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:40,942 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:40,942 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:41,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:41,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:41,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:41,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:41,613 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:42,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:42,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:42,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:42,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:42,613 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:43,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:43,370 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:43,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:43,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:43,614 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:44,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:44,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:44,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:44,485 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:44,490 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,490 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,491 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,491 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,491 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,491 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:44,492 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:44,492 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:44,492 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:44,493 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:44,493 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:44,493 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:44,496 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72586 bucket: bucket73824 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:44,497 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local339080931_0003_m_000001_0
2019-09-19 16:51:44,497 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:44,498 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:44,510 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 16:51:44,516 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,518 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,521 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,523 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,524 [Thread-639] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000590448756/.staging/_distcp2084277603
2019-09-19 16:51:44,527 [Thread-639] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local339080931_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 --> o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket73824.volume72586/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:44,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:44,589 [Thread-592] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local339080931_0003 failed with state FAILED due to: NA
2019-09-19 16:51:44,589 [Thread-592] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 0
2019-09-19 16:51:44,592 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,594 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,595 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72586, bucket=bucket73824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,597 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume72586, bucket=bucket73824, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 16:51:44,599 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume72586, bucket=bucket73824, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,600 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,601 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume72586, bucket=bucket73824, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume72586, bucket=bucket73824, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testLargeFilesFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.165">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:528)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testLargeFilesFromRemote(AbstractContractDistCpTest.java:464)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-19 16:51:44,622 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-19 16:51:44,624 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:44,644 [Thread-662] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 16:51:44,648 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin01867, owner=user68292, volume=volume50003, creationTime=1568911904647, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 16:51:44,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume50003, bucket=bucket96376, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 16:51:44,698 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume50003} | ret=SUCCESS |  
2019-09-19 16:51:44,700 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume50003, bucket=bucket96376} | ret=SUCCESS |  
2019-09-19 16:51:44,701 [Thread-662] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket96376.volume50003 implemented by OzoneFileSystem{URI=o3fs://bucket96376.volume50003, workingDir=o3fs://bucket96376.volume50003/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 103 read ops, 0 large read ops, 60 write ops}
2019-09-19 16:51:44,710 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume50003, bucket=bucket96376, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,725 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,726 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,728 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume50003, bucket=bucket96376, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:44,729 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,730 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume50003, bucket=bucket96376, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:44,732 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50003 bucket: bucket96376 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:44,734 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,735 [Thread-662] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-19 16:51:44,737 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,737 [Thread-662] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-19 16:51:44,756 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,756 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,756 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,756 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,757 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:44,757 [IPC Server handler 9 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:44,757 [IPC Server handler 9 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:44,757 [IPC Server handler 9 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:44,758 [IPC Server handler 9 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:44,758 [IPC Server handler 9 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:44,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:44,759 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:44,761 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50003, bucket=bucket96376, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,762 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50003, bucket=bucket96376, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,763 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50003, bucket=bucket96376, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume50003, bucket=bucket96376, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 16:51:44,766 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume50003, bucket=bucket96376, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,769 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume50003, bucket=bucket96376, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,770 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume50003, bucket=bucket96376, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testUpdateDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="8.665">
    <error message="DistCp failure: Job job_local1303242693_0004 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1303242693_0004 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-19 16:51:44,796 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin64303, owner=user11128, volume=volume42781, creationTime=1568911904795, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 16:51:44,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume42781, bucket=bucket37983, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 16:51:44,845 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume42781} | ret=SUCCESS |  
2019-09-19 16:51:44,847 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume42781, bucket=bucket37983} | ret=SUCCESS |  
2019-09-19 16:51:44,848 [Thread-666] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket37983.volume42781 implemented by OzoneFileSystem{URI=o3fs://bucket37983.volume42781, workingDir=o3fs://bucket37983.volume42781/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 109 read ops, 0 large read ops, 63 write ops}
2019-09-19 16:51:44,850 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,862 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,863 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume42781, bucket=bucket37983, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:44,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,868 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume42781, bucket=bucket37983, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:44,869 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:44,871 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:44,872 [Thread-666] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-19 16:51:44,969 [Thread-666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:44,987 [Thread-666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:44,999 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:45,084 [Thread-666] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-19 16:51:45,085 [Thread-666] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 16:51:45,098 [Thread-666] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 16:51:45,113 [Thread-666] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 16:51:45,114 [Thread-666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 16:51:45,125 [Thread-666] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 16:51:45,195 [Thread-666] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:7
2019-09-19 16:51:45,235 [Thread-666] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1303242693_0004
2019-09-19 16:51:45,235 [Thread-666] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 16:51:45,342 [Thread-666] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 16:51:45,346 [Thread-728] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 16:51:45,347 [Thread-666] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1303242693_0004
2019-09-19 16:51:45,347 [Thread-728] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:45,347 [Thread-666] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1303242693_0004
2019-09-19 16:51:45,347 [Thread-728] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:45,348 [Thread-728] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 16:51:45,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:45,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:45,372 [Thread-728] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 16:51:45,372 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:45,373 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:45,373 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:45,373 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:45,374 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:45,375 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:1684+1417
2019-09-19 16:51:45,375 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:45,375 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:45,398 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:45,400 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-19 16:51:45,406 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:45,407 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:45,410 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:45,410 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:45,411 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:45,411 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:45,411 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:45,411 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:45,411 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:45,412 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:45,412 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:45,412 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:45,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:45,413 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:45,415 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:45,415 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:45,416 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:45,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:45,624 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:46,348 [Thread-666] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1303242693_0004 running in uber mode : false
2019-09-19 16:51:46,348 [Thread-666] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 16:51:46,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:46,368 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:46,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:46,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:46,625 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:47,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:47,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:47,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:47,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:47,624 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:48,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:48,320 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:48,320 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:48,320 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:48,320 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:48,321 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:48,321 [IPC Server handler 0 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:48,321 [IPC Server handler 0 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:48,321 [IPC Server handler 0 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:48,322 [IPC Server handler 0 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:48,322 [IPC Server handler 0 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:48,322 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:48,323 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:48,326 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:48,326 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:48,327 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:48,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:48,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:48,372 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:48,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:48,625 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:49,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:49,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:49,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:49,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:49,626 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:50,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:50,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:50,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:50,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:50,624 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 > map
2019-09-19 16:51:50,627 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:51,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:51,370 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:51,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:51,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:51,627 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:51,710 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-19 16:51:52,364 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:52,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:52,371 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:52,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:52,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:52,549 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:52,549 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:52,549 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:52,550 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:52,550 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:52,550 [IPC Server handler 3 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:52,550 [IPC Server handler 3 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:52,550 [IPC Server handler 3 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:52,551 [IPC Server handler 3 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:52,551 [IPC Server handler 3 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:52,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:52,552 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:52,555 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:52,556 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1303242693_0004_m_000000_0
2019-09-19 16:51:52,556 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 16:51:52,556 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:52,557 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000001_0
2019-09-19 16:51:52,562 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,562 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,562 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:52,564 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:0+327
2019-09-19 16:51:52,564 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,564 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,587 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:52,589 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 16:51:52,597 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:52,601 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,602 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,602 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1303242693_0004_m_000001_0 is done. And is in the process of committing
2019-09-19 16:51:52,603 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,603 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1303242693_0004_m_000001_0 is allowed to commit now
2019-09-19 16:51:52,604 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1303242693_0004_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/_logs
2019-09-19 16:51:52,605 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 16:51:52,605 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1303242693_0004_m_000001_0' done.
2019-09-19 16:51:52,606 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1303242693_0004_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=879873
		FILE: Number of bytes written=12799484
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=120
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:52,606 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1303242693_0004_m_000001_0
2019-09-19 16:51:52,606 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000002_0
2019-09-19 16:51:52,607 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,607 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,607 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:52,608 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:327+281
2019-09-19 16:51:52,609 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,609 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,626 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=5a3ee61b-140e-4199-b942-69cb3515ef3d, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:52,629 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 16:51:52,638 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:52,641 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,642 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,642 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1303242693_0004_m_000002_0 is done. And is in the process of committing
2019-09-19 16:51:52,643 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,643 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1303242693_0004_m_000002_0 is allowed to commit now
2019-09-19 16:51:52,644 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1303242693_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/_logs
2019-09-19 16:51:52,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 16:51:52,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1303242693_0004_m_000002_0' done.
2019-09-19 16:51:52,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1303242693_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=884170
		FILE: Number of bytes written=12799492
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=122
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:52,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1303242693_0004_m_000002_0
2019-09-19 16:51:52,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000003_0
2019-09-19 16:51:52,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,647 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:52,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:1138+281
2019-09-19 16:51:52,648 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,649 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,668 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,668 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 16:51:52,676 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:52,679 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,680 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,680 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1303242693_0004_m_000003_0 is done. And is in the process of committing
2019-09-19 16:51:52,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1303242693_0004_m_000003_0 is allowed to commit now
2019-09-19 16:51:52,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1303242693_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/_logs
2019-09-19 16:51:52,683 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 16:51:52,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1303242693_0004_m_000003_0' done.
2019-09-19 16:51:52,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1303242693_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=888467
		FILE: Number of bytes written=12799500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=124
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:52,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1303242693_0004_m_000003_0
2019-09-19 16:51:52,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000004_0
2019-09-19 16:51:52,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:52,688 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:608+265
2019-09-19 16:51:52,688 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,689 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,712 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,713 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 16:51:52,721 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1303242693_0004_m_000004_0 is done. And is in the process of committing
2019-09-19 16:51:52,727 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,727 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1303242693_0004_m_000004_0 is allowed to commit now
2019-09-19 16:51:52,729 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1303242693_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/_logs
2019-09-19 16:51:52,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 16:51:52,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1303242693_0004_m_000004_0' done.
2019-09-19 16:51:52,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1303242693_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=892252
		FILE: Number of bytes written=12799508
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=126
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:52,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1303242693_0004_m_000004_0
2019-09-19 16:51:52,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000005_0
2019-09-19 16:51:52,732 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,732 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,732 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:52,734 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:873+265
2019-09-19 16:51:52,734 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,734 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,756 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 16:51:52,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1303242693_0004_m_000005_0 is done. And is in the process of committing
2019-09-19 16:51:52,769 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,769 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1303242693_0004_m_000005_0 is allowed to commit now
2019-09-19 16:51:52,770 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1303242693_0004_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/_logs
2019-09-19 16:51:52,771 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 16:51:52,771 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1303242693_0004_m_000005_0' done.
2019-09-19 16:51:52,771 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1303242693_0004_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=896037
		FILE: Number of bytes written=12799516
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=128
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:52,771 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1303242693_0004_m_000005_0
2019-09-19 16:51:52,772 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1303242693_0004_m_000006_0
2019-09-19 16:51:52,772 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,772 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,772 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 16:51:52,773 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/fileList.seq:1419+265
2019-09-19 16:51:52,773 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 16:51:52,773 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 16:51:52,792 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,793 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 16:51:52,801 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume42781 bucket: bucket37983 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:52,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,805 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,805 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1303242693_0004_m_000006_0 is done. And is in the process of committing
2019-09-19 16:51:52,806 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 16:51:52,806 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1303242693_0004_m_000006_0 is allowed to commit now
2019-09-19 16:51:52,807 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1303242693_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902/_logs
2019-09-19 16:51:52,808 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 16:51:52,808 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1303242693_0004_m_000006_0' done.
2019-09-19 16:51:52,808 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1303242693_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=899822
		FILE: Number of bytes written=12799524
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=130
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=70
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 16:51:52,808 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1303242693_0004_m_000006_0
2019-09-19 16:51:52,809 [Thread-728] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 16:51:52,814 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,816 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,819 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,821 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:52,822 [Thread-728] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001544398439/.staging/_distcp-1096497902
2019-09-19 16:51:52,825 [Thread-728] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1303242693_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket37983.volume42781/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 16:51:53,352 [Thread-666] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 16:51:53,353 [Thread-666] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1303242693_0004 failed with state FAILED due to: NA
2019-09-19 16:51:53,367 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=18ae6263-d76c-4059-8eaf-4f5e3148b226, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:53,391 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=e437f173-6a54-4062-88a9-cae9a5018cc4, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:53,389 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=6fd479a2-5728-477d-9065-d2b622b80b85, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:53,414 [Thread-666] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=5340621
		FILE: Number of bytes written=76797024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=750
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=420
	Map-Reduce Framework
		Map input records=6
		Map output records=0
		Input split bytes=954
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=12041846784
	File Input Format Counters 
		Bytes Read=18942
	File Output Format Counters 
		Bytes Written=48
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-19 16:51:53,416 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,418 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,419 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume42781, bucket=bucket37983, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,421 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume42781, bucket=bucket37983, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 16:51:53,424 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,425 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,427 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,428 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,431 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume42781, bucket=bucket37983, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume42781, bucket=bucket37983, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testDeepDirectoryStructureFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.136">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:488)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testDeepDirectoryStructureFromRemote(AbstractContractDistCpTest.java:458)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-19 16:51:53,463 [Thread-764] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 16:51:53,465 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin31741, owner=user98556, volume=volume63987, creationTime=1568911913465, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 16:51:53,467 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume63987, bucket=bucket77118, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 16:51:53,520 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume63987} | ret=SUCCESS |  
2019-09-19 16:51:53,521 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume63987, bucket=bucket77118} | ret=SUCCESS |  
2019-09-19 16:51:53,522 [Thread-764] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket77118.volume63987 implemented by OzoneFileSystem{URI=o3fs://bucket77118.volume63987, workingDir=o3fs://bucket77118.volume63987/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 137 read ops, 0 large read ops, 71 write ops}
2019-09-19 16:51:53,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63987, bucket=bucket77118, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=SEND_HEARTBEAT {datanodeUUID=f763b2c0-c12b-45c9-b18c-74b12c137ba3, command=[]} | ret=SUCCESS |  
2019-09-19 16:51:53,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,540 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,543 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63987, bucket=bucket77118, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:53,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,545 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63987, bucket=bucket77118, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 16:51:53,547 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume63987 bucket: bucket77118 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 16:51:53,549 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,550 [Thread-764] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-19 16:51:53,552 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,554 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,557 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:53,557 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:53,557 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:53,557 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:53,558 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 16:51:53,558 [IPC Server handler 6 on 45504] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:53,558 [IPC Server handler 6 on 45504] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 16:51:53,558 [IPC Server handler 6 on 45504] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 16:51:53,558 [IPC Server handler 6 on 45504] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 16:51:53,558 [IPC Server handler 6 on 45504] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 16:51:53,559 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.226 | op=ALLOCATE_BLOCK {owner=1baa0ba8-6fe6-432f-a0b9-923bfdab0fc3, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 16:51:53,559 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 16:51:53,560 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63987, bucket=bucket77118, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,562 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63987, bucket=bucket77118, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,563 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63987, bucket=bucket77118, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,564 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63987, bucket=bucket77118, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 16:51:53,566 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63987, bucket=bucket77118, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,567 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,568 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,570 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63987, bucket=bucket77118, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 16:51:53,570 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63987, bucket=bucket77118, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
</testsuite>
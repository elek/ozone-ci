<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="101.649" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7013253225409552193.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-09-25T11-13-37_982-jvmRun1 surefire3466825288764923582tmp surefire_947032161000303127973tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter7013253225409552193.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpdateDeepDirectoryStructureNoChange" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="23.782">
    <error message="DistCp failure: Job job_local1038849443_0001 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1038849443_0001 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureNoChange(AbstractContractDistCpTest.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 12:42:49,729 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:49,838 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:49,841 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:49,855 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @853ms
2019-09-25 12:42:49,936 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-25 12:42:49,936 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-25 12:42:49,937 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-25 12:42:49,937 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-25 12:42:49,937 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-25 12:42:49,937 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-25 12:42:49,947 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 12:42:49,948 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 12:42:49,949 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 12:42:50,165 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@dd05255
2019-09-25 12:42:50,166 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-25 12:42:50,225 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 12:42:50,227 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 12:42:50,229 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-25 12:42:50,335 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-25 12:42:50,348 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:50,415 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-25 12:42:50,417 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:50,525 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-25 12:42:50,840 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 12:42:51,006 [Socket Reader #1 for port 39160] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39160
2019-09-25 12:42:51,040 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 12:42:51,041 [Socket Reader #1 for port 45259] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45259
2019-09-25 12:42:51,052 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 12:42:51,052 [Socket Reader #1 for port 33900] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33900
2019-09-25 12:42:51,075 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-25 12:42:51,240 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:51,255 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:51,266 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:51,268 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-25 12:42:51,268 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:51,268 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:51,294 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:33900
2019-09-25 12:42:51,339 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-25 12:42:51,350 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-25 12:42:51,350 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-25 12:42:51,605 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:33900
2019-09-25 12:42:51,606 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 12:42:51,606 [IPC Server listener on 33900] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33900: starting
2019-09-25 12:42:51,609 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45259
2019-09-25 12:42:51,611 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45259
2019-09-25 12:42:51,611 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 12:42:51,611 [IPC Server listener on 45259] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45259: starting
2019-09-25 12:42:51,614 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:39160
2019-09-25 12:42:51,614 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:39160
2019-09-25 12:42:51,614 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 12:42:51,614 [IPC Server listener on 39160] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39160: starting
2019-09-25 12:42:51,618 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36180
2019-09-25 12:42:51,620 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:51,654 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:51,654 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:51,724 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@aec50a1{/,file:///tmp/jetty-0.0.0.0-36180-scm-_-any-3924172992325394495.dir/webapp/,AVAILABLE}{/scm}
2019-09-25 12:42:51,729 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:36180}
2019-09-25 12:42:51,729 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @2728ms
2019-09-25 12:42:51,732 [JUnit] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-25 12:42:51,732 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-25 12:42:51,733 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:36180
2019-09-25 12:42:51,741 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c1fca1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 12:42:51,745 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:51,857 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:51,858 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:51,859 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(652)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-25 12:42:51,859 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(658)) - OM Node ID is not set. Setting it to the OmStorage's OmID: a3062ed0-5179-49b2-8aaa-28a3cf3f0576
2019-09-25 12:42:51,860 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-25 12:42:52,655 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 12:42:52,665 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-25 12:42:52,665 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-25 12:42:52,666 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-25 12:42:52,666 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-25 12:42:52,666 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-25 12:42:52,666 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-25 12:42:52,667 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-25 12:42:52,667 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-25 12:42:52,667 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-25 12:42:52,667 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-25 12:42:52,668 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-25 12:42:52,668 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-25 12:42:52,668 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-25 12:42:52,668 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-25 12:42:52,668 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-25 12:42:52,669 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-25 12:42:52,669 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-25 12:42:52,669 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-25 12:42:52,669 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-25 12:42:52,670 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-25 12:42:52,670 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-25 12:42:52,670 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-25 12:42:52,671 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 12:42:52,671 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 12:42:52,671 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 12:42:52,982 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 12:42:52,983 [Socket Reader #1 for port 45560] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45560
2019-09-25 12:42:53,008 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45560
2019-09-25 12:42:53,008 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-25 12:42:53,009 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 12:42:53,009 [IPC Server listener on 45560] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45560: starting
2019-09-25 12:42:53,014 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-25 12:42:53,017 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:53,018 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:53,023 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:53,025 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-25 12:42:53,025 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:53,183 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:53,187 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46747
2019-09-25 12:42:53,187 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:53,189 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:53,190 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:53,273 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7103ab0{/,file:///tmp/jetty-0.0.0.0-46747-ozoneManager-_-any-1241427106919213653.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-25 12:42:53,274 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:46747}
2019-09-25 12:42:53,274 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4272ms
2019-09-25 12:42:53,275 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 12:42:53,276 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:46747
2019-09-25 12:42:53,478 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 12:42:53,541 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-shd4m-3693607622 ip:192.168.151.73
2019-09-25 12:42:53,576 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 12:42:53,578 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/containers/hdds to VolumeSet
2019-09-25 12:42:53,580 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-25 12:42:53,597 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-25 12:42:53,728 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 12:42:53,799 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 12:42:53,804 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 12:42:53,805 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 12:42:53,807 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:53,808 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 12:42:53,808 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 12:42:53,986 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:42:54,046 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 12:42:54,050 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:54,051 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:54,053 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:54,054 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 12:42:54,055 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:54,055 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:54,057 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33353
2019-09-25 12:42:54,057 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:54,059 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:54,060 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:54,090 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73844119{/,file:///tmp/jetty-0.0.0.0-33353-hddsDatanode-_-any-7104527021600531517.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 12:42:54,091 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:33353}
2019-09-25 12:42:54,091 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5090ms
2019-09-25 12:42:54,092 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 12:42:54,094 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33353
2019-09-25 12:42:54,095 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 12:42:54,099 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-shd4m-3693607622 ip:192.168.151.73
2019-09-25 12:42:54,103 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26207b85] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 12:42:54,108 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 12:42:54,109 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/containers/hdds to VolumeSet
2019-09-25 12:42:54,109 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@77a074b4
2019-09-25 12:42:54,110 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@77a074b4
2019-09-25 12:42:54,133 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 12:42:54,134 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 12:42:54,134 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 12:42:54,134 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 12:42:54,134 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:54,135 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 12:42:54,135 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 12:42:54,135 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:42:54,137 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 12:42:54,139 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:54,139 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:54,141 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:54,142 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 12:42:54,142 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:54,142 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:54,143 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34974
2019-09-25 12:42:54,143 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:54,147 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@618ff5c2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:54,148 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f84acf7{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:54,176 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6e4f263e{/,file:///tmp/jetty-0.0.0.0-34974-hddsDatanode-_-any-1789952532992504677.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 12:42:54,177 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48b4a043{HTTP/1.1,[http/1.1]}{0.0.0.0:34974}
2019-09-25 12:42:54,178 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5175ms
2019-09-25 12:42:54,178 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 12:42:54,179 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34974
2019-09-25 12:42:54,179 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 12:42:54,182 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-shd4m-3693607622 ip:192.168.151.73
2019-09-25 12:42:54,183 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1af6f650] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 12:42:54,191 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 12:42:54,193 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/containers/hdds to VolumeSet
2019-09-25 12:42:54,193 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@534180a2
2019-09-25 12:42:54,194 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@534180a2
2019-09-25 12:42:54,213 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 12:42:54,214 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 12:42:54,214 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 12:42:54,214 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 12:42:54,214 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:54,215 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 12:42:54,215 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 12:42:54,216 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:42:54,218 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 12:42:54,220 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:54,220 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:54,223 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:54,225 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 12:42:54,225 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:54,225 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:54,226 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40248
2019-09-25 12:42:54,226 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:54,228 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/meta/datanode.id
2019-09-25 12:42:54,228 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c83468e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:54,230 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d7fb838{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:54,233 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/meta/datanode.id
2019-09-25 12:42:54,260 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6812fa3a{/,file:///tmp/jetty-0.0.0.0-40248-hddsDatanode-_-any-4063394965136738928.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 12:42:54,261 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@29149030{HTTP/1.1,[http/1.1]}{0.0.0.0:40248}
2019-09-25 12:42:54,262 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5260ms
2019-09-25 12:42:54,262 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 12:42:54,263 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40248
2019-09-25 12:42:54,264 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 12:42:54,267 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-shd4m-3693607622 ip:192.168.151.73
2019-09-25 12:42:54,267 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@548d6ba6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 12:42:54,271 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/meta/datanode.id
2019-09-25 12:42:54,276 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 12:42:54,276 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/containers/hdds to VolumeSet
2019-09-25 12:42:54,276 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-25 12:42:54,277 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-25 12:42:54,304 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 12:42:54,304 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 12:42:54,304 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 12:42:54,305 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 12:42:54,305 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:54,305 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 12:42:54,305 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 12:42:54,306 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:42:54,308 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 12:42:54,309 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:54,310 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:54,312 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:54,313 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 12:42:54,314 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:54,314 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:54,315 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34618
2019-09-25 12:42:54,315 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:54,319 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26350ea2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:54,319 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a08efdc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:54,348 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cd3ad8a{/,file:///tmp/jetty-0.0.0.0-34618-hddsDatanode-_-any-4970062688824527495.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 12:42:54,349 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@75181b50{HTTP/1.1,[http/1.1]}{0.0.0.0:34618}
2019-09-25 12:42:54,349 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5348ms
2019-09-25 12:42:54,351 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 12:42:54,352 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34618
2019-09-25 12:42:54,352 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 12:42:54,356 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d311640] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 12:42:54,356 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-shd4m-3693607622 ip:192.168.151.73
2019-09-25 12:42:54,359 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/meta/datanode.id
2019-09-25 12:42:54,366 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 12:42:54,367 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/containers/hdds to VolumeSet
2019-09-25 12:42:54,367 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2a869a16
2019-09-25 12:42:54,368 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2a869a16
2019-09-25 12:42:54,405 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 12:42:54,406 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 12:42:54,406 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 12:42:54,406 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 12:42:54,407 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:54,407 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 12:42:54,407 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 12:42:54,408 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:42:54,410 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 12:42:54,412 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 12:42:54,413 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 12:42:54,416 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 12:42:54,418 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 12:42:54,418 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 12:42:54,418 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 12:42:54,419 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38756
2019-09-25 12:42:54,419 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 12:42:54,422 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e446d92{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-25 12:42:54,423 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d5c2745{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 12:42:54,456 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4cb2918c{/,file:///tmp/jetty-0.0.0.0-38756-hddsDatanode-_-any-2216444620581144928.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 12:42:54,457 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72e295cc{HTTP/1.1,[http/1.1]}{0.0.0.0:38756}
2019-09-25 12:42:54,458 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5457ms
2019-09-25 12:42:54,460 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 12:42:54,461 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38756
2019-09-25 12:42:54,463 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 12:42:54,464 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@94632b3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 12:42:54,467 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/meta/datanode.id
2019-09-25 12:42:55,463 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 12:42:56,179 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 12:42:56,182 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 12:42:56,183 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at port 0
2019-09-25 12:42:56,209 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 12:42:56,213 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start RPC server
2019-09-25 12:42:56,215 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 12:42:56,215 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at port 0
2019-09-25 12:42:56,225 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start RPC server
2019-09-25 12:42:56,282 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 12:42:56,284 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 12:42:56,284 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at port 0
2019-09-25 12:42:56,292 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start RPC server
2019-09-25 12:42:56,381 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: GrpcService started, listening on 0.0.0.0/0.0.0.0:36105
2019-09-25 12:42:56,381 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: GrpcService started, listening on 0.0.0.0/0.0.0.0:45964
2019-09-25 12:42:56,382 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 is started using port 36105
2019-09-25 12:42:56,381 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: GrpcService started, listening on 0.0.0.0/0.0.0.0:38412
2019-09-25 12:42:56,382 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 46e204cb-f3c6-48b7-a572-0bdf52c235a1 is started using port 45964
2019-09-25 12:42:56,383 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 is started using port 38412
2019-09-25 12:42:56,383 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 12:42:56,387 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 12:42:56,390 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at port 0
2019-09-25 12:42:56,392 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 is started using port 38789
2019-09-25 12:42:56,392 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 is started using port 37193
2019-09-25 12:42:56,392 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 46e204cb-f3c6-48b7-a572-0bdf52c235a1 is started using port 35971
2019-09-25 12:42:56,412 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start RPC server
2019-09-25 12:42:56,418 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: GrpcService started, listening on 0.0.0.0/0.0.0.0:33315
2019-09-25 12:42:56,418 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f is started using port 33315
2019-09-25 12:42:56,421 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f is started using port 38581
2019-09-25 12:42:56,465 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 12:42:56,475 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 12:42:56,484 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 12:42:56,485 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 35a9f88d-76d2-4b6c-86f2-100b645542d6 at port 0
2019-09-25 12:42:56,494 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start RPC server
2019-09-25 12:42:56,497 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: GrpcService started, listening on 0.0.0.0/0.0.0.0:44393
2019-09-25 12:42:56,497 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 35a9f88d-76d2-4b6c-86f2-100b645542d6 is started using port 44393
2019-09-25 12:42:56,500 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 35a9f88d-76d2-4b6c-86f2-100b645542d6 is started using port 44600
2019-09-25 12:42:57,466 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 12:42:58,152 [IPC Server handler 0 on 39160] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:42:58,153 [IPC Server handler 0 on 39160] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}
2019-09-25 12:42:58,159 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-25 12:42:58,159 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-25 12:42:58,160 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-25 12:42:58,185 [IPC Server handler 1 on 39160] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:42:58,185 [IPC Server handler 1 on 39160] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}
2019-09-25 12:42:58,270 [IPC Server handler 2 on 39160] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:42:58,271 [IPC Server handler 2 on 39160] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}
2019-09-25 12:42:58,360 [IPC Server handler 5 on 39160] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:42:58,360 [IPC Server handler 5 on 39160] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}
2019-09-25 12:42:58,467 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-25 12:42:58,468 [IPC Server handler 3 on 39160] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:42:58,469 [IPC Server handler 3 on 39160] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}
2019-09-25 12:42:58,782 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: addNew group-BC04EE9DD79B:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] returns group-BC04EE9DD79B:java.util.concurrent.CompletableFuture@706812d[Not completed]
2019-09-25 12:42:58,813 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: new RaftServerImpl for group-BC04EE9DD79B:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] with ContainerStateMachine:uninitialized
2019-09-25 12:42:58,815 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:58,817 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:58,817 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:58,819 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:58,820 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:58,831 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: ConfigurationManager, init=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:58,831 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:42:58,840 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ce1f1114-75b8-4b2d-9ed1-bc04ee9dd79b does not exist. Creating ...
2019-09-25 12:42:58,858 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ce1f1114-75b8-4b2d-9ed1-bc04ee9dd79b/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:58,876 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ce1f1114-75b8-4b2d-9ed1-bc04ee9dd79b has been successfully formatted.
2019-09-25 12:42:58,878 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-BC04EE9DD79B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:58,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:58,881 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:58,889 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:58,889 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:58,892 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:58,897 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:58,904 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ce1f1114-75b8-4b2d-9ed1-bc04ee9dd79b
2019-09-25 12:42:58,906 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-25 12:42:58,913 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-25 12:42:58,948 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:58,949 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:58,952 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:58,952 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:58,953 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:58,953 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:58,954 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:58,954 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:58,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:58,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:58,968 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:58,973 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:58,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:58,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:58,975 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,004 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: start as a follower, conf=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:42:59,005 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,006 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start FollowerState
2019-09-25 12:42:59,009 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC04EE9DD79B,id=5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:42:59,092 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ce1f1114-75b8-4b2d-9ed1-bc04ee9dd79b, Nodes: 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,116 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: addNew group-19194B09ECDB:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] returns group-19194B09ECDB:java.util.concurrent.CompletableFuture@1306c6a3[Not completed]
2019-09-25 12:42:59,164 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: new RaftServerImpl for group-19194B09ECDB:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,166 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: ConfigurationManager, init=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:42:59,167 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/479be886-90ce-44b4-8573-19194b09ecdb does not exist. Creating ...
2019-09-25 12:42:59,193 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/479be886-90ce-44b4-8573-19194b09ecdb/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,208 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/479be886-90ce-44b4-8573-19194b09ecdb has been successfully formatted.
2019-09-25 12:42:59,209 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-19194B09ECDB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,210 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,210 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,210 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,210 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,211 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,211 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,211 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/479be886-90ce-44b4-8573-19194b09ecdb
2019-09-25 12:42:59,218 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,219 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,219 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,219 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,220 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,220 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,220 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,220 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,221 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,221 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,222 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,230 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: start as a follower, conf=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:42:59,230 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,230 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start FollowerState
2019-09-25 12:42:59,232 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-19194B09ECDB,id=46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:42:59,254 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 479be886-90ce-44b4-8573-19194b09ecdb, Nodes: 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,276 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: addNew group-882BEFD9D90C:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] returns group-882BEFD9D90C:java.util.concurrent.CompletableFuture@2273485e[Not completed]
2019-09-25 12:42:59,292 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: new RaftServerImpl for group-882BEFD9D90C:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,293 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,293 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,293 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,293 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,293 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,293 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: ConfigurationManager, init=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,294 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:42:59,294 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/bd079b6b-652b-4dd8-b60c-882befd9d90c does not exist. Creating ...
2019-09-25 12:42:59,308 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/bd079b6b-652b-4dd8-b60c-882befd9d90c/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,320 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/bd079b6b-652b-4dd8-b60c-882befd9d90c has been successfully formatted.
2019-09-25 12:42:59,321 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-882BEFD9D90C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,321 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,321 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,321 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,321 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,322 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,322 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,322 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/bd079b6b-652b-4dd8-b60c-882befd9d90c
2019-09-25 12:42:59,351 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,351 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,352 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,353 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,353 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,354 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,354 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,354 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,354 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,358 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: start as a follower, conf=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:42:59,359 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,359 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start FollowerState
2019-09-25 12:42:59,359 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-882BEFD9D90C,id=11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:42:59,368 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bd079b6b-652b-4dd8-b60c-882befd9d90c, Nodes: 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,382 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: addNew group-EFA7C27C315A:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] returns group-EFA7C27C315A:java.util.concurrent.CompletableFuture@5950be37[Not completed]
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: new RaftServerImpl for group-EFA7C27C315A:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,384 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: ConfigurationManager, init=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,385 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:42:59,385 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/2c30861a-8147-4b0f-9bf6-efa7c27c315a does not exist. Creating ...
2019-09-25 12:42:59,407 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/2c30861a-8147-4b0f-9bf6-efa7c27c315a/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,419 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/2c30861a-8147-4b0f-9bf6-efa7c27c315a has been successfully formatted.
2019-09-25 12:42:59,420 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-EFA7C27C315A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/2c30861a-8147-4b0f-9bf6-efa7c27c315a
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,421 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,422 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,422 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,422 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,422 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,422 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,423 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,423 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,423 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,423 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,427 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: start as a follower, conf=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:42:59,427 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,427 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start FollowerState
2019-09-25 12:42:59,429 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EFA7C27C315A,id=11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:42:59,438 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2c30861a-8147-4b0f-9bf6-efa7c27c315a, Nodes: 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,460 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: addNew group-7C9962309E7E:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] returns group-7C9962309E7E:java.util.concurrent.CompletableFuture@2fcfe977[Not completed]
2019-09-25 12:42:59,463 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: new RaftServerImpl for group-7C9962309E7E:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,463 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,464 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,464 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,464 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,464 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,464 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: ConfigurationManager, init=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,465 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:42:59,465 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/b0c1a7e2-c71c-4bed-aa81-7c9962309e7e does not exist. Creating ...
2019-09-25 12:42:59,468 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-25 12:42:59,479 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/b0c1a7e2-c71c-4bed-aa81-7c9962309e7e/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,490 [Thread-221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:42:59,492 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/b0c1a7e2-c71c-4bed-aa81-7c9962309e7e has been successfully formatted.
2019-09-25 12:42:59,493 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7C9962309E7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,493 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,493 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,493 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,493 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,494 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,494 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,494 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/b0c1a7e2-c71c-4bed-aa81-7c9962309e7e
2019-09-25 12:42:59,500 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,501 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,502 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,503 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,503 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,504 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,574 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: start as a follower, conf=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:42:59,574 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,574 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start FollowerState
2019-09-25 12:42:59,575 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7C9962309E7E,id=35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:42:59,613 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0c1a7e2-c71c-4bed-aa81-7c9962309e7e, Nodes: 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,628 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: addNew group-DD4C4D04DDF4:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] returns group-DD4C4D04DDF4:java.util.concurrent.CompletableFuture@5c9e269d[Not completed]
2019-09-25 12:42:59,629 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: new RaftServerImpl for group-DD4C4D04DDF4:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,629 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,629 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,630 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,630 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,630 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,630 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: ConfigurationManager, init=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,630 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:42:59,630 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/8960647b-6211-4ca8-94c0-dd4c4d04ddf4 does not exist. Creating ...
2019-09-25 12:42:59,643 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/8960647b-6211-4ca8-94c0-dd4c4d04ddf4/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,672 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/8960647b-6211-4ca8-94c0-dd4c4d04ddf4 has been successfully formatted.
2019-09-25 12:42:59,672 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DD4C4D04DDF4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,672 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,672 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,672 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,672 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/8960647b-6211-4ca8-94c0-dd4c4d04ddf4
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,673 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,674 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,674 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,674 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,674 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,674 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,674 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,675 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,675 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,675 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,678 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: start as a follower, conf=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:42:59,678 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,678 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start FollowerState
2019-09-25 12:42:59,678 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD4C4D04DDF4,id=46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:42:59,690 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8960647b-6211-4ca8-94c0-dd4c4d04ddf4, Nodes: 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,702 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: addNew group-0546568B3916:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] returns group-0546568B3916:java.util.concurrent.CompletableFuture@36671802[Not completed]
2019-09-25 12:42:59,704 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: new RaftServerImpl for group-0546568B3916:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,704 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,705 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,705 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,705 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,705 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,705 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: ConfigurationManager, init=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,705 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:42:59,706 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/43456d4e-59a4-41e0-9ad6-0546568b3916 does not exist. Creating ...
2019-09-25 12:42:59,719 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/43456d4e-59a4-41e0-9ad6-0546568b3916/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,732 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/43456d4e-59a4-41e0-9ad6-0546568b3916 has been successfully formatted.
2019-09-25 12:42:59,733 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0546568B3916: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,733 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,733 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,733 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,733 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,733 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,734 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,734 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/43456d4e-59a4-41e0-9ad6-0546568b3916
2019-09-25 12:42:59,737 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,737 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,739 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,739 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,739 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,740 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,740 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,740 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,740 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,743 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: start as a follower, conf=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:42:59,744 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,744 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start FollowerState
2019-09-25 12:42:59,744 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0546568B3916,id=0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:42:59,758 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 43456d4e-59a4-41e0-9ad6-0546568b3916, Nodes: 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,771 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: addNew group-81EBC5F52618:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] returns group-81EBC5F52618:java.util.concurrent.CompletableFuture@74eb8648[Not completed]
2019-09-25 12:42:59,773 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: new RaftServerImpl for group-81EBC5F52618:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: ConfigurationManager, init=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:42:59,774 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/8431f23f-ccec-4a06-8024-81ebc5f52618 does not exist. Creating ...
2019-09-25 12:42:59,788 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/8431f23f-ccec-4a06-8024-81ebc5f52618/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,801 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/8431f23f-ccec-4a06-8024-81ebc5f52618 has been successfully formatted.
2019-09-25 12:42:59,801 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-81EBC5F52618: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,801 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,801 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/8431f23f-ccec-4a06-8024-81ebc5f52618
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,802 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,803 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,804 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,806 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: start as a follower, conf=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:42:59,806 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,807 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start FollowerState
2019-09-25 12:42:59,807 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-81EBC5F52618,id=11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:42:59,816 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8431f23f-ccec-4a06-8024-81ebc5f52618, Nodes: 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,831 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: addNew group-979E51C5A7BF:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] returns group-979E51C5A7BF:java.util.concurrent.CompletableFuture@63457257[Not completed]
2019-09-25 12:42:59,833 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: new RaftServerImpl for group-979E51C5A7BF:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,833 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,833 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,833 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,833 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,834 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,834 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: ConfigurationManager, init=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,834 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:42:59,834 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5666250b-c554-4fec-925b-979e51c5a7bf does not exist. Creating ...
2019-09-25 12:42:59,854 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5666250b-c554-4fec-925b-979e51c5a7bf/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,868 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5666250b-c554-4fec-925b-979e51c5a7bf has been successfully formatted.
2019-09-25 12:42:59,868 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-979E51C5A7BF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,868 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,868 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,868 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,869 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,869 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,869 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,869 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5666250b-c554-4fec-925b-979e51c5a7bf
2019-09-25 12:42:59,869 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,870 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,870 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,870 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,870 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,870 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,870 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,871 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,871 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,871 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,871 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,872 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,872 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,872 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,872 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,875 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: start as a follower, conf=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:42:59,875 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,875 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start FollowerState
2019-09-25 12:42:59,876 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-979E51C5A7BF,id=0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:42:59,884 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5666250b-c554-4fec-925b-979e51c5a7bf, Nodes: 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,897 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: addNew group-65F9244FE44E:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] returns group-65F9244FE44E:java.util.concurrent.CompletableFuture@539858d3[Not completed]
2019-09-25 12:42:59,899 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: new RaftServerImpl for group-65F9244FE44E:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,899 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,899 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,899 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,899 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,899 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,900 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: ConfigurationManager, init=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,900 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:42:59,900 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/507915f6-eeaf-4141-9c1e-65f9244fe44e does not exist. Creating ...
2019-09-25 12:42:59,913 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/507915f6-eeaf-4141-9c1e-65f9244fe44e/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,930 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/507915f6-eeaf-4141-9c1e-65f9244fe44e has been successfully formatted.
2019-09-25 12:42:59,931 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-65F9244FE44E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,931 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,931 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,931 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,931 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,931 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,932 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/507915f6-eeaf-4141-9c1e-65f9244fe44e
2019-09-25 12:42:59,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,934 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,935 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,937 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: start as a follower, conf=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:42:59,938 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,938 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start FollowerState
2019-09-25 12:42:59,938 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-65F9244FE44E,id=46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:42:59,947 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 507915f6-eeaf-4141-9c1e-65f9244fe44e, Nodes: 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:42:59,959 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: addNew group-9EA931517C34:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] returns group-9EA931517C34:java.util.concurrent.CompletableFuture@10e77f02[Not completed]
2019-09-25 12:42:59,960 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: new RaftServerImpl for group-9EA931517C34:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] with ContainerStateMachine:uninitialized
2019-09-25 12:42:59,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:42:59,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:42:59,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:42:59,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:42:59,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:42:59,961 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: ConfigurationManager, init=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 12:42:59,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:42:59,962 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5c655cfc-b5bd-4bdf-916d-9ea931517c34 does not exist. Creating ...
2019-09-25 12:42:59,974 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5c655cfc-b5bd-4bdf-916d-9ea931517c34/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:42:59,987 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5c655cfc-b5bd-4bdf-916d-9ea931517c34 has been successfully formatted.
2019-09-25 12:42:59,987 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-9EA931517C34: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:42:59,987 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:42:59,987 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5c655cfc-b5bd-4bdf-916d-9ea931517c34
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:42:59,988 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:42:59,989 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:42:59,990 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:42:59,990 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:42:59,990 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:42:59,990 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:42:59,990 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:42:59,992 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: start as a follower, conf=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:42:59,993 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:42:59,993 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start FollowerState
2019-09-25 12:42:59,993 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9EA931517C34,id=0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:43:00,001 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5c655cfc-b5bd-4bdf-916d-9ea931517c34, Nodes: 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,021 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: addNew group-12ABCFD6FA0B:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] returns group-12ABCFD6FA0B:java.util.concurrent.CompletableFuture@303107ca[Not completed]
2019-09-25 12:43:00,022 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: new RaftServerImpl for group-12ABCFD6FA0B:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,022 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: ConfigurationManager, init=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:43:00,023 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/9b7a0c85-61b6-4b4f-8e6b-12abcfd6fa0b does not exist. Creating ...
2019-09-25 12:43:00,035 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/9b7a0c85-61b6-4b4f-8e6b-12abcfd6fa0b/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,037 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/9b7a0c85-61b6-4b4f-8e6b-12abcfd6fa0b has been successfully formatted.
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-12ABCFD6FA0B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,038 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/9b7a0c85-61b6-4b4f-8e6b-12abcfd6fa0b
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,039 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,040 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,040 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,042 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: start as a follower, conf=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:00,042 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,042 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start FollowerState
2019-09-25 12:43:00,042 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12ABCFD6FA0B,id=0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:43:00,049 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9b7a0c85-61b6-4b4f-8e6b-12abcfd6fa0b, Nodes: 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,068 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: addNew group-72C3C3A4BBCA:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] returns group-72C3C3A4BBCA:java.util.concurrent.CompletableFuture@2a393b[Not completed]
2019-09-25 12:43:00,069 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: new RaftServerImpl for group-72C3C3A4BBCA:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,069 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,069 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,069 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,069 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,069 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,070 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: ConfigurationManager, init=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,070 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:43:00,070 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/548502a8-4253-45fe-9db0-72c3c3a4bbca does not exist. Creating ...
2019-09-25 12:43:00,082 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/548502a8-4253-45fe-9db0-72c3c3a4bbca/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,095 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/548502a8-4253-45fe-9db0-72c3c3a4bbca has been successfully formatted.
2019-09-25 12:43:00,095 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-72C3C3A4BBCA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,096 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,096 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,096 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,096 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,097 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,097 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,097 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/548502a8-4253-45fe-9db0-72c3c3a4bbca
2019-09-25 12:43:00,097 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,097 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,098 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,098 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,098 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,098 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,098 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,099 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,099 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,100 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,101 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,104 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: start as a follower, conf=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:00,104 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,104 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start FollowerState
2019-09-25 12:43:00,105 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C3C3A4BBCA,id=11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:43:00,116 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 548502a8-4253-45fe-9db0-72c3c3a4bbca, Nodes: 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,129 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: addNew group-4C14DE199E4E:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] returns group-4C14DE199E4E:java.util.concurrent.CompletableFuture@6dd9c755[Not completed]
2019-09-25 12:43:00,131 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: new RaftServerImpl for group-4C14DE199E4E:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,131 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,131 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,131 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,131 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,132 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,132 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: ConfigurationManager, init=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,132 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:43:00,132 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/a6d64692-7cc8-4549-bd83-4c14de199e4e does not exist. Creating ...
2019-09-25 12:43:00,145 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/a6d64692-7cc8-4549-bd83-4c14de199e4e/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,155 [Thread-221] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume43006, with user19449 as owner.
2019-09-25 12:43:00,161 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/a6d64692-7cc8-4549-bd83-4c14de199e4e has been successfully formatted.
2019-09-25 12:43:00,163 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4C14DE199E4E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,165 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/a6d64692-7cc8-4549-bd83-4c14de199e4e
2019-09-25 12:43:00,165 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,165 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,165 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,168 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,168 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,169 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,169 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,169 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,174 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: start as a follower, conf=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:00,174 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,174 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start FollowerState
2019-09-25 12:43:00,175 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4C14DE199E4E,id=46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:43:00,186 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a6d64692-7cc8-4549-bd83-4c14de199e4e, Nodes: 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,204 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: addNew group-8FBC25286D0C:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] returns group-8FBC25286D0C:java.util.concurrent.CompletableFuture@654dc57a[Not completed]
2019-09-25 12:43:00,205 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: new RaftServerImpl for group-8FBC25286D0C:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,205 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,206 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,206 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,206 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,206 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,206 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: ConfigurationManager, init=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,206 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:43:00,207 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/215aed43-623e-4a64-b342-8fbc25286d0c does not exist. Creating ...
2019-09-25 12:43:00,219 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/215aed43-623e-4a64-b342-8fbc25286d0c/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,232 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/215aed43-623e-4a64-b342-8fbc25286d0c has been successfully formatted.
2019-09-25 12:43:00,232 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-8FBC25286D0C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,232 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,232 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/215aed43-623e-4a64-b342-8fbc25286d0c
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,234 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,236 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,236 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,236 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,237 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,237 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,239 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: start as a follower, conf=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:00,239 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,239 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start FollowerState
2019-09-25 12:43:00,239 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8FBC25286D0C,id=0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:43:00,245 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 215aed43-623e-4a64-b342-8fbc25286d0c, Nodes: 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,255 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: addNew group-A9D9FD26D764:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] returns group-A9D9FD26D764:java.util.concurrent.CompletableFuture@2638908a[Not completed]
2019-09-25 12:43:00,256 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: new RaftServerImpl for group-A9D9FD26D764:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,256 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,256 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,256 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,257 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,257 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,257 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: ConfigurationManager, init=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,257 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:43:00,257 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/b3cc667c-8991-43be-be7e-a9d9fd26d764 does not exist. Creating ...
2019-09-25 12:43:00,270 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/b3cc667c-8991-43be-be7e-a9d9fd26d764/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,283 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/b3cc667c-8991-43be-be7e-a9d9fd26d764 has been successfully formatted.
2019-09-25 12:43:00,283 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A9D9FD26D764: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/b3cc667c-8991-43be-be7e-a9d9fd26d764
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,285 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,286 [IPC Server handler 19 on 45560] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume43006 for user:user19449
2019-09-25 12:43:00,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,286 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,288 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: start as a follower, conf=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:00,288 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,288 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start FollowerState
2019-09-25 12:43:00,288 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9D9FD26D764,id=46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:43:00,293 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b3cc667c-8991-43be-be7e-a9d9fd26d764, Nodes: 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,302 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: addNew group-123619E4588B:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] returns group-123619E4588B:java.util.concurrent.CompletableFuture@17a086c[Not completed]
2019-09-25 12:43:00,302 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: new RaftServerImpl for group-123619E4588B:[46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: ConfigurationManager, init=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis] (custom)
2019-09-25 12:43:00,303 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/2c91c3f1-5761-4534-99fb-123619e4588b does not exist. Creating ...
2019-09-25 12:43:00,320 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/2c91c3f1-5761-4534-99fb-123619e4588b/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,332 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/2c91c3f1-5761-4534-99fb-123619e4588b has been successfully formatted.
2019-09-25 12:43:00,332 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-123619E4588B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,332 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/2c91c3f1-5761-4534-99fb-123619e4588b
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,333 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,334 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,335 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,335 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,335 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,335 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,337 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: start as a follower, conf=-1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:00,337 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,337 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start FollowerState
2019-09-25 12:43:00,337 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-123619E4588B,id=46e204cb-f3c6-48b7-a572-0bdf52c235a1
2019-09-25 12:43:00,670 [Thread-221] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume43006/bucket71097, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:43:00,672 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2c91c3f1-5761-4534-99fb-123619e4588b, Nodes: 46e204cb-f3c6-48b7-a572-0bdf52c235a1{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,673 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:00,685 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: addNew group-29D20914A3C7:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] returns group-29D20914A3C7:java.util.concurrent.CompletableFuture@61411d3b[Not completed]
2019-09-25 12:43:00,689 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: new RaftServerImpl for group-29D20914A3C7:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,689 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,690 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,691 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: ConfigurationManager, init=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,691 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:43:00,692 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/33dd23ff-cc80-45ce-9936-29d20914a3c7 does not exist. Creating ...
2019-09-25 12:43:00,705 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/33dd23ff-cc80-45ce-9936-29d20914a3c7/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,719 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/33dd23ff-cc80-45ce-9936-29d20914a3c7 has been successfully formatted.
2019-09-25 12:43:00,719 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-29D20914A3C7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,720 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,720 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,720 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,720 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,720 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,720 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/33dd23ff-cc80-45ce-9936-29d20914a3c7
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,721 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,722 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,722 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,722 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,722 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,723 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,723 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,723 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,723 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,725 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: start as a follower, conf=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:00,726 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,726 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start FollowerState
2019-09-25 12:43:00,726 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-29D20914A3C7,id=11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:43:00,731 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 33dd23ff-cc80-45ce-9936-29d20914a3c7, Nodes: 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,732 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:00,748 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: addNew group-AF2CEE0E206C:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] returns group-AF2CEE0E206C:java.util.concurrent.CompletableFuture@39f12c1b[Not completed]
2019-09-25 12:43:00,750 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: new RaftServerImpl for group-AF2CEE0E206C:[11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,751 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: ConfigurationManager, init=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,751 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis] (custom)
2019-09-25 12:43:00,751 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/7da2add8-31dd-4fca-aff2-af2cee0e206c does not exist. Creating ...
2019-09-25 12:43:00,764 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/7da2add8-31dd-4fca-aff2-af2cee0e206c/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,777 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/7da2add8-31dd-4fca-aff2-af2cee0e206c has been successfully formatted.
2019-09-25 12:43:00,777 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AF2CEE0E206C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,778 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/7da2add8-31dd-4fca-aff2-af2cee0e206c
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,779 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,780 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,780 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,780 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,780 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,780 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,781 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,781 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,781 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,783 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: start as a follower, conf=-1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:00,783 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,783 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start FollowerState
2019-09-25 12:43:00,784 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF2CEE0E206C,id=11e2e2c2-ccb4-47dd-8370-62ab6b97f33f
2019-09-25 12:43:00,789 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7da2add8-31dd-4fca-aff2-af2cee0e206c, Nodes: 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,790 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:00,790 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:00,808 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: addNew group-0F8805FFE2D2:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] returns group-0F8805FFE2D2:java.util.concurrent.CompletableFuture@28df380b[Not completed]
2019-09-25 12:43:00,810 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: new RaftServerImpl for group-0F8805FFE2D2:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,810 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,810 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,811 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,811 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,811 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,811 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: ConfigurationManager, init=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,811 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:43:00,812 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/6f1ffa76-81f2-4cf4-9960-0f8805ffe2d2 does not exist. Creating ...
2019-09-25 12:43:00,824 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/6f1ffa76-81f2-4cf4-9960-0f8805ffe2d2/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,851 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/6f1ffa76-81f2-4cf4-9960-0f8805ffe2d2 has been successfully formatted.
2019-09-25 12:43:00,862 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0F8805FFE2D2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,863 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/6f1ffa76-81f2-4cf4-9960-0f8805ffe2d2
2019-09-25 12:43:00,864 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,864 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,864 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,864 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,864 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,866 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,866 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,866 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,866 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,866 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,866 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,867 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,867 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,867 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,867 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,869 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: start as a follower, conf=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:00,869 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,870 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start FollowerState
2019-09-25 12:43:00,875 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F8805FFE2D2,id=35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:43:00,888 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6f1ffa76-81f2-4cf4-9960-0f8805ffe2d2, Nodes: 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,889 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:00,889 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:00,898 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: addNew group-997BDB1EB992:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] returns group-997BDB1EB992:java.util.concurrent.CompletableFuture@3b44408f[Not completed]
2019-09-25 12:43:00,899 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: new RaftServerImpl for group-997BDB1EB992:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,899 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,899 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,899 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,899 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,900 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,900 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: ConfigurationManager, init=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,900 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:43:00,900 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/0f2c3008-6062-4f0c-8903-997bdb1eb992 does not exist. Creating ...
2019-09-25 12:43:00,901 [Thread-221] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket71097.volume43006 implemented by OzoneFileSystem{URI=o3fs://bucket71097.volume43006, workingDir=o3fs://bucket71097.volume43006/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-25 12:43:00,913 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/0f2c3008-6062-4f0c-8903-997bdb1eb992/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,926 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/0f2c3008-6062-4f0c-8903-997bdb1eb992 has been successfully formatted.
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-997BDB1EB992: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/0f2c3008-6062-4f0c-8903-997bdb1eb992
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,930 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,933 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: start as a follower, conf=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:00,933 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,933 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start FollowerState
2019-09-25 12:43:00,934 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-997BDB1EB992,id=5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:43:00,938 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0f2c3008-6062-4f0c-8903-997bdb1eb992, Nodes: 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,938 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:00,938 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:00,951 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: addNew group-A50072B5C5BD:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] returns group-A50072B5C5BD:java.util.concurrent.CompletableFuture@59c934b7[Not completed]
2019-09-25 12:43:00,952 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: new RaftServerImpl for group-A50072B5C5BD:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] with ContainerStateMachine:uninitialized
2019-09-25 12:43:00,952 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:00,954 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:00,958 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:00,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:00,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:00,959 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: ConfigurationManager, init=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:00,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:43:00,959 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/e66645ab-a946-4eb0-b8c0-a50072b5c5bd does not exist. Creating ...
2019-09-25 12:43:00,963 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/e66645ab-a946-4eb0-b8c0-a50072b5c5bd/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:00,985 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/e66645ab-a946-4eb0-b8c0-a50072b5c5bd has been successfully formatted.
2019-09-25 12:43:00,985 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A50072B5C5BD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:00,985 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:00,985 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/e66645ab-a946-4eb0-b8c0-a50072b5c5bd
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:00,986 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:00,987 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:00,988 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:00,988 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:00,988 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:00,988 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:00,990 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: start as a follower, conf=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:00,990 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:00,991 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start FollowerState
2019-09-25 12:43:00,991 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A50072B5C5BD,id=5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:43:00,995 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e66645ab-a946-4eb0-b8c0-a50072b5c5bd, Nodes: 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:00,995 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:00,995 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,003 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: addNew group-42481A510715:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] returns group-42481A510715:java.util.concurrent.CompletableFuture@62f7c914[Not completed]
2019-09-25 12:43:01,004 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: new RaftServerImpl for group-42481A510715:[0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,005 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,005 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,005 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,005 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,005 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,005 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: ConfigurationManager, init=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,006 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis] (custom)
2019-09-25 12:43:01,006 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/e90970f1-4653-47a1-bda4-42481a510715 does not exist. Creating ...
2019-09-25 12:43:01,019 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/e90970f1-4653-47a1-bda4-42481a510715/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,032 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/e90970f1-4653-47a1-bda4-42481a510715 has been successfully formatted.
2019-09-25 12:43:01,032 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-42481A510715: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,032 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,032 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/e90970f1-4653-47a1-bda4-42481a510715
12:43:01.025 [IPC Server handler 19 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,033 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,034 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,034 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,034 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,034 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,034 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,034 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,035 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,035 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,035 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,035 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,036 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,036 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,036 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,040 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: start as a follower, conf=-1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:01,040 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,040 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start FollowerState
2019-09-25 12:43:01,040 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-42481A510715,id=0d6d7abe-064e-4f87-bb34-13a3ff0fda59
2019-09-25 12:43:01,044 [Thread-221] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-25 12:43:01,045 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e90970f1-4653-47a1-bda4-42481a510715, Nodes: 0d6d7abe-064e-4f87-bb34-13a3ff0fda59{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,045 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,046 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,046 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,079 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: addNew group-77C63239C954:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] returns group-77C63239C954:java.util.concurrent.CompletableFuture@40e85405[Not completed]
2019-09-25 12:43:01,080 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: new RaftServerImpl for group-77C63239C954:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,083 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,085 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,085 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,085 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,085 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,086 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: ConfigurationManager, init=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,086 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:43:01,086 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/9a9d0600-3538-4c57-b3dc-77c63239c954 does not exist. Creating ...
2019-09-25 12:43:01,100 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/9a9d0600-3538-4c57-b3dc-77c63239c954/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,114 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/9a9d0600-3538-4c57-b3dc-77c63239c954 has been successfully formatted.
2019-09-25 12:43:01,115 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-77C63239C954: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,115 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,115 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,115 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,116 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,116 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,116 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,116 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/9a9d0600-3538-4c57-b3dc-77c63239c954
2019-09-25 12:43:01,116 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,116 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,117 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,117 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,117 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,117 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,117 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,125 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,125 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,126 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,126 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,126 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,127 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,127 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,127 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,133 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: start as a follower, conf=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:01,133 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,134 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start FollowerState
2019-09-25 12:43:01,134 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-77C63239C954,id=5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:43:01,150 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9a9d0600-3538-4c57-b3dc-77c63239c954, Nodes: 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,150 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,150 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,150 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,163 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: addNew group-BCD4E8320554:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] returns group-BCD4E8320554:java.util.concurrent.CompletableFuture@125d557a[Not completed]
2019-09-25 12:43:01,172 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-25 12:43:01,174 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: new RaftServerImpl for group-BCD4E8320554:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,174 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,174 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-25 12:43:01,174 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,176 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,177 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: ConfigurationManager, init=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:43:01,178 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ff757009-dbe1-4930-8fe2-bcd4e8320554 does not exist. Creating ...
2019-09-25 12:43:01,201 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ff757009-dbe1-4930-8fe2-bcd4e8320554/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,225 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ff757009-dbe1-4930-8fe2-bcd4e8320554 has been successfully formatted.
2019-09-25 12:43:01,225 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-BCD4E8320554: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,225 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,225 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,225 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,225 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ff757009-dbe1-4930-8fe2-bcd4e8320554
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,226 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,227 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,227 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,227 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,227 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,227 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,230 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: start as a follower, conf=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:01,230 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,230 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start FollowerState
2019-09-25 12:43:01,230 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCD4E8320554,id=5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:43:01,235 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ff757009-dbe1-4930-8fe2-bcd4e8320554, Nodes: 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,235 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,236 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,236 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,240 [Thread-221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:01,245 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: addNew group-66EEA4202132:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] returns group-66EEA4202132:java.util.concurrent.CompletableFuture@6587c443[Not completed]
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: new RaftServerImpl for group-66EEA4202132:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,246 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: ConfigurationManager, init=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,247 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:43:01,247 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/086a7fa8-fa2c-4a27-b2b0-66eea4202132 does not exist. Creating ...
2019-09-25 12:43:01,260 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/086a7fa8-fa2c-4a27-b2b0-66eea4202132/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/086a7fa8-fa2c-4a27-b2b0-66eea4202132 has been successfully formatted.
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-66EEA4202132: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,274 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/086a7fa8-fa2c-4a27-b2b0-66eea4202132
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,275 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,276 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,276 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,276 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,286 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,287 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,287 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,287 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,288 [Thread-221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:01,289 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: start as a follower, conf=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:01,290 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,290 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start FollowerState
2019-09-25 12:43:01,290 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-66EEA4202132,id=35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:43:01,296 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 086a7fa8-fa2c-4a27-b2b0-66eea4202132, Nodes: 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,296 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,296 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,296 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,305 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: addNew group-F458F83F2872:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] returns group-F458F83F2872:java.util.concurrent.CompletableFuture@275bc23c[Not completed]
2019-09-25 12:43:01,306 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: new RaftServerImpl for group-F458F83F2872:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,306 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,306 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,306 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,306 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,307 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,307 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: ConfigurationManager, init=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,307 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:43:01,307 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/8cf25c8c-c525-45a7-8822-f458f83f2872 does not exist. Creating ...
2019-09-25 12:43:01,320 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/8cf25c8c-c525-45a7-8822-f458f83f2872/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,333 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/8cf25c8c-c525-45a7-8822-f458f83f2872 has been successfully formatted.
2019-09-25 12:43:01,333 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F458F83F2872: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,333 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,333 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,333 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/8cf25c8c-c525-45a7-8822-f458f83f2872
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,334 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,335 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,335 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,335 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,335 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,335 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,335 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,336 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,336 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,336 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,336 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,336 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,337 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,339 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: start as a follower, conf=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:01,339 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,339 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start FollowerState
2019-09-25 12:43:01,340 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F458F83F2872,id=35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:43:01,344 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8cf25c8c-c525-45a7-8822-f458f83f2872, Nodes: 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,345 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,345 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,345 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,354 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: addNew group-79C027DC6F78:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] returns group-79C027DC6F78:java.util.concurrent.CompletableFuture@74867580[Not completed]
12:43:01.410 [IPC Server handler 17 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:01,521 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: new RaftServerImpl for group-79C027DC6F78:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,521 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,522 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: ConfigurationManager, init=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,522 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:43:01,523 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/f21a9223-e4ec-4039-9d19-79c027dc6f78 does not exist. Creating ...
2019-09-25 12:43:01,538 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/f21a9223-e4ec-4039-9d19-79c027dc6f78/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,553 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/f21a9223-e4ec-4039-9d19-79c027dc6f78 has been successfully formatted.
2019-09-25 12:43:01,553 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-79C027DC6F78: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,554 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,554 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,554 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,554 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,554 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,555 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/f21a9223-e4ec-4039-9d19-79c027dc6f78
2019-09-25 12:43:01,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,557 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,557 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,557 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,557 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,558 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,558 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,561 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: start as a follower, conf=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:01,561 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,561 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start FollowerState
2019-09-25 12:43:01,562 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-79C027DC6F78,id=35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:43:01,569 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f21a9223-e4ec-4039-9d19-79c027dc6f78, Nodes: 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,569 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,569 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,569 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,578 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: addNew group-DB60C150B1A3:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] returns group-DB60C150B1A3:java.util.concurrent.CompletableFuture@7fc3758b[Not completed]
2019-09-25 12:43:01,579 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: new RaftServerImpl for group-DB60C150B1A3:[35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,579 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,579 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,579 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,580 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,580 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,580 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: ConfigurationManager, init=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,580 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis] (custom)
2019-09-25 12:43:01,580 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/08a94983-f9e3-473d-aceb-db60c150b1a3 does not exist. Creating ...
2019-09-25 12:43:01,593 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/08a94983-f9e3-473d-aceb-db60c150b1a3/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,595 [Thread-221] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 12:43:01,595 [Thread-221] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:43:01,598 [Thread-221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-25 12:43:01,598 [Thread-221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-25 12:43:01,606 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/08a94983-f9e3-473d-aceb-db60c150b1a3 has been successfully formatted.
2019-09-25 12:43:01,606 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DB60C150B1A3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,606 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,606 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/08a94983-f9e3-473d-aceb-db60c150b1a3
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,607 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,608 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,609 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,609 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,609 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,609 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,610 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,610 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,612 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: start as a follower, conf=-1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:01,613 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,613 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start FollowerState
2019-09-25 12:43:01,613 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DB60C150B1A3,id=35a9f88d-76d2-4b6c-86f2-100b645542d6
2019-09-25 12:43:01,618 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 08a94983-f9e3-473d-aceb-db60c150b1a3, Nodes: 35a9f88d-76d2-4b6c-86f2-100b645542d6{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,618 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:01,618 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,619 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,619 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,627 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: addNew group-463FAC9FD497:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] returns group-463FAC9FD497:java.util.concurrent.CompletableFuture@577689fc[Not completed]
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: new RaftServerImpl for group-463FAC9FD497:[5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105] with ContainerStateMachine:uninitialized
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 12:43:01,629 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: ConfigurationManager, init=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null, confs=<EMPTY_MAP>
2019-09-25 12:43:01,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis] (custom)
2019-09-25 12:43:01,630 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/33d5baad-f563-47de-ae32-463fac9fd497 does not exist. Creating ...
2019-09-25 12:43:01,633 [Thread-221] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:43:01,643 [Thread-221] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:43:01,643 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/33d5baad-f563-47de-ae32-463fac9fd497/in_use.lock acquired by nodename 17025@pr-hdds-1569-shd4m-3693607622
2019-09-25 12:43:01,647 [Thread-221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:01,656 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/33d5baad-f563-47de-ae32-463fac9fd497 has been successfully formatted.
2019-09-25 12:43:01,656 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-463FAC9FD497: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 12:43:01,656 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 12:43:01,656 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 12:43:01,656 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 12:43:01,656 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/33d5baad-f563-47de-ae32-463fac9fd497
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 12:43:01,657 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 12:43:01,658 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 12:43:01,658 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 12:43:01,658 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 12:43:01,658 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 12:43:01,658 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 12:43:01,659 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 12:43:01,659 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 12:43:01,659 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 12:43:01,659 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 12:43:01,661 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: start as a follower, conf=-1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:01,661 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 12:43:01,661 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start FollowerState
2019-09-25 12:43:01,661 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-463FAC9FD497,id=5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9
2019-09-25 12:43:01,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 33d5baad-f563-47de-ae32-463fac9fd497, Nodes: 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9{ip: 192.168.151.73, host: pr-hdds-1569-shd4m-3693607622, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 12:43:01,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:01,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:01,667 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,667 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,667 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,667 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:01,670 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:01,671 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:01,672 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:01,672 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,672 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,672 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,672 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:01,672 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:01,673 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:01,673 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:01,673 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,674 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,674 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,674 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:01,674 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:01,675 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:01,675 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:01,675 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:01,676 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:01,676 [Thread-221] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:43:01,676 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:01,676 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:01,676 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:01,745 [Thread-221] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-25 12:43:01,885 [Thread-221] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1038849443_0001
2019-09-25 12:43:01,886 [Thread-221] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:43:02,075 [Thread-221] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:43:02,075 [Thread-221] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1038849443_0001
2019-09-25 12:43:02,076 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1038849443_0001
2019-09-25 12:43:02,082 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:43:02,096 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:02,097 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:02,100 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:43:02,172 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:43:02,174 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:02,218 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:02,220 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:02,251 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:02,254 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:2230+838
2019-09-25 12:43:02,265 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:02,266 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:43:02.292 [IPC Server handler 17 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:02,296 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
12:43:02.301 [IPC Server handler 16 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:02,309 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:02,334 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:02,334 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:02,334 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:02,334 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:02,335 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:02,335 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:02,335 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:02,336 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:02,336 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:02,336 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:02.345 [IPC Server handler 13 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:02,347 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:02,348 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:03,079 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1038849443_0001 running in uber mode : false
2019-09-25 12:43:03,081 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 12:43:04,119 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:group-BC04EE9DD79B changes to CANDIDATE, lastRpcTime:5113, electionTimeout:5112ms
2019-09-25 12:43:04,124 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown FollowerState
2019-09-25 12:43:04,125 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,130 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderElection
2019-09-25 12:43:04,150 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1: begin an election at term 1 for -1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:04,153 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown LeaderElection
2019-09-25 12:43:04,153 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,153 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: change Leader from null to 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at term 1 for becomeLeader, leader elected after 5274ms
2019-09-25 12:43:04,163 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,163 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,166 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,170 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,170 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,171 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,184 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderState
2019-09-25 12:43:04,215 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,229 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B: set configuration 0: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null at 0
2019-09-25 12:43:04,355 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1:group-19194B09ECDB changes to CANDIDATE, lastRpcTime:5125, electionTimeout:5123ms
2019-09-25 12:43:04,364 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:group-882BEFD9D90C changes to CANDIDATE, lastRpcTime:5005, electionTimeout:5001ms
2019-09-25 12:43:04,367 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown FollowerState
2019-09-25 12:43:04,367 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown FollowerState
2019-09-25 12:43:04,367 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,367 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,367 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderElection
2019-09-25 12:43:04,367 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderElection
2019-09-25 12:43:04,423 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BC04EE9DD79B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ce1f1114-75b8-4b2d-9ed1-bc04ee9dd79b/current/log_inprogress_0
2019-09-25 12:43:04,423 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2: begin an election at term 1 for -1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:04,423 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3: begin an election at term 1 for -1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:04,425 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown LeaderElection
2019-09-25 12:43:04,425 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown LeaderElection
2019-09-25 12:43:04,426 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,426 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,426 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: change Leader from null to 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at term 1 for becomeLeader, leader elected after 5104ms
2019-09-25 12:43:04,426 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: change Leader from null to 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at term 1 for becomeLeader, leader elected after 5215ms
2019-09-25 12:43:04,428 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,430 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,430 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,430 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,430 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,431 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,431 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,431 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,431 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,431 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,432 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,432 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,435 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderState
2019-09-25 12:43:04,436 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,436 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderState
2019-09-25 12:43:04,436 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,436 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C: set configuration 0: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null at 0
2019-09-25 12:43:04,463 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB: set configuration 0: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null at 0
2019-09-25 12:43:04,499 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-882BEFD9D90C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/bd079b6b-652b-4dd8-b60c-882befd9d90c/current/log_inprogress_0
2019-09-25 12:43:04,513 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-19194B09ECDB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/479be886-90ce-44b4-8573-19194b09ecdb/current/log_inprogress_0
2019-09-25 12:43:04,600 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:group-EFA7C27C315A changes to CANDIDATE, lastRpcTime:5172, electionTimeout:5172ms
2019-09-25 12:43:04,600 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown FollowerState
2019-09-25 12:43:04,600 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,601 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderElection
2019-09-25 12:43:04,618 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4: begin an election at term 1 for -1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:04,618 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown LeaderElection
2019-09-25 12:43:04,618 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,618 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: change Leader from null to 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at term 1 for becomeLeader, leader elected after 5198ms
2019-09-25 12:43:04,618 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,619 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,619 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,619 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,619 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,619 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,624 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderState
2019-09-25 12:43:04,625 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,626 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A: set configuration 0: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null at 0
2019-09-25 12:43:04,664 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:04,668 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:04,668 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:04,669 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:04,669 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:04,669 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:04,669 [IPC Server handler 0 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:04,670 [IPC Server handler 0 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:04,670 [IPC Server handler 0 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:04,671 [IPC Server handler 0 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:04,671 [IPC Server handler 0 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:04.677 [IPC Server handler 11 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:04,681 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:04,681 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:04,685 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6:group-7C9962309E7E changes to CANDIDATE, lastRpcTime:5110, electionTimeout:5110ms
2019-09-25 12:43:04,685 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown FollowerState
2019-09-25 12:43:04,685 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,685 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderElection
2019-09-25 12:43:04,687 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-EFA7C27C315A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/2c30861a-8147-4b0f-9bf6-efa7c27c315a/current/log_inprogress_0
2019-09-25 12:43:04,703 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5: begin an election at term 1 for -1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:04,703 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown LeaderElection
2019-09-25 12:43:04,704 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,704 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: change Leader from null to 35a9f88d-76d2-4b6c-86f2-100b645542d6 at term 1 for becomeLeader, leader elected after 5211ms
2019-09-25 12:43:04,705 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,705 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,706 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,706 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,706 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,706 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,709 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderState
2019-09-25 12:43:04,710 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,710 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E: set configuration 0: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null at 0
2019-09-25 12:43:04,771 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-7C9962309E7E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/b0c1a7e2-c71c-4bed-aa81-7c9962309e7e/current/log_inprogress_0
2019-09-25 12:43:04,796 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59:group-0546568B3916 changes to CANDIDATE, lastRpcTime:5052, electionTimeout:5052ms
2019-09-25 12:43:04,797 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown FollowerState
2019-09-25 12:43:04,797 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,797 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderElection
2019-09-25 12:43:04,814 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6: begin an election at term 1 for -1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:04,814 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown LeaderElection
2019-09-25 12:43:04,814 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,814 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: change Leader from null to 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at term 1 for becomeLeader, leader elected after 5081ms
2019-09-25 12:43:04,816 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,817 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,817 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,817 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,817 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,817 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,823 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderState
2019-09-25 12:43:04,823 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,824 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916: set configuration 0: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null at 0
2019-09-25 12:43:04,859 [Thread-226] INFO  impl.FollowerState (FollowerState.java:run(106)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1:group-DD4C4D04DDF4 changes to CANDIDATE, lastRpcTime:5180, electionTimeout:5169ms
2019-09-25 12:43:04,859 [Thread-226] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown FollowerState
2019-09-25 12:43:04,859 [Thread-226] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,859 [Thread-226] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderElection
2019-09-25 12:43:04,871 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(106)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:group-81EBC5F52618 changes to CANDIDATE, lastRpcTime:5064, electionTimeout:5064ms
2019-09-25 12:43:04,871 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown FollowerState
2019-09-25 12:43:04,872 [Thread-232] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:04,872 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderElection
2019-09-25 12:43:04,883 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-0546568B3916-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/43456d4e-59a4-41e0-9ad6-0546568b3916/current/log_inprogress_0
2019-09-25 12:43:04,884 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7: begin an election at term 1 for -1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:04,884 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown LeaderElection
2019-09-25 12:43:04,884 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,884 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: change Leader from null to 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at term 1 for becomeLeader, leader elected after 5212ms
2019-09-25 12:43:04,884 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,884 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,885 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,885 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,885 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,885 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,889 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderState
2019-09-25 12:43:04,889 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,890 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4: set configuration 0: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null at 0
2019-09-25 12:43:04,897 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8: begin an election at term 1 for -1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:04,898 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown LeaderElection
2019-09-25 12:43:04,898 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:04,898 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: change Leader from null to 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at term 1 for becomeLeader, leader elected after 5096ms
2019-09-25 12:43:04,898 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:04,898 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:04,898 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:04,899 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:04,899 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:04,899 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:04,901 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderState
2019-09-25 12:43:04,902 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:04,902 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618: set configuration 0: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null at 0
2019-09-25 12:43:04,948 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-DD4C4D04DDF4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/8960647b-6211-4ca8-94c0-dd4c4d04ddf4/current/log_inprogress_0
2019-09-25 12:43:04,948 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-81EBC5F52618-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/8431f23f-ccec-4a06-8024-81ebc5f52618/current/log_inprogress_0
2019-09-25 12:43:05,059 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59:group-9EA931517C34 changes to CANDIDATE, lastRpcTime:5066, electionTimeout:5066ms
2019-09-25 12:43:05,060 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown FollowerState
2019-09-25 12:43:05,060 [Thread-242] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,060 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderElection
2019-09-25 12:43:05,064 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59:group-979E51C5A7BF changes to CANDIDATE, lastRpcTime:5188, electionTimeout:5188ms
2019-09-25 12:43:05,064 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown FollowerState
2019-09-25 12:43:05,064 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,064 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderElection
2019-09-25 12:43:05,077 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9: begin an election at term 1 for -1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:05,077 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10: begin an election at term 1 for -1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown LeaderElection
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown LeaderElection
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: change Leader from null to 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at term 1 for becomeLeader, leader elected after 5090ms
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: change Leader from null to 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at term 1 for becomeLeader, leader elected after 5210ms
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,078 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,079 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,080 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,080 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,083 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderState
2019-09-25 12:43:05,083 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,083 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderState
2019-09-25 12:43:05,083 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34: set configuration 0: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null at 0
2019-09-25 12:43:05,084 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,119 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59:group-12ABCFD6FA0B changes to CANDIDATE, lastRpcTime:5077, electionTimeout:5051ms
2019-09-25 12:43:05,119 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(106)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:group-72C3C3A4BBCA changes to CANDIDATE, lastRpcTime:5014, electionTimeout:5008ms
2019-09-25 12:43:05,120 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown FollowerState
2019-09-25 12:43:05,120 [Thread-249] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown FollowerState
2019-09-25 12:43:05,120 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF: set configuration 0: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null at 0
2019-09-25 12:43:05,120 [Thread-249] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,120 [Thread-245] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,163 [Thread-249] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderElection
2019-09-25 12:43:05,163 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderElection
2019-09-25 12:43:05,156 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-9EA931517C34-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5c655cfc-b5bd-4bdf-916d-9ea931517c34/current/log_inprogress_0
2019-09-25 12:43:05,156 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1:group-65F9244FE44E changes to CANDIDATE, lastRpcTime:5217, electionTimeout:5198ms
2019-09-25 12:43:05,170 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown FollowerState
2019-09-25 12:43:05,170 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,170 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderElection
2019-09-25 12:43:05,180 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-979E51C5A7BF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/5666250b-c554-4fec-925b-979e51c5a7bf/current/log_inprogress_0
2019-09-25 12:43:05,204 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13: begin an election at term 1 for -1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:05,204 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11: begin an election at term 1 for -1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:05,204 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown LeaderElection
2019-09-25 12:43:05,204 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12: begin an election at term 1 for -1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:05,204 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,204 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown LeaderElection
2019-09-25 12:43:05,205 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: change Leader from null to 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at term 1 for becomeLeader, leader elected after 5273ms
2019-09-25 12:43:05,204 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown LeaderElection
2019-09-25 12:43:05,205 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,205 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,205 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,205 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,205 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,205 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: change Leader from null to 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at term 1 for becomeLeader, leader elected after 5109ms
2019-09-25 12:43:05,206 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,206 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: change Leader from null to 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-25 12:43:05,206 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,206 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,206 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,206 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,206 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,207 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,207 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,207 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,207 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,208 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,208 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,208 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,208 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,208 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,209 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderState
2019-09-25 12:43:05,210 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,210 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E: set configuration 0: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null at 0
2019-09-25 12:43:05,246 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderState
2019-09-25 12:43:05,246 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,247 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderState
2019-09-25 12:43:05,247 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA: set configuration 0: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null at 0
2019-09-25 12:43:05,247 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,279 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-65F9244FE44E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/507915f6-eeaf-4141-9c1e-65f9244fe44e/current/log_inprogress_0
2019-09-25 12:43:05,279 [Thread-253] INFO  impl.FollowerState (FollowerState.java:run(106)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1:group-4C14DE199E4E changes to CANDIDATE, lastRpcTime:5104, electionTimeout:5084ms
2019-09-25 12:43:05,279 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B: set configuration 0: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null at 0
2019-09-25 12:43:05,279 [Thread-253] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown FollowerState
2019-09-25 12:43:05,316 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-72C3C3A4BBCA-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/548502a8-4253-45fe-9db0-72c3c3a4bbca/current/log_inprogress_0
2019-09-25 12:43:05,317 [Thread-253] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,317 [Thread-253] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderElection
2019-09-25 12:43:05,329 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-12ABCFD6FA0B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/9b7a0c85-61b6-4b4f-8e6b-12abcfd6fa0b/current/log_inprogress_0
2019-09-25 12:43:05,329 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14: begin an election at term 1 for -1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:05,329 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown LeaderElection
2019-09-25 12:43:05,330 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,330 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: change Leader from null to 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at term 1 for becomeLeader, leader elected after 5166ms
2019-09-25 12:43:05,330 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,330 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,330 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,330 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,331 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,331 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,334 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderState
2019-09-25 12:43:05,334 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,334 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E: set configuration 0: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null at 0
2019-09-25 12:43:05,375 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-4C14DE199E4E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/a6d64692-7cc8-4549-bd83-4c14de199e4e/current/log_inprogress_0
2019-09-25 12:43:05,436 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59:group-8FBC25286D0C changes to CANDIDATE, lastRpcTime:5197, electionTimeout:5197ms
2019-09-25 12:43:05,437 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown FollowerState
2019-09-25 12:43:05,437 [Thread-256] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,437 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderElection
2019-09-25 12:43:05,448 [Thread-263] INFO  impl.FollowerState (FollowerState.java:run(106)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1:group-123619E4588B changes to CANDIDATE, lastRpcTime:5111, electionTimeout:5111ms
2019-09-25 12:43:05,449 [Thread-263] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown FollowerState
2019-09-25 12:43:05,449 [Thread-263] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,449 [Thread-263] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderElection
2019-09-25 12:43:05,454 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15: begin an election at term 1 for -1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:05,454 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown LeaderElection
2019-09-25 12:43:05,454 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,454 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: change Leader from null to 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at term 1 for becomeLeader, leader elected after 5222ms
2019-09-25 12:43:05,455 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,455 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,455 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,455 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,455 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,455 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,460 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderState
2019-09-25 12:43:05,460 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,461 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C: set configuration 0: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null at 0
2019-09-25 12:43:05,498 [Thread-259] INFO  impl.FollowerState (FollowerState.java:run(106)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1:group-A9D9FD26D764 changes to CANDIDATE, lastRpcTime:5209, electionTimeout:5188ms
2019-09-25 12:43:05,498 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16: begin an election at term 1 for -1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:05,498 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown FollowerState
2019-09-25 12:43:05,498 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown LeaderElection
2019-09-25 12:43:05,499 [Thread-259] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,499 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,499 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderElection
2019-09-25 12:43:05,499 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: change Leader from null to 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at term 1 for becomeLeader, leader elected after 5166ms
2019-09-25 12:43:05,499 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,503 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,503 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,503 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,503 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,504 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,507 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderState
2019-09-25 12:43:05,507 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,508 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B: set configuration 0: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null at 0
2019-09-25 12:43:05,543 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-8FBC25286D0C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/215aed43-623e-4a64-b342-8fbc25286d0c/current/log_inprogress_0
2019-09-25 12:43:05,543 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17: begin an election at term 1 for -1: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null
2019-09-25 12:43:05,544 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: shutdown LeaderElection
2019-09-25 12:43:05,544 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,544 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: change Leader from null to 46e204cb-f3c6-48b7-a572-0bdf52c235a1 at term 1 for becomeLeader, leader elected after 5260ms
2019-09-25 12:43:05,544 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,544 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,544 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,545 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,545 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,545 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,548 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1: start LeaderState
2019-09-25 12:43:05,548 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,549 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764: set configuration 0: [46e204cb-f3c6-48b7-a572-0bdf52c235a1:192.168.151.73:45964], old=null at 0
2019-09-25 12:43:05,573 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-123619E4588B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/2c91c3f1-5761-4534-99fb-123619e4588b/current/log_inprogress_0
2019-09-25 12:43:05,598 [46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 46e204cb-f3c6-48b7-a572-0bdf52c235a1@group-A9D9FD26D764-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-2/data/ratis/b3cc667c-8991-43be-be7e-a9d9fd26d764/current/log_inprogress_0
2019-09-25 12:43:05,784 [Thread-266] INFO  impl.FollowerState (FollowerState.java:run(106)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:group-29D20914A3C7 changes to CANDIDATE, lastRpcTime:5058, electionTimeout:5058ms
2019-09-25 12:43:05,785 [Thread-266] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown FollowerState
2019-09-25 12:43:05,785 [Thread-266] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,785 [Thread-266] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderElection
2019-09-25 12:43:05,803 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18: begin an election at term 1 for -1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:05,804 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown LeaderElection
2019-09-25 12:43:05,804 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,804 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: change Leader from null to 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at term 1 for becomeLeader, leader elected after 5084ms
2019-09-25 12:43:05,804 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,804 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,804 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,805 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,805 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,805 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,808 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderState
2019-09-25 12:43:05,808 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,809 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7: set configuration 0: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null at 0
2019-09-25 12:43:05,865 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-29D20914A3C7-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/33dd23ff-cc80-45ce-9936-29d20914a3c7/current/log_inprogress_0
2019-09-25 12:43:05,940 [Thread-269] INFO  impl.FollowerState (FollowerState.java:run(106)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:group-AF2CEE0E206C changes to CANDIDATE, lastRpcTime:5156, electionTimeout:5156ms
2019-09-25 12:43:05,940 [Thread-269] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown FollowerState
2019-09-25 12:43:05,940 [Thread-269] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,941 [Thread-269] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderElection
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19: begin an election at term 1 for -1: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: shutdown LeaderElection
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: change Leader from null to 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f at term 1 for becomeLeader, leader elected after 5179ms
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:05,957 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:05,958 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:05,958 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:05,958 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:05,960 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f: start LeaderState
2019-09-25 12:43:05,960 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:05,960 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C: set configuration 0: [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f:192.168.151.73:33315], old=null at 0
2019-09-25 12:43:05,996 [Thread-282] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:group-A50072B5C5BD changes to CANDIDATE, lastRpcTime:5005, electionTimeout:5005ms
2019-09-25 12:43:05,997 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown FollowerState
2019-09-25 12:43:05,997 [Thread-282] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:05,997 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderElection
2019-09-25 12:43:06,015 [Thread-273] INFO  impl.FollowerState (FollowerState.java:run(106)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6:group-0F8805FFE2D2 changes to CANDIDATE, lastRpcTime:5140, electionTimeout:5138ms
2019-09-25 12:43:06,016 [Thread-273] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown FollowerState
2019-09-25 12:43:06,016 [Thread-273] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,016 [Thread-273] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderElection
2019-09-25 12:43:06,020 [11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f@group-AF2CEE0E206C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-3/data/ratis/7da2add8-31dd-4fca-aff2-af2cee0e206c/current/log_inprogress_0
2019-09-25 12:43:06,029 [Thread-276] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:group-997BDB1EB992 changes to CANDIDATE, lastRpcTime:5095, electionTimeout:5095ms
2019-09-25 12:43:06,029 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown FollowerState
2019-09-25 12:43:06,029 [Thread-276] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,029 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderElection
2019-09-25 12:43:06,051 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21: begin an election at term 1 for -1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:06,051 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20: begin an election at term 1 for -1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:06,051 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown LeaderElection
2019-09-25 12:43:06,052 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown LeaderElection
2019-09-25 12:43:06,052 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,052 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,052 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: change Leader from null to 35a9f88d-76d2-4b6c-86f2-100b645542d6 at term 1 for becomeLeader, leader elected after 5189ms
2019-09-25 12:43:06,052 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: change Leader from null to 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at term 1 for becomeLeader, leader elected after 5066ms
2019-09-25 12:43:06,052 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,053 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,053 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,053 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,053 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,053 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,053 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,054 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,054 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,054 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,054 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,054 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,055 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22: begin an election at term 1 for -1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:06,055 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown LeaderElection
2019-09-25 12:43:06,055 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,055 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: change Leader from null to 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at term 1 for becomeLeader, leader elected after 5128ms
2019-09-25 12:43:06,055 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,055 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,056 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,056 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,056 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,056 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,061 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderState
2019-09-25 12:43:06,061 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,061 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderState
2019-09-25 12:43:06,062 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderState
2019-09-25 12:43:06,062 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,062 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,062 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2: set configuration 0: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null at 0
2019-09-25 12:43:06,062 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD: set configuration 0: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null at 0
2019-09-25 12:43:06,104 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992: set configuration 0: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null at 0
2019-09-25 12:43:06,137 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-A50072B5C5BD-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/e66645ab-a946-4eb0-b8c0-a50072b5c5bd/current/log_inprogress_0
2019-09-25 12:43:06,137 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-0F8805FFE2D2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/6f1ffa76-81f2-4cf4-9960-0f8805ffe2d2/current/log_inprogress_0
2019-09-25 12:43:06,140 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-997BDB1EB992-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/0f2c3008-6062-4f0c-8903-997bdb1eb992/current/log_inprogress_0
2019-09-25 12:43:06,177 [Thread-285] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59:group-42481A510715 changes to CANDIDATE, lastRpcTime:5136, electionTimeout:5136ms
2019-09-25 12:43:06,177 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown FollowerState
2019-09-25 12:43:06,177 [Thread-285] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,177 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderElection
2019-09-25 12:43:06,183 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23: begin an election at term 1 for -1: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null
2019-09-25 12:43:06,183 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: shutdown LeaderElection
2019-09-25 12:43:06,183 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,183 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: change Leader from null to 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 at term 1 for becomeLeader, leader elected after 5151ms
2019-09-25 12:43:06,184 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,184 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,184 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,184 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,184 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,184 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,187 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59: start LeaderState
2019-09-25 12:43:06,187 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,188 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715: set configuration 0: [0d6d7abe-064e-4f87-bb34-13a3ff0fda59:192.168.151.73:38412], old=null at 0
2019-09-25 12:43:06,225 [0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0d6d7abe-064e-4f87-bb34-13a3ff0fda59@group-42481A510715-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-1/data/ratis/e90970f1-4653-47a1-bda4-42481a510715/current/log_inprogress_0
2019-09-25 12:43:06,310 [Thread-309] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:group-BCD4E8320554 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5080ms
2019-09-25 12:43:06,310 [Thread-309] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown FollowerState
2019-09-25 12:43:06,311 [Thread-309] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,311 [Thread-309] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderElection
2019-09-25 12:43:06,318 [Thread-296] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:group-77C63239C954 changes to CANDIDATE, lastRpcTime:5184, electionTimeout:5184ms
2019-09-25 12:43:06,318 [Thread-296] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown FollowerState
2019-09-25 12:43:06,319 [Thread-296] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,319 [Thread-296] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderElection
2019-09-25 12:43:06,327 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24: begin an election at term 1 for -1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:06,327 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25: begin an election at term 1 for -1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown LeaderElection
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown LeaderElection
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: change Leader from null to 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at term 1 for becomeLeader, leader elected after 5103ms
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: change Leader from null to 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at term 1 for becomeLeader, leader elected after 5213ms
2019-09-25 12:43:06,328 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,329 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,330 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,330 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,330 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,333 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderState
2019-09-25 12:43:06,333 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,333 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderState
2019-09-25 12:43:06,334 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,334 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554: set configuration 0: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null at 0
2019-09-25 12:43:06,371 [Thread-322] INFO  impl.FollowerState (FollowerState.java:run(106)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6:group-F458F83F2872 changes to CANDIDATE, lastRpcTime:5031, electionTimeout:5025ms
2019-09-25 12:43:06,372 [Thread-322] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown FollowerState
2019-09-25 12:43:06,372 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954: set configuration 0: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null at 0
2019-09-25 12:43:06,372 [Thread-322] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,406 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-BCD4E8320554-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/ff757009-dbe1-4930-8fe2-bcd4e8320554/current/log_inprogress_0
2019-09-25 12:43:06,407 [Thread-322] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderElection
2019-09-25 12:43:06,419 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-77C63239C954-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/9a9d0600-3538-4c57-b3dc-77c63239c954/current/log_inprogress_0
2019-09-25 12:43:06,420 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26: begin an election at term 1 for -1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:06,420 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown LeaderElection
2019-09-25 12:43:06,420 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,420 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: change Leader from null to 35a9f88d-76d2-4b6c-86f2-100b645542d6 at term 1 for becomeLeader, leader elected after 5086ms
2019-09-25 12:43:06,420 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,420 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,421 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,421 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,421 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,421 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,422 [Thread-317] INFO  impl.FollowerState (FollowerState.java:run(106)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6:group-66EEA4202132 changes to CANDIDATE, lastRpcTime:5132, electionTimeout:5132ms
2019-09-25 12:43:06,422 [Thread-317] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown FollowerState
2019-09-25 12:43:06,422 [Thread-317] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,422 [Thread-317] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderElection
2019-09-25 12:43:06,426 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderState
2019-09-25 12:43:06,426 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,426 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872: set configuration 0: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null at 0
2019-09-25 12:43:06,462 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27: begin an election at term 1 for -1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:06,462 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown LeaderElection
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: change Leader from null to 35a9f88d-76d2-4b6c-86f2-100b645542d6 at term 1 for becomeLeader, leader elected after 5188ms
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,463 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,464 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,466 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderState
2019-09-25 12:43:06,467 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,467 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132: set configuration 0: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null at 0
2019-09-25 12:43:06,501 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-F458F83F2872-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/8cf25c8c-c525-45a7-8822-f458f83f2872/current/log_inprogress_0
2019-09-25 12:43:06,508 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-66EEA4202132-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/086a7fa8-fa2c-4a27-b2b0-66eea4202132/current/log_inprogress_0
2019-09-25 12:43:06,643 [Thread-333] INFO  impl.FollowerState (FollowerState.java:run(106)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6:group-79C027DC6F78 changes to CANDIDATE, lastRpcTime:5081, electionTimeout:5081ms
2019-09-25 12:43:06,643 [Thread-333] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown FollowerState
2019-09-25 12:43:06,643 [Thread-333] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,644 [Thread-333] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderElection
2019-09-25 12:43:06,661 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28: begin an election at term 1 for -1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:06,661 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown LeaderElection
2019-09-25 12:43:06,661 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,661 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: change Leader from null to 35a9f88d-76d2-4b6c-86f2-100b645542d6 at term 1 for becomeLeader, leader elected after 5107ms
2019-09-25 12:43:06,661 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,661 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,662 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,662 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,662 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,662 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,665 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderState
2019-09-25 12:43:06,665 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,666 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78: set configuration 0: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null at 0
2019-09-25 12:43:06,702 [Thread-351] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:group-463FAC9FD497 changes to CANDIDATE, lastRpcTime:5040, electionTimeout:5008ms
2019-09-25 12:43:06,702 [Thread-351] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown FollowerState
2019-09-25 12:43:06,702 [Thread-351] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,702 [Thread-351] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderElection
2019-09-25 12:43:06,726 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-79C027DC6F78-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/f21a9223-e4ec-4039-9d19-79c027dc6f78/current/log_inprogress_0
2019-09-25 12:43:06,727 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29: begin an election at term 1 for -1: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null
2019-09-25 12:43:06,727 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: shutdown LeaderElection
2019-09-25 12:43:06,727 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,727 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: change Leader from null to 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 at term 1 for becomeLeader, leader elected after 5070ms
2019-09-25 12:43:06,727 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,727 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,728 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,728 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,728 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,728 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,731 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9: start LeaderState
2019-09-25 12:43:06,731 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,732 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497: set configuration 0: [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9:192.168.151.73:36105], old=null at 0
2019-09-25 12:43:06,769 [5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9@group-463FAC9FD497-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-0/data/ratis/33d5baad-f563-47de-ae32-463fac9fd497/current/log_inprogress_0
2019-09-25 12:43:06,796 [Thread-342] INFO  impl.FollowerState (FollowerState.java:run(106)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6:group-DB60C150B1A3 changes to CANDIDATE, lastRpcTime:5183, electionTimeout:5183ms
2019-09-25 12:43:06,796 [Thread-342] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown FollowerState
2019-09-25 12:43:06,797 [Thread-342] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 12:43:06,797 [Thread-342] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderElection
2019-09-25 12:43:06,812 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30: begin an election at term 1 for -1: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null
2019-09-25 12:43:06,812 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: shutdown LeaderElection
2019-09-25 12:43:06,812 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 12:43:06,812 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: change Leader from null to 35a9f88d-76d2-4b6c-86f2-100b645542d6 at term 1 for becomeLeader, leader elected after 5205ms
2019-09-25 12:43:06,812 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 12:43:06,812 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 12:43:06,813 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 12:43:06,813 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 12:43:06,813 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 12:43:06,813 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 12:43:06,816 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6: start LeaderState
2019-09-25 12:43:06,816 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 12:43:06,816 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3: set configuration 0: [35a9f88d-76d2-4b6c-86f2-100b645542d6:192.168.151.73:44393], old=null at 0
2019-09-25 12:43:06,877 [35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 35a9f88d-76d2-4b6c-86f2-100b645542d6@group-DB60C150B1A3-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-34fe9b01-745e-4f22-aba3-9a09d300e091/datanode-4/data/ratis/08a94983-f9e3-473d-aceb-db60c150b1a3/current/log_inprogress_0
2019-09-25 12:43:09,214 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:09,218 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:09,218 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:09,218 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:09,218 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:09,219 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:09,219 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:09,219 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:09,220 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:09,220 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:09,220 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:09.223 [IPC Server handler 17 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:09,224 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000000_0
2019-09-25 12:43:09,224 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:09,225 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:09,229 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000001_0
2019-09-25 12:43:09,234 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:09,234 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:09,235 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:09,236 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:0+324
2019-09-25 12:43:09,237 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:09,237 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:43:09.251 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:09,252 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
12:43:09.257 [IPC Server handler 13 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:09,271 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:09,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1038849443_0001_m_000001_0 is done. And is in the process of committing
2019-09-25 12:43:09,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:09,281 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1038849443_0001_m_000001_0 is allowed to commit now
2019-09-25 12:43:09,282 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1038849443_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/_logs
2019-09-25 12:43:09,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-25 12:43:09,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1038849443_0001_m_000001_0' done.
2019-09-25 12:43:09,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1038849443_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=208504
		FILE: Number of bytes written=822794
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:09,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1038849443_0001_m_000001_0
2019-09-25 12:43:09,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:09,291 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:09,291 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:09,292 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:09,293 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:602+290
2019-09-25 12:43:09,293 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:09,293 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:09,306 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
12:43:09.311 [IPC Server handler 9 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:09,315 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:09,318 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:09,320 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:09,320 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:09,320 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:09,321 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:09,321 [IPC Server handler 5 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:09,321 [IPC Server handler 5 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:09,322 [IPC Server handler 5 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:09,322 [IPC Server handler 5 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:09,322 [IPC Server handler 5 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:09.326 [IPC Server handler 10 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:09,329 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:09,329 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:10,141 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:43:10,802 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:10,805 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:10,806 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:10,806 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:10,806 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:10,806 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:10,807 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:10,807 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:10,807 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:10,808 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:10,808 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:10.812 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:10,813 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:10,814 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:14,239 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 12:43:15,144 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-25 12:43:16,790 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:16,794 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:16,794 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:16,794 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:16,794 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:16,795 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:16,795 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:16,795 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:16,795 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:16,795 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:16,796 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:16.799 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:16,800 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000002_0
2019-09-25 12:43:16,801 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:16,801 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:16,802 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000003_0
2019-09-25 12:43:16,812 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:16,812 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:16,813 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:16,815 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:324+278
2019-09-25 12:43:16,816 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:16,816 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:16,833 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
12:43:16.839 [IPC Server handler 3 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:16,845 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:16,845 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1038849443_0001_m_000003_0 is done. And is in the process of committing
2019-09-25 12:43:16,846 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:16,846 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1038849443_0001_m_000003_0 is allowed to commit now
2019-09-25 12:43:16,847 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1038849443_0001_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/_logs
2019-09-25 12:43:16,848 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 12:43:16,848 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1038849443_0001_m_000003_0' done.
2019-09-25 12:43:16,849 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1038849443_0001_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=217650
		FILE: Number of bytes written=822810
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=18
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:16,849 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1038849443_0001_m_000003_0
2019-09-25 12:43:16,849 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000004_0
2019-09-25 12:43:16,850 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:16,850 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:16,851 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:16,852 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:1428+278
2019-09-25 12:43:16,852 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:16,852 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:16,867 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
12:43:16.874 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:16,878 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:16,879 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1038849443_0001_m_000004_0 is done. And is in the process of committing
2019-09-25 12:43:16,880 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:16,880 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1038849443_0001_m_000004_0 is allowed to commit now
2019-09-25 12:43:16,882 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1038849443_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/_logs
2019-09-25 12:43:16,883 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 12:43:16,883 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1038849443_0001_m_000004_0' done.
2019-09-25 12:43:16,884 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1038849443_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=221711
		FILE: Number of bytes written=822818
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=20
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:16,884 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1038849443_0001_m_000004_0
2019-09-25 12:43:16,884 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:16,885 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:16,885 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:16,886 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:16,887 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:1154+274
2019-09-25 12:43:16,887 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:16,888 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:16,902 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
12:43:16.907 [IPC Server handler 19 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:16,908 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:16,926 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:16,929 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:16,929 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:16,929 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:16,930 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:16,930 [IPC Server handler 5 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:16,930 [IPC Server handler 5 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:16,930 [IPC Server handler 5 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:16,931 [IPC Server handler 5 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:16,931 [IPC Server handler 5 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:16.933 [IPC Server handler 16 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:16,935 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:16,935 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:17,145 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:43:18,770 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:18,774 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:18,774 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:18,775 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:18,775 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:18,775 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:18,775 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:18,776 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:18,776 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:18,776 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:18,776 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:18.779 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:18,780 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:18,781 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:20,241 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-25 12:43:21,147 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 37% reduce 0%
2019-09-25 12:43:21,309 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 12:43:21,986 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:21,996 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:21,996 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:21,997 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:21,997 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:21,997 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:21,997 [IPC Server handler 1 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:21,998 [IPC Server handler 1 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:21,998 [IPC Server handler 1 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:21,999 [IPC Server handler 1 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:21,999 [IPC Server handler 1 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:22.002 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:22,003 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1038849443_0001_m_000005_0
2019-09-25 12:43:22,003 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:22,004 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:22,005 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000006_0
2019-09-25 12:43:22,006 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:22,007 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:22,007 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:22,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:892+262
2019-09-25 12:43:22,010 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:22,010 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:22,027 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-25 12:43:22,038 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:22,038 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1038849443_0001_m_000006_0 is done. And is in the process of committing
2019-09-25 12:43:22,039 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:22,039 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1038849443_0001_m_000006_0 is allowed to commit now
2019-09-25 12:43:22,041 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1038849443_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/_logs
2019-09-25 12:43:22,042 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-25 12:43:22,042 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1038849443_0001_m_000006_0' done.
2019-09-25 12:43:22,043 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1038849443_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=229833
		FILE: Number of bytes written=822834
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=27
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:22,043 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1038849443_0001_m_000006_0
2019-09-25 12:43:22,043 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000007_0
2019-09-25 12:43:22,044 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:22,044 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:22,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:22,046 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:1706+262
2019-09-25 12:43:22,046 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:22,046 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:22,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-25 12:43:22,071 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:22,072 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1038849443_0001_m_000007_0 is done. And is in the process of committing
2019-09-25 12:43:22,073 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:22,073 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1038849443_0001_m_000007_0 is allowed to commit now
2019-09-25 12:43:22,074 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1038849443_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/_logs
2019-09-25 12:43:22,075 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-25 12:43:22,075 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1038849443_0001_m_000007_0' done.
2019-09-25 12:43:22,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1038849443_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=233382
		FILE: Number of bytes written=822842
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=29
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:22,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1038849443_0001_m_000007_0
2019-09-25 12:43:22,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1038849443_0001_m_000008_0
2019-09-25 12:43:22,077 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:22,077 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:22,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:22,078 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/fileList.seq:1968+262
2019-09-25 12:43:22,079 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:22,079 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:22,092 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
12:43:22.098 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume43006, bucket=bucket71097, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume43006 bucket: bucket71097 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:22,102 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:22,102 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1038849443_0001_m_000008_0 is done. And is in the process of committing
2019-09-25 12:43:22,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:22,104 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1038849443_0001_m_000008_0 is allowed to commit now
2019-09-25 12:43:22,105 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1038849443_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708/_logs
2019-09-25 12:43:22,106 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-25 12:43:22,106 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1038849443_0001_m_000008_0' done.
2019-09-25 12:43:22,107 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1038849443_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=236931
		FILE: Number of bytes written=822850
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=31
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:22,107 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1038849443_0001_m_000008_0
2019-09-25 12:43:22,107 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:43:22,142 [Thread-371] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001416477610/.staging/_distcp1434358708
2019-09-25 12:43:22,148 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:43:22,164 [Thread-371] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1038849443_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket71097.volume43006/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:23,149 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1038849443_0001 failed with state FAILED due to: NA
2019-09-25 12:43:23,216 [Thread-221] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=1799555
		FILE: Number of bytes written=6582600
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=184
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=124
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1264
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16466837504
	File Input Format Counters 
		Bytes Read=24992
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
]]></system-err>
  </testcase>
  <testcase name="testTrackDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="17.642">
    <error message="DistCp failure: Job job_local102355592_0002 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local102355592_0002 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testTrackDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 12:43:23,274 [Thread-483] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:43:23,304 [Thread-483] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume89502, with user71321 as owner.
2019-09-25 12:43:23,306 [IPC Server handler 6 on 45560] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume89502 for user:user71321
2019-09-25 12:43:23,311 [Thread-483] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume89502/bucket73164, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:43:23,380 [Thread-483] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket73164.volume89502 implemented by OzoneFileSystem{URI=o3fs://bucket73164.volume89502, workingDir=o3fs://bucket73164.volume89502/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 38 read ops, 0 large read ops, 20 write ops}
12:43:23.399 [IPC Server handler 11 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:23,402 [Thread-483] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-25 12:43:23,477 [Thread-483] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:23,485 [Thread-483] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
12:43:23.497 [IPC Server handler 9 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:23,555 [Thread-483] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 12:43:23,556 [Thread-483] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:43:23,563 [Thread-483] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:43:23,572 [Thread-483] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:43:23,573 [Thread-483] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:23,582 [Thread-483] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:43:23,621 [Thread-483] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-25 12:43:23,649 [Thread-483] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local102355592_0002
2019-09-25 12:43:23,650 [Thread-483] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:43:23,778 [Thread-483] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:43:23,781 [Thread-547] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:43:23,782 [Thread-483] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local102355592_0002
2019-09-25 12:43:23,782 [Thread-547] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:23,782 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local102355592_0002
2019-09-25 12:43:23,782 [Thread-547] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:23,782 [Thread-547] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:43:23,809 [Thread-547] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:43:23,809 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:23,810 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:23,810 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:23,811 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:23,813 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:1411+835
2019-09-25 12:43:23,819 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:23,819 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:43:23.837 [IPC Server handler 12 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:23,839 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
12:43:23.851 [IPC Server handler 10 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:23,851 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:23,855 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:23,855 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:23,856 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:23,856 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:23,856 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:23,856 [IPC Server handler 5 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:23,856 [IPC Server handler 5 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:23,857 [IPC Server handler 5 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:23,858 [IPC Server handler 5 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:23,858 [IPC Server handler 5 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:23.860 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:23,861 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:23,863 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:24,782 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local102355592_0002 running in uber mode : false
2019-09-25 12:43:24,783 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 12:43:26,330 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:26,334 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:26,334 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:26,334 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:26,334 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:26,335 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:26,335 [IPC Server handler 3 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:26,335 [IPC Server handler 3 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:26,336 [IPC Server handler 3 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:26,336 [IPC Server handler 3 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:26,336 [IPC Server handler 3 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:26.339 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:26,340 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:26,340 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:27,310 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 12:43:28,894 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-25 12:43:29,505 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:29,508 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:29,508 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:29,508 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:29,509 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:29,509 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:29,509 [IPC Server handler 11 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:29,509 [IPC Server handler 11 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:29,509 [IPC Server handler 11 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:29,509 [IPC Server handler 11 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:29,510 [IPC Server handler 11 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:29.512 [IPC Server handler 10 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:29,512 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000000_0
2019-09-25 12:43:29,512 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:29,513 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:29,514 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000001_0
2019-09-25 12:43:29,514 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:29,514 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:29,515 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:29,515 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:0+323
2019-09-25 12:43:29,516 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:29,516 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:43:29.530 [IPC Server handler 7 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:29,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
12:43:29.536 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:29,540 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:29,540 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local102355592_0002_m_000001_0 is done. And is in the process of committing
2019-09-25 12:43:29,541 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:29,541 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local102355592_0002_m_000001_0 is allowed to commit now
2019-09-25 12:43:29,542 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local102355592_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/_logs
2019-09-25 12:43:29,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-25 12:43:29,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local102355592_0002_m_000001_0' done.
2019-09-25 12:43:29,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local102355592_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=445340
		FILE: Number of bytes written=1642578
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=49
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=27
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:29,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local102355592_0002_m_000001_0
2019-09-25 12:43:29,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:29,544 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:29,544 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:29,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:29,545 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:2768+289
2019-09-25 12:43:29,545 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:29,546 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:29,560 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
12:43:29.565 [IPC Server handler 1 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:29,566 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:29,569 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:29,571 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:29,571 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:29,572 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:29,572 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:29,572 [IPC Server handler 2 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:29,572 [IPC Server handler 2 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:29,573 [IPC Server handler 2 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:29,573 [IPC Server handler 2 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:29,573 [IPC Server handler 2 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:29.575 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:29,576 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:29,576 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:29,786 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:43:31,450 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:31,455 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:31,455 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:31,456 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:31,456 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:31,456 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:31,456 [IPC Server handler 11 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:31,457 [IPC Server handler 11 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:31,457 [IPC Server handler 11 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:31,458 [IPC Server handler 11 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:31,458 [IPC Server handler 11 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:31.460 [IPC Server handler 12 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:31,461 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:31,461 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:35,084 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:35,088 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:35,088 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:35,088 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:35,088 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:35,089 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:35,089 [IPC Server handler 3 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:35,089 [IPC Server handler 3 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:35,090 [IPC Server handler 3 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:35,090 [IPC Server handler 3 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:35,090 [IPC Server handler 3 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:35.093 [IPC Server handler 0 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:35,094 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000002_0
2019-09-25 12:43:35,095 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:35,095 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:35,097 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000003_0
2019-09-25 12:43:35,098 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:35,098 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:35,098 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:35,100 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:323+277
2019-09-25 12:43:35,100 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:35,100 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:35,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
12:43:35.122 [IPC Server handler 16 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:35,126 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local102355592_0002_m_000003_0 is done. And is in the process of committing
2019-09-25 12:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:35,128 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local102355592_0002_m_000003_0 is allowed to commit now
2019-09-25 12:43:35,129 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local102355592_0002_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/_logs
2019-09-25 12:43:35,130 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 12:43:35,130 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local102355592_0002_m_000003_0' done.
2019-09-25 12:43:35,130 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local102355592_0002_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=454446
		FILE: Number of bytes written=1642594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=56
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:35,131 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local102355592_0002_m_000003_0
2019-09-25 12:43:35,131 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000004_0
2019-09-25 12:43:35,131 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:35,132 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:35,132 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:35,134 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:873+277
2019-09-25 12:43:35,134 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:35,135 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:35,147 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
12:43:35.152 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:35,156 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:35,156 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local102355592_0002_m_000004_0 is done. And is in the process of committing
2019-09-25 12:43:35,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:35,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local102355592_0002_m_000004_0 is allowed to commit now
2019-09-25 12:43:35,158 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local102355592_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/_logs
2019-09-25 12:43:35,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 12:43:35,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local102355592_0002_m_000004_0' done.
2019-09-25 12:43:35,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local102355592_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=458487
		FILE: Number of bytes written=1642602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=58
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:35,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local102355592_0002_m_000004_0
2019-09-25 12:43:35,160 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:35,160 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:35,160 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:35,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:35,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:600+273
2019-09-25 12:43:35,162 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:35,162 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:35,174 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
12:43:35.179 [IPC Server handler 14 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:35,180 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:35,187 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:35,190 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:35,190 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:35,190 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:35,191 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:35,191 [IPC Server handler 11 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:35,191 [IPC Server handler 11 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:35,205 [IPC Server handler 11 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:35,206 [IPC Server handler 11 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:35,206 [IPC Server handler 11 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:35.209 [IPC Server handler 12 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:35,210 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:35,210 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:35,825 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-25 12:43:36,364 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:36,368 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:36,369 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:36,369 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:36,369 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:36,369 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:36,370 [IPC Server handler 2 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:36,370 [IPC Server handler 2 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:36,371 [IPC Server handler 2 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:36,371 [IPC Server handler 2 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:36,371 [IPC Server handler 2 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:36.374 [IPC Server handler 7 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:36,375 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:36,375 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:36,789 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 37% reduce 0%
2019-09-25 12:43:40,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:40,537 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:40,538 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:40,538 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:40,538 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:40,538 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:40,538 [IPC Server handler 6 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:40,538 [IPC Server handler 6 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:40,539 [IPC Server handler 6 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:40,539 [IPC Server handler 6 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:40,539 [IPC Server handler 6 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:40.542 [IPC Server handler 3 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:40,543 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local102355592_0002_m_000005_0
2019-09-25 12:43:40,543 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:40,544 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:40,545 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000006_0
2019-09-25 12:43:40,547 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:40,547 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:40,547 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:40,549 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:1150+261
2019-09-25 12:43:40,549 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:40,550 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:40,566 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
12:43:40.572 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume89502, bucket=bucket73164, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume89502 bucket: bucket73164 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:40,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:40,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local102355592_0002_m_000006_0 is done. And is in the process of committing
2019-09-25 12:43:40,578 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:40,578 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local102355592_0002_m_000006_0 is allowed to commit now
2019-09-25 12:43:40,579 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local102355592_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/_logs
2019-09-25 12:43:40,580 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 12:43:40,580 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local102355592_0002_m_000006_0' done.
2019-09-25 12:43:40,580 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local102355592_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=466569
		FILE: Number of bytes written=1642618
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=65
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:40,580 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local102355592_0002_m_000006_0
2019-09-25 12:43:40,580 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000007_0
2019-09-25 12:43:40,581 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:40,581 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:40,581 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:40,582 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:2246+261
2019-09-25 12:43:40,583 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:40,583 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:40,597 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:43:40,609 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:40,609 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local102355592_0002_m_000007_0 is done. And is in the process of committing
2019-09-25 12:43:40,610 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:40,610 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local102355592_0002_m_000007_0 is allowed to commit now
2019-09-25 12:43:40,611 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local102355592_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/_logs
2019-09-25 12:43:40,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:43:40,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local102355592_0002_m_000007_0' done.
2019-09-25 12:43:40,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local102355592_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=470098
		FILE: Number of bytes written=1642626
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=67
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:40,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local102355592_0002_m_000007_0
2019-09-25 12:43:40,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local102355592_0002_m_000008_0
2019-09-25 12:43:40,613 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:40,613 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:40,614 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:40,614 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/fileList.seq:2507+261
2019-09-25 12:43:40,615 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:40,615 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:40,629 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:43:40,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:40,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local102355592_0002_m_000008_0 is done. And is in the process of committing
2019-09-25 12:43:40,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:43:40,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local102355592_0002_m_000008_0 is allowed to commit now
2019-09-25 12:43:40,640 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local102355592_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570/_logs
2019-09-25 12:43:40,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:43:40,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local102355592_0002_m_000008_0' done.
2019-09-25 12:43:40,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local102355592_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=473627
		FILE: Number of bytes written=1642634
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=69
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=39
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:43:40,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local102355592_0002_m_000008_0
2019-09-25 12:43:40,641 [Thread-547] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:43:40,654 [Thread-547] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000471425692/.staging/_distcp-148767570
2019-09-25 12:43:40,657 [Thread-547] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local102355592_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket73164.volume89502/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:40,791 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:43:40,792 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local102355592_0002 failed with state FAILED due to: NA
2019-09-25 12:43:40,864 [Thread-483] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=3231095
		FILE: Number of bytes written=11498262
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=425
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=245
	Map-Reduce Framework
		Map input records=7
		Map output records=0
		Input split bytes=1099
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=14408482816
	File Input Format Counters 
		Bytes Read=21791
	File Output Format Counters 
		Bytes Written=56
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
  </testcase>
  <testcase name="largeFilesToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="12.8">
    <error message="DistCp failure: Job job_local2092398694_0003 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local2092398694_0003 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:534)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFilesToRemote(AbstractContractDistCpTest.java:452)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 12:43:40,927 [Thread-591] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:43:40,960 [Thread-591] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume10589, with user90151 as owner.
2019-09-25 12:43:40,964 [IPC Server handler 18 on 45560] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume10589 for user:user90151
2019-09-25 12:43:40,969 [Thread-591] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume10589/bucket82558, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:43:41,034 [Thread-591] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket82558.volume10589 implemented by OzoneFileSystem{URI=o3fs://bucket82558.volume10589, workingDir=o3fs://bucket82558.volume10589/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 76 read ops, 0 large read ops, 40 write ops}
12:43:41.056 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:41,059 [Thread-591] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-25 12:43:41,066 [Thread-591] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-25 12:43:41,210 [Thread-591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:41,219 [Thread-591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
12:43:41.233 [IPC Server handler 8 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:41,269 [Thread-591] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-25 12:43:41,272 [Thread-591] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:43:41,281 [Thread-591] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-25 12:43:41,292 [Thread-591] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-25 12:43:41,293 [Thread-591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:41,301 [Thread-591] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:43:41,349 [Thread-591] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-25 12:43:41,410 [Thread-591] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local2092398694_0003
2019-09-25 12:43:41,410 [Thread-591] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:43:41,563 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-25 12:43:41,657 [Thread-591] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:43:41,659 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:43:41,659 [Thread-591] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local2092398694_0003
2019-09-25 12:43:41,659 [Thread-639] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:41,659 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local2092398694_0003
2019-09-25 12:43:41,659 [Thread-639] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:41,660 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:43:41,678 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:43:41,678 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:41,679 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:41,679 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:41,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:41,680 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002079903409/.staging/_distcp335732227/fileList.seq:0+771
2019-09-25 12:43:41,681 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:41,681 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:43:41.700 [IPC Server handler 0 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:41,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
12:43:41.707 [IPC Server handler 19 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:41,712 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
12:43:41.717 [IPC Server handler 18 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:41,719 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:41,721 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:41,721 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:41,722 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:41,722 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:41,722 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:41,722 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:41,723 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:41,723 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:41,723 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:41,723 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:41.725 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:41,726 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:41,727 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:42,660 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local2092398694_0003 running in uber mode : false
2019-09-25 12:43:42,660 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 12:43:43,105 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:43,109 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:43,109 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:43,109 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:43,109 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:43,110 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:43,110 [IPC Server handler 11 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:43,110 [IPC Server handler 11 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:43,111 [IPC Server handler 11 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:43,111 [IPC Server handler 11 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:43,111 [IPC Server handler 11 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:43.114 [IPC Server handler 0 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:43,115 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:43,115 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:46,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:46,690 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:46,690 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:46,691 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:46,691 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:46,691 [IPC Server handler 0 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:46,691 [IPC Server handler 0 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:46,691 [IPC Server handler 0 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:46,692 [IPC Server handler 0 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:46,692 [IPC Server handler 0 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:46,693 [IPC Server handler 0 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:46.695 [IPC Server handler 16 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:46,696 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000000_0
2019-09-25 12:43:46,696 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:46,697 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:46,697 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:46,698 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:46,698 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:46,698 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:46,699 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002079903409/.staging/_distcp335732227/fileList.seq:771+235
2019-09-25 12:43:46,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:46,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:46,715 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
12:43:46.721 [IPC Server handler 17 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:46,722 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:46,724 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:46,724 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:46,724 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:46,724 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:46,724 [IPC Server handler 17 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:46,725 [IPC Server handler 17 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:46,725 [IPC Server handler 17 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:46,725 [IPC Server handler 17 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:46,725 [IPC Server handler 17 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:46,726 [IPC Server handler 17 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:46.727 [IPC Server handler 13 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:46,728 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:46,728 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:47,168 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-25 12:43:48,891 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:48,894 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:48,895 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:48,895 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:48,895 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:48,895 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:48,896 [IPC Server handler 1 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:48,896 [IPC Server handler 1 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:48,897 [IPC Server handler 1 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:48,897 [IPC Server handler 1 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:48,897 [IPC Server handler 1 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:48.900 [IPC Server handler 14 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:48,901 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:48,901 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:53,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:53,547 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:53,547 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:53,548 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:53,548 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:53,548 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:53,548 [IPC Server handler 6 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:53,548 [IPC Server handler 6 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:53,549 [IPC Server handler 6 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:53,549 [IPC Server handler 6 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:53,549 [IPC Server handler 6 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:53.553 [IPC Server handler 16 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10589, bucket=bucket82558, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10589 bucket: bucket82558 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:53,554 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local2092398694_0003_m_000001_0
2019-09-25 12:43:53,555 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:53,555 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:53,556 [Thread-639] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:43:53,567 [Thread-639] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10002079903409/.staging/_distcp335732227
2019-09-25 12:43:53,568 [Thread-639] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local2092398694_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket82558.volume10589/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:43:53,668 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local2092398694_0003 failed with state FAILED due to: NA
2019-09-25 12:43:53,668 [Thread-591] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 0
2019-09-25 12:43:53,686 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 > map
]]></system-out>
  </testcase>
  <testcase name="testLargeFilesFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.172">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:528)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testLargeFilesFromRemote(AbstractContractDistCpTest.java:464)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 12:43:53,726 [Thread-656] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:43:53,756 [Thread-656] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume28760, with user87498 as owner.
2019-09-25 12:43:53,758 [IPC Server handler 1 on 45560] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume28760 for user:user87498
2019-09-25 12:43:53,760 [Thread-656] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume28760/bucket25454, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:43:53,816 [Thread-656] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket25454.volume28760 implemented by OzoneFileSystem{URI=o3fs://bucket25454.volume28760, workingDir=o3fs://bucket25454.volume28760/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 98 read ops, 0 large read ops, 54 write ops}
12:43:53.834 [IPC Server handler 12 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume28760, bucket=bucket25454, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume28760 bucket: bucket25454 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:53,837 [Thread-656] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-25 12:43:53,840 [Thread-656] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-25 12:43:53,852 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:53,852 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:53,852 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:53,852 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:53,853 [IPC Server handler 5 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:53,853 [IPC Server handler 5 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:53,853 [IPC Server handler 5 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:53,853 [IPC Server handler 5 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:53,854 [IPC Server handler 5 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:53,854 [IPC Server handler 5 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
]]></system-out>
  </testcase>
  <testcase name="testUpdateDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="21.508">
    <error message="DistCp failure: Job job_local1728463876_0004 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local1728463876_0004 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 12:43:53,905 [Thread-661] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume88852, with user20551 as owner.
2019-09-25 12:43:53,906 [IPC Server handler 18 on 45560] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume88852 for user:user20551
2019-09-25 12:43:53,908 [Thread-661] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume88852/bucket05525, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:43:53,957 [Thread-661] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket05525.volume88852 implemented by OzoneFileSystem{URI=o3fs://bucket05525.volume88852, workingDir=o3fs://bucket05525.volume88852/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 104 read ops, 0 large read ops, 57 write ops}
12:43:53.976 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:53,979 [Thread-661] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-25 12:43:54,061 [Thread-661] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:54,070 [Thread-661] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
12:43:54.081 [IPC Server handler 8 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:54,136 [Thread-661] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-25 12:43:54,136 [Thread-661] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-25 12:43:54,147 [Thread-661] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:43:54,157 [Thread-661] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-25 12:43:54,158 [Thread-661] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-25 12:43:54,165 [Thread-661] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-25 12:43:54,208 [Thread-661] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-25 12:43:54,237 [Thread-661] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1728463876_0004
2019-09-25 12:43:54,237 [Thread-661] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-25 12:43:54,333 [Thread-661] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-25 12:43:54,334 [Thread-661] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1728463876_0004
2019-09-25 12:43:54,335 [Thread-725] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-25 12:43:54,335 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1728463876_0004
2019-09-25 12:43:54,336 [Thread-725] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:54,336 [Thread-725] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:54,336 [Thread-725] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-25 12:43:54,360 [Thread-725] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-25 12:43:54,360 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000000_0
2019-09-25 12:43:54,360 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:54,361 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:43:54,361 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:43:54,362 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:2246+822
2019-09-25 12:43:54,363 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:43:54,363 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:43:54.382 [IPC Server handler 0 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:54,383 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
12:43:54.390 [IPC Server handler 19 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:54,391 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
2019-09-25 12:43:54,393 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:54,394 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:54,394 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:54,394 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:54,394 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:54,394 [IPC Server handler 6 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:54,394 [IPC Server handler 6 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:54,395 [IPC Server handler 6 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:54,395 [IPC Server handler 6 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:54,395 [IPC Server handler 6 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:54.397 [IPC Server handler 18 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:54,398 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
2019-09-25 12:43:54,398 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:55,336 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1728463876_0004 running in uber mode : false
2019-09-25 12:43:55,336 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-25 12:43:57,261 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
2019-09-25 12:43:57,264 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:43:57,264 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:43:57,264 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:43:57,264 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:43:57,264 [IPC Server handler 2 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:43:57,265 [IPC Server handler 2 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:43:57,265 [IPC Server handler 2 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:57,265 [IPC Server handler 2 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:43:57,265 [IPC Server handler 2 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:43:57,265 [IPC Server handler 2 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:43:57.268 [IPC Server handler 19 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:43:57,269 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
2019-09-25 12:43:57,269 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:43:58,705 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-25 12:44:02,857 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
2019-09-25 12:44:02,862 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:02,862 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:02,862 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:02,862 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:02,863 [IPC Server handler 1 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:02,863 [IPC Server handler 1 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:02,863 [IPC Server handler 1 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:02,864 [IPC Server handler 1 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:02,865 [IPC Server handler 1 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:02,865 [IPC Server handler 1 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:02.868 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:02,869 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000000_0
2019-09-25 12:44:02,870 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:02,871 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:44:02,881 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000001_0
2019-09-25 12:44:02,882 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:02,882 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:02,883 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:02,884 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:0+324
2019-09-25 12:44:02,884 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:02,885 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12:44:02.900 [IPC Server handler 13 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:02,901 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
12:44:02.907 [IPC Server handler 11 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:02,912 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:02,913 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1728463876_0004_m_000001_0 is done. And is in the process of committing
2019-09-25 12:44:02,913 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:02,914 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1728463876_0004_m_000001_0 is allowed to commit now
2019-09-25 12:44:02,915 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1728463876_0004_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/_logs
2019-09-25 12:44:02,915 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-25 12:44:02,916 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1728463876_0004_m_000001_0' done.
2019-09-25 12:44:02,916 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1728463876_0004_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=874069
		FILE: Number of bytes written=12790373
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=115
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=64
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1997012992
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:44:02,916 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1728463876_0004_m_000001_0
2019-09-25 12:44:02,916 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:02,917 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:02,917 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:02,917 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:02,918 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:324+290
2019-09-25 12:44:02,918 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:02,918 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:02,935 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
12:44:02.942 [IPC Server handler 12 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:02,943 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:02,947 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:02,949 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:02,950 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:02,950 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:02,950 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:02,950 [IPC Server handler 3 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:02,951 [IPC Server handler 3 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:02,951 [IPC Server handler 3 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:02,952 [IPC Server handler 3 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:02,952 [IPC Server handler 3 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:02.954 [IPC Server handler 7 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:02,954 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:02,954 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:03,340 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-25 12:44:04,706 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-25 12:44:04,915 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:04,920 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:04,920 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:04,921 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:04,921 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:04,921 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:04,921 [IPC Server handler 3 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:04,922 [IPC Server handler 3 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:04,922 [IPC Server handler 3 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:04,923 [IPC Server handler 3 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:04,923 [IPC Server handler 3 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:04.926 [IPC Server handler 12 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:04,927 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:04,927 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:06,369 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-25 12:44:07,342 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-25 12:44:08,896 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:08,900 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:08,900 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:08,901 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:08,901 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:08,901 [IPC Server handler 3 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:08,901 [IPC Server handler 3 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:08,901 [IPC Server handler 3 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:08,902 [IPC Server handler 3 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:08,903 [IPC Server handler 3 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:08,903 [IPC Server handler 3 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:08.905 [IPC Server handler 11 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:08,906 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000002_0
2019-09-25 12:44:08,907 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:08,907 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:44:08,908 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:08,909 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:08,909 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:08,910 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:08,911 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:1694+290
2019-09-25 12:44:08,911 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:08,911 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:08,925 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
12:44:08.931 [IPC Server handler 10 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:08,932 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:08,934 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:08,935 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:08,935 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:08,935 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:08,935 [IPC Server handler 11 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:08,935 [IPC Server handler 11 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:08,935 [IPC Server handler 11 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:08,936 [IPC Server handler 11 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:08,936 [IPC Server handler 11 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:08,936 [IPC Server handler 11 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:08.938 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:08,939 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:08,939 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:10,427 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:10,430 [IPC Server handler 13 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:10,430 [IPC Server handler 13 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:10,431 [IPC Server handler 13 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:10,431 [IPC Server handler 13 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:10,431 [IPC Server handler 13 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:10,431 [IPC Server handler 13 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:10,432 [IPC Server handler 13 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:10,432 [IPC Server handler 13 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:10,433 [IPC Server handler 13 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:10,433 [IPC Server handler 13 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:10.436 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:10,437 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:10,437 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:12,372 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-25 12:44:14,334 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:14,337 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:14,337 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:14,337 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:14,338 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:14,338 [IPC Server handler 6 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:14,338 [IPC Server handler 6 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:14,338 [IPC Server handler 6 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:14,339 [IPC Server handler 6 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:14,339 [IPC Server handler 6 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:14,339 [IPC Server handler 6 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
12:44:14.342 [IPC Server handler 18 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:14,343 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1728463876_0004_m_000003_0
2019-09-25 12:44:14,343 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-25 12:44:14,344 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:44:14,345 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000004_0
2019-09-25 12:44:14,346 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,346 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,346 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:14,347 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:614+278
2019-09-25 12:44:14,348 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,348 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,363 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
12:44:14.368 [IPC Server handler 15 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:14,373 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,373 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1728463876_0004_m_000004_0 is done. And is in the process of committing
2019-09-25 12:44:14,374 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,374 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1728463876_0004_m_000004_0 is allowed to commit now
2019-09-25 12:44:14,375 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1728463876_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/_logs
2019-09-25 12:44:14,376 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-25 12:44:14,376 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1728463876_0004_m_000004_0' done.
2019-09-25 12:44:14,376 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1728463876_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=887249
		FILE: Number of bytes written=12790397
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=127
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1997012992
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:44:14,377 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1728463876_0004_m_000004_0
2019-09-25 12:44:14,377 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000005_0
2019-09-25 12:44:14,378 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,378 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,378 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:14,379 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:1154+278
2019-09-25 12:44:14,379 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,380 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,396 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
12:44:14.403 [IPC Server handler 14 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:14,407 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,408 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1728463876_0004_m_000005_0 is done. And is in the process of committing
2019-09-25 12:44:14,409 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,409 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1728463876_0004_m_000005_0 is allowed to commit now
2019-09-25 12:44:14,411 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1728463876_0004_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/_logs
2019-09-25 12:44:14,411 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-25 12:44:14,411 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1728463876_0004_m_000005_0' done.
2019-09-25 12:44:14,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1728463876_0004_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=891301
		FILE: Number of bytes written=12790405
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=129
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1997012992
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:44:14,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1728463876_0004_m_000005_0
2019-09-25 12:44:14,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000006_0
2019-09-25 12:44:14,413 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,414 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,414 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:14,415 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:892+262
2019-09-25 12:44:14,415 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,416 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,430 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:44:14,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1728463876_0004_m_000006_0 is done. And is in the process of committing
2019-09-25 12:44:14,439 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,439 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1728463876_0004_m_000006_0 is allowed to commit now
2019-09-25 12:44:14,440 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1728463876_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/_logs
2019-09-25 12:44:14,443 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-25 12:44:14,443 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1728463876_0004_m_000006_0' done.
2019-09-25 12:44:14,443 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1728463876_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=895353
		FILE: Number of bytes written=12790413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=131
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1997012992
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:44:14,443 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1728463876_0004_m_000006_0
2019-09-25 12:44:14,444 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000007_0
2019-09-25 12:44:14,445 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,445 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,445 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:14,446 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:1432+262
2019-09-25 12:44:14,446 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,447 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,461 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:44:14,469 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,469 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1728463876_0004_m_000007_0 is done. And is in the process of committing
2019-09-25 12:44:14,470 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,470 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1728463876_0004_m_000007_0 is allowed to commit now
2019-09-25 12:44:14,471 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1728463876_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/_logs
2019-09-25 12:44:14,471 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-25 12:44:14,471 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1728463876_0004_m_000007_0' done.
2019-09-25 12:44:14,471 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1728463876_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=898893
		FILE: Number of bytes written=12790421
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=133
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1997012992
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:44:14,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1728463876_0004_m_000007_0
2019-09-25 12:44:14,472 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1728463876_0004_m_000008_0
2019-09-25 12:44:14,472 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,472 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,473 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-25 12:44:14,473 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/fileList.seq:1984+262
2019-09-25 12:44:14,473 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-25 12:44:14,474 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-25 12:44:14,485 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
12:44:14.490 [IPC Server handler 4 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume88852, bucket=bucket05525, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume88852 bucket: bucket05525 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:14,493 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,493 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1728463876_0004_m_000008_0 is done. And is in the process of committing
2019-09-25 12:44:14,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-25 12:44:14,494 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1728463876_0004_m_000008_0 is allowed to commit now
2019-09-25 12:44:14,495 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1728463876_0004_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963/_logs
2019-09-25 12:44:14,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-25 12:44:14,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1728463876_0004_m_000008_0' done.
2019-09-25 12:44:14,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1728463876_0004_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=902433
		FILE: Number of bytes written=12790429
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=135
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1997012992
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-25 12:44:14,496 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1728463876_0004_m_000008_0
2019-09-25 12:44:14,496 [Thread-725] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-25 12:44:14,507 [Thread-725] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001578336760/.staging/_distcp885991963
2019-09-25 12:44:14,508 [Thread-725] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1728463876_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket05525.volume88852/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-25 12:44:14,937 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-25 12:44:15,345 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 81% reduce 0%
2019-09-25 12:44:15,346 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1728463876_0004 failed with state FAILED due to: NA
2019-09-25 12:44:15,352 [Thread-661] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=7134928
		FILE: Number of bytes written=102323256
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1033
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=594
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1256
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=15976103936
	File Input Format Counters 
		Bytes Read=24992
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
]]></system-out>
  </testcase>
  <testcase name="testDeepDirectoryStructureFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.193">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:488)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testDeepDirectoryStructureFromRemote(AbstractContractDistCpTest.java:458)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-25 12:44:15,408 [Thread-774] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-25 12:44:15,443 [Thread-774] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume95480, with user48123 as owner.
2019-09-25 12:44:15,445 [IPC Server handler 5 on 45560] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume95480 for user:user48123
2019-09-25 12:44:15,448 [Thread-774] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume95480/bucket94390, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-25 12:44:15,526 [Thread-774] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket94390.volume95480 implemented by OzoneFileSystem{URI=o3fs://bucket94390.volume95480, workingDir=o3fs://bucket94390.volume95480/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 142 read ops, 0 large read ops, 77 write ops}
12:44:15.544 [IPC Server handler 6 on 45560] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95480, bucket=bucket94390, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95480 bucket: bucket94390 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-25 12:44:15,547 [Thread-774] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-25 12:44:15,553 [IPC Server handler 9 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 35a9f88d-76d2-4b6c-86f2-100b645542d6 Heaviness: 6 limit: 5
2019-09-25 12:44:15,553 [IPC Server handler 9 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 5ed5034e-e207-4b91-a9fd-56a7ae9c6bc9 Heaviness: 6 limit: 5
2019-09-25 12:44:15,553 [IPC Server handler 9 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 46e204cb-f3c6-48b7-a572-0bdf52c235a1 Heaviness: 6 limit: 5
2019-09-25 12:44:15,554 [IPC Server handler 9 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 11e2e2c2-ccb4-47dd-8370-62ab6b97f33f Heaviness: 6 limit: 5
2019-09-25 12:44:15,554 [IPC Server handler 9 on 45259] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 0d6d7abe-064e-4f87-bb34-13a3ff0fda59 Heaviness: 6 limit: 5
2019-09-25 12:44:15,554 [IPC Server handler 9 on 45259] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-25 12:44:15,554 [IPC Server handler 9 on 45259] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:15,555 [IPC Server handler 9 on 45259] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-25 12:44:15,556 [IPC Server handler 9 on 45259] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-25 12:44:15,556 [IPC Server handler 9 on 45259] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
]]></system-out>
  </testcase>
</testsuite>
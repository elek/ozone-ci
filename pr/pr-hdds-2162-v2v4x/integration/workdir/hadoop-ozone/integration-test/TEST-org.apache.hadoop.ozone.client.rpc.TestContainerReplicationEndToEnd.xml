<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.ozone.client.rpc.TestContainerReplicationEndToEnd" time="131.279" tests="1" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/integration-test/target/test-classes:/workdir/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.0/hadoop-minikdc-3.2.0.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/integration-test/target/surefire/surefirebooter6769911980961929012.jar /workdir/hadoop-ozone/integration-test/target/surefire 2019-09-24T20-51-17_462-jvmRun1 surefire5595208039602096526tmp surefire_728765980838456441787tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/integration-test/target/test-classes:/workdir/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0/ratis-server-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0/ratis-proto-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0/ratis-common-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0/ratis-client-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0/ratis-metrics-0.4.0.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0/ratis-netty-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0/ratis-grpc-0.4.0.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.0/hadoop-minikdc-3.2.0.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/integration-test/target/surefire/surefirebooter6769911980961929012.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/integration-test/target/native/target/usr/local/lib:/workdir/hadoop-ozone/integration-test/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="org.apache.hadoop.ozone.client.rpc.TestContainerReplicationEndToEnd" classname="org.apache.hadoop.ozone.client.rpc.TestContainerReplicationEndToEnd" time="131.279">
    <error message="Connection refused" type="java.net.ConnectException"><![CDATA[java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestContainerReplicationEndToEnd.init(TestContainerReplicationEndToEnd.java:110)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
]]></error>
    <system-out><![CDATA[2019-09-24 22:54:35,514 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:35,609 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:35,612 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:35,629 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @865ms
2019-09-24 22:54:35,742 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-24 22:54:35,743 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-24 22:54:35,744 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-24 22:54:35,744 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-24 22:54:35,744 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-24 22:54:35,745 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-24 22:54:35,760 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 22:54:35,760 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 22:54:35,762 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 22:54:36,143 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@71d44a3
2019-09-24 22:54:36,145 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-24 22:54:36,214 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-24 22:54:36,286 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-24 22:54:36,300 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:36,428 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-24 22:54:36,432 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:36,558 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for hdds.scm.replication.thread.interval(2000) assuming MILLISECONDS
2019-09-24 22:54:36,591 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-24 22:54:36,927 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 22:54:36,954 [Socket Reader #1 for port 39763] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39763
2019-09-24 22:54:37,095 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 22:54:37,097 [Socket Reader #1 for port 45302] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45302
2019-09-24 22:54:37,108 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 22:54:37,109 [Socket Reader #1 for port 42768] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42768
2019-09-24 22:54:37,136 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-24 22:54:37,272 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 22:54:37,280 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 22:54:37,288 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 22:54:37,290 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-24 22:54:37,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 22:54:37,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 22:54:37,319 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42768
2019-09-24 22:54:37,374 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-24 22:54:37,387 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-24 22:54:37,387 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-24 22:54:37,603 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:42768
2019-09-24 22:54:37,605 [IPC Server listener on 42768] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42768: starting
2019-09-24 22:54:37,605 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 22:54:37,610 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45302
2019-09-24 22:54:37,612 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45302
2019-09-24 22:54:37,613 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 22:54:37,614 [IPC Server listener on 45302] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45302: starting
2019-09-24 22:54:37,624 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:39763
2019-09-24 22:54:37,624 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:39763
2019-09-24 22:54:37,627 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 22:54:37,627 [IPC Server listener on 39763] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39763: starting
2019-09-24 22:54:37,642 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38026
2019-09-24 22:54:37,644 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 22:54:37,684 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b00f608{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 22:54:37,685 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e821657{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-24 22:54:37,716 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6928f576{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-24 22:54:37,721 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@548e76f1{HTTP/1.1,[http/1.1]}{0.0.0.0:38026}
2019-09-24 22:54:37,722 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2958ms
2019-09-24 22:54:37,724 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-24 22:54:37,724 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-24 22:54:37,726 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:38026
2019-09-24 22:54:37,732 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73511076] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 22:54:37,734 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:37,987 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(181)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-24 22:54:37,987 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(211)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-24 22:54:37,989 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:37,990 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:38,702 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 22:54:38,709 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-24 22:54:38,709 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-24 22:54:38,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-24 22:54:38,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-24 22:54:38,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-24 22:54:38,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-24 22:54:38,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-24 22:54:38,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-24 22:54:38,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-24 22:54:38,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-24 22:54:38,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-24 22:54:38,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-24 22:54:38,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-24 22:54:38,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-24 22:54:38,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-24 22:54:38,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-24 22:54:38,713 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-24 22:54:38,713 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-24 22:54:38,713 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-24 22:54:38,713 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-24 22:54:38,714 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-24 22:54:38,714 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-24 22:54:38,714 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 22:54:38,714 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 22:54:38,715 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 22:54:39,210 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 22:54:39,212 [Socket Reader #1 for port 37757] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37757
2019-09-24 22:54:39,234 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37757
2019-09-24 22:54:39,234 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-24 22:54:39,236 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 22:54:39,237 [IPC Server listener on 37757] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37757: starting
2019-09-24 22:54:39,257 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-24 22:54:39,260 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 22:54:39,261 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 22:54:39,266 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 22:54:39,267 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-24 22:54:39,268 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 22:54:39,268 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 22:54:39,271 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43044
2019-09-24 22:54:39,272 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 22:54:39,275 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a627c80{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 22:54:39,275 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@963176{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-24 22:54:39,286 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4af46df3{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-24 22:54:39,289 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4158debd{HTTP/1.1,[http/1.1]}{0.0.0.0:43044}
2019-09-24 22:54:39,290 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4526ms
2019-09-24 22:54:39,290 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 22:54:39,291 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:43044
2019-09-24 22:54:39,603 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 22:54:39,670 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-24 22:54:39,704 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 22:54:39,706 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/containers/hdds to VolumeSet
2019-09-24 22:54:39,709 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fdecce
2019-09-24 22:54:39,726 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fdecce
2019-09-24 22:54:39,839 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 22:54:39,905 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 22:54:39,910 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 22:54:39,911 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 22:54:39,913 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:39,914 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 22:54:39,914 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 22:54:40,097 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis] (custom)
2019-09-24 22:54:40,159 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 22:54:40,162 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 22:54:40,163 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 22:54:40,165 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 22:54:40,166 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 22:54:40,166 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 22:54:40,166 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 22:54:40,168 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36145
2019-09-24 22:54:40,168 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 22:54:40,171 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d1dcdff{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 22:54:40,171 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ff35a3f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 22:54:40,204 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a66e580{/,file:///tmp/jetty-0.0.0.0-36145-hddsDatanode-_-any-3295242988578650199.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 22:54:40,205 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b852b49{HTTP/1.1,[http/1.1]}{0.0.0.0:36145}
2019-09-24 22:54:40,205 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5442ms
2019-09-24 22:54:40,207 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 22:54:40,208 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36145
2019-09-24 22:54:40,209 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 22:54:40,212 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-24 22:54:40,216 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fcc5ef4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 22:54:40,221 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 22:54:40,222 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/containers/hdds to VolumeSet
2019-09-24 22:54:40,222 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-24 22:54:40,223 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-24 22:54:40,238 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 22:54:40,238 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 22:54:40,239 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 22:54:40,239 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 22:54:40,239 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:40,239 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 22:54:40,240 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 22:54:40,240 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis] (custom)
2019-09-24 22:54:40,242 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 22:54:40,243 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 22:54:40,244 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 22:54:40,246 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 22:54:40,246 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 22:54:40,246 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 22:54:40,246 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 22:54:40,247 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33227
2019-09-24 22:54:40,248 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 22:54:40,254 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 22:54:40,254 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 22:54:40,283 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7bc44ce8{/,file:///tmp/jetty-0.0.0.0-33227-hddsDatanode-_-any-6172680856937108192.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 22:54:40,285 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:33227}
2019-09-24 22:54:40,285 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5522ms
2019-09-24 22:54:40,286 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 22:54:40,287 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33227
2019-09-24 22:54:40,287 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 22:54:40,290 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@724d739a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 22:54:40,290 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-24 22:54:40,298 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 22:54:40,300 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/containers/hdds to VolumeSet
2019-09-24 22:54:40,300 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cc86152
2019-09-24 22:54:40,301 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cc86152
2019-09-24 22:54:40,313 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 22:54:40,314 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 22:54:40,314 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 22:54:40,314 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 22:54:40,314 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:40,315 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 22:54:40,315 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 22:54:40,316 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis] (custom)
2019-09-24 22:54:40,318 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 22:54:40,319 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 22:54:40,319 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 22:54:40,321 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 22:54:40,321 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 22:54:40,322 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 22:54:40,322 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 22:54:40,322 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35356
2019-09-24 22:54:40,323 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 22:54:40,324 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77b919a3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 22:54:40,325 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36681447{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 22:54:40,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12e0f1cb{/,file:///tmp/jetty-0.0.0.0-35356-hddsDatanode-_-any-6971051554895038675.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 22:54:40,356 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a163575{HTTP/1.1,[http/1.1]}{0.0.0.0:35356}
2019-09-24 22:54:40,356 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5593ms
2019-09-24 22:54:40,357 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 22:54:40,358 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35356
2019-09-24 22:54:40,358 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 22:54:40,361 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/meta/datanode.id
2019-09-24 22:54:40,362 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62e98d0d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 22:54:40,362 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-24 22:54:40,367 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/meta/datanode.id
2019-09-24 22:54:40,371 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/meta/datanode.id
2019-09-24 22:54:40,372 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 22:54:40,373 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/containers/hdds to VolumeSet
2019-09-24 22:54:40,373 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6540cf1d
2019-09-24 22:54:40,373 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6540cf1d
2019-09-24 22:54:40,387 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 22:54:40,387 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 22:54:40,387 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 22:54:40,387 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 22:54:40,388 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:40,388 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 22:54:40,388 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 22:54:40,389 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis] (custom)
2019-09-24 22:54:40,390 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 22:54:40,392 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 22:54:40,392 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 22:54:40,394 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 22:54:40,394 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 22:54:40,395 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 22:54:40,395 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 22:54:40,395 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45679
2019-09-24 22:54:40,396 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 22:54:40,401 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@378cfecf{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 22:54:40,402 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e7c141d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 22:54:40,430 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@437486cd{/,file:///tmp/jetty-0.0.0.0-45679-hddsDatanode-_-any-4638378408643110888.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 22:54:40,431 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15b642b9{HTTP/1.1,[http/1.1]}{0.0.0.0:45679}
2019-09-24 22:54:40,432 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5668ms
2019-09-24 22:54:40,432 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 22:54:40,433 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45679
2019-09-24 22:54:40,436 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-24 22:54:40,437 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20921129] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 22:54:40,441 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/meta/datanode.id
2019-09-24 22:54:41,436 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-24 22:54:42,283 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 22:54:42,286 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 22:54:42,286 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf at port 0
2019-09-24 22:54:42,318 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: start RPC server
2019-09-24 22:54:42,319 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 22:54:42,325 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 22:54:42,325 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 09a241b9-b8d1-4472-89b0-8795fabd1640 at port 0
2019-09-24 22:54:42,337 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start RPC server
2019-09-24 22:54:42,378 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 22:54:42,380 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 22:54:42,380 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 9d5442d4-ee95-4410-8c78-fbec62863c16 at port 0
2019-09-24 22:54:42,389 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: start RPC server
2019-09-24 22:54:42,437 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-24 22:54:42,453 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 22:54:42,455 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 22:54:42,456 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 37866424-2e21-4e75-b95a-a562e1eae4e3 at port 0
2019-09-24 22:54:42,475 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start RPC server
2019-09-24 22:54:42,497 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: GrpcService started, listening on 0.0.0.0/0.0.0.0:46129
2019-09-24 22:54:42,497 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: GrpcService started, listening on 0.0.0.0/0.0.0.0:43692
2019-09-24 22:54:42,498 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 09a241b9-b8d1-4472-89b0-8795fabd1640 is started using port 46129
2019-09-24 22:54:42,497 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: GrpcService started, listening on 0.0.0.0/0.0.0.0:32788
2019-09-24 22:54:42,497 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: GrpcService started, listening on 0.0.0.0/0.0.0.0:39424
2019-09-24 22:54:42,498 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 37866424-2e21-4e75-b95a-a562e1eae4e3 is started using port 32788
2019-09-24 22:54:42,498 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf is started using port 43692
2019-09-24 22:54:42,498 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 9d5442d4-ee95-4410-8c78-fbec62863c16 is started using port 39424
2019-09-24 22:54:42,506 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 09a241b9-b8d1-4472-89b0-8795fabd1640 is started using port 41341
2019-09-24 22:54:42,507 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 9d5442d4-ee95-4410-8c78-fbec62863c16 is started using port 43176
2019-09-24 22:54:42,507 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf is started using port 37309
2019-09-24 22:54:42,506 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 37866424-2e21-4e75-b95a-a562e1eae4e3 is started using port 38635
2019-09-24 22:54:43,438 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-24 22:54:44,263 [IPC Server handler 0 on 39763] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf
2019-09-24 22:54:44,263 [IPC Server handler 0 on 39763] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-24 22:54:44,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-24 22:54:44,269 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-24 22:54:44,270 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-24 22:54:44,294 [IPC Server handler 1 on 39763] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/09a241b9-b8d1-4472-89b0-8795fabd1640
2019-09-24 22:54:44,295 [IPC Server handler 1 on 39763] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-24 22:54:44,365 [IPC Server handler 3 on 39763] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/9d5442d4-ee95-4410-8c78-fbec62863c16
2019-09-24 22:54:44,365 [IPC Server handler 3 on 39763] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-24 22:54:44,439 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 3 of 4 DN Heartbeats.
2019-09-24 22:54:44,440 [IPC Server handler 4 on 39763] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/37866424-2e21-4e75-b95a-a562e1eae4e3
2019-09-24 22:54:44,440 [IPC Server handler 4 on 39763] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-24 22:54:44,799 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: addNew group-F129C625B686:[e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692] returns group-F129C625B686:java.util.concurrent.CompletableFuture@669f7617[Not completed]
2019-09-24 22:54:44,819 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: new RaftServerImpl for group-F129C625B686:[e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692] with ContainerStateMachine:uninitialized
2019-09-24 22:54:44,822 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:44,823 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:44,824 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:44,825 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:44,826 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:44,836 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: ConfigurationManager, init=-1: [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:44,836 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis] (custom)
2019-09-24 22:54:44,845 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis/a68ccee6-5887-4d6d-9d2d-f129c625b686 does not exist. Creating ...
2019-09-24 22:54:44,871 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis/a68ccee6-5887-4d6d-9d2d-f129c625b686/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:44,888 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis/a68ccee6-5887-4d6d-9d2d-f129c625b686 has been successfully formatted.
2019-09-24 22:54:44,890 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F129C625B686: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:44,891 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:44,893 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:44,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:44,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:44,904 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:44,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:44,916 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis/a68ccee6-5887-4d6d-9d2d-f129c625b686
2019-09-24 22:54:44,918 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-24 22:54:44,924 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-24 22:54:44,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:44,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:44,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:44,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:44,960 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:44,960 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:44,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:44,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:44,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:44,970 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:44,975 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:44,979 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:44,980 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:44,980 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:44,981 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,005 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: start as a follower, conf=-1: [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692], old=null
2019-09-24 22:54:45,006 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,007 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: start FollowerState
2019-09-24 22:54:45,008 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F129C625B686,id=e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf
2019-09-24 22:54:45,081 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a68ccee6-5887-4d6d-9d2d-f129c625b686, Nodes: e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:54:45,105 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: addNew group-2A3A5D74A4DD:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129] returns group-2A3A5D74A4DD:java.util.concurrent.CompletableFuture@4af1cfc4[Not completed]
2019-09-24 22:54:45,148 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: new RaftServerImpl for group-2A3A5D74A4DD:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129] with ContainerStateMachine:uninitialized
2019-09-24 22:54:45,150 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:45,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:45,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:45,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:45,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:45,151 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: ConfigurationManager, init=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:45,152 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis] (custom)
2019-09-24 22:54:45,152 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd does not exist. Creating ...
2019-09-24 22:54:45,167 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:45,188 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd has been successfully formatted.
2019-09-24 22:54:45,190 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-2A3A5D74A4DD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:45,192 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:45,192 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:45,192 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:45,192 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:45,193 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,193 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:45,193 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd
2019-09-24 22:54:45,201 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:45,201 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:45,201 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,202 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:45,202 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:45,202 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:45,202 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:45,203 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:45,203 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:45,203 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:45,204 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:45,204 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:45,205 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:45,205 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:45,205 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,214 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: start as a follower, conf=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129], old=null
2019-09-24 22:54:45,214 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,214 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start FollowerState
2019-09-24 22:54:45,217 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2A3A5D74A4DD,id=09a241b9-b8d1-4472-89b0-8795fabd1640
2019-09-24 22:54:45,238 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:54:45,262 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: addNew group-1B596ADB384B:[9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] returns group-1B596ADB384B:java.util.concurrent.CompletableFuture@1e4af204[Not completed]
2019-09-24 22:54:45,288 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: new RaftServerImpl for group-1B596ADB384B:[9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] with ContainerStateMachine:uninitialized
2019-09-24 22:54:45,292 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:45,292 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:45,292 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:45,292 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:45,293 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:45,293 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: ConfigurationManager, init=-1: [9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:45,293 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis] (custom)
2019-09-24 22:54:45,294 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/615f9a82-b642-4e35-b02c-1b596adb384b does not exist. Creating ...
2019-09-24 22:54:45,315 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/615f9a82-b642-4e35-b02c-1b596adb384b/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:45,318 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/615f9a82-b642-4e35-b02c-1b596adb384b has been successfully formatted.
2019-09-24 22:54:45,319 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1B596ADB384B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:45,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:45,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:45,320 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:45,320 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:45,320 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,320 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:45,320 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/615f9a82-b642-4e35-b02c-1b596adb384b
2019-09-24 22:54:45,348 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:45,348 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:45,348 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:45,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:45,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:45,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:45,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:45,350 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:45,350 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:45,350 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:45,351 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:45,351 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:45,351 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:45,351 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,356 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: start as a follower, conf=-1: [9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:45,356 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,357 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: start FollowerState
2019-09-24 22:54:45,357 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1B596ADB384B,id=9d5442d4-ee95-4410-8c78-fbec62863c16
2019-09-24 22:54:45,368 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 615f9a82-b642-4e35-b02c-1b596adb384b, Nodes: 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:54:45,386 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: addNew group-592E6245275C:[37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788] returns group-592E6245275C:java.util.concurrent.CompletableFuture@50c06d89[Not completed]
2019-09-24 22:54:45,389 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: new RaftServerImpl for group-592E6245275C:[37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788] with ContainerStateMachine:uninitialized
2019-09-24 22:54:45,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:45,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:45,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:45,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:45,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:45,391 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: ConfigurationManager, init=-1: [37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:45,391 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis] (custom)
2019-09-24 22:54:45,392 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/e7edc268-b035-4203-956f-592e6245275c does not exist. Creating ...
2019-09-24 22:54:45,403 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/e7edc268-b035-4203-956f-592e6245275c/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:45,407 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/e7edc268-b035-4203-956f-592e6245275c has been successfully formatted.
2019-09-24 22:54:45,408 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-592E6245275C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:45,408 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:45,408 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:45,408 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:45,409 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:45,409 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,409 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:45,409 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/e7edc268-b035-4203-956f-592e6245275c
2019-09-24 22:54:45,416 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:45,416 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:45,416 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,417 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:45,417 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:45,417 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:45,417 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:45,418 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:45,418 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:45,418 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:45,419 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:45,419 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:45,419 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:45,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:45,420 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,426 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: start as a follower, conf=-1: [37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788], old=null
2019-09-24 22:54:45,426 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,426 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start FollowerState
2019-09-24 22:54:45,427 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-592E6245275C,id=37866424-2e21-4e75-b95a-a562e1eae4e3
2019-09-24 22:54:45,440 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 4 of 4 DN Heartbeats.
2019-09-24 22:54:45,440 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e7edc268-b035-4203-956f-592e6245275c, Nodes: 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:54:45,446 [main] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-24 22:54:45,465 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 9 milliseconds for processing 0 containers.
2019-09-24 22:54:45,507 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: addNew group-AE1F32BEED35:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] returns group-AE1F32BEED35:java.util.concurrent.CompletableFuture@2218b831[Not completed]
2019-09-24 22:54:45,507 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: addNew group-AE1F32BEED35:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] returns group-AE1F32BEED35:java.util.concurrent.CompletableFuture@35a0cb54[Not completed]
2019-09-24 22:54:45,507 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: addNew group-AE1F32BEED35:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] returns group-AE1F32BEED35:java.util.concurrent.CompletableFuture@21c39550[Not completed]
2019-09-24 22:54:45,509 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: new RaftServerImpl for group-AE1F32BEED35:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] with ContainerStateMachine:uninitialized
2019-09-24 22:54:45,509 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:45,510 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:45,510 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:45,510 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:45,510 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:45,510 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: ConfigurationManager, init=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:45,510 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: new RaftServerImpl for group-AE1F32BEED35:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] with ContainerStateMachine:uninitialized
2019-09-24 22:54:45,510 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis] (custom)
2019-09-24 22:54:45,511 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:45,511 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:45,511 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35 does not exist. Creating ...
2019-09-24 22:54:45,511 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:45,512 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: new RaftServerImpl for group-AE1F32BEED35:[09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424] with ContainerStateMachine:uninitialized
2019-09-24 22:54:45,512 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:45,512 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 22:54:45,512 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:45,512 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 22:54:45,512 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: ConfigurationManager, init=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:45,513 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 22:54:45,513 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis] (custom)
2019-09-24 22:54:45,513 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 22:54:45,513 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:45,513 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35 does not exist. Creating ...
2019-09-24 22:54:45,513 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: ConfigurationManager, init=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null, confs=<EMPTY_MAP>
2019-09-24 22:54:45,514 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis] (custom)
2019-09-24 22:54:45,514 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35 does not exist. Creating ...
2019-09-24 22:54:45,536 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:45,536 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:45,536 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35/in_use.lock acquired by nodename 4483@pr-hdds-2162-v2v4x-1150571016
2019-09-24 22:54:45,562 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35 has been successfully formatted.
2019-09-24 22:54:45,562 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35 has been successfully formatted.
2019-09-24 22:54:45,562 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35 has been successfully formatted.
2019-09-24 22:54:45,562 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AE1F32BEED35: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:45,562 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AE1F32BEED35: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:45,563 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:45,563 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AE1F32BEED35: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 22:54:45,563 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:45,563 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:45,563 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:45,563 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 22:54:45,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:45,564 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:45,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,564 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 22:54:45,565 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:45,564 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:45,565 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35
2019-09-24 22:54:45,565 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 22:54:45,565 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:45,565 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:45,566 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:45,566 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:45,566 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,566 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,567 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:45,566 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,567 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:45,567 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:45,568 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:45,567 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 22:54:45,568 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:45,568 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35
2019-09-24 22:54:45,568 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:45,568 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35
2019-09-24 22:54:45,569 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:45,569 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:45,569 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:45,569 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 22:54:45,569 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:45,570 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:45,570 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 22:54:45,570 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,570 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 22:54:45,571 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:45,570 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:45,571 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:45,571 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 22:54:45,571 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:45,571 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:45,572 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:45,572 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 22:54:45,572 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:45,572 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:45,573 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:45,572 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 22:54:45,573 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:45,573 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,573 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 22:54:45,574 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:45,574 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 22:54:45,574 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 22:54:45,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:45,574 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 22:54:45,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:45,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:45,575 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 22:54:45,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,575 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 22:54:45,576 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 22:54:45,576 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 22:54:45,576 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 22:54:45,580 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: start as a follower, conf=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:45,581 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,581 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: start FollowerState
2019-09-24 22:54:45,581 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE1F32BEED35,id=9d5442d4-ee95-4410-8c78-fbec62863c16
2019-09-24 22:54:45,582 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: start as a follower, conf=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:45,582 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,582 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: start as a follower, conf=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:45,582 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 22:54:45,582 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start FollowerState
2019-09-24 22:54:45,583 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start FollowerState
2019-09-24 22:54:45,583 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE1F32BEED35,id=09a241b9-b8d1-4472-89b0-8795fabd1640
2019-09-24 22:54:45,583 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE1F32BEED35,id=37866424-2e21-4e75-b95a-a562e1eae4e3
2019-09-24 22:54:45,613 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fff0de51-527a-449d-979c-ae1f32beed35, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-24 22:54:46,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:47,272 [Thread-193] INFO  container.ReplicationManager (ReplicationManager.java:start(169)) - Replication Monitor Thread is already running.
2019-09-24 22:54:47,467 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:54:47,707 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:48,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:49,471 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:54:49,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:50,112 [Thread-195] INFO  impl.FollowerState (FollowerState.java:run(106)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:group-F129C625B686 changes to CANDIDATE, lastRpcTime:5104, electionTimeout:5104ms
2019-09-24 22:54:50,114 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: shutdown FollowerState
2019-09-24 22:54:50,115 [Thread-195] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 22:54:50,123 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: start LeaderElection
2019-09-24 22:54:50,152 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1: begin an election at term 1 for -1: [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692], old=null
2019-09-24 22:54:50,154 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: shutdown LeaderElection
2019-09-24 22:54:50,155 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 22:54:50,155 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: change Leader from null to e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf at term 1 for becomeLeader, leader elected after 5264ms
2019-09-24 22:54:50,163 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 22:54:50,164 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 22:54:50,167 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 22:54:50,169 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 22:54:50,170 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 22:54:50,171 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 22:54:50,184 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: start LeaderState
2019-09-24 22:54:50,205 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,214 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: set configuration 0: [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692], old=null at 0
2019-09-24 22:54:50,286 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(106)) - 09a241b9-b8d1-4472-89b0-8795fabd1640:group-2A3A5D74A4DD changes to CANDIDATE, lastRpcTime:5071, electionTimeout:5069ms
2019-09-24 22:54:50,288 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown FollowerState
2019-09-24 22:54:50,288 [Thread-198] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 22:54:50,288 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start LeaderElection
2019-09-24 22:54:50,304 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2: begin an election at term 1 for -1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129], old=null
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown LeaderElection
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: change Leader from null to 09a241b9-b8d1-4472-89b0-8795fabd1640 at term 1 for becomeLeader, leader elected after 5113ms
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 22:54:50,305 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 22:54:50,306 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 22:54:50,308 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start LeaderState
2019-09-24 22:54:50,308 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,308 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: set configuration 0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129], old=null at 0
2019-09-24 22:54:50,417 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/ratis/a68ccee6-5887-4d6d-9d2d-f129c625b686/current/log_inprogress_0
2019-09-24 22:54:50,417 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd/current/log_inprogress_0
2019-09-24 22:54:50,551 [Thread-201] INFO  impl.FollowerState (FollowerState.java:run(106)) - 9d5442d4-ee95-4410-8c78-fbec62863c16:group-1B596ADB384B changes to CANDIDATE, lastRpcTime:5194, electionTimeout:5194ms
2019-09-24 22:54:50,551 [Thread-201] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown FollowerState
2019-09-24 22:54:50,552 [Thread-201] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 22:54:50,552 [Thread-201] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: start LeaderElection
2019-09-24 22:54:50,578 [Thread-204] INFO  impl.FollowerState (FollowerState.java:run(106)) - 37866424-2e21-4e75-b95a-a562e1eae4e3:group-592E6245275C changes to CANDIDATE, lastRpcTime:5151, electionTimeout:5151ms
2019-09-24 22:54:50,578 [Thread-204] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown FollowerState
2019-09-24 22:54:50,578 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3: begin an election at term 1 for -1: [9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:50,578 [Thread-204] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 22:54:50,578 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown LeaderElection
2019-09-24 22:54:50,579 [Thread-204] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start LeaderElection
2019-09-24 22:54:50,579 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 22:54:50,579 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: change Leader from null to 9d5442d4-ee95-4410-8c78-fbec62863c16 at term 1 for becomeLeader, leader elected after 5259ms
2019-09-24 22:54:50,584 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 22:54:50,584 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 22:54:50,585 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 22:54:50,585 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 22:54:50,585 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 22:54:50,585 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 22:54:50,590 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: start LeaderState
2019-09-24 22:54:50,590 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,591 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: set configuration 0: [9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null at 0
2019-09-24 22:54:50,610 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4: begin an election at term 1 for -1: [37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788], old=null
2019-09-24 22:54:50,610 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown LeaderElection
2019-09-24 22:54:50,610 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 22:54:50,611 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: change Leader from null to 37866424-2e21-4e75-b95a-a562e1eae4e3 at term 1 for becomeLeader, leader elected after 5202ms
2019-09-24 22:54:50,612 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 22:54:50,612 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 22:54:50,612 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 22:54:50,612 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 22:54:50,613 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 22:54:50,613 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 22:54:50,616 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start LeaderState
2019-09-24 22:54:50,616 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,617 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: set configuration 0: [37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788], old=null at 0
2019-09-24 22:54:50,636 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(106)) - 37866424-2e21-4e75-b95a-a562e1eae4e3:group-AE1F32BEED35 changes to CANDIDATE, lastRpcTime:5052, electionTimeout:5043ms
2019-09-24 22:54:50,636 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/615f9a82-b642-4e35-b02c-1b596adb384b/current/log_inprogress_0
2019-09-24 22:54:50,636 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown FollowerState
2019-09-24 22:54:50,636 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 22:54:50,637 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start LeaderElection
2019-09-24 22:54:50,649 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/e7edc268-b035-4203-956f-592e6245275c/current/log_inprogress_0
2019-09-24 22:54:50,649 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5: begin an election at term 1 for -1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:50,678 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(106)) - 09a241b9-b8d1-4472-89b0-8795fabd1640:group-AE1F32BEED35 changes to CANDIDATE, lastRpcTime:5094, electionTimeout:5094ms
2019-09-24 22:54:50,678 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown FollowerState
2019-09-24 22:54:50,679 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 22:54:50,679 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start LeaderElection
2019-09-24 22:54:50,685 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:37866424-2e21-4e75-b95a-a562e1eae4e3
2019-09-24 22:54:50,685 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown FollowerState
2019-09-24 22:54:50,686 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: start FollowerState
2019-09-24 22:54:50,686 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(115)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 22:54:50,711 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:50,712 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6: begin an election at term 1 for -1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:50,738 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5: Election PASSED; received 1 response(s) [37866424-2e21-4e75-b95a-a562e1eae4e3<-9d5442d4-ee95-4410-8c78-fbec62863c16#0:OK-t1] and 0 exception(s); 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:t1, leader=null, voted=37866424-2e21-4e75-b95a-a562e1eae4e3, raftlog=37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:50,738 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown LeaderElection
2019-09-24 22:54:50,738 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 22:54:50,740 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: change Leader from null to 37866424-2e21-4e75-b95a-a562e1eae4e3 at term 1 for becomeLeader, leader elected after 5176ms
2019-09-24 22:54:50,742 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 22:54:50,742 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 22:54:50,742 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 22:54:50,742 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 22:54:50,742 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 22:54:50,743 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 22:54:50,754 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 22:54:50,755 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:50,755 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 22:54:50,760 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 22:54:50,766 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 22:54:50,766 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:50,768 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 22:54:50,768 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 22:54:50,768 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 22:54:50,768 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 22:54:50,769 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 22:54:50,769 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 22:54:50,773 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: start LeaderState
2019-09-24 22:54:50,773 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,774 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: set configuration 0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null at 0
2019-09-24 22:54:50,793 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:requestVote(758)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-   LEADER: Withhold vote from candidate 09a241b9-b8d1-4472-89b0-8795fabd1640 with term 1. State: leader=37866424-2e21-4e75-b95a-a562e1eae4e3, term=1, lastRpcElapsed=null
2019-09-24 22:54:50,808 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6: Election REJECTED; received 2 response(s) [09a241b9-b8d1-4472-89b0-8795fabd1640<-37866424-2e21-4e75-b95a-a562e1eae4e3#0:FAIL-t1, 09a241b9-b8d1-4472-89b0-8795fabd1640<-9d5442d4-ee95-4410-8c78-fbec62863c16#0:FAIL-t1] and 0 exception(s); 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:t1, leader=null, voted=09a241b9-b8d1-4472-89b0-8795fabd1640, raftlog=09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null
2019-09-24 22:54:50,808 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-24 22:54:50,810 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown LeaderElection
2019-09-24 22:54:50,810 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: start FollowerState
2019-09-24 22:54:50,817 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35/current/log_inprogress_0
2019-09-24 22:54:50,834 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: change Leader from null to 37866424-2e21-4e75-b95a-a562e1eae4e3 at term 1 for appendEntries, leader elected after 5271ms
2019-09-24 22:54:50,834 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: change Leader from null to 37866424-2e21-4e75-b95a-a562e1eae4e3 at term 1 for appendEntries, leader elected after 5271ms
2019-09-24 22:54:50,870 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: set configuration 0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null at 0
2019-09-24 22:54:50,870 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: set configuration 0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null at 0
2019-09-24 22:54:50,870 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,870 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 22:54:50,900 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35/current/log_inprogress_0
2019-09-24 22:54:50,900 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/ratis/fff0de51-527a-449d-979c-ae1f32beed35/current/log_inprogress_0
2019-09-24 22:54:51,471 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:54:51,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:52,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:53,472 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:54:53,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:54,717 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:55,472 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:54:55,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:56,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:57,473 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:54:57,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:58,728 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:54:59,479 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-24 22:54:59,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:00,731 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:01,479 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:01,733 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:02,734 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:03,480 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:03,735 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:04,736 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:05,480 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:05,737 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:05,739 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 22:55:06,740 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:07,481 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:07,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:08,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:09,481 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:09,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:10,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:11,481 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:11,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:12,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:13,482 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:13,749 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:14,750 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:15,482 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:15,752 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:15,753 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 22:55:16,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:17,483 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:17,756 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:18,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:19,483 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:19,758 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:20,759 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:21,483 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:21,760 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:22,762 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:23,484 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:23,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:24,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:25,484 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:25,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:25,767 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 22:55:26,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:27,485 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:27,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:28,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:29,485 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:29,772 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:30,773 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:31,486 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:31,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:32,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:33,486 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:33,777 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:34,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:35,488 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:35,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:35,781 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 22:55:36,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:37,488 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:37,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:38,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:39,489 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:39,786 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:40,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:41,489 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:41,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:42,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:43,489 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:43,791 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:44,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:45,490 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:45,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:45,795 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 22:55:46,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:47,490 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:47,798 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:48,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:49,491 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:49,800 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:50,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:51,491 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:51,803 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:52,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:53,492 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:53,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:54,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:55,492 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:55,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:55,809 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 22:55:56,810 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:57,493 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:57,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:58,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:55:59,493 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:55:59,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:00,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:01,494 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:01,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:02,819 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:03,494 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:03,820 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:04,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:05,495 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:05,823 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:05,825 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 22:56:06,826 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:07,495 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:07,827 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:08,828 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:09,496 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:09,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:10,831 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:11,496 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:11,832 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:12,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:13,497 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:13,837 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:14,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:15,497 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:15,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:15,840 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 22:56:16,841 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:17,498 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:17,843 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:18,844 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:19,498 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:19,845 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:20,846 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:21,499 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:21,847 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:22,848 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:23,499 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:23,849 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:24,850 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:25,500 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:25,851 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:25,852 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 22:56:26,853 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:27,500 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:27,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:28,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:29,500 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:29,857 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:30,858 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:31,501 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:31,859 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:32,860 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:33,501 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:33,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:34,862 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:35,502 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:35,863 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 22:56:35,865 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 22:56:35,870 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestContainerReplicationEndToEnd.init(TestContainerReplicationEndToEnd.java:110)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-24 22:56:35,876 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-24 22:56:35,877 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-24 22:56:35,877 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-24 22:56:35,877 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37757
2019-09-24 22:56:35,883 [IPC Server listener on 37757] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37757
2019-09-24 22:56:35,889 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-24 22:56:35,891 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 22:56:35,901 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-24 22:56:35,916 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-24 22:56:35,923 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4af46df3{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-24 22:56:35,930 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4158debd{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 22:56:35,930 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@963176{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-24 22:56:35,931 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a627c80{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 22:56:35,936 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-24 22:56:35,969 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 22:56:36,052 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 22:56:37,502 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:37,825 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd, PipelineID=fff0de51-527a-449d-979c-ae1f32beed35]
2019-09-24 22:56:37,826 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:56:37,831 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-24 22:56:37,833 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: fff0de51-527a-449d-979c-ae1f32beed35, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-24 22:56:37,833 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: fff0de51-527a-449d-979c-ae1f32beed35, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-09-24 22:56:37,925 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=fff0de51-527a-449d-979c-ae1f32beed35, PipelineID=615f9a82-b642-4e35-b02c-1b596adb384b]
2019-09-24 22:56:37,926 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: fff0de51-527a-449d-979c-ae1f32beed35, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-24 22:56:37,926 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 615f9a82-b642-4e35-b02c-1b596adb384b, Nodes: 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:56:37,926 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 615f9a82-b642-4e35-b02c-1b596adb384b, Nodes: 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-24 22:56:39,502 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:39,831 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-24 22:56:39,858 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: remove    LEADER 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD:t1, leader=09a241b9-b8d1-4472-89b0-8795fabd1640, voted=09a241b9-b8d1-4472-89b0-8795fabd1640, raftlog=09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129], old=null RUNNING
2019-09-24 22:56:39,862 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: shutdown
2019-09-24 22:56:39,863 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2A3A5D74A4DD,id=09a241b9-b8d1-4472-89b0-8795fabd1640
2019-09-24 22:56:39,863 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown LeaderState
2019-09-24 22:56:39,864 [grpc-default-executor-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 09a241b9-b8d1-4472-89b0-8795fabd1640-PendingRequests: sendNotLeaderResponses
2019-09-24 22:56:39,867 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:39,869 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD: closes. applyIndex: 0
2019-09-24 22:56:39,872 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:39,874 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-2A3A5D74A4DD-SegmentedRaftLogWorker close()
2019-09-24 22:56:39,893 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: 97d5872a-ae1c-4f2a-af5d-2a3a5d74a4dd, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-24 22:56:39,894 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: fff0de51-527a-449d-979c-ae1f32beed35, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-24 22:56:39,907 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: remove  FOLLOWER 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35:t1, leader=37866424-2e21-4e75-b95a-a562e1eae4e3, voted=09a241b9-b8d1-4472-89b0-8795fabd1640, raftlog=09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null RUNNING
2019-09-24 22:56:39,907 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: shutdown
2019-09-24 22:56:39,908 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE1F32BEED35,id=09a241b9-b8d1-4472-89b0-8795fabd1640
2019-09-24 22:56:39,908 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown FollowerState
2019-09-24 22:56:39,908 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:39,908 [Thread-235] INFO  impl.FollowerState (FollowerState.java:run(115)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 22:56:39,911 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35: closes. applyIndex: 0
2019-09-24 22:56:39,912 [09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:39,913 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 09a241b9-b8d1-4472-89b0-8795fabd1640@group-AE1F32BEED35-SegmentedRaftLogWorker close()
2019-09-24 22:56:39,935 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: remove  FOLLOWER 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35:t1, leader=37866424-2e21-4e75-b95a-a562e1eae4e3, voted=37866424-2e21-4e75-b95a-a562e1eae4e3, raftlog=9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null RUNNING
2019-09-24 22:56:39,935 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: shutdown
2019-09-24 22:56:39,935 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE1F32BEED35,id=9d5442d4-ee95-4410-8c78-fbec62863c16
2019-09-24 22:56:39,935 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown FollowerState
2019-09-24 22:56:39,936 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:39,936 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(115)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 22:56:39,939 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35: closes. applyIndex: 0
2019-09-24 22:56:39,939 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:39,940 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-AE1F32BEED35-SegmentedRaftLogWorker close()
2019-09-24 22:56:39,961 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: remove    LEADER 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35:t1, leader=37866424-2e21-4e75-b95a-a562e1eae4e3, voted=37866424-2e21-4e75-b95a-a562e1eae4e3, raftlog=37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [09a241b9-b8d1-4472-89b0-8795fabd1640:192.168.151.66:46129, 37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788, 9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null RUNNING
2019-09-24 22:56:39,962 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: shutdown
2019-09-24 22:56:39,962 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AE1F32BEED35,id=37866424-2e21-4e75-b95a-a562e1eae4e3
2019-09-24 22:56:39,962 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown LeaderState
2019-09-24 22:56:39,965 [grpc-default-executor-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 37866424-2e21-4e75-b95a-a562e1eae4e3-PendingRequests: sendNotLeaderResponses
2019-09-24 22:56:39,965 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$400/1026146011@158a49f2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35->09a241b9-b8d1-4472-89b0-8795fabd1640-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 22:56:39,968 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:39,965 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$400/1026146011@69238074] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35->9d5442d4-ee95-4410-8c78-fbec62863c16-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 22:56:39,970 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35: closes. applyIndex: 0
2019-09-24 22:56:39,972 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:39,975 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35-SegmentedRaftLogWorker close()
2019-09-24 22:56:39,980 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: Completed APPEND_ENTRIES, lastRequest: 37866424-2e21-4e75-b95a-a562e1eae4e3->09a241b9-b8d1-4472-89b0-8795fabd1640#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 22:56:39,980 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: Completed APPEND_ENTRIES, lastRequest: 37866424-2e21-4e75-b95a-a562e1eae4e3->9d5442d4-ee95-4410-8c78-fbec62863c16#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 22:56:39,983 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35->09a241b9-b8d1-4472-89b0-8795fabd1640-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-24 22:56:39,983 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35->9d5442d4-ee95-4410-8c78-fbec62863c16-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-24 22:56:39,994 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35->9d5442d4-ee95-4410-8c78-fbec62863c16: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 22:56:39,996 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: fff0de51-527a-449d-979c-ae1f32beed35, Nodes: 09a241b9-b8d1-4472-89b0-8795fabd1640{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] removed from db
2019-09-24 22:56:39,994 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-AE1F32BEED35->09a241b9-b8d1-4472-89b0-8795fabd1640: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 22:56:39,997 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 615f9a82-b642-4e35-b02c-1b596adb384b, Nodes: 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-24 22:56:40,011 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: remove    LEADER 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B:t1, leader=9d5442d4-ee95-4410-8c78-fbec62863c16, voted=9d5442d4-ee95-4410-8c78-fbec62863c16, raftlog=9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [9d5442d4-ee95-4410-8c78-fbec62863c16:192.168.151.66:39424], old=null RUNNING
2019-09-24 22:56:40,011 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: shutdown
2019-09-24 22:56:40,011 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1B596ADB384B,id=9d5442d4-ee95-4410-8c78-fbec62863c16
2019-09-24 22:56:40,011 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown LeaderState
2019-09-24 22:56:40,012 [grpc-default-executor-3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 9d5442d4-ee95-4410-8c78-fbec62863c16-PendingRequests: sendNotLeaderResponses
2019-09-24 22:56:40,013 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:40,016 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B: closes. applyIndex: 0
2019-09-24 22:56:40,016 [9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:40,018 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 9d5442d4-ee95-4410-8c78-fbec62863c16@group-1B596ADB384B-SegmentedRaftLogWorker close()
2019-09-24 22:56:40,027 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: 615f9a82-b642-4e35-b02c-1b596adb384b, Nodes: 9d5442d4-ee95-4410-8c78-fbec62863c16{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-24 22:56:40,368 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 22:56:40,369 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: close
2019-09-24 22:56:40,372 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown server with port 39424 now
2019-09-24 22:56:40,379 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 9d5442d4-ee95-4410-8c78-fbec62863c16: shutdown server with port 39424 successfully
2019-09-24 22:56:40,382 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 22:56:40,404 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 22:56:40,409 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 22:56:40,410 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12e0f1cb{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 22:56:40,411 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a163575{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 22:56:40,411 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@36681447{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 22:56:40,412 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77b919a3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 22:56:40,566 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 22:56:40,938 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 22:56:40,939 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: close
2019-09-24 22:56:40,940 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown server with port 46129 now
2019-09-24 22:56:40,943 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 09a241b9-b8d1-4472-89b0-8795fabd1640: shutdown server with port 46129 successfully
2019-09-24 22:56:40,956 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 22:56:40,981 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 22:56:40,985 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 22:56:40,989 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7bc44ce8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 22:56:40,990 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 22:56:40,991 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 22:56:40,993 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 22:56:41,167 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 22:56:41,505 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:42,433 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=e7edc268-b035-4203-956f-592e6245275c]
2019-09-24 22:56:42,433 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: e7edc268-b035-4203-956f-592e6245275c, Nodes: 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:56:42,433 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: e7edc268-b035-4203-956f-592e6245275c, Nodes: 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-24 22:56:43,034 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=a68ccee6-5887-4d6d-9d2d-f129c625b686]
2019-09-24 22:56:43,034 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: a68ccee6-5887-4d6d-9d2d-f129c625b686, Nodes: e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 22:56:43,034 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: a68ccee6-5887-4d6d-9d2d-f129c625b686, Nodes: e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-24 22:56:43,506 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:44,436 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: e7edc268-b035-4203-956f-592e6245275c, Nodes: 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-24 22:56:44,450 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: remove    LEADER 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C:t1, leader=37866424-2e21-4e75-b95a-a562e1eae4e3, voted=37866424-2e21-4e75-b95a-a562e1eae4e3, raftlog=37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [37866424-2e21-4e75-b95a-a562e1eae4e3:192.168.151.66:32788], old=null RUNNING
2019-09-24 22:56:44,450 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: shutdown
2019-09-24 22:56:44,450 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-592E6245275C,id=37866424-2e21-4e75-b95a-a562e1eae4e3
2019-09-24 22:56:44,450 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown LeaderState
2019-09-24 22:56:44,451 [grpc-default-executor-3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 37866424-2e21-4e75-b95a-a562e1eae4e3-PendingRequests: sendNotLeaderResponses
2019-09-24 22:56:44,452 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:44,454 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C: closes. applyIndex: 0
2019-09-24 22:56:44,454 [37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:44,456 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 37866424-2e21-4e75-b95a-a562e1eae4e3@group-592E6245275C-SegmentedRaftLogWorker close()
2019-09-24 22:56:44,469 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: e7edc268-b035-4203-956f-592e6245275c, Nodes: 37866424-2e21-4e75-b95a-a562e1eae4e3{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-24 22:56:45,037 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: a68ccee6-5887-4d6d-9d2d-f129c625b686, Nodes: e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-24 22:56:45,050 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: remove    LEADER e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686:t1, leader=e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf, voted=e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf, raftlog=e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf:192.168.151.66:43692], old=null RUNNING
2019-09-24 22:56:45,051 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: shutdown
2019-09-24 22:56:45,051 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F129C625B686,id=e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf
2019-09-24 22:56:45,052 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: shutdown LeaderState
2019-09-24 22:56:45,052 [grpc-default-executor-3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf-PendingRequests: sendNotLeaderResponses
2019-09-24 22:56:45,053 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-StateMachineUpdater: set stopIndex = 0
2019-09-24 22:56:45,054 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686: closes. applyIndex: 0
2019-09-24 22:56:45,055 [e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 22:56:45,056 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf@group-F129C625B686-SegmentedRaftLogWorker close()
2019-09-24 22:56:45,067 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: a68ccee6-5887-4d6d-9d2d-f129c625b686, Nodes: e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-24 22:56:45,413 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 22:56:45,414 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: close
2019-09-24 22:56:45,415 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown server with port 32788 now
2019-09-24 22:56:45,415 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 37866424-2e21-4e75-b95a-a562e1eae4e3: shutdown server with port 32788 successfully
2019-09-24 22:56:45,417 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 22:56:45,438 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 22:56:45,442 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 22:56:45,443 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@437486cd{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 22:56:45,444 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15b642b9{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 22:56:45,445 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e7c141d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 22:56:45,445 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@378cfecf{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 22:56:45,506 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 22:56:45,994 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 22:56:45,996 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: close
2019-09-24 22:56:45,996 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: shutdown server with port 43692 now
2019-09-24 22:56:45,998 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - e5a9a54f-d1a0-45e7-8f4f-d5625ac88bbf: shutdown server with port 43692 successfully
2019-09-24 22:56:46,002 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f1e77b2f-0d0c-4b94-9bca-fcbc5d1dd781/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 22:56:46,020 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 22:56:46,023 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 22:56:46,026 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a66e580{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 22:56:46,027 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b852b49{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 22:56:46,028 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ff35a3f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 22:56:46,029 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d1dcdff{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 22:56:46,030 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-24 22:56:46,031 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-24 22:56:46,031 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-24 22:56:46,031 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-24 22:56:46,031 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-24 22:56:46,032 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-24 22:56:46,032 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39763
2019-09-24 22:56:46,034 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 22:56:46,034 [IPC Server listener on 39763] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39763
2019-09-24 22:56:46,038 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-24 22:56:46,039 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-24 22:56:46,039 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-24 22:56:46,039 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45302
2019-09-24 22:56:46,042 [IPC Server listener on 45302] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45302
2019-09-24 22:56:46,042 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-24 22:56:46,042 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 22:56:46,042 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-24 22:56:46,042 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42768
2019-09-24 22:56:46,045 [IPC Server listener on 42768] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42768
2019-09-24 22:56:46,045 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-24 22:56:46,045 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 22:56:46,046 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6928f576{/,null,UNAVAILABLE}{/scm}
2019-09-24 22:56:46,047 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@548e76f1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 22:56:46,047 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e821657{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-24 22:56:46,047 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b00f608{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 22:56:46,048 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-24 22:56:46,049 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 22:56:46,049 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 22:56:46,050 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-24 22:56:46,058 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-24 22:56:46,066 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-24 22:56:46,066 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
]]></system-err>
  </testcase>
</testsuite>